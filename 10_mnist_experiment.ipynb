{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b81bf40-bd03-4910-bd8d-4768b6150d34",
   "metadata": {},
   "source": [
    "# [Neural CDE](https://docs.kidger.site/diffrax/examples/neural_cde/)\n",
    "Neural CDE は次のような式で表現されるモデルである。\n",
    "\n",
    "$$y(t) = y(0) + \\int_0^t f_\\theta(y(s)) \\frac{\\mathrm{d}x}{\\mathrm{d}s}(s) \\mathrm{d}s$$\n",
    "\n",
    "ここでは、 Neural CDE を用いて時計回りの渦と、反時計回りの渦の分類を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6d07437-f38a-4448-91f6-05d19c5633f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/pydantic/_internal/_model_construction.py:54: UserWarning: `validate_input_format` overrides an existing Pydantic `@field_validator` decorator\n",
      "  warnings.warn(f'`{k}` overrides an existing Pydantic `{existing.decorator_info.decorator_repr}` decorator')\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import gc\n",
    "from typing import Sequence, Tuple, Union, Callable, Optional\n",
    "\n",
    "import jax\n",
    "import jax.random as jr\n",
    "from jaxtyping import Array, Float, PRNGKeyArray\n",
    "import optax  # https://github.com/deepmind/optax\n",
    "import equinox as eqx\n",
    "from memray import Tracker\n",
    "\n",
    "from tools._dataset.datasets import MNISTStrokeDataset\n",
    "from tools._dataset.dataloader import dataloader_ununiformed_sequence\n",
    "from tools._model.neural_cde import NeuralCDE\n",
    "from tools._model.discrete_cde import RNN\n",
    "from tools._loss.cross_entropy import bce_loss, nll_loss\n",
    "from tools.config import ExperimentConfig\n",
    "from tools._train.update import Trainer, run_train\n",
    "from tools._eval.evaluation import run_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3d845f-2bba-4617-add9-1ce7ac97a85d",
   "metadata": {},
   "source": [
    "# Train and Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43cb3a69-ed28-4fa0-ab69-338841a3a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(\n",
    "    *,\n",
    "    dataset_size_train: int,\n",
    "    dataset_size_test: int,\n",
    "    noise_ratio: float,\n",
    "    input_format: str,\n",
    "    interpolation: str,\n",
    "    neural_model_name: str,\n",
    "    out_size: int,\n",
    "    hidden_size: int,\n",
    "    width_size: int,\n",
    "    depth: int,\n",
    "    batch_size: int,\n",
    "    lr: float,\n",
    "    steps: int,\n",
    "    seed: int,\n",
    "    output_model_path: str,\n",
    ") -> Tuple[float, float, float]:\n",
    "    key = jr.PRNGKey(seed)\n",
    "    train_data_key, test_data_key, train_model_key, test_model_key, train_run_key, test_run_key = jr.split(key, 6)\n",
    "    experiment_result = {}\n",
    "\n",
    "    # Load the train dataset\n",
    "    dataset = MNISTStrokeDataset(dataset_size=dataset_size_train, mode_train=True, input_format=input_format, noise_ratio=noise_ratio, interpolation=interpolation, key=train_data_key)\n",
    "    ts, _, coeffs, labels, in_size = dataset.make_dataset()\n",
    "\n",
    "    # Initialize the model\n",
    "    if neural_model_name == 'NeuralCDE':\n",
    "        Model = NeuralCDE\n",
    "    elif neural_model_name == 'RNN':\n",
    "        Model = RNN\n",
    "    model = Model(in_size, out_size, hidden_size, width_size, depth, interpolation=interpolation, key=train_model_key)\n",
    "\n",
    "    # Choice loss function\n",
    "    if out_size == 2:\n",
    "        loss_func = bce_loss\n",
    "    elif out_size > 2:\n",
    "        loss_func = nll_loss\n",
    "    else:\n",
    "        raise ValueError(f'The `out_size` must be greater than or equal to 2. But now {out_size}')\n",
    "\n",
    "    # Training\n",
    "    model, train_time_avg = run_train(steps, batch_size, (ts, *coeffs, labels), model, loss_func, optax.adam(lr), out_size, key=train_run_key)\n",
    "    experiment_result['train_time_avg'] = float(train_time_avg)\n",
    "\n",
    "    # Save the model\n",
    "    eqx.tree_serialise_leaves(output_model_path, model)\n",
    "\n",
    "    # Clear caches\n",
    "    del model, dataset, ts, coeffs, labels\n",
    "    eqx.clear_caches()\n",
    "    jax.clear_caches()\n",
    "    gc.collect()\n",
    "    \n",
    "    # Load the test dataset\n",
    "    dataset = MNISTStrokeDataset(dataset_size=dataset_size_test, mode_train=False, input_format=input_format, noise_ratio=noise_ratio, interpolation=interpolation, key=test_data_key)\n",
    "    ts, _, coeffs, labels, _ = dataset.make_dataset()\n",
    "\n",
    "    # Load the trained model\n",
    "    model = eqx.filter_eval_shape(Model, in_size, out_size, hidden_size, width_size, depth, interpolation=interpolation, key=test_model_key)\n",
    "    model = eqx.tree_deserialise_leaves(output_model_path, model)\n",
    "\n",
    "    # Evaluation\n",
    "    test_loss_avg, test_acc_avg, test_time_avg = run_eval((ts, *coeffs, labels), model, loss_func, out_size, key=test_run_key)\n",
    "    experiment_result['test_loss_avg'] = float(test_loss_avg)\n",
    "    experiment_result['test_acc_avg'] = float(test_acc_avg)\n",
    "    experiment_result['test_time_avg'] = float(test_time_avg)\n",
    "    \n",
    "    return experiment_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f20eda4c-fd1a-4a2e-a3f0-91c5ba98ec0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    eqx.clear_caches()\n",
    "    jax.clear_caches()\n",
    "    gc.collect()\n",
    "    \n",
    "    config = ExperimentConfig()\n",
    "    \n",
    "    config.steps = 10000\n",
    "    config.dataset_size_train = -1\n",
    "    config.dataset_size_test = -1\n",
    "    \n",
    "    config.noise_ratio = 0.75\n",
    "    config.neural_model_name = 'NeuralCDE'\n",
    "    \n",
    "    date = datetime.datetime.now().strftime('%Y年%m月%d日-%H:%M:%S')\n",
    "    config.output_model_name = f'/{config.neural_model_name}-{date}'\n",
    "\n",
    "    include_fields = [key for key in config.model_dump() if not 'output_' in key] + ['output_model_path',]\n",
    "    experiment_condition = config.model_dump(include={*include_fields})\n",
    "    with Tracker(config.output_memray_path):\n",
    "        experiment_result = experiment(**experiment_condition)\n",
    "\n",
    "    with open(config.output_config_path, \"w\") as o:\n",
    "        print(config.model_dump_json(indent=4), file=o)\n",
    "\n",
    "    experiment_result['date'] = date\n",
    "    experiment_result['neural_model_name'] = config.neural_model_name\n",
    "    experiment_result['interpolation'] = config.interpolation\n",
    "    experiment_result['noise_ratio'] = config.noise_ratio\n",
    "\n",
    "    with open(config.output_result_path, mode=\"w\", encoding=\"utf-8\") as o:\n",
    "        json.dump(experiment_result, o, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a3a169e-f7c7-476b-9727-f7666bbf30da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60000/60000 [1:07:11<00:00, 14.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Loss: 10.188117980957031, Accuracy: 0.0625, Computation time: 4.353410005569458\n",
      "Step: 1, Loss: 7.19356107711792, Accuracy: 0.0, Computation time: 4.817702770233154\n",
      "Step: 2, Loss: 3.3303074836730957, Accuracy: 0.0625, Computation time: 4.23955512046814\n",
      "Step: 3, Loss: 3.830678701400757, Accuracy: 0.21875, Computation time: 4.750100135803223\n",
      "Step: 4, Loss: 3.833340883255005, Accuracy: 0.09375, Computation time: 0.566748857498169\n",
      "Step: 5, Loss: 3.784780263900757, Accuracy: 0.09375, Computation time: 4.225117206573486\n",
      "Step: 6, Loss: 3.485246181488037, Accuracy: 0.0625, Computation time: 4.745680809020996\n",
      "Step: 7, Loss: 4.207230567932129, Accuracy: 0.0625, Computation time: 0.448012113571167\n",
      "Step: 8, Loss: 3.5348446369171143, Accuracy: 0.15625, Computation time: 4.707114934921265\n",
      "Step: 9, Loss: 2.786353826522827, Accuracy: 0.0625, Computation time: 0.44878268241882324\n",
      "Step: 10, Loss: 2.901895761489868, Accuracy: 0.15625, Computation time: 4.876110076904297\n",
      "Step: 11, Loss: 3.0823845863342285, Accuracy: 0.28125, Computation time: 0.4749150276184082\n",
      "Step: 12, Loss: 2.54790997505188, Accuracy: 0.21875, Computation time: 0.4837369918823242\n",
      "Step: 13, Loss: 3.674837112426758, Accuracy: 0.03125, Computation time: 4.467887878417969\n",
      "Step: 14, Loss: 3.1936380863189697, Accuracy: 0.09375, Computation time: 4.2549169063568115\n",
      "Step: 15, Loss: 3.2017416954040527, Accuracy: 0.125, Computation time: 4.957900047302246\n",
      "Step: 16, Loss: 2.4673335552215576, Accuracy: 0.0625, Computation time: 4.755933046340942\n",
      "Step: 17, Loss: 2.869044542312622, Accuracy: 0.09375, Computation time: 0.4241831302642822\n",
      "Step: 18, Loss: 3.218916654586792, Accuracy: 0.15625, Computation time: 0.4834330081939697\n",
      "Step: 19, Loss: 3.4397342205047607, Accuracy: 0.21875, Computation time: 0.5122370719909668\n",
      "Step: 20, Loss: 2.5563440322875977, Accuracy: 0.21875, Computation time: 0.6849970817565918\n",
      "Step: 21, Loss: 2.4863502979278564, Accuracy: 0.09375, Computation time: 0.46341395378112793\n",
      "Step: 22, Loss: 3.1218457221984863, Accuracy: 0.03125, Computation time: 0.47468113899230957\n",
      "Step: 23, Loss: 3.1965622901916504, Accuracy: 0.09375, Computation time: 4.193242788314819\n",
      "Step: 24, Loss: 2.4299049377441406, Accuracy: 0.09375, Computation time: 4.30193305015564\n",
      "Step: 25, Loss: 2.8726046085357666, Accuracy: 0.1875, Computation time: 0.7015318870544434\n",
      "Step: 26, Loss: 2.8312599658966064, Accuracy: 0.125, Computation time: 0.6305532455444336\n",
      "Step: 27, Loss: 2.903416156768799, Accuracy: 0.1875, Computation time: 5.069088935852051\n",
      "Step: 28, Loss: 2.8826842308044434, Accuracy: 0.09375, Computation time: 0.5864830017089844\n",
      "Step: 29, Loss: 2.6123878955841064, Accuracy: 0.0625, Computation time: 0.5294859409332275\n",
      "Step: 30, Loss: 2.6781861782073975, Accuracy: 0.1875, Computation time: 0.5226080417633057\n",
      "Step: 31, Loss: 2.5362744331359863, Accuracy: 0.0625, Computation time: 0.6314902305603027\n",
      "Step: 32, Loss: 2.4641692638397217, Accuracy: 0.15625, Computation time: 0.5258948802947998\n",
      "Step: 33, Loss: 2.2100491523742676, Accuracy: 0.21875, Computation time: 0.6134250164031982\n",
      "Step: 34, Loss: 2.807807445526123, Accuracy: 0.0625, Computation time: 0.6015691757202148\n",
      "Step: 35, Loss: 2.7400355339050293, Accuracy: 0.09375, Computation time: 0.6129841804504395\n",
      "Step: 36, Loss: 2.8149330615997314, Accuracy: 0.1875, Computation time: 0.6618680953979492\n",
      "Step: 37, Loss: 2.424790143966675, Accuracy: 0.125, Computation time: 0.5107378959655762\n",
      "Step: 38, Loss: 2.445173740386963, Accuracy: 0.0625, Computation time: 4.286112070083618\n",
      "Step: 39, Loss: 2.2044291496276855, Accuracy: 0.25, Computation time: 0.5600948333740234\n",
      "Step: 40, Loss: 2.495933771133423, Accuracy: 0.125, Computation time: 4.332087993621826\n",
      "Step: 41, Loss: 2.6189441680908203, Accuracy: 0.0625, Computation time: 0.5028018951416016\n",
      "Step: 42, Loss: 2.575408697128296, Accuracy: 0.1875, Computation time: 5.319056749343872\n",
      "Step: 43, Loss: 2.7533352375030518, Accuracy: 0.09375, Computation time: 0.506005048751831\n",
      "Step: 44, Loss: 2.5826704502105713, Accuracy: 0.09375, Computation time: 4.797489166259766\n",
      "Step: 45, Loss: 2.48530912399292, Accuracy: 0.21875, Computation time: 0.6416082382202148\n",
      "Step: 46, Loss: 2.1941275596618652, Accuracy: 0.1875, Computation time: 4.281176805496216\n",
      "Step: 47, Loss: 2.5492613315582275, Accuracy: 0.09375, Computation time: 0.5866687297821045\n",
      "Step: 48, Loss: 2.4674770832061768, Accuracy: 0.0625, Computation time: 4.759363174438477\n",
      "Step: 49, Loss: 2.1802945137023926, Accuracy: 0.21875, Computation time: 0.5653939247131348\n",
      "Step: 50, Loss: 2.3548762798309326, Accuracy: 0.21875, Computation time: 0.4745798110961914\n",
      "Step: 51, Loss: 2.535508871078491, Accuracy: 0.1875, Computation time: 0.6614601612091064\n",
      "Step: 52, Loss: 2.455400228500366, Accuracy: 0.15625, Computation time: 0.6107258796691895\n",
      "Step: 53, Loss: 2.34487247467041, Accuracy: 0.09375, Computation time: 0.4454658031463623\n",
      "Step: 54, Loss: 2.234849214553833, Accuracy: 0.125, Computation time: 0.5183737277984619\n",
      "Step: 55, Loss: 2.213285446166992, Accuracy: 0.21875, Computation time: 1005.9015159606934\n",
      "Step: 56, Loss: 2.615241050720215, Accuracy: 0.09375, Computation time: 0.5102558135986328\n",
      "Step: 57, Loss: 2.155893325805664, Accuracy: 0.28125, Computation time: 0.5505111217498779\n",
      "Step: 58, Loss: 2.672795534133911, Accuracy: 0.15625, Computation time: 0.6546108722686768\n",
      "Step: 59, Loss: 2.4120841026306152, Accuracy: 0.1875, Computation time: 0.5197861194610596\n",
      "Step: 60, Loss: 2.221853256225586, Accuracy: 0.1875, Computation time: 0.6984190940856934\n",
      "Step: 61, Loss: 2.467503547668457, Accuracy: 0.15625, Computation time: 0.5273330211639404\n",
      "Step: 62, Loss: 2.2891430854797363, Accuracy: 0.0625, Computation time: 0.551231861114502\n",
      "Step: 63, Loss: 2.363312244415283, Accuracy: 0.125, Computation time: 0.5249080657958984\n",
      "Step: 64, Loss: 2.36750864982605, Accuracy: 0.21875, Computation time: 0.537959098815918\n",
      "Step: 65, Loss: 2.4772558212280273, Accuracy: 0.125, Computation time: 0.49138736724853516\n",
      "Step: 66, Loss: 2.4463486671447754, Accuracy: 0.21875, Computation time: 0.505836009979248\n",
      "Step: 67, Loss: 2.1501245498657227, Accuracy: 0.28125, Computation time: 0.4643740653991699\n",
      "Step: 68, Loss: 2.160104751586914, Accuracy: 0.28125, Computation time: 0.6597192287445068\n",
      "Step: 69, Loss: 2.453195810317993, Accuracy: 0.125, Computation time: 0.4193108081817627\n",
      "Step: 70, Loss: 2.152254104614258, Accuracy: 0.1875, Computation time: 0.5187852382659912\n",
      "Step: 71, Loss: 2.4267330169677734, Accuracy: 0.25, Computation time: 0.49090576171875\n",
      "Step: 72, Loss: 2.270303249359131, Accuracy: 0.15625, Computation time: 0.4843566417694092\n",
      "Step: 73, Loss: 2.2223522663116455, Accuracy: 0.21875, Computation time: 5.180656909942627\n",
      "Step: 74, Loss: 2.095323324203491, Accuracy: 0.15625, Computation time: 0.5923209190368652\n",
      "Step: 75, Loss: 1.9420807361602783, Accuracy: 0.28125, Computation time: 0.48952770233154297\n",
      "Step: 76, Loss: 2.352400541305542, Accuracy: 0.25, Computation time: 0.625514030456543\n",
      "Step: 77, Loss: 2.360496997833252, Accuracy: 0.09375, Computation time: 0.5332121849060059\n",
      "Step: 78, Loss: 2.355797290802002, Accuracy: 0.09375, Computation time: 1.0123801231384277\n",
      "Step: 79, Loss: 2.391104221343994, Accuracy: 0.34375, Computation time: 4.289679050445557\n",
      "Step: 80, Loss: 2.025893449783325, Accuracy: 0.21875, Computation time: 0.5059702396392822\n",
      "Step: 81, Loss: 2.2053048610687256, Accuracy: 0.21875, Computation time: 0.4435408115386963\n",
      "Step: 82, Loss: 3.1771059036254883, Accuracy: 0.125, Computation time: 0.5391442775726318\n",
      "Step: 83, Loss: 1.9114857912063599, Accuracy: 0.375, Computation time: 0.5018908977508545\n",
      "Step: 84, Loss: 2.4004929065704346, Accuracy: 0.15625, Computation time: 4.191723108291626\n",
      "Step: 85, Loss: 2.486612319946289, Accuracy: 0.21875, Computation time: 0.5201921463012695\n",
      "Step: 86, Loss: 2.210573434829712, Accuracy: 0.1875, Computation time: 0.5876359939575195\n",
      "Step: 87, Loss: 2.363830089569092, Accuracy: 0.25, Computation time: 0.4806251525878906\n",
      "Step: 88, Loss: 2.195565938949585, Accuracy: 0.21875, Computation time: 0.544929027557373\n",
      "Step: 89, Loss: 2.1534416675567627, Accuracy: 0.1875, Computation time: 4.1514201164245605\n",
      "Step: 90, Loss: 2.224761486053467, Accuracy: 0.1875, Computation time: 0.5233750343322754\n",
      "Step: 91, Loss: 2.1787946224212646, Accuracy: 0.21875, Computation time: 0.42641425132751465\n",
      "Step: 92, Loss: 2.0800938606262207, Accuracy: 0.21875, Computation time: 0.4893028736114502\n",
      "Step: 93, Loss: 2.4681153297424316, Accuracy: 0.15625, Computation time: 0.5881998538970947\n",
      "Step: 94, Loss: 2.235474109649658, Accuracy: 0.25, Computation time: 0.416719913482666\n",
      "Step: 95, Loss: 1.8592417240142822, Accuracy: 0.28125, Computation time: 0.4199512004852295\n",
      "Step: 96, Loss: 2.1904501914978027, Accuracy: 0.15625, Computation time: 0.3559699058532715\n",
      "Step: 97, Loss: 2.0295674800872803, Accuracy: 0.34375, Computation time: 0.49129295349121094\n",
      "Step: 98, Loss: 2.037522315979004, Accuracy: 0.21875, Computation time: 0.576606035232544\n",
      "Step: 99, Loss: 2.1061201095581055, Accuracy: 0.21875, Computation time: 0.4425640106201172\n",
      "Step: 100, Loss: 2.4003612995147705, Accuracy: 0.09375, Computation time: 0.4246490001678467\n",
      "Step: 101, Loss: 2.1098432540893555, Accuracy: 0.25, Computation time: 4.57840895652771\n",
      "Step: 102, Loss: 2.043633222579956, Accuracy: 0.25, Computation time: 0.4908909797668457\n",
      "Step: 103, Loss: 2.0569145679473877, Accuracy: 0.1875, Computation time: 0.4614732265472412\n",
      "Step: 104, Loss: 2.1614019870758057, Accuracy: 0.125, Computation time: 0.4740931987762451\n",
      "Step: 105, Loss: 2.2623233795166016, Accuracy: 0.15625, Computation time: 0.5239732265472412\n",
      "Step: 106, Loss: 2.6206748485565186, Accuracy: 0.03125, Computation time: 0.4202439785003662\n",
      "Step: 107, Loss: 2.1374268531799316, Accuracy: 0.09375, Computation time: 0.5411820411682129\n",
      "Step: 108, Loss: 2.049614906311035, Accuracy: 0.21875, Computation time: 0.6134321689605713\n",
      "Step: 109, Loss: 2.1553046703338623, Accuracy: 0.1875, Computation time: 0.6180810928344727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "jax.pure_callback failed\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/jax/_src/callback.py\", line 77, in pure_callback_impl\n",
      "    return callback(*args)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/jax/_src/callback.py\", line 65, in __call__\n",
      "    return tree_util.tree_leaves(self.callback_func(*args, **kwargs))\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/equinox/_errors.py\", line 70, in raises\n",
      "    raise EqxRuntimeError(msgs[_index.item()])\n",
      "equinox._errors.EqxRuntimeError: The maximum number of solver steps was reached. Try increasing `max_steps`.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 13 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/jax/_src/interpreters/pxla.py:1205\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1204\u001b[0m input_bufs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_tokens_to_inputs(input_bufs)\n\u001b[0;32m-> 1205\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxla_executable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_sharded\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_bufs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m   1207\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1208\u001b[0m result_token_bufs \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mdisassemble_prefix_into_single_device_arrays(\n\u001b[1;32m   1209\u001b[0m     \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mordered_effects))\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: INTERNAL: Generated function failed: CpuCallback error: Traceback (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n  File \"/Users/tomoki.fujihara/.pyenv/versions/3.11.5/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n  File \"/Users/tomoki.fujihara/.pyenv/versions/3.11.5/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n  File \"/Users/tomoki.fujihara/.pyenv/versions/3.11.5/lib/python3.11/asyncio/events.py\", line 80, in _run\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n  File \"/var/folders/7f/qsyyp3lj4wqfx7nsyjvy6jfr0000gq/T/ipykernel_12074/451043146.py\", line 1, in <module>\n  File \"/var/folders/7f/qsyyp3lj4wqfx7nsyjvy6jfr0000gq/T/ipykernel_12074/2657884037.py\", line 21, in main\n  File \"/var/folders/7f/qsyyp3lj4wqfx7nsyjvy6jfr0000gq/T/ipykernel_12074/1792052327.py\", line 43, in experiment\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/tools/_train/update.py\", line 57, in run_train\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/equinox/_module.py\", line 1071, in __call__\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/equinox/_jit.py\", line 206, in __call__\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/equinox/_module.py\", line 935, in __call__\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/equinox/_jit.py\", line 200, in _call\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/jax/_src/traceback_util.py\", line 179, in reraise_with_filtered_traceback\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/jax/_src/pjit.py\", line 298, in cache_miss\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/jax/_src/pjit.py\", line 176, in _python_pjit_helper\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/jax/_src/core.py\", line 2788, in bind\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/jax/_src/core.py\", line 425, in bind_with_trace\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/jax/_src/core.py\", line 913, in process_primitive\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/jax/_src/pjit.py\", line 1488, in _pjit_call_impl\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/jax/_src/pjit.py\", line 1471, in call_impl_cache_miss\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/jax/_src/pjit.py\", line 1427, in _pjit_call_impl_python\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/jax/_src/profiler.py\", line 335, in wrapper\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/jax/_src/interpreters/pxla.py\", line 1205, in __call__\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/jax/_src/interpreters/mlir.py\", line 2466, in _wrapped_callback\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/jax/_src/callback.py\", line 219, in _callback\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/jax/_src/callback.py\", line 80, in pure_callback_impl\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/jax/_src/callback.py\", line 65, in __call__\n  File \"/Users/tomoki.fujihara/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/equinox/_errors.py\", line 70, in raises\nEqxRuntimeError: The maximum number of solver steps was reached. Try increasing `max_steps`.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 21\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m experiment_condition \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mmodel_dump(include\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m*\u001b[39minclude_fields})\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Tracker(config\u001b[38;5;241m.\u001b[39moutput_memray_path):\n\u001b[0;32m---> 21\u001b[0m     experiment_result \u001b[38;5;241m=\u001b[39m \u001b[43mexperiment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexperiment_condition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(config\u001b[38;5;241m.\u001b[39moutput_config_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m o:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(config\u001b[38;5;241m.\u001b[39mmodel_dump_json(indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m), file\u001b[38;5;241m=\u001b[39mo)\n",
      "Cell \u001b[0;32mIn[2], line 43\u001b[0m, in \u001b[0;36mexperiment\u001b[0;34m(dataset_size_train, dataset_size_test, noise_ratio, input_format, interpolation, neural_model_name, out_size, hidden_size, width_size, depth, batch_size, lr, steps, seed, output_model_path)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe `out_size` must be greater than or equal to 2. But now \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m model, train_time_avg \u001b[38;5;241m=\u001b[39m \u001b[43mrun_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcoeffs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_run_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m experiment_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_time_avg\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(train_time_avg)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/test_diffrax/test_diffrax/tools/_train/update.py:57\u001b[0m, in \u001b[0;36mrun_train\u001b[0;34m(steps, batch_size, data, model, loss_func, optimizer, key, *args)\u001b[0m\n\u001b[1;32m     55\u001b[0m train_step_key, _train_step_key \u001b[38;5;241m=\u001b[39m jr\u001b[38;5;241m.\u001b[39msplit(train_step_key, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     56\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 57\u001b[0m xe, acc, model, opt_state \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_train_step_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxe\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Computation time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/equinox/_module.py:1071\u001b[0m, in \u001b[0;36mPartial.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the wrapped `self.func`.\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \n\u001b[1;32m   1061\u001b[0m \u001b[38;5;124;03m    **Arguments:**\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;124;03m    The result of the wrapped function.\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1071\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeywords\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/test_diffrax/test_diffrax/.venv/lib/python3.11/site-packages/equinox/_jit.py:215\u001b[0m, in \u001b[0;36m_JitWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEqxRuntimeError: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m msg:\n\u001b[1;32m    214\u001b[0m     _, msg \u001b[38;5;241m=\u001b[39m msg\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEqxRuntimeError: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 215\u001b[0m     msg, _ \u001b[38;5;241m=\u001b[39m msg\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAt:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    216\u001b[0m     msg \u001b[38;5;241m=\u001b[39m msg \u001b[38;5;241m+\u001b[39m _eqx_on_error_msg\n\u001b[1;32m    217\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m (msg,)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61d1adc-1024-4119-ad69-05e8d4446a89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
