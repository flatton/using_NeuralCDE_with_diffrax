{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b81bf40-bd03-4910-bd8d-4768b6150d34",
   "metadata": {},
   "source": [
    "# [Neural CDE](https://docs.kidger.site/diffrax/examples/neural_cde/)\n",
    "Neural CDE は次のような式で表現されるモデルである。\n",
    "\n",
    "$$y(t) = y(0) + \\int_0^t f_\\theta(y(s)) \\frac{\\mathrm{d}x}{\\mathrm{d}s}(s) \\mathrm{d}s$$\n",
    "\n",
    "ここでは、 Neural CDE を用いて時計回りの渦と、反時計回りの渦の分類を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6d07437-f38a-4448-91f6-05d19c5633f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import gc\n",
    "from typing import Sequence, Tuple, Union, Callable, Optional\n",
    "\n",
    "import jax\n",
    "import jax.random as jr\n",
    "from jaxtyping import Array, Float, PRNGKeyArray\n",
    "import optax  # https://github.com/deepmind/optax\n",
    "import equinox as eqx\n",
    "from memray import Tracker\n",
    "\n",
    "from tools._dataset.datasets import MNISTStrokeDataset\n",
    "from tools._dataset.dataloader import dataloader_ununiformed_sequence\n",
    "from tools._model.neural_cde import NeuralCDE\n",
    "from tools._model.discrete_cde import RNN\n",
    "from tools._loss.cross_entropy import bce_loss, nll_loss\n",
    "from tools.config import ExperimentConfig\n",
    "from tools._train.update import Trainer, run_train\n",
    "from tools._eval.evaluation import run_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3d845f-2bba-4617-add9-1ce7ac97a85d",
   "metadata": {},
   "source": [
    "# Train and Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43cb3a69-ed28-4fa0-ab69-338841a3a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(\n",
    "    *,\n",
    "    dataset_size_train: int,\n",
    "    dataset_size_test: int,\n",
    "    noise_ratio: float,\n",
    "    input_format: str,\n",
    "    interpolation: str,\n",
    "    neural_model_name: str,\n",
    "    out_size: int,\n",
    "    hidden_size: int,\n",
    "    width_size: int,\n",
    "    depth: int,\n",
    "    batch_size: int,\n",
    "    lr: float,\n",
    "    steps: int,\n",
    "    seed: int,\n",
    "    output_model_path: str,\n",
    ") -> Tuple[float, float, float]:\n",
    "    key = jr.PRNGKey(seed)\n",
    "    train_data_key, test_data_key, train_model_key, test_model_key, train_run_key, test_run_key = jr.split(key, 6)\n",
    "    experiment_result = {}\n",
    "\n",
    "    # Load the train dataset\n",
    "    dataset = MNISTStrokeDataset(dataset_size=dataset_size_train, mode_train=True, input_format=input_format, noise_ratio=noise_ratio, interpolation=interpolation, key=train_data_key)\n",
    "    ts, _, coeffs, labels, in_size = dataset.make_dataset()\n",
    "\n",
    "    # Initialize the model\n",
    "    if neural_model_name == 'NeuralCDE':\n",
    "        Model = NeuralCDE\n",
    "    elif neural_model_name == 'RNN':\n",
    "        Model = RNN\n",
    "    model = Model(in_size, out_size, hidden_size, width_size, depth, interpolation=interpolation, key=train_model_key)\n",
    "\n",
    "    # Choice loss function\n",
    "    if out_size == 2:\n",
    "        loss_func = bce_loss\n",
    "    elif out_size > 2:\n",
    "        loss_func = nll_loss\n",
    "    else:\n",
    "        raise ValueError(f'The `out_size` must be greater than or equal to 2. But now {out_size}')\n",
    "\n",
    "    # Training\n",
    "    model, train_time_avg = run_train(steps, batch_size, (ts, *coeffs, labels), model, loss_func, optax.adam(lr), out_size, key=train_run_key)\n",
    "    experiment_result['train_time_avg'] = float(train_time_avg)\n",
    "\n",
    "    # Save the model\n",
    "    eqx.tree_serialise_leaves(output_model_path, model)\n",
    "\n",
    "    # Clear caches\n",
    "    del model, dataset, ts, coeffs, labels\n",
    "    eqx.clear_caches()\n",
    "    jax.clear_caches()\n",
    "    gc.collect()\n",
    "    \n",
    "    # Load the test dataset\n",
    "    dataset = MNISTStrokeDataset(dataset_size=dataset_size_test, mode_train=False, input_format=input_format, noise_ratio=noise_ratio, interpolation=interpolation, key=test_data_key)\n",
    "    ts, _, coeffs, labels, _ = dataset.make_dataset()\n",
    "\n",
    "    # Load the trained model\n",
    "    model = eqx.filter_eval_shape(Model, in_size, out_size, hidden_size, width_size, depth, interpolation=interpolation, key=test_model_key)\n",
    "    model = eqx.tree_deserialise_leaves(output_model_path, model)\n",
    "\n",
    "    # Evaluation\n",
    "    test_loss_avg, test_acc_avg, test_time_avg = run_eval((ts, *coeffs, labels), model, loss_func, out_size, key=test_run_key)\n",
    "    experiment_result['test_loss_avg'] = float(test_loss_avg)\n",
    "    experiment_result['test_acc_avg'] = float(test_acc_avg)\n",
    "    experiment_result['test_time_avg'] = float(test_time_avg)\n",
    "    \n",
    "    return experiment_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f20eda4c-fd1a-4a2e-a3f0-91c5ba98ec0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() -> None:\n",
    "    #%%memray_flamegraph\n",
    "    eqx.clear_caches()\n",
    "    jax.clear_caches()\n",
    "    gc.collect()\n",
    "    \n",
    "    config = ExperimentConfig()\n",
    "    \n",
    "    config.steps = 10000\n",
    "    config.dataset_size_train = -1\n",
    "    config.dataset_size_test = -1\n",
    "    \n",
    "    config.noise_ratio = 0.5\n",
    "    config.neural_model_name = 'NeuralCDE'\n",
    "    \n",
    "    date = datetime.datetime.now().strftime('%Y年%m月%d日-%H:%M:%S')\n",
    "    config.output_model_name = f'/{config.neural_model_name}-{date}'\n",
    "\n",
    "    include_fields = [key for key in config.model_dump() if not 'output_' in key] + ['output_model_path',]\n",
    "    experiment_condition = config.model_dump(include={*include_fields})\n",
    "    with Tracker(config.output_memray_path):\n",
    "        experiment_result = experiment(**experiment_condition)\n",
    "\n",
    "    with open(config.output_config_path, \"w\") as o:\n",
    "        print(config.model_dump_json(indent=4), file=o)\n",
    "\n",
    "    experiment_result['date'] = date\n",
    "    experiment_result['neural_model_name'] = config.neural_model_name\n",
    "    experiment_result['interpolation'] = config.interpolation\n",
    "    experiment_result['noise_ratio'] = config.noise_ratio\n",
    "\n",
    "    with open(config.output_result_path, mode=\"w\", encoding=\"utf-8\") as o:\n",
    "        json.dump(experiment_result, o, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a3a169e-f7c7-476b-9727-f7666bbf30da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                              | 48/60000 [00:10<2:24:18,  6.92it/s]2024-05-06 12:37:05.711014: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 15m49.192389s\n",
      "\n",
      "********************************\n",
      "[Compiling module jit__shuffle] Very slow compile? If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "********************************\n",
      "100%|███████████████████████████████████████████████████████████| 60000/60000 [3:07:10<00:00,  5.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Loss: 8.166421890258789, Accuracy: 0.09375, Computation time: 4.532424211502075\n",
      "Step: 1, Loss: 6.043856620788574, Accuracy: 0.125, Computation time: 4.851641893386841\n",
      "Step: 2, Loss: 2.9999325275421143, Accuracy: 0.125, Computation time: 4.959268093109131\n",
      "Step: 3, Loss: 3.5801517963409424, Accuracy: 0.15625, Computation time: 4.858425140380859\n",
      "Step: 4, Loss: 3.2347958087921143, Accuracy: 0.25, Computation time: 0.8257510662078857\n",
      "Step: 5, Loss: 3.60296630859375, Accuracy: 0.125, Computation time: 5.070477724075317\n",
      "Step: 6, Loss: 2.9986965656280518, Accuracy: 0.125, Computation time: 4.378866910934448\n",
      "Step: 7, Loss: 3.673431634902954, Accuracy: 0.0625, Computation time: 0.5008561611175537\n",
      "Step: 8, Loss: 3.1192572116851807, Accuracy: 0.125, Computation time: 4.413270711898804\n",
      "Step: 9, Loss: 3.1442630290985107, Accuracy: 0.03125, Computation time: 0.5458641052246094\n",
      "Step: 10, Loss: 3.2677061557769775, Accuracy: 0.09375, Computation time: 5.133293151855469\n",
      "Step: 11, Loss: 2.4693684577941895, Accuracy: 0.1875, Computation time: 0.5536432266235352\n",
      "Step: 12, Loss: 2.453479528427124, Accuracy: 0.09375, Computation time: 0.6301929950714111\n",
      "Step: 13, Loss: 3.167731285095215, Accuracy: 0.03125, Computation time: 5.071233034133911\n",
      "Step: 14, Loss: 2.680006742477417, Accuracy: 0.0625, Computation time: 4.494820833206177\n",
      "Step: 15, Loss: 2.7863590717315674, Accuracy: 0.25, Computation time: 5.191136598587036\n",
      "Step: 16, Loss: 2.341348171234131, Accuracy: 0.3125, Computation time: 4.48941707611084\n",
      "Step: 17, Loss: 2.8745315074920654, Accuracy: 0.15625, Computation time: 0.7622301578521729\n",
      "Step: 18, Loss: 2.6981077194213867, Accuracy: 0.1875, Computation time: 0.6166689395904541\n",
      "Step: 19, Loss: 2.3193306922912598, Accuracy: 0.25, Computation time: 0.6555032730102539\n",
      "Step: 20, Loss: 2.3392152786254883, Accuracy: 0.09375, Computation time: 0.5930171012878418\n",
      "Step: 21, Loss: 2.402003288269043, Accuracy: 0.1875, Computation time: 0.8353800773620605\n",
      "Step: 22, Loss: 2.6354494094848633, Accuracy: 0.125, Computation time: 0.6043870449066162\n",
      "Step: 23, Loss: 2.29480242729187, Accuracy: 0.1875, Computation time: 5.164947986602783\n",
      "Step: 24, Loss: 2.35090708732605, Accuracy: 0.21875, Computation time: 4.617371320724487\n",
      "Step: 25, Loss: 2.3074231147766113, Accuracy: 0.21875, Computation time: 0.8092541694641113\n",
      "Step: 26, Loss: 2.0291638374328613, Accuracy: 0.21875, Computation time: 0.6835148334503174\n",
      "Step: 27, Loss: 2.2107913494110107, Accuracy: 0.3125, Computation time: 4.6348888874053955\n",
      "Step: 28, Loss: 2.828503370285034, Accuracy: 0.1875, Computation time: 0.6086010932922363\n",
      "Step: 29, Loss: 2.2685117721557617, Accuracy: 0.125, Computation time: 0.7237358093261719\n",
      "Step: 30, Loss: 2.415773868560791, Accuracy: 0.125, Computation time: 0.6419861316680908\n",
      "Step: 31, Loss: 2.3504269123077393, Accuracy: 0.1875, Computation time: 0.6615331172943115\n",
      "Step: 32, Loss: 2.136155366897583, Accuracy: 0.21875, Computation time: 0.7299740314483643\n",
      "Step: 33, Loss: 2.2097346782684326, Accuracy: 0.125, Computation time: 0.703603982925415\n",
      "Step: 34, Loss: 2.306391716003418, Accuracy: 0.0625, Computation time: 0.623654842376709\n",
      "Step: 35, Loss: 2.1999309062957764, Accuracy: 0.15625, Computation time: 0.6533479690551758\n",
      "Step: 36, Loss: 2.4504199028015137, Accuracy: 0.21875, Computation time: 0.7489809989929199\n",
      "Step: 37, Loss: 2.0924789905548096, Accuracy: 0.375, Computation time: 0.5467209815979004\n",
      "Step: 38, Loss: 2.5953550338745117, Accuracy: 0.09375, Computation time: 4.578402757644653\n",
      "Step: 39, Loss: 2.4039130210876465, Accuracy: 0.1875, Computation time: 0.66513991355896\n",
      "Step: 40, Loss: 2.212080478668213, Accuracy: 0.3125, Computation time: 6.01696515083313\n",
      "Step: 41, Loss: 2.326615810394287, Accuracy: 0.09375, Computation time: 0.5693879127502441\n",
      "Step: 42, Loss: 2.3798470497131348, Accuracy: 0.21875, Computation time: 4.460834264755249\n",
      "Step: 43, Loss: 2.6610195636749268, Accuracy: 0.1875, Computation time: 0.5925259590148926\n",
      "Step: 44, Loss: 2.373520612716675, Accuracy: 0.15625, Computation time: 5.3933470249176025\n",
      "Step: 45, Loss: 2.3544487953186035, Accuracy: 0.1875, Computation time: 1.124903917312622\n",
      "Step: 46, Loss: 2.10626482963562, Accuracy: 0.1875, Computation time: 4.501467227935791\n",
      "Step: 47, Loss: 2.3130245208740234, Accuracy: 0.1875, Computation time: 0.6565849781036377\n",
      "Step: 48, Loss: 2.1771817207336426, Accuracy: 0.1875, Computation time: 5.487727880477905\n",
      "Step: 49, Loss: 2.2678985595703125, Accuracy: 0.25, Computation time: 0.6866340637207031\n",
      "Step: 50, Loss: 2.1114933490753174, Accuracy: 0.21875, Computation time: 1.1196649074554443\n",
      "Step: 51, Loss: 2.328657627105713, Accuracy: 0.15625, Computation time: 0.6951420307159424\n",
      "Step: 52, Loss: 2.551058053970337, Accuracy: 0.0625, Computation time: 0.7027180194854736\n",
      "Step: 53, Loss: 2.053194999694824, Accuracy: 0.21875, Computation time: 0.5611698627471924\n",
      "Step: 54, Loss: 2.1706624031066895, Accuracy: 0.21875, Computation time: 0.8026289939880371\n",
      "Step: 55, Loss: 1.6626452207565308, Accuracy: 0.375, Computation time: 0.4964630603790283\n",
      "Step: 56, Loss: 2.42492413520813, Accuracy: 0.1875, Computation time: 0.6300821304321289\n",
      "Step: 57, Loss: 2.005038022994995, Accuracy: 0.25, Computation time: 0.6514890193939209\n",
      "Step: 58, Loss: 2.5164358615875244, Accuracy: 0.15625, Computation time: 0.5598931312561035\n",
      "Step: 59, Loss: 2.311469078063965, Accuracy: 0.21875, Computation time: 0.5723049640655518\n",
      "Step: 60, Loss: 2.0442724227905273, Accuracy: 0.34375, Computation time: 0.5889039039611816\n",
      "Step: 61, Loss: 2.16814923286438, Accuracy: 0.34375, Computation time: 0.696613073348999\n",
      "Step: 62, Loss: 2.2615835666656494, Accuracy: 0.1875, Computation time: 0.6515820026397705\n",
      "Step: 63, Loss: 2.3419392108917236, Accuracy: 0.15625, Computation time: 0.7214617729187012\n",
      "Step: 64, Loss: 2.1833882331848145, Accuracy: 0.28125, Computation time: 0.5817720890045166\n",
      "Step: 65, Loss: 2.0864028930664062, Accuracy: 0.21875, Computation time: 0.813485860824585\n",
      "Step: 66, Loss: 2.3773996829986572, Accuracy: 0.21875, Computation time: 0.5052967071533203\n",
      "Step: 67, Loss: 2.0395078659057617, Accuracy: 0.3125, Computation time: 0.7110500335693359\n",
      "Step: 68, Loss: 2.09599232673645, Accuracy: 0.25, Computation time: 0.6797242164611816\n",
      "Step: 69, Loss: 2.299947500228882, Accuracy: 0.21875, Computation time: 0.6313598155975342\n",
      "Step: 70, Loss: 2.0237221717834473, Accuracy: 0.25, Computation time: 0.5600032806396484\n",
      "Step: 71, Loss: 2.4281117916107178, Accuracy: 0.25, Computation time: 0.7061901092529297\n",
      "Step: 72, Loss: 1.8893678188323975, Accuracy: 0.28125, Computation time: 0.6607651710510254\n",
      "Step: 73, Loss: 2.2083091735839844, Accuracy: 0.25, Computation time: 4.405129909515381\n",
      "Step: 74, Loss: 2.2094459533691406, Accuracy: 0.21875, Computation time: 0.5648839473724365\n",
      "Step: 75, Loss: 2.3554770946502686, Accuracy: 0.1875, Computation time: 0.6438441276550293\n",
      "Step: 76, Loss: 2.0585827827453613, Accuracy: 0.21875, Computation time: 0.5887749195098877\n",
      "Step: 77, Loss: 2.272141933441162, Accuracy: 0.25, Computation time: 0.6407918930053711\n",
      "Step: 78, Loss: 2.421846628189087, Accuracy: 0.09375, Computation time: 0.6021220684051514\n",
      "Step: 79, Loss: 2.1167447566986084, Accuracy: 0.1875, Computation time: 5.334618330001831\n",
      "Step: 80, Loss: 1.9423304796218872, Accuracy: 0.1875, Computation time: 0.6891930103302002\n",
      "Step: 81, Loss: 1.9371947050094604, Accuracy: 0.3125, Computation time: 0.615574836730957\n",
      "Step: 82, Loss: 1.9286153316497803, Accuracy: 0.25, Computation time: 0.9165449142456055\n",
      "Step: 83, Loss: 2.0710458755493164, Accuracy: 0.28125, Computation time: 0.651202917098999\n",
      "Step: 84, Loss: 2.2480504512786865, Accuracy: 0.15625, Computation time: 4.701957941055298\n",
      "Step: 85, Loss: 2.2678236961364746, Accuracy: 0.09375, Computation time: 0.6394481658935547\n",
      "Step: 86, Loss: 2.1392602920532227, Accuracy: 0.125, Computation time: 0.9259178638458252\n",
      "Step: 87, Loss: 2.0893425941467285, Accuracy: 0.1875, Computation time: 0.5887670516967773\n",
      "Step: 88, Loss: 1.8979926109313965, Accuracy: 0.25, Computation time: 0.7761619091033936\n",
      "Step: 89, Loss: 1.8324767351150513, Accuracy: 0.375, Computation time: 5.76898980140686\n",
      "Step: 90, Loss: 2.3029165267944336, Accuracy: 0.1875, Computation time: 0.6607110500335693\n",
      "Step: 91, Loss: 1.9068530797958374, Accuracy: 0.34375, Computation time: 0.5279388427734375\n",
      "Step: 92, Loss: 1.7617895603179932, Accuracy: 0.25, Computation time: 0.7027199268341064\n",
      "Step: 93, Loss: 1.9642481803894043, Accuracy: 0.28125, Computation time: 0.6188690662384033\n",
      "Step: 94, Loss: 2.178633213043213, Accuracy: 0.21875, Computation time: 0.5589907169342041\n",
      "Step: 95, Loss: 2.003065347671509, Accuracy: 0.28125, Computation time: 0.5656321048736572\n",
      "Step: 96, Loss: 1.7554199695587158, Accuracy: 0.375, Computation time: 0.5903880596160889\n",
      "Step: 97, Loss: 1.915318489074707, Accuracy: 0.28125, Computation time: 0.7726941108703613\n",
      "Step: 98, Loss: 1.8969225883483887, Accuracy: 0.375, Computation time: 0.732978105545044\n",
      "Step: 99, Loss: 1.9393256902694702, Accuracy: 0.25, Computation time: 0.5938639640808105\n",
      "Step: 100, Loss: 2.002267599105835, Accuracy: 0.3125, Computation time: 0.5580370426177979\n",
      "Step: 101, Loss: 1.796673059463501, Accuracy: 0.46875, Computation time: 4.613645792007446\n",
      "Step: 102, Loss: 1.7055463790893555, Accuracy: 0.34375, Computation time: 0.7327961921691895\n",
      "Step: 103, Loss: 1.6540765762329102, Accuracy: 0.46875, Computation time: 0.537247896194458\n",
      "Step: 104, Loss: 1.7875546216964722, Accuracy: 0.4375, Computation time: 0.9042198657989502\n",
      "Step: 105, Loss: 1.9914207458496094, Accuracy: 0.4375, Computation time: 0.6680150032043457\n",
      "Step: 106, Loss: 2.9836950302124023, Accuracy: 0.09375, Computation time: 0.5770828723907471\n",
      "Step: 107, Loss: 2.0249640941619873, Accuracy: 0.28125, Computation time: 0.859565019607544\n",
      "Step: 108, Loss: 2.2429041862487793, Accuracy: 0.3125, Computation time: 0.7613370418548584\n",
      "Step: 109, Loss: 1.823493480682373, Accuracy: 0.3125, Computation time: 0.6907992362976074\n",
      "Step: 110, Loss: 2.431427001953125, Accuracy: 0.28125, Computation time: 0.6449871063232422\n",
      "Step: 111, Loss: 1.7989721298217773, Accuracy: 0.34375, Computation time: 0.7617969512939453\n",
      "Step: 112, Loss: 1.6970738172531128, Accuracy: 0.4375, Computation time: 0.6361589431762695\n",
      "Step: 113, Loss: 1.8387198448181152, Accuracy: 0.40625, Computation time: 0.6132280826568604\n",
      "Step: 114, Loss: 2.256260395050049, Accuracy: 0.25, Computation time: 0.5176777839660645\n",
      "Step: 115, Loss: 2.172931671142578, Accuracy: 0.40625, Computation time: 0.6106359958648682\n",
      "Step: 116, Loss: 1.919539213180542, Accuracy: 0.3125, Computation time: 1.077589750289917\n",
      "Step: 117, Loss: 1.8877193927764893, Accuracy: 0.3125, Computation time: 0.9828741550445557\n",
      "Step: 118, Loss: 1.653126835823059, Accuracy: 0.40625, Computation time: 4.500096082687378\n",
      "Step: 119, Loss: 2.0780811309814453, Accuracy: 0.34375, Computation time: 0.8253252506256104\n",
      "Step: 120, Loss: 2.345315456390381, Accuracy: 0.28125, Computation time: 0.655285120010376\n",
      "Step: 121, Loss: 1.8041678667068481, Accuracy: 0.46875, Computation time: 0.5577468872070312\n",
      "Step: 122, Loss: 1.7004082202911377, Accuracy: 0.3125, Computation time: 0.7421877384185791\n",
      "Step: 123, Loss: 1.997849941253662, Accuracy: 0.25, Computation time: 0.6412708759307861\n",
      "Step: 124, Loss: 1.9849530458450317, Accuracy: 0.3125, Computation time: 0.718376874923706\n",
      "Step: 125, Loss: 2.3540666103363037, Accuracy: 0.34375, Computation time: 0.6333391666412354\n",
      "Step: 126, Loss: 2.0296449661254883, Accuracy: 0.375, Computation time: 1.429992914199829\n",
      "Step: 127, Loss: 2.018139600753784, Accuracy: 0.375, Computation time: 0.673363208770752\n",
      "Step: 128, Loss: 2.3295698165893555, Accuracy: 0.375, Computation time: 0.6458160877227783\n",
      "Step: 129, Loss: 2.22477388381958, Accuracy: 0.15625, Computation time: 0.6294598579406738\n",
      "Step: 130, Loss: 1.9986172914505005, Accuracy: 0.4375, Computation time: 0.6436200141906738\n",
      "Step: 131, Loss: 2.0613973140716553, Accuracy: 0.34375, Computation time: 0.6925969123840332\n",
      "Step: 132, Loss: 2.105764865875244, Accuracy: 0.28125, Computation time: 0.6704950332641602\n",
      "Step: 133, Loss: 1.9054158926010132, Accuracy: 0.375, Computation time: 0.715317964553833\n",
      "Step: 134, Loss: 2.0198333263397217, Accuracy: 0.28125, Computation time: 0.7096972465515137\n",
      "Step: 135, Loss: 2.3802618980407715, Accuracy: 0.1875, Computation time: 0.7056670188903809\n",
      "Step: 136, Loss: 2.2699673175811768, Accuracy: 0.21875, Computation time: 0.7464888095855713\n",
      "Step: 137, Loss: 2.078683853149414, Accuracy: 0.25, Computation time: 0.6893308162689209\n",
      "Step: 138, Loss: 1.949456810951233, Accuracy: 0.40625, Computation time: 0.6548840999603271\n",
      "Step: 139, Loss: 1.9204665422439575, Accuracy: 0.3125, Computation time: 4.627374172210693\n",
      "Step: 140, Loss: 2.2378060817718506, Accuracy: 0.375, Computation time: 0.6401429176330566\n",
      "Step: 141, Loss: 2.188546657562256, Accuracy: 0.21875, Computation time: 0.7693512439727783\n",
      "Step: 142, Loss: 1.8970452547073364, Accuracy: 0.375, Computation time: 0.8186089992523193\n",
      "Step: 143, Loss: 1.8631691932678223, Accuracy: 0.28125, Computation time: 0.5681042671203613\n",
      "Step: 144, Loss: 1.6539621353149414, Accuracy: 0.34375, Computation time: 0.7228810787200928\n",
      "Step: 145, Loss: 2.7518486976623535, Accuracy: 0.25, Computation time: 0.7748420238494873\n",
      "Step: 146, Loss: 2.1874985694885254, Accuracy: 0.28125, Computation time: 0.576056957244873\n",
      "Step: 147, Loss: 2.1374270915985107, Accuracy: 0.1875, Computation time: 0.7297711372375488\n",
      "Step: 148, Loss: 2.1009223461151123, Accuracy: 0.3125, Computation time: 0.6194748878479004\n",
      "Step: 149, Loss: 1.9916812181472778, Accuracy: 0.25, Computation time: 0.6348071098327637\n",
      "Step: 150, Loss: 1.7361186742782593, Accuracy: 0.46875, Computation time: 0.6623711585998535\n",
      "Step: 151, Loss: 1.9772201776504517, Accuracy: 0.3125, Computation time: 0.6379919052124023\n",
      "Step: 152, Loss: 2.1379077434539795, Accuracy: 0.28125, Computation time: 0.6214041709899902\n",
      "Step: 153, Loss: 2.1858367919921875, Accuracy: 0.21875, Computation time: 0.5480749607086182\n",
      "Step: 154, Loss: 1.6263824701309204, Accuracy: 0.53125, Computation time: 0.6585290431976318\n",
      "Step: 155, Loss: 2.1221256256103516, Accuracy: 0.25, Computation time: 0.6437921524047852\n",
      "Step: 156, Loss: 1.8170888423919678, Accuracy: 0.40625, Computation time: 0.7665159702301025\n",
      "Step: 157, Loss: 1.855507731437683, Accuracy: 0.34375, Computation time: 0.627208948135376\n",
      "Step: 158, Loss: 2.1762242317199707, Accuracy: 0.40625, Computation time: 0.957056999206543\n",
      "Step: 159, Loss: 1.9623979330062866, Accuracy: 0.28125, Computation time: 0.6086218357086182\n",
      "Step: 160, Loss: 1.8287014961242676, Accuracy: 0.375, Computation time: 1.0188450813293457\n",
      "Step: 161, Loss: 1.667553186416626, Accuracy: 0.46875, Computation time: 0.7401506900787354\n",
      "Step: 162, Loss: 1.9182261228561401, Accuracy: 0.375, Computation time: 0.7480180263519287\n",
      "Step: 163, Loss: 1.7794877290725708, Accuracy: 0.375, Computation time: 0.7357831001281738\n",
      "Step: 164, Loss: 2.0337462425231934, Accuracy: 0.28125, Computation time: 0.6435539722442627\n",
      "Step: 165, Loss: 2.131545066833496, Accuracy: 0.3125, Computation time: 0.8042223453521729\n",
      "Step: 166, Loss: 1.9233980178833008, Accuracy: 0.34375, Computation time: 0.8020021915435791\n",
      "Step: 167, Loss: 1.865761399269104, Accuracy: 0.25, Computation time: 0.5117120742797852\n",
      "Step: 168, Loss: 1.8163139820098877, Accuracy: 0.375, Computation time: 0.9769589900970459\n",
      "Step: 169, Loss: 1.6248010396957397, Accuracy: 0.46875, Computation time: 0.6086368560791016\n",
      "Step: 170, Loss: 1.7145010232925415, Accuracy: 0.40625, Computation time: 0.5430316925048828\n",
      "Step: 171, Loss: 1.7706879377365112, Accuracy: 0.34375, Computation time: 0.696847677230835\n",
      "Step: 172, Loss: 2.3968875408172607, Accuracy: 0.21875, Computation time: 0.6734991073608398\n",
      "Step: 173, Loss: 2.2887942790985107, Accuracy: 0.21875, Computation time: 5.593723773956299\n",
      "Step: 174, Loss: 1.8096435070037842, Accuracy: 0.375, Computation time: 0.6114158630371094\n",
      "Step: 175, Loss: 1.9518200159072876, Accuracy: 0.3125, Computation time: 0.6921768188476562\n",
      "Step: 176, Loss: 2.163520336151123, Accuracy: 0.25, Computation time: 0.6100542545318604\n",
      "Step: 177, Loss: 1.7171475887298584, Accuracy: 0.3125, Computation time: 4.559638977050781\n",
      "Step: 178, Loss: 1.6960365772247314, Accuracy: 0.4375, Computation time: 0.76875901222229\n",
      "Step: 179, Loss: 2.0673625469207764, Accuracy: 0.375, Computation time: 0.6470949649810791\n",
      "Step: 180, Loss: 2.207017183303833, Accuracy: 0.28125, Computation time: 0.5574071407318115\n",
      "Step: 181, Loss: 1.7476221323013306, Accuracy: 0.4375, Computation time: 0.7117359638214111\n",
      "Step: 182, Loss: 1.8216183185577393, Accuracy: 0.5, Computation time: 0.6984829902648926\n",
      "Step: 183, Loss: 1.7869646549224854, Accuracy: 0.34375, Computation time: 1.0124249458312988\n",
      "Step: 184, Loss: 1.6530234813690186, Accuracy: 0.5, Computation time: 0.6322000026702881\n",
      "Step: 185, Loss: 1.7086526155471802, Accuracy: 0.375, Computation time: 0.7376420497894287\n",
      "Step: 186, Loss: 1.871398687362671, Accuracy: 0.34375, Computation time: 0.5645349025726318\n",
      "Step: 187, Loss: 1.873131275177002, Accuracy: 0.34375, Computation time: 0.7624881267547607\n",
      "Step: 188, Loss: 1.946843147277832, Accuracy: 0.3125, Computation time: 0.7890579700469971\n",
      "Step: 189, Loss: 1.6754415035247803, Accuracy: 0.4375, Computation time: 0.760739803314209\n",
      "Step: 190, Loss: 1.6750984191894531, Accuracy: 0.25, Computation time: 0.5487942695617676\n",
      "Step: 191, Loss: 1.7572786808013916, Accuracy: 0.3125, Computation time: 0.5706210136413574\n",
      "Step: 192, Loss: 1.601854920387268, Accuracy: 0.40625, Computation time: 0.7669050693511963\n",
      "Step: 193, Loss: 1.7561616897583008, Accuracy: 0.375, Computation time: 0.8111810684204102\n",
      "Step: 194, Loss: 1.6313717365264893, Accuracy: 0.4375, Computation time: 0.6562550067901611\n",
      "Step: 195, Loss: 1.8318989276885986, Accuracy: 0.40625, Computation time: 0.6187930107116699\n",
      "Step: 196, Loss: 1.7744308710098267, Accuracy: 0.3125, Computation time: 0.6165189743041992\n",
      "Step: 197, Loss: 1.7445728778839111, Accuracy: 0.5, Computation time: 0.8131787776947021\n",
      "Step: 198, Loss: 1.614978313446045, Accuracy: 0.5, Computation time: 0.6157519817352295\n",
      "Step: 199, Loss: 1.4837236404418945, Accuracy: 0.46875, Computation time: 0.7675678730010986\n",
      "Step: 200, Loss: 1.8004363775253296, Accuracy: 0.375, Computation time: 0.7225971221923828\n",
      "Step: 201, Loss: 2.0369486808776855, Accuracy: 0.375, Computation time: 0.6800708770751953\n",
      "Step: 202, Loss: 1.6637674570083618, Accuracy: 0.34375, Computation time: 0.6793630123138428\n",
      "Step: 203, Loss: 1.7389609813690186, Accuracy: 0.34375, Computation time: 0.9543678760528564\n",
      "Step: 204, Loss: 1.6066598892211914, Accuracy: 0.4375, Computation time: 0.6851561069488525\n",
      "Step: 205, Loss: 2.0786168575286865, Accuracy: 0.34375, Computation time: 0.5464231967926025\n",
      "Step: 206, Loss: 1.7195278406143188, Accuracy: 0.375, Computation time: 0.7755641937255859\n",
      "Step: 207, Loss: 2.1218061447143555, Accuracy: 0.21875, Computation time: 0.7128708362579346\n",
      "Step: 208, Loss: 1.846463918685913, Accuracy: 0.4375, Computation time: 0.8888599872589111\n",
      "Step: 209, Loss: 1.507045865058899, Accuracy: 0.46875, Computation time: 0.6699590682983398\n",
      "Step: 210, Loss: 1.6621754169464111, Accuracy: 0.4375, Computation time: 0.6447510719299316\n",
      "Step: 211, Loss: 1.8807332515716553, Accuracy: 0.5, Computation time: 0.6243209838867188\n",
      "Step: 212, Loss: 1.694525122642517, Accuracy: 0.40625, Computation time: 0.7166469097137451\n",
      "Step: 213, Loss: 1.8921397924423218, Accuracy: 0.34375, Computation time: 0.7891662120819092\n",
      "Step: 214, Loss: 1.56809663772583, Accuracy: 0.4375, Computation time: 0.7686178684234619\n",
      "Step: 215, Loss: 1.4980868101119995, Accuracy: 0.5625, Computation time: 0.9657049179077148\n",
      "Step: 216, Loss: 2.198831558227539, Accuracy: 0.4375, Computation time: 0.6423161029815674\n",
      "Step: 217, Loss: 1.6815413236618042, Accuracy: 0.5625, Computation time: 0.6581418514251709\n",
      "Step: 218, Loss: 1.5779966115951538, Accuracy: 0.5625, Computation time: 0.5878300666809082\n",
      "Step: 219, Loss: 2.4787678718566895, Accuracy: 0.21875, Computation time: 0.6556110382080078\n",
      "Step: 220, Loss: 1.6850855350494385, Accuracy: 0.46875, Computation time: 1.160829782485962\n",
      "Step: 221, Loss: 1.9253398180007935, Accuracy: 0.34375, Computation time: 0.6378390789031982\n",
      "Step: 222, Loss: 1.74147629737854, Accuracy: 0.4375, Computation time: 0.714914083480835\n",
      "Step: 223, Loss: 1.6735481023788452, Accuracy: 0.34375, Computation time: 0.6882889270782471\n",
      "Step: 224, Loss: 1.7667453289031982, Accuracy: 0.40625, Computation time: 0.6628799438476562\n",
      "Step: 225, Loss: 1.6043120622634888, Accuracy: 0.40625, Computation time: 0.628939151763916\n",
      "Step: 226, Loss: 2.132411241531372, Accuracy: 0.3125, Computation time: 0.7266008853912354\n",
      "Step: 227, Loss: 1.9984818696975708, Accuracy: 0.3125, Computation time: 0.7082729339599609\n",
      "Step: 228, Loss: 1.9298310279846191, Accuracy: 0.34375, Computation time: 0.7353620529174805\n",
      "Step: 229, Loss: 1.9580613374710083, Accuracy: 0.3125, Computation time: 0.6315460205078125\n",
      "Step: 230, Loss: 1.8377156257629395, Accuracy: 0.40625, Computation time: 0.6555719375610352\n",
      "Step: 231, Loss: 2.4708242416381836, Accuracy: 0.3125, Computation time: 0.7673330307006836\n",
      "Step: 232, Loss: 1.964162826538086, Accuracy: 0.5, Computation time: 0.6275460720062256\n",
      "Step: 233, Loss: 1.4350783824920654, Accuracy: 0.5, Computation time: 0.689765214920044\n",
      "Step: 234, Loss: 1.9176650047302246, Accuracy: 0.4375, Computation time: 0.6595797538757324\n",
      "Step: 235, Loss: 1.9593192338943481, Accuracy: 0.34375, Computation time: 0.7171127796173096\n",
      "Step: 236, Loss: 2.0637271404266357, Accuracy: 0.3125, Computation time: 0.8488080501556396\n",
      "Step: 237, Loss: 1.827929973602295, Accuracy: 0.3125, Computation time: 4.731308937072754\n",
      "Step: 238, Loss: 1.9441617727279663, Accuracy: 0.28125, Computation time: 0.6190991401672363\n",
      "Step: 239, Loss: 1.9793814420700073, Accuracy: 0.40625, Computation time: 0.7359039783477783\n",
      "Step: 240, Loss: 2.043675422668457, Accuracy: 0.40625, Computation time: 0.655689001083374\n",
      "Step: 241, Loss: 1.6287046670913696, Accuracy: 0.53125, Computation time: 0.6315431594848633\n",
      "Step: 242, Loss: 1.7973437309265137, Accuracy: 0.34375, Computation time: 0.7462289333343506\n",
      "Step: 243, Loss: 1.9900734424591064, Accuracy: 0.34375, Computation time: 0.7125136852264404\n",
      "Step: 244, Loss: 1.5880659818649292, Accuracy: 0.34375, Computation time: 0.7898938655853271\n",
      "Step: 245, Loss: 1.628580093383789, Accuracy: 0.5, Computation time: 0.6883840560913086\n",
      "Step: 246, Loss: 1.5921945571899414, Accuracy: 0.5625, Computation time: 0.6357669830322266\n",
      "Step: 247, Loss: 1.9511052370071411, Accuracy: 0.375, Computation time: 0.5354857444763184\n",
      "Step: 248, Loss: 1.6870442628860474, Accuracy: 0.46875, Computation time: 0.6790928840637207\n",
      "Step: 249, Loss: 1.711720585823059, Accuracy: 0.40625, Computation time: 0.585655927658081\n",
      "Step: 250, Loss: 2.1047074794769287, Accuracy: 0.40625, Computation time: 4.78124213218689\n",
      "Step: 251, Loss: 1.7534524202346802, Accuracy: 0.40625, Computation time: 0.7820048332214355\n",
      "Step: 252, Loss: 1.3459841012954712, Accuracy: 0.5, Computation time: 0.7606072425842285\n",
      "Step: 253, Loss: 1.9417418241500854, Accuracy: 0.375, Computation time: 1.280491828918457\n",
      "Step: 254, Loss: 1.7806233167648315, Accuracy: 0.4375, Computation time: 0.6678500175476074\n",
      "Step: 255, Loss: 1.6060388088226318, Accuracy: 0.375, Computation time: 0.6754570007324219\n",
      "Step: 256, Loss: 1.9923584461212158, Accuracy: 0.28125, Computation time: 0.6627519130706787\n",
      "Step: 257, Loss: 1.8980942964553833, Accuracy: 0.40625, Computation time: 1.3050029277801514\n",
      "Step: 258, Loss: 1.3643574714660645, Accuracy: 0.5, Computation time: 0.6165697574615479\n",
      "Step: 259, Loss: 1.7259061336517334, Accuracy: 0.4375, Computation time: 0.7720761299133301\n",
      "Step: 260, Loss: 1.644735336303711, Accuracy: 0.5, Computation time: 0.6339647769927979\n",
      "Step: 261, Loss: 1.596423864364624, Accuracy: 0.53125, Computation time: 0.662388801574707\n",
      "Step: 262, Loss: 1.664984941482544, Accuracy: 0.5625, Computation time: 0.6200478076934814\n",
      "Step: 263, Loss: 1.843494176864624, Accuracy: 0.4375, Computation time: 1.2283389568328857\n",
      "Step: 264, Loss: 1.4688527584075928, Accuracy: 0.53125, Computation time: 0.6444873809814453\n",
      "Step: 265, Loss: 1.6263422966003418, Accuracy: 0.5, Computation time: 0.6974151134490967\n",
      "Step: 266, Loss: 1.616255760192871, Accuracy: 0.4375, Computation time: 0.7272629737854004\n",
      "Step: 267, Loss: 1.5171345472335815, Accuracy: 0.5625, Computation time: 0.47859930992126465\n",
      "Step: 268, Loss: 2.1516644954681396, Accuracy: 0.375, Computation time: 0.6756970882415771\n",
      "Step: 269, Loss: 1.9449788331985474, Accuracy: 0.40625, Computation time: 0.5742290019989014\n",
      "Step: 270, Loss: 1.6016470193862915, Accuracy: 0.46875, Computation time: 0.7783999443054199\n",
      "Step: 271, Loss: 1.6125202178955078, Accuracy: 0.46875, Computation time: 0.6647679805755615\n",
      "Step: 272, Loss: 1.6561203002929688, Accuracy: 0.375, Computation time: 0.7621917724609375\n",
      "Step: 273, Loss: 2.074509859085083, Accuracy: 0.28125, Computation time: 0.717879056930542\n",
      "Step: 274, Loss: 1.9153116941452026, Accuracy: 0.3125, Computation time: 0.7414829730987549\n",
      "Step: 275, Loss: 1.8019393682479858, Accuracy: 0.3125, Computation time: 0.6419601440429688\n",
      "Step: 276, Loss: 1.4267414808273315, Accuracy: 0.4375, Computation time: 0.6367120742797852\n",
      "Step: 277, Loss: 1.5652662515640259, Accuracy: 0.5625, Computation time: 0.8590152263641357\n",
      "Step: 278, Loss: 1.6169363260269165, Accuracy: 0.40625, Computation time: 0.7065417766571045\n",
      "Step: 279, Loss: 1.67380690574646, Accuracy: 0.46875, Computation time: 0.5855200290679932\n",
      "Step: 280, Loss: 1.178822636604309, Accuracy: 0.65625, Computation time: 0.6924929618835449\n",
      "Step: 281, Loss: 1.7943625450134277, Accuracy: 0.46875, Computation time: 0.7531349658966064\n",
      "Step: 282, Loss: 1.5105081796646118, Accuracy: 0.4375, Computation time: 1.010221242904663\n",
      "Step: 283, Loss: 1.6450239419937134, Accuracy: 0.59375, Computation time: 0.7149970531463623\n",
      "Step: 284, Loss: 1.6415221691131592, Accuracy: 0.53125, Computation time: 0.6771759986877441\n",
      "Step: 285, Loss: 1.3782936334609985, Accuracy: 0.59375, Computation time: 0.6239171028137207\n",
      "Step: 286, Loss: 1.4138500690460205, Accuracy: 0.59375, Computation time: 0.6920342445373535\n",
      "Step: 287, Loss: 1.6906087398529053, Accuracy: 0.5, Computation time: 0.7764837741851807\n",
      "Step: 288, Loss: 2.167299270629883, Accuracy: 0.28125, Computation time: 0.8152661323547363\n",
      "Step: 289, Loss: 1.9450042247772217, Accuracy: 0.375, Computation time: 0.6143898963928223\n",
      "Step: 290, Loss: 1.6399462223052979, Accuracy: 0.4375, Computation time: 0.5674269199371338\n",
      "Step: 291, Loss: 1.636378288269043, Accuracy: 0.5, Computation time: 0.6269228458404541\n",
      "Step: 292, Loss: 1.3157744407653809, Accuracy: 0.59375, Computation time: 0.6436800956726074\n",
      "Step: 293, Loss: 1.4151099920272827, Accuracy: 0.5625, Computation time: 0.7436537742614746\n",
      "Step: 294, Loss: 1.7979999780654907, Accuracy: 0.375, Computation time: 0.7788653373718262\n",
      "Step: 295, Loss: 1.293394923210144, Accuracy: 0.65625, Computation time: 0.7600789070129395\n",
      "Step: 296, Loss: 1.6664575338363647, Accuracy: 0.53125, Computation time: 0.770082950592041\n",
      "Step: 297, Loss: 1.4573582410812378, Accuracy: 0.4375, Computation time: 0.5885870456695557\n",
      "Step: 298, Loss: 1.6945407390594482, Accuracy: 0.53125, Computation time: 0.6261739730834961\n",
      "Step: 299, Loss: 1.872282862663269, Accuracy: 0.34375, Computation time: 0.5896151065826416\n",
      "Step: 300, Loss: 1.3763748407363892, Accuracy: 0.5, Computation time: 0.8345961570739746\n",
      "Step: 301, Loss: 1.9604994058609009, Accuracy: 0.4375, Computation time: 0.8032882213592529\n",
      "Step: 302, Loss: 1.7422579526901245, Accuracy: 0.4375, Computation time: 0.6446406841278076\n",
      "Step: 303, Loss: 1.3568073511123657, Accuracy: 0.5625, Computation time: 0.5917911529541016\n",
      "Step: 304, Loss: 2.0266971588134766, Accuracy: 0.28125, Computation time: 0.5974879264831543\n",
      "Step: 305, Loss: 1.5747581720352173, Accuracy: 0.375, Computation time: 0.6830589771270752\n",
      "Step: 306, Loss: 1.6612560749053955, Accuracy: 0.46875, Computation time: 0.8784582614898682\n",
      "Step: 307, Loss: 1.4580323696136475, Accuracy: 0.53125, Computation time: 0.7486357688903809\n",
      "Step: 308, Loss: 1.269403100013733, Accuracy: 0.59375, Computation time: 0.7729580402374268\n",
      "Step: 309, Loss: 1.4418628215789795, Accuracy: 0.53125, Computation time: 0.6158168315887451\n",
      "Step: 310, Loss: 1.7355417013168335, Accuracy: 0.4375, Computation time: 0.6672518253326416\n",
      "Step: 311, Loss: 1.7268186807632446, Accuracy: 0.4375, Computation time: 0.6676790714263916\n",
      "Step: 312, Loss: 1.3184289932250977, Accuracy: 0.4375, Computation time: 0.7334070205688477\n",
      "Step: 313, Loss: 1.4676542282104492, Accuracy: 0.625, Computation time: 0.6110918521881104\n",
      "Step: 314, Loss: 1.996611475944519, Accuracy: 0.28125, Computation time: 0.7174689769744873\n",
      "Step: 315, Loss: 1.5509271621704102, Accuracy: 0.28125, Computation time: 0.8339338302612305\n",
      "Step: 316, Loss: 1.7828072309494019, Accuracy: 0.4375, Computation time: 0.7920420169830322\n",
      "Step: 317, Loss: 1.1795415878295898, Accuracy: 0.5625, Computation time: 0.6775548458099365\n",
      "Step: 318, Loss: 1.3179045915603638, Accuracy: 0.59375, Computation time: 0.9172000885009766\n",
      "Step: 319, Loss: 1.2546894550323486, Accuracy: 0.65625, Computation time: 1.1084492206573486\n",
      "Step: 320, Loss: 1.6450024843215942, Accuracy: 0.4375, Computation time: 0.6892621517181396\n",
      "Step: 321, Loss: 1.9095568656921387, Accuracy: 0.3125, Computation time: 0.6611108779907227\n",
      "Step: 322, Loss: 1.8881936073303223, Accuracy: 0.46875, Computation time: 0.7753052711486816\n",
      "Step: 323, Loss: 1.2425878047943115, Accuracy: 0.46875, Computation time: 0.7236969470977783\n",
      "Step: 324, Loss: 2.2470176219940186, Accuracy: 0.34375, Computation time: 0.6677591800689697\n",
      "Step: 325, Loss: 2.5965735912323, Accuracy: 0.40625, Computation time: 0.8823440074920654\n",
      "Step: 326, Loss: 1.316536784172058, Accuracy: 0.5625, Computation time: 0.556298017501831\n",
      "Step: 327, Loss: 1.7125952243804932, Accuracy: 0.53125, Computation time: 0.6898469924926758\n",
      "Step: 328, Loss: 1.800191879272461, Accuracy: 0.4375, Computation time: 0.7423989772796631\n",
      "Step: 329, Loss: 1.737491250038147, Accuracy: 0.34375, Computation time: 0.8091459274291992\n",
      "Step: 330, Loss: 1.7101085186004639, Accuracy: 0.46875, Computation time: 0.7737329006195068\n",
      "Step: 331, Loss: 1.6261118650436401, Accuracy: 0.375, Computation time: 0.6865017414093018\n",
      "Step: 332, Loss: 1.812530517578125, Accuracy: 0.46875, Computation time: 1.0797619819641113\n",
      "Step: 333, Loss: 1.6917877197265625, Accuracy: 0.46875, Computation time: 0.7011361122131348\n",
      "Step: 334, Loss: 1.6831083297729492, Accuracy: 0.4375, Computation time: 0.635673999786377\n",
      "Step: 335, Loss: 1.7992409467697144, Accuracy: 0.53125, Computation time: 0.654512882232666\n",
      "Step: 336, Loss: 1.7498382329940796, Accuracy: 0.40625, Computation time: 0.6493430137634277\n",
      "Step: 337, Loss: 1.5136516094207764, Accuracy: 0.5625, Computation time: 0.7237789630889893\n",
      "Step: 338, Loss: 1.7287342548370361, Accuracy: 0.53125, Computation time: 0.6802911758422852\n",
      "Step: 339, Loss: 2.0598344802856445, Accuracy: 0.4375, Computation time: 0.7728509902954102\n",
      "Step: 340, Loss: 1.380904197692871, Accuracy: 0.5, Computation time: 0.6719090938568115\n",
      "Step: 341, Loss: 1.306147575378418, Accuracy: 0.5625, Computation time: 0.6721930503845215\n",
      "Step: 342, Loss: 1.5960792303085327, Accuracy: 0.4375, Computation time: 0.711341142654419\n",
      "Step: 343, Loss: 1.5825588703155518, Accuracy: 0.59375, Computation time: 0.6050817966461182\n",
      "Step: 344, Loss: 1.588193655014038, Accuracy: 0.4375, Computation time: 0.5696620941162109\n",
      "Step: 345, Loss: 1.577934741973877, Accuracy: 0.5625, Computation time: 0.6910531520843506\n",
      "Step: 346, Loss: 1.46782648563385, Accuracy: 0.46875, Computation time: 0.6613247394561768\n",
      "Step: 347, Loss: 2.228276491165161, Accuracy: 0.25, Computation time: 0.7120730876922607\n",
      "Step: 348, Loss: 1.344660997390747, Accuracy: 0.625, Computation time: 0.8015673160552979\n",
      "Step: 349, Loss: 1.9360415935516357, Accuracy: 0.375, Computation time: 0.6152091026306152\n",
      "Step: 350, Loss: 1.2777537107467651, Accuracy: 0.46875, Computation time: 0.6784927845001221\n",
      "Step: 351, Loss: 1.6269323825836182, Accuracy: 0.4375, Computation time: 0.7049453258514404\n",
      "Step: 352, Loss: 1.7845743894577026, Accuracy: 0.40625, Computation time: 0.6935930252075195\n",
      "Step: 353, Loss: 1.563722848892212, Accuracy: 0.5625, Computation time: 0.6272661685943604\n",
      "Step: 354, Loss: 2.0568342208862305, Accuracy: 0.34375, Computation time: 0.5926971435546875\n",
      "Step: 355, Loss: 1.7867640256881714, Accuracy: 0.4375, Computation time: 0.6522653102874756\n",
      "Step: 356, Loss: 1.3052666187286377, Accuracy: 0.53125, Computation time: 1.4334068298339844\n",
      "Step: 357, Loss: 1.6173996925354004, Accuracy: 0.53125, Computation time: 0.6114587783813477\n",
      "Step: 358, Loss: 1.268540620803833, Accuracy: 0.625, Computation time: 0.5860140323638916\n",
      "Step: 359, Loss: 1.695281982421875, Accuracy: 0.5, Computation time: 0.850675106048584\n",
      "Step: 360, Loss: 1.5638513565063477, Accuracy: 0.40625, Computation time: 0.9036428928375244\n",
      "Step: 361, Loss: 1.4420307874679565, Accuracy: 0.59375, Computation time: 0.6640160083770752\n",
      "Step: 362, Loss: 1.5650674104690552, Accuracy: 0.53125, Computation time: 0.6689417362213135\n",
      "Step: 363, Loss: 1.6289581060409546, Accuracy: 0.5, Computation time: 0.8760380744934082\n",
      "Step: 364, Loss: 1.5145827531814575, Accuracy: 0.5, Computation time: 1.3045899868011475\n",
      "Step: 365, Loss: 2.120992422103882, Accuracy: 0.4375, Computation time: 0.8211798667907715\n",
      "Step: 366, Loss: 1.2695573568344116, Accuracy: 0.5625, Computation time: 0.6362271308898926\n",
      "Step: 367, Loss: 1.3189215660095215, Accuracy: 0.625, Computation time: 0.6576461791992188\n",
      "Step: 368, Loss: 1.7568280696868896, Accuracy: 0.40625, Computation time: 0.6268107891082764\n",
      "Step: 369, Loss: 2.1681597232818604, Accuracy: 0.4375, Computation time: 0.7764308452606201\n",
      "Step: 370, Loss: 1.7241969108581543, Accuracy: 0.3125, Computation time: 0.6431140899658203\n",
      "Step: 371, Loss: 1.6910247802734375, Accuracy: 0.40625, Computation time: 0.6942520141601562\n",
      "Step: 372, Loss: 1.560912847518921, Accuracy: 0.46875, Computation time: 0.7481689453125\n",
      "Step: 373, Loss: 1.5059220790863037, Accuracy: 0.5, Computation time: 0.7215993404388428\n",
      "Step: 374, Loss: 1.3557720184326172, Accuracy: 0.6875, Computation time: 0.8384757041931152\n",
      "Step: 375, Loss: 1.4951239824295044, Accuracy: 0.5625, Computation time: 0.6972527503967285\n",
      "Step: 376, Loss: 1.5422133207321167, Accuracy: 0.59375, Computation time: 0.59493088722229\n",
      "Step: 377, Loss: 1.5185707807540894, Accuracy: 0.5, Computation time: 0.6646831035614014\n",
      "Step: 378, Loss: 1.5197067260742188, Accuracy: 0.5625, Computation time: 0.6453037261962891\n",
      "Step: 379, Loss: 1.77096688747406, Accuracy: 0.40625, Computation time: 0.7042748928070068\n",
      "Step: 380, Loss: 1.2954144477844238, Accuracy: 0.625, Computation time: 0.6355068683624268\n",
      "Step: 381, Loss: 1.7500054836273193, Accuracy: 0.40625, Computation time: 0.6718571186065674\n",
      "Step: 382, Loss: 1.545088768005371, Accuracy: 0.5625, Computation time: 0.7066869735717773\n",
      "Step: 383, Loss: 1.758710503578186, Accuracy: 0.34375, Computation time: 0.6422667503356934\n",
      "Step: 384, Loss: 1.8710910081863403, Accuracy: 0.40625, Computation time: 0.724729061126709\n",
      "Step: 385, Loss: 1.6024808883666992, Accuracy: 0.4375, Computation time: 0.8628189563751221\n",
      "Step: 386, Loss: 1.5173249244689941, Accuracy: 0.53125, Computation time: 0.6628627777099609\n",
      "Step: 387, Loss: 1.2790642976760864, Accuracy: 0.5625, Computation time: 0.6023731231689453\n",
      "Step: 388, Loss: 1.4684476852416992, Accuracy: 0.375, Computation time: 0.6329319477081299\n",
      "Step: 389, Loss: 1.1870850324630737, Accuracy: 0.59375, Computation time: 0.7162010669708252\n",
      "Step: 390, Loss: 1.133340835571289, Accuracy: 0.625, Computation time: 0.6783311367034912\n",
      "Step: 391, Loss: 1.477181315422058, Accuracy: 0.46875, Computation time: 0.6062610149383545\n",
      "Step: 392, Loss: 1.622503638267517, Accuracy: 0.625, Computation time: 0.8396506309509277\n",
      "Step: 393, Loss: 1.6241917610168457, Accuracy: 0.4375, Computation time: 0.7009899616241455\n",
      "Step: 394, Loss: 1.447831630706787, Accuracy: 0.5, Computation time: 0.6702778339385986\n",
      "Step: 395, Loss: 1.4721992015838623, Accuracy: 0.59375, Computation time: 0.6663548946380615\n",
      "Step: 396, Loss: 2.0780889987945557, Accuracy: 0.375, Computation time: 0.6470010280609131\n",
      "Step: 397, Loss: 1.3229955434799194, Accuracy: 0.53125, Computation time: 0.7732222080230713\n",
      "Step: 398, Loss: 1.6516468524932861, Accuracy: 0.625, Computation time: 0.8965847492218018\n",
      "Step: 399, Loss: 1.2913864850997925, Accuracy: 0.65625, Computation time: 0.7893819808959961\n",
      "Step: 400, Loss: 1.5917688608169556, Accuracy: 0.5625, Computation time: 0.759641170501709\n",
      "Step: 401, Loss: 2.7878172397613525, Accuracy: 0.40625, Computation time: 0.6853652000427246\n",
      "Step: 402, Loss: 1.8499854803085327, Accuracy: 0.375, Computation time: 0.6958820819854736\n",
      "Step: 403, Loss: 1.4922131299972534, Accuracy: 0.5625, Computation time: 0.6472468376159668\n",
      "Step: 404, Loss: 1.6747775077819824, Accuracy: 0.59375, Computation time: 0.7294931411743164\n",
      "Step: 405, Loss: 1.7936385869979858, Accuracy: 0.40625, Computation time: 0.8079171180725098\n",
      "Step: 406, Loss: 1.3937479257583618, Accuracy: 0.46875, Computation time: 4.834572792053223\n",
      "Step: 407, Loss: 1.6058251857757568, Accuracy: 0.53125, Computation time: 0.9081239700317383\n",
      "Step: 408, Loss: 1.5152639150619507, Accuracy: 0.4375, Computation time: 0.8992700576782227\n",
      "Step: 409, Loss: 1.3562771081924438, Accuracy: 0.59375, Computation time: 0.6439988613128662\n",
      "Step: 410, Loss: 1.6125832796096802, Accuracy: 0.5, Computation time: 0.5956950187683105\n",
      "Step: 411, Loss: 1.8392529487609863, Accuracy: 0.34375, Computation time: 0.7537100315093994\n",
      "Step: 412, Loss: 1.1520514488220215, Accuracy: 0.65625, Computation time: 0.7730941772460938\n",
      "Step: 413, Loss: 1.4598575830459595, Accuracy: 0.4375, Computation time: 0.6283247470855713\n",
      "Step: 414, Loss: 1.6015201807022095, Accuracy: 0.5625, Computation time: 0.792940616607666\n",
      "Step: 415, Loss: 1.597580909729004, Accuracy: 0.5, Computation time: 0.7794113159179688\n",
      "Step: 416, Loss: 1.7738399505615234, Accuracy: 0.4375, Computation time: 0.7673332691192627\n",
      "Step: 417, Loss: 1.5360052585601807, Accuracy: 0.46875, Computation time: 0.8213100433349609\n",
      "Step: 418, Loss: 1.2284228801727295, Accuracy: 0.6875, Computation time: 0.5639762878417969\n",
      "Step: 419, Loss: 1.3083690404891968, Accuracy: 0.46875, Computation time: 0.7918751239776611\n",
      "Step: 420, Loss: 1.5643408298492432, Accuracy: 0.5, Computation time: 0.7989470958709717\n",
      "Step: 421, Loss: 1.509238362312317, Accuracy: 0.46875, Computation time: 0.6457147598266602\n",
      "Step: 422, Loss: 1.728821873664856, Accuracy: 0.40625, Computation time: 1.0219950675964355\n",
      "Step: 423, Loss: 1.6012994050979614, Accuracy: 0.5, Computation time: 0.8765370845794678\n",
      "Step: 424, Loss: 1.4239667654037476, Accuracy: 0.59375, Computation time: 0.8116810321807861\n",
      "Step: 425, Loss: 1.3620057106018066, Accuracy: 0.5, Computation time: 0.6794528961181641\n",
      "Step: 426, Loss: 1.4045615196228027, Accuracy: 0.65625, Computation time: 0.8870100975036621\n",
      "Step: 427, Loss: 1.655590534210205, Accuracy: 0.40625, Computation time: 0.9490559101104736\n",
      "Step: 428, Loss: 1.7032697200775146, Accuracy: 0.5, Computation time: 0.667288064956665\n",
      "Step: 429, Loss: 1.305693507194519, Accuracy: 0.59375, Computation time: 0.8752269744873047\n",
      "Step: 430, Loss: 1.3593039512634277, Accuracy: 0.5, Computation time: 0.7142620086669922\n",
      "Step: 431, Loss: 1.178542971611023, Accuracy: 0.625, Computation time: 0.6201279163360596\n",
      "Step: 432, Loss: 1.439767837524414, Accuracy: 0.5625, Computation time: 0.6918258666992188\n",
      "Step: 433, Loss: 1.3887622356414795, Accuracy: 0.6875, Computation time: 0.7295832633972168\n",
      "Step: 434, Loss: 1.1447975635528564, Accuracy: 0.6875, Computation time: 0.7485837936401367\n",
      "Step: 435, Loss: 1.3072562217712402, Accuracy: 0.59375, Computation time: 0.5759527683258057\n",
      "Step: 436, Loss: 1.4514902830123901, Accuracy: 0.5625, Computation time: 0.6153700351715088\n",
      "Step: 437, Loss: 1.8931816816329956, Accuracy: 0.5625, Computation time: 0.7541108131408691\n",
      "Step: 438, Loss: 1.2865585088729858, Accuracy: 0.6875, Computation time: 0.5866799354553223\n",
      "Step: 439, Loss: 1.4065858125686646, Accuracy: 0.59375, Computation time: 0.7839360237121582\n",
      "Step: 440, Loss: 1.6220383644104004, Accuracy: 0.5625, Computation time: 0.6890099048614502\n",
      "Step: 441, Loss: 1.0465298891067505, Accuracy: 0.75, Computation time: 0.7183020114898682\n",
      "Step: 442, Loss: 1.5492308139801025, Accuracy: 0.53125, Computation time: 0.7051639556884766\n",
      "Step: 443, Loss: 1.3111354112625122, Accuracy: 0.5625, Computation time: 0.6573989391326904\n",
      "Step: 444, Loss: 1.2677974700927734, Accuracy: 0.625, Computation time: 0.6602089405059814\n",
      "Step: 445, Loss: 1.2362439632415771, Accuracy: 0.5625, Computation time: 0.731065034866333\n",
      "Step: 446, Loss: 1.7625459432601929, Accuracy: 0.5, Computation time: 0.6787841320037842\n",
      "Step: 447, Loss: 1.2815766334533691, Accuracy: 0.625, Computation time: 0.5979330539703369\n",
      "Step: 448, Loss: 1.5917118787765503, Accuracy: 0.5, Computation time: 0.7165780067443848\n",
      "Step: 449, Loss: 1.3587490320205688, Accuracy: 0.4375, Computation time: 0.7099881172180176\n",
      "Step: 450, Loss: 1.6414591073989868, Accuracy: 0.46875, Computation time: 0.6390557289123535\n",
      "Step: 451, Loss: 1.0039852857589722, Accuracy: 0.65625, Computation time: 0.7600297927856445\n",
      "Step: 452, Loss: 1.574666976928711, Accuracy: 0.5, Computation time: 0.7286810874938965\n",
      "Step: 453, Loss: 1.459998607635498, Accuracy: 0.5625, Computation time: 0.7166581153869629\n",
      "Step: 454, Loss: 1.1744414567947388, Accuracy: 0.625, Computation time: 0.6014280319213867\n",
      "Step: 455, Loss: 1.1932381391525269, Accuracy: 0.53125, Computation time: 0.7162439823150635\n",
      "Step: 456, Loss: 1.1493618488311768, Accuracy: 0.5, Computation time: 0.7410678863525391\n",
      "Step: 457, Loss: 1.5067678689956665, Accuracy: 0.59375, Computation time: 0.8130519390106201\n",
      "Step: 458, Loss: 1.3259789943695068, Accuracy: 0.53125, Computation time: 0.7417340278625488\n",
      "Step: 459, Loss: 1.3687580823898315, Accuracy: 0.6875, Computation time: 0.5883471965789795\n",
      "Step: 460, Loss: 1.5249662399291992, Accuracy: 0.40625, Computation time: 0.667902946472168\n",
      "Step: 461, Loss: 0.9645277261734009, Accuracy: 0.65625, Computation time: 0.7073802947998047\n",
      "Step: 462, Loss: 1.5704716444015503, Accuracy: 0.625, Computation time: 0.666956901550293\n",
      "Step: 463, Loss: 1.8477493524551392, Accuracy: 0.4375, Computation time: 0.6023509502410889\n",
      "Step: 464, Loss: 1.7859506607055664, Accuracy: 0.4375, Computation time: 0.8551139831542969\n",
      "Step: 465, Loss: 1.4624913930892944, Accuracy: 0.5, Computation time: 0.7958002090454102\n",
      "Step: 466, Loss: 1.5693227052688599, Accuracy: 0.46875, Computation time: 0.6136336326599121\n",
      "Step: 467, Loss: 1.4731652736663818, Accuracy: 0.65625, Computation time: 0.6645011901855469\n",
      "Step: 468, Loss: 1.4922535419464111, Accuracy: 0.53125, Computation time: 0.6135129928588867\n",
      "Step: 469, Loss: 1.2035531997680664, Accuracy: 0.625, Computation time: 0.6764132976531982\n",
      "Step: 470, Loss: 1.762795090675354, Accuracy: 0.5, Computation time: 0.6989789009094238\n",
      "Step: 471, Loss: 1.2383216619491577, Accuracy: 0.59375, Computation time: 0.703603982925415\n",
      "Step: 472, Loss: 1.5144788026809692, Accuracy: 0.5625, Computation time: 0.5581080913543701\n",
      "Step: 473, Loss: 1.3228814601898193, Accuracy: 0.53125, Computation time: 0.7153449058532715\n",
      "Step: 474, Loss: 1.813818097114563, Accuracy: 0.5, Computation time: 0.83319091796875\n",
      "Step: 475, Loss: 1.3378278017044067, Accuracy: 0.6875, Computation time: 0.6057009696960449\n",
      "Step: 476, Loss: 1.4048888683319092, Accuracy: 0.5, Computation time: 0.7006309032440186\n",
      "Step: 477, Loss: 1.441814661026001, Accuracy: 0.53125, Computation time: 0.9283041954040527\n",
      "Step: 478, Loss: 1.4054139852523804, Accuracy: 0.46875, Computation time: 0.7370970249176025\n",
      "Step: 479, Loss: 1.4882922172546387, Accuracy: 0.53125, Computation time: 1.0121991634368896\n",
      "Step: 480, Loss: 1.2474033832550049, Accuracy: 0.5625, Computation time: 0.5833783149719238\n",
      "Step: 481, Loss: 1.0710598230361938, Accuracy: 0.59375, Computation time: 0.6995019912719727\n",
      "Step: 482, Loss: 1.1730809211730957, Accuracy: 0.75, Computation time: 0.7816488742828369\n",
      "Step: 483, Loss: 1.1133015155792236, Accuracy: 0.65625, Computation time: 0.6327810287475586\n",
      "Step: 484, Loss: 1.1265525817871094, Accuracy: 0.6875, Computation time: 0.6230089664459229\n",
      "Step: 485, Loss: 2.015472173690796, Accuracy: 0.40625, Computation time: 0.6726720333099365\n",
      "Step: 486, Loss: 1.3267834186553955, Accuracy: 0.75, Computation time: 0.9266738891601562\n",
      "Step: 487, Loss: 1.246225118637085, Accuracy: 0.625, Computation time: 0.7071490287780762\n",
      "Step: 488, Loss: 1.4317549467086792, Accuracy: 0.5, Computation time: 0.6899142265319824\n",
      "Step: 489, Loss: 1.4874804019927979, Accuracy: 0.46875, Computation time: 0.7836241722106934\n",
      "Step: 490, Loss: 1.1238594055175781, Accuracy: 0.59375, Computation time: 0.6512019634246826\n",
      "Step: 491, Loss: 1.5558891296386719, Accuracy: 0.5625, Computation time: 0.7384839057922363\n",
      "Step: 492, Loss: 1.385797381401062, Accuracy: 0.59375, Computation time: 0.7537548542022705\n",
      "Step: 493, Loss: 1.4650144577026367, Accuracy: 0.53125, Computation time: 0.8555350303649902\n",
      "Step: 494, Loss: 1.2997796535491943, Accuracy: 0.625, Computation time: 0.7025599479675293\n",
      "Step: 495, Loss: 1.5490899085998535, Accuracy: 0.4375, Computation time: 0.720566987991333\n",
      "Step: 496, Loss: 1.162224531173706, Accuracy: 0.65625, Computation time: 1.0516862869262695\n",
      "Step: 497, Loss: 1.1439846754074097, Accuracy: 0.65625, Computation time: 6.244263172149658\n",
      "Step: 498, Loss: 2.2331655025482178, Accuracy: 0.3125, Computation time: 0.8752930164337158\n",
      "Step: 499, Loss: 1.4497357606887817, Accuracy: 0.53125, Computation time: 0.6954219341278076\n",
      "Step: 500, Loss: 1.0959018468856812, Accuracy: 0.59375, Computation time: 0.6433510780334473\n",
      "Step: 501, Loss: 1.4960554838180542, Accuracy: 0.34375, Computation time: 0.8097448348999023\n",
      "Step: 502, Loss: 1.0942367315292358, Accuracy: 0.6875, Computation time: 1.1990330219268799\n",
      "Step: 503, Loss: 1.2955656051635742, Accuracy: 0.5625, Computation time: 0.6476950645446777\n",
      "Step: 504, Loss: 1.0030758380889893, Accuracy: 0.65625, Computation time: 0.8609373569488525\n",
      "Step: 505, Loss: 1.4494330883026123, Accuracy: 0.59375, Computation time: 0.7040650844573975\n",
      "Step: 506, Loss: 1.221717357635498, Accuracy: 0.65625, Computation time: 0.8580102920532227\n",
      "Step: 507, Loss: 1.6238676309585571, Accuracy: 0.4375, Computation time: 0.7232420444488525\n",
      "Step: 508, Loss: 1.1448020935058594, Accuracy: 0.6875, Computation time: 0.8085758686065674\n",
      "Step: 509, Loss: 1.309198260307312, Accuracy: 0.65625, Computation time: 1.2774698734283447\n",
      "Step: 510, Loss: 1.192807912826538, Accuracy: 0.59375, Computation time: 0.6803839206695557\n",
      "Step: 511, Loss: 1.3391064405441284, Accuracy: 0.625, Computation time: 0.8186209201812744\n",
      "Step: 512, Loss: 1.1566575765609741, Accuracy: 0.5625, Computation time: 0.9964280128479004\n",
      "Step: 513, Loss: 1.0936520099639893, Accuracy: 0.6875, Computation time: 0.783843994140625\n",
      "Step: 514, Loss: 1.1535625457763672, Accuracy: 0.53125, Computation time: 0.7279291152954102\n",
      "Step: 515, Loss: 1.1456098556518555, Accuracy: 0.625, Computation time: 0.6152639389038086\n",
      "Step: 516, Loss: 1.4202829599380493, Accuracy: 0.625, Computation time: 1.2167928218841553\n",
      "Step: 517, Loss: 1.4931946992874146, Accuracy: 0.46875, Computation time: 0.8050680160522461\n",
      "Step: 518, Loss: 1.4025123119354248, Accuracy: 0.5, Computation time: 0.6980962753295898\n",
      "Step: 519, Loss: 1.1871994733810425, Accuracy: 0.5625, Computation time: 0.8459591865539551\n",
      "Step: 520, Loss: 1.6045552492141724, Accuracy: 0.5625, Computation time: 0.5909061431884766\n",
      "Step: 521, Loss: 1.2903144359588623, Accuracy: 0.53125, Computation time: 0.7319011688232422\n",
      "Step: 522, Loss: 1.6720116138458252, Accuracy: 0.59375, Computation time: 1.1314527988433838\n",
      "Step: 523, Loss: 1.2053560018539429, Accuracy: 0.71875, Computation time: 0.7671120166778564\n",
      "Step: 524, Loss: 1.3252906799316406, Accuracy: 0.6875, Computation time: 0.6462500095367432\n",
      "Step: 525, Loss: 1.0323702096939087, Accuracy: 0.8125, Computation time: 0.8003151416778564\n",
      "Step: 526, Loss: 1.2582100629806519, Accuracy: 0.65625, Computation time: 0.747061014175415\n",
      "Step: 527, Loss: 1.288548469543457, Accuracy: 0.71875, Computation time: 0.65962815284729\n",
      "Step: 528, Loss: 0.9183499813079834, Accuracy: 0.65625, Computation time: 0.8095130920410156\n",
      "Step: 529, Loss: 2.1079652309417725, Accuracy: 0.46875, Computation time: 0.7411618232727051\n",
      "Step: 530, Loss: 1.5393723249435425, Accuracy: 0.53125, Computation time: 0.6931519508361816\n",
      "Step: 531, Loss: 1.2664000988006592, Accuracy: 0.59375, Computation time: 0.6957550048828125\n",
      "Step: 532, Loss: 1.050297737121582, Accuracy: 0.6875, Computation time: 0.6860170364379883\n",
      "Step: 533, Loss: 1.3904697895050049, Accuracy: 0.53125, Computation time: 0.6953637599945068\n",
      "Step: 534, Loss: 1.1909189224243164, Accuracy: 0.65625, Computation time: 0.783839225769043\n",
      "Step: 535, Loss: 1.5065120458602905, Accuracy: 0.65625, Computation time: 0.6731042861938477\n",
      "Step: 536, Loss: 1.4152277708053589, Accuracy: 0.5625, Computation time: 0.7129840850830078\n",
      "Step: 537, Loss: 1.557624101638794, Accuracy: 0.53125, Computation time: 0.7547919750213623\n",
      "Step: 538, Loss: 1.1288414001464844, Accuracy: 0.59375, Computation time: 0.7095510959625244\n",
      "Step: 539, Loss: 0.9733537435531616, Accuracy: 0.59375, Computation time: 0.6183719635009766\n",
      "Step: 540, Loss: 1.4225188493728638, Accuracy: 0.59375, Computation time: 0.5579471588134766\n",
      "Step: 541, Loss: 1.1225214004516602, Accuracy: 0.59375, Computation time: 0.9053840637207031\n",
      "Step: 542, Loss: 1.3502576351165771, Accuracy: 0.625, Computation time: 0.7911586761474609\n",
      "Step: 543, Loss: 1.015450119972229, Accuracy: 0.65625, Computation time: 0.7569658756256104\n",
      "Step: 544, Loss: 1.3617968559265137, Accuracy: 0.5625, Computation time: 0.7260298728942871\n",
      "Step: 545, Loss: 1.2457644939422607, Accuracy: 0.65625, Computation time: 0.7497611045837402\n",
      "Step: 546, Loss: 1.2097219228744507, Accuracy: 0.6875, Computation time: 0.7634179592132568\n",
      "Step: 547, Loss: 1.0858066082000732, Accuracy: 0.625, Computation time: 0.9012517929077148\n",
      "Step: 548, Loss: 1.1101042032241821, Accuracy: 0.65625, Computation time: 0.7394819259643555\n",
      "Step: 549, Loss: 1.1752312183380127, Accuracy: 0.625, Computation time: 0.8450109958648682\n",
      "Step: 550, Loss: 0.8121070861816406, Accuracy: 0.78125, Computation time: 0.6434528827667236\n",
      "Step: 551, Loss: 1.3053687810897827, Accuracy: 0.53125, Computation time: 0.6249861717224121\n",
      "Step: 552, Loss: 1.2197654247283936, Accuracy: 0.65625, Computation time: 0.9217767715454102\n",
      "Step: 553, Loss: 1.520354986190796, Accuracy: 0.4375, Computation time: 0.7221288681030273\n",
      "Step: 554, Loss: 1.3015735149383545, Accuracy: 0.625, Computation time: 0.9241352081298828\n",
      "Step: 555, Loss: 0.9015269875526428, Accuracy: 0.75, Computation time: 0.6997199058532715\n",
      "Step: 556, Loss: 1.216663122177124, Accuracy: 0.625, Computation time: 0.6810979843139648\n",
      "Step: 557, Loss: 1.5354799032211304, Accuracy: 0.6875, Computation time: 0.8908469676971436\n",
      "Step: 558, Loss: 1.4956793785095215, Accuracy: 0.625, Computation time: 0.6847789287567139\n",
      "Step: 559, Loss: 1.7504383325576782, Accuracy: 0.34375, Computation time: 0.766042947769165\n",
      "Step: 560, Loss: 1.454416275024414, Accuracy: 0.5625, Computation time: 0.6636378765106201\n",
      "Step: 561, Loss: 1.3476053476333618, Accuracy: 0.5, Computation time: 0.7779090404510498\n",
      "Step: 562, Loss: 1.2289259433746338, Accuracy: 0.625, Computation time: 1.1939959526062012\n",
      "Step: 563, Loss: 1.6054333448410034, Accuracy: 0.375, Computation time: 1.0184388160705566\n",
      "Step: 564, Loss: 1.7334706783294678, Accuracy: 0.59375, Computation time: 0.7557690143585205\n",
      "Step: 565, Loss: 1.2878726720809937, Accuracy: 0.53125, Computation time: 0.8847248554229736\n",
      "Step: 566, Loss: 1.3726742267608643, Accuracy: 0.53125, Computation time: 0.7549340724945068\n",
      "Step: 567, Loss: 1.6352200508117676, Accuracy: 0.46875, Computation time: 0.8321940898895264\n",
      "Step: 568, Loss: 1.4161373376846313, Accuracy: 0.5625, Computation time: 0.6490249633789062\n",
      "Step: 569, Loss: 1.0631370544433594, Accuracy: 0.65625, Computation time: 0.7185721397399902\n",
      "Step: 570, Loss: 1.1529135704040527, Accuracy: 0.5, Computation time: 0.747981071472168\n",
      "Step: 571, Loss: 1.2331359386444092, Accuracy: 0.625, Computation time: 0.6337811946868896\n",
      "Step: 572, Loss: 1.4257392883300781, Accuracy: 0.5, Computation time: 0.7875192165374756\n",
      "Step: 573, Loss: 1.4966593980789185, Accuracy: 0.59375, Computation time: 0.7924530506134033\n",
      "Step: 574, Loss: 1.2349094152450562, Accuracy: 0.53125, Computation time: 0.7584438323974609\n",
      "Step: 575, Loss: 0.9356905221939087, Accuracy: 0.6875, Computation time: 0.7354562282562256\n",
      "Step: 576, Loss: 0.8121482729911804, Accuracy: 0.6875, Computation time: 0.6475701332092285\n",
      "Step: 577, Loss: 1.6370211839675903, Accuracy: 0.65625, Computation time: 0.797680139541626\n",
      "Step: 578, Loss: 0.828612208366394, Accuracy: 0.84375, Computation time: 0.7538042068481445\n",
      "Step: 579, Loss: 1.499340295791626, Accuracy: 0.4375, Computation time: 0.802232027053833\n",
      "Step: 580, Loss: 1.4559125900268555, Accuracy: 0.59375, Computation time: 0.6494917869567871\n",
      "Step: 581, Loss: 1.4484789371490479, Accuracy: 0.5, Computation time: 0.7309019565582275\n",
      "Step: 582, Loss: 1.635147213935852, Accuracy: 0.4375, Computation time: 0.7051980495452881\n",
      "Step: 583, Loss: 1.2178609371185303, Accuracy: 0.5625, Computation time: 0.731658935546875\n",
      "Step: 584, Loss: 1.0715587139129639, Accuracy: 0.71875, Computation time: 0.8226759433746338\n",
      "Step: 585, Loss: 1.2224942445755005, Accuracy: 0.625, Computation time: 0.6012539863586426\n",
      "Step: 586, Loss: 0.7974470853805542, Accuracy: 0.78125, Computation time: 0.7152729034423828\n",
      "Step: 587, Loss: 0.8984040021896362, Accuracy: 0.71875, Computation time: 1.1214001178741455\n",
      "Step: 588, Loss: 1.5183889865875244, Accuracy: 0.59375, Computation time: 0.7800390720367432\n",
      "Step: 589, Loss: 1.0711296796798706, Accuracy: 0.625, Computation time: 0.7804369926452637\n",
      "Step: 590, Loss: 1.134998083114624, Accuracy: 0.5625, Computation time: 1.0018107891082764\n",
      "Step: 591, Loss: 1.1887534856796265, Accuracy: 0.71875, Computation time: 0.5950891971588135\n",
      "Step: 592, Loss: 1.9970604181289673, Accuracy: 0.5, Computation time: 1.1729669570922852\n",
      "Step: 593, Loss: 0.8845329880714417, Accuracy: 0.6875, Computation time: 0.7726969718933105\n",
      "Step: 594, Loss: 1.5414201021194458, Accuracy: 0.53125, Computation time: 0.6199727058410645\n",
      "Step: 595, Loss: 1.334531307220459, Accuracy: 0.59375, Computation time: 0.6511080265045166\n",
      "Step: 596, Loss: 1.6349890232086182, Accuracy: 0.5625, Computation time: 0.6742119789123535\n",
      "Step: 597, Loss: 1.6683974266052246, Accuracy: 0.53125, Computation time: 0.7803430557250977\n",
      "Step: 598, Loss: 1.011830449104309, Accuracy: 0.71875, Computation time: 0.6818532943725586\n",
      "Step: 599, Loss: 1.3821616172790527, Accuracy: 0.53125, Computation time: 0.595566987991333\n",
      "Step: 600, Loss: 1.5300554037094116, Accuracy: 0.5, Computation time: 0.8096439838409424\n",
      "Step: 601, Loss: 1.2263530492782593, Accuracy: 0.59375, Computation time: 0.8156938552856445\n",
      "Step: 602, Loss: 0.7163546681404114, Accuracy: 0.8125, Computation time: 0.704481840133667\n",
      "Step: 603, Loss: 1.2383784055709839, Accuracy: 0.5625, Computation time: 0.9649209976196289\n",
      "Step: 604, Loss: 1.7254321575164795, Accuracy: 0.53125, Computation time: 0.6992559432983398\n",
      "Step: 605, Loss: 0.8514450788497925, Accuracy: 0.75, Computation time: 0.8044285774230957\n",
      "Step: 606, Loss: 1.120627522468567, Accuracy: 0.625, Computation time: 0.6812140941619873\n",
      "Step: 607, Loss: 1.5121281147003174, Accuracy: 0.625, Computation time: 0.7316591739654541\n",
      "Step: 608, Loss: 1.12883460521698, Accuracy: 0.625, Computation time: 0.6562018394470215\n",
      "Step: 609, Loss: 0.9618629813194275, Accuracy: 0.6875, Computation time: 0.6711709499359131\n",
      "Step: 610, Loss: 1.3404688835144043, Accuracy: 0.59375, Computation time: 0.6707830429077148\n",
      "Step: 611, Loss: 1.0274227857589722, Accuracy: 0.71875, Computation time: 0.6845428943634033\n",
      "Step: 612, Loss: 1.6522895097732544, Accuracy: 0.59375, Computation time: 0.845745325088501\n",
      "Step: 613, Loss: 1.1448943614959717, Accuracy: 0.6875, Computation time: 0.8973748683929443\n",
      "Step: 614, Loss: 1.8451265096664429, Accuracy: 0.375, Computation time: 0.793442964553833\n",
      "Step: 615, Loss: 0.8043646216392517, Accuracy: 0.75, Computation time: 0.790869951248169\n",
      "Step: 616, Loss: 1.8454383611679077, Accuracy: 0.59375, Computation time: 0.6866202354431152\n",
      "Step: 617, Loss: 1.2105542421340942, Accuracy: 0.5625, Computation time: 0.8573360443115234\n",
      "Step: 618, Loss: 1.199957013130188, Accuracy: 0.625, Computation time: 0.5884249210357666\n",
      "Step: 619, Loss: 1.0702000856399536, Accuracy: 0.65625, Computation time: 0.6974637508392334\n",
      "Step: 620, Loss: 1.2193052768707275, Accuracy: 0.59375, Computation time: 0.8460867404937744\n",
      "Step: 621, Loss: 1.5275700092315674, Accuracy: 0.53125, Computation time: 0.8159770965576172\n",
      "Step: 622, Loss: 1.0180171728134155, Accuracy: 0.78125, Computation time: 0.6589620113372803\n",
      "Step: 623, Loss: 1.5378080606460571, Accuracy: 0.5, Computation time: 0.64068603515625\n",
      "Step: 624, Loss: 1.0597535371780396, Accuracy: 0.75, Computation time: 0.644660234451294\n",
      "Step: 625, Loss: 1.3210933208465576, Accuracy: 0.71875, Computation time: 0.8337290287017822\n",
      "Step: 626, Loss: 1.1828876733779907, Accuracy: 0.53125, Computation time: 0.7156980037689209\n",
      "Step: 627, Loss: 1.4351366758346558, Accuracy: 0.46875, Computation time: 0.7068030834197998\n",
      "Step: 628, Loss: 1.2244831323623657, Accuracy: 0.59375, Computation time: 1.1263542175292969\n",
      "Step: 629, Loss: 0.8597725033760071, Accuracy: 0.65625, Computation time: 0.8217530250549316\n",
      "Step: 630, Loss: 0.7332447171211243, Accuracy: 0.84375, Computation time: 0.7472341060638428\n",
      "Step: 631, Loss: 1.5740488767623901, Accuracy: 0.5, Computation time: 0.6333720684051514\n",
      "Step: 632, Loss: 0.9232267737388611, Accuracy: 0.78125, Computation time: 0.7944731712341309\n",
      "Step: 633, Loss: 1.182892084121704, Accuracy: 0.5625, Computation time: 0.7124800682067871\n",
      "Step: 634, Loss: 1.742715835571289, Accuracy: 0.59375, Computation time: 0.9600281715393066\n",
      "Step: 635, Loss: 1.266959309577942, Accuracy: 0.5625, Computation time: 0.8043780326843262\n",
      "Step: 636, Loss: 1.043994426727295, Accuracy: 0.65625, Computation time: 0.5502450466156006\n",
      "Step: 637, Loss: 1.5943330526351929, Accuracy: 0.59375, Computation time: 0.6865062713623047\n",
      "Step: 638, Loss: 1.2227451801300049, Accuracy: 0.5625, Computation time: 0.7153749465942383\n",
      "Step: 639, Loss: 0.729306697845459, Accuracy: 0.78125, Computation time: 0.6439130306243896\n",
      "Step: 640, Loss: 1.477537751197815, Accuracy: 0.59375, Computation time: 0.6471641063690186\n",
      "Step: 641, Loss: 1.0396393537521362, Accuracy: 0.78125, Computation time: 0.9363253116607666\n",
      "Step: 642, Loss: 1.115007758140564, Accuracy: 0.625, Computation time: 0.8586788177490234\n",
      "Step: 643, Loss: 0.9846735000610352, Accuracy: 0.59375, Computation time: 0.8522148132324219\n",
      "Step: 644, Loss: 0.8244747519493103, Accuracy: 0.71875, Computation time: 0.7299048900604248\n",
      "Step: 645, Loss: 1.0838860273361206, Accuracy: 0.6875, Computation time: 0.7137739658355713\n",
      "Step: 646, Loss: 0.9540528059005737, Accuracy: 0.78125, Computation time: 0.8150079250335693\n",
      "Step: 647, Loss: 1.0475599765777588, Accuracy: 0.6875, Computation time: 0.9755032062530518\n",
      "Step: 648, Loss: 1.3284170627593994, Accuracy: 0.65625, Computation time: 0.9010391235351562\n",
      "Step: 649, Loss: 0.7455577850341797, Accuracy: 0.75, Computation time: 0.5614790916442871\n",
      "Step: 650, Loss: 1.5373375415802002, Accuracy: 0.53125, Computation time: 0.8986828327178955\n",
      "Step: 651, Loss: 1.0724890232086182, Accuracy: 0.625, Computation time: 0.5864109992980957\n",
      "Step: 652, Loss: 1.6068832874298096, Accuracy: 0.5625, Computation time: 0.6828408241271973\n",
      "Step: 653, Loss: 1.1129852533340454, Accuracy: 0.71875, Computation time: 0.685800313949585\n",
      "Step: 654, Loss: 1.0478652715682983, Accuracy: 0.65625, Computation time: 0.6691651344299316\n",
      "Step: 655, Loss: 1.2928364276885986, Accuracy: 0.5, Computation time: 0.6844160556793213\n",
      "Step: 656, Loss: 1.620587944984436, Accuracy: 0.59375, Computation time: 0.8053610324859619\n",
      "Step: 657, Loss: 1.3831300735473633, Accuracy: 0.5625, Computation time: 0.7284929752349854\n",
      "Step: 658, Loss: 1.3535497188568115, Accuracy: 0.65625, Computation time: 0.7352731227874756\n",
      "Step: 659, Loss: 0.9005613327026367, Accuracy: 0.6875, Computation time: 0.6430339813232422\n",
      "Step: 660, Loss: 1.1839784383773804, Accuracy: 0.71875, Computation time: 0.6390020847320557\n",
      "Step: 661, Loss: 1.5072081089019775, Accuracy: 0.65625, Computation time: 0.7090260982513428\n",
      "Step: 662, Loss: 1.4296388626098633, Accuracy: 0.625, Computation time: 0.7486312389373779\n",
      "Step: 663, Loss: 1.3390854597091675, Accuracy: 0.53125, Computation time: 1.1648049354553223\n",
      "Step: 664, Loss: 1.4172505140304565, Accuracy: 0.625, Computation time: 0.6591248512268066\n",
      "Step: 665, Loss: 1.1799119710922241, Accuracy: 0.625, Computation time: 0.619985818862915\n",
      "Step: 666, Loss: 0.8634503483772278, Accuracy: 0.71875, Computation time: 0.7992630004882812\n",
      "Step: 667, Loss: 1.3788042068481445, Accuracy: 0.5625, Computation time: 0.8272078037261963\n",
      "Step: 668, Loss: 0.6967074871063232, Accuracy: 0.8125, Computation time: 0.6749401092529297\n",
      "Step: 669, Loss: 0.7425329685211182, Accuracy: 0.75, Computation time: 0.8763298988342285\n",
      "Step: 670, Loss: 1.1832258701324463, Accuracy: 0.65625, Computation time: 0.6746621131896973\n",
      "Step: 671, Loss: 0.9058462381362915, Accuracy: 0.65625, Computation time: 0.6718552112579346\n",
      "Step: 672, Loss: 1.3902560472488403, Accuracy: 0.46875, Computation time: 0.753587007522583\n",
      "Step: 673, Loss: 1.328962802886963, Accuracy: 0.46875, Computation time: 0.7120919227600098\n",
      "Step: 674, Loss: 0.7703481316566467, Accuracy: 0.8125, Computation time: 1.094736099243164\n",
      "Step: 675, Loss: 1.2465195655822754, Accuracy: 0.65625, Computation time: 0.7851290702819824\n",
      "Step: 676, Loss: 1.1979635953903198, Accuracy: 0.6875, Computation time: 0.8682818412780762\n",
      "Step: 677, Loss: 1.120488166809082, Accuracy: 0.65625, Computation time: 0.7042908668518066\n",
      "Step: 678, Loss: 1.531063199043274, Accuracy: 0.5, Computation time: 0.701420783996582\n",
      "Step: 679, Loss: 1.0323121547698975, Accuracy: 0.65625, Computation time: 0.6649250984191895\n",
      "Step: 680, Loss: 0.9822976589202881, Accuracy: 0.65625, Computation time: 4.691422939300537\n",
      "Step: 681, Loss: 1.959386944770813, Accuracy: 0.34375, Computation time: 0.6265132427215576\n",
      "Step: 682, Loss: 1.1031575202941895, Accuracy: 0.53125, Computation time: 0.6499910354614258\n",
      "Step: 683, Loss: 1.1109378337860107, Accuracy: 0.6875, Computation time: 4.628308057785034\n",
      "Step: 684, Loss: 1.062182903289795, Accuracy: 0.6875, Computation time: 0.6491599082946777\n",
      "Step: 685, Loss: 0.7906991839408875, Accuracy: 0.6875, Computation time: 0.6349360942840576\n",
      "Step: 686, Loss: 0.929669201374054, Accuracy: 0.75, Computation time: 0.7375349998474121\n",
      "Step: 687, Loss: 1.3442273139953613, Accuracy: 0.59375, Computation time: 0.7419829368591309\n",
      "Step: 688, Loss: 1.1198949813842773, Accuracy: 0.59375, Computation time: 0.7722287178039551\n",
      "Step: 689, Loss: 1.4384167194366455, Accuracy: 0.625, Computation time: 0.9390039443969727\n",
      "Step: 690, Loss: 1.1920690536499023, Accuracy: 0.5625, Computation time: 0.6728551387786865\n",
      "Step: 691, Loss: 0.6974582672119141, Accuracy: 0.875, Computation time: 0.7415201663970947\n",
      "Step: 692, Loss: 1.421324610710144, Accuracy: 0.59375, Computation time: 0.6815869808197021\n",
      "Step: 693, Loss: 1.4796538352966309, Accuracy: 0.59375, Computation time: 0.8377187252044678\n",
      "Step: 694, Loss: 1.142924427986145, Accuracy: 0.625, Computation time: 0.6670141220092773\n",
      "Step: 695, Loss: 0.8418221473693848, Accuracy: 0.71875, Computation time: 0.6982059478759766\n",
      "Step: 696, Loss: 1.165235161781311, Accuracy: 0.59375, Computation time: 0.6607978343963623\n",
      "Step: 697, Loss: 1.6169027090072632, Accuracy: 0.5625, Computation time: 0.6943919658660889\n",
      "Step: 698, Loss: 0.8954044580459595, Accuracy: 0.78125, Computation time: 0.7216958999633789\n",
      "Step: 699, Loss: 0.9518595933914185, Accuracy: 0.71875, Computation time: 0.7787249088287354\n",
      "Step: 700, Loss: 1.0817393064498901, Accuracy: 0.71875, Computation time: 0.8704807758331299\n",
      "Step: 701, Loss: 0.9369807839393616, Accuracy: 0.71875, Computation time: 0.7747998237609863\n",
      "Step: 702, Loss: 1.0040007829666138, Accuracy: 0.71875, Computation time: 0.6960551738739014\n",
      "Step: 703, Loss: 1.490572214126587, Accuracy: 0.5625, Computation time: 0.7375478744506836\n",
      "Step: 704, Loss: 1.5571519136428833, Accuracy: 0.46875, Computation time: 0.7086348533630371\n",
      "Step: 705, Loss: 1.0077922344207764, Accuracy: 0.65625, Computation time: 0.7119870185852051\n",
      "Step: 706, Loss: 1.0040278434753418, Accuracy: 0.71875, Computation time: 0.6958580017089844\n",
      "Step: 707, Loss: 1.290399193763733, Accuracy: 0.5, Computation time: 0.8999450206756592\n",
      "Step: 708, Loss: 1.461808681488037, Accuracy: 0.5625, Computation time: 0.8098340034484863\n",
      "Step: 709, Loss: 1.2387712001800537, Accuracy: 0.6875, Computation time: 0.7761819362640381\n",
      "Step: 710, Loss: 1.5970872640609741, Accuracy: 0.65625, Computation time: 0.7745299339294434\n",
      "Step: 711, Loss: 1.4863581657409668, Accuracy: 0.59375, Computation time: 0.9999380111694336\n",
      "Step: 712, Loss: 1.0628833770751953, Accuracy: 0.6875, Computation time: 0.753399133682251\n",
      "Step: 713, Loss: 1.1264963150024414, Accuracy: 0.65625, Computation time: 0.5993480682373047\n",
      "Step: 714, Loss: 1.057350516319275, Accuracy: 0.625, Computation time: 0.6855406761169434\n",
      "Step: 715, Loss: 0.9490364789962769, Accuracy: 0.71875, Computation time: 0.7415528297424316\n",
      "Step: 716, Loss: 1.4916948080062866, Accuracy: 0.46875, Computation time: 0.655545711517334\n",
      "Step: 717, Loss: 0.8819537162780762, Accuracy: 0.75, Computation time: 0.8281981945037842\n",
      "Step: 718, Loss: 0.9866223335266113, Accuracy: 0.71875, Computation time: 0.6450941562652588\n",
      "Step: 719, Loss: 1.0035474300384521, Accuracy: 0.6875, Computation time: 0.92677903175354\n",
      "Step: 720, Loss: 1.2841745615005493, Accuracy: 0.5, Computation time: 0.8316590785980225\n",
      "Step: 721, Loss: 1.0352991819381714, Accuracy: 0.71875, Computation time: 0.8485500812530518\n",
      "Step: 722, Loss: 1.4444676637649536, Accuracy: 0.46875, Computation time: 0.7712557315826416\n",
      "Step: 723, Loss: 1.2327401638031006, Accuracy: 0.71875, Computation time: 1.19769287109375\n",
      "Step: 724, Loss: 0.8351849913597107, Accuracy: 0.75, Computation time: 0.7746641635894775\n",
      "Step: 725, Loss: 1.3802684545516968, Accuracy: 0.5625, Computation time: 0.7372968196868896\n",
      "Step: 726, Loss: 0.9882175922393799, Accuracy: 0.625, Computation time: 0.7232491970062256\n",
      "Step: 727, Loss: 0.5926223397254944, Accuracy: 0.875, Computation time: 0.7187788486480713\n",
      "Step: 728, Loss: 1.0129482746124268, Accuracy: 0.71875, Computation time: 0.7209689617156982\n",
      "Step: 729, Loss: 1.0116522312164307, Accuracy: 0.75, Computation time: 0.7190778255462646\n",
      "Step: 730, Loss: 0.8288535475730896, Accuracy: 0.71875, Computation time: 0.7301080226898193\n",
      "Step: 731, Loss: 1.2926652431488037, Accuracy: 0.5625, Computation time: 0.7110283374786377\n",
      "Step: 732, Loss: 0.8938825726509094, Accuracy: 0.6875, Computation time: 0.6781558990478516\n",
      "Step: 733, Loss: 1.2603013515472412, Accuracy: 0.71875, Computation time: 0.7113921642303467\n",
      "Step: 734, Loss: 1.1834098100662231, Accuracy: 0.71875, Computation time: 0.8785750865936279\n",
      "Step: 735, Loss: 1.3274933099746704, Accuracy: 0.625, Computation time: 0.7185609340667725\n",
      "Step: 736, Loss: 1.2964173555374146, Accuracy: 0.5, Computation time: 0.7947239875793457\n",
      "Step: 737, Loss: 0.8910769820213318, Accuracy: 0.78125, Computation time: 0.813305139541626\n",
      "Step: 738, Loss: 1.686410903930664, Accuracy: 0.46875, Computation time: 0.7857418060302734\n",
      "Step: 739, Loss: 1.2046183347702026, Accuracy: 0.625, Computation time: 0.7196950912475586\n",
      "Step: 740, Loss: 1.2027404308319092, Accuracy: 0.6875, Computation time: 0.7236130237579346\n",
      "Step: 741, Loss: 1.106194257736206, Accuracy: 0.75, Computation time: 0.6429641246795654\n",
      "Step: 742, Loss: 1.173717975616455, Accuracy: 0.53125, Computation time: 0.9350748062133789\n",
      "Step: 743, Loss: 1.3003100156784058, Accuracy: 0.59375, Computation time: 0.9136524200439453\n",
      "Step: 744, Loss: 0.8784263730049133, Accuracy: 0.75, Computation time: 0.9915668964385986\n",
      "Step: 745, Loss: 0.9089865684509277, Accuracy: 0.65625, Computation time: 0.716865062713623\n",
      "Step: 746, Loss: 0.683523416519165, Accuracy: 0.75, Computation time: 0.6794309616088867\n",
      "Step: 747, Loss: 1.0722389221191406, Accuracy: 0.6875, Computation time: 1.0250952243804932\n",
      "Step: 748, Loss: 1.1331586837768555, Accuracy: 0.71875, Computation time: 0.8210821151733398\n",
      "Step: 749, Loss: 0.8824504613876343, Accuracy: 0.65625, Computation time: 0.792529821395874\n",
      "Step: 750, Loss: 1.1220208406448364, Accuracy: 0.5625, Computation time: 0.8289840221405029\n",
      "Step: 751, Loss: 1.1951332092285156, Accuracy: 0.53125, Computation time: 4.805665016174316\n",
      "Step: 752, Loss: 1.3347868919372559, Accuracy: 0.6875, Computation time: 1.0567617416381836\n",
      "Step: 753, Loss: 0.9033284187316895, Accuracy: 0.625, Computation time: 0.835716962814331\n",
      "Step: 754, Loss: 1.1781127452850342, Accuracy: 0.65625, Computation time: 0.741523027420044\n",
      "Step: 755, Loss: 0.8431620001792908, Accuracy: 0.625, Computation time: 0.7691881656646729\n",
      "Step: 756, Loss: 1.3125747442245483, Accuracy: 0.59375, Computation time: 0.796558141708374\n",
      "Step: 757, Loss: 1.1807466745376587, Accuracy: 0.625, Computation time: 0.7975599765777588\n",
      "Step: 758, Loss: 0.8698291182518005, Accuracy: 0.71875, Computation time: 0.824599027633667\n",
      "Step: 759, Loss: 1.4617555141448975, Accuracy: 0.40625, Computation time: 0.6322171688079834\n",
      "Step: 760, Loss: 1.002276062965393, Accuracy: 0.59375, Computation time: 0.827031135559082\n",
      "Step: 761, Loss: 0.6612668037414551, Accuracy: 0.65625, Computation time: 0.7342941761016846\n",
      "Step: 762, Loss: 1.0391197204589844, Accuracy: 0.75, Computation time: 0.6492209434509277\n",
      "Step: 763, Loss: 1.1169449090957642, Accuracy: 0.6875, Computation time: 0.8893387317657471\n",
      "Step: 764, Loss: 1.1025757789611816, Accuracy: 0.75, Computation time: 0.9323129653930664\n",
      "Step: 765, Loss: 1.4619284868240356, Accuracy: 0.53125, Computation time: 0.8290629386901855\n",
      "Step: 766, Loss: 1.6435331106185913, Accuracy: 0.4375, Computation time: 0.830826997756958\n",
      "Step: 767, Loss: 1.542895793914795, Accuracy: 0.5, Computation time: 0.7849071025848389\n",
      "Step: 768, Loss: 1.1525444984436035, Accuracy: 0.625, Computation time: 0.7558116912841797\n",
      "Step: 769, Loss: 1.267220377922058, Accuracy: 0.5625, Computation time: 0.8747279644012451\n",
      "Step: 770, Loss: 0.9905426502227783, Accuracy: 0.5625, Computation time: 0.8202712535858154\n",
      "Step: 771, Loss: 1.323106288909912, Accuracy: 0.59375, Computation time: 0.710521936416626\n",
      "Step: 772, Loss: 0.6723069548606873, Accuracy: 0.8125, Computation time: 0.7389860153198242\n",
      "Step: 773, Loss: 0.9494553208351135, Accuracy: 0.75, Computation time: 0.6021900177001953\n",
      "Step: 774, Loss: 1.0634695291519165, Accuracy: 0.71875, Computation time: 0.7600498199462891\n",
      "Step: 775, Loss: 0.8477559089660645, Accuracy: 0.78125, Computation time: 0.7131872177124023\n",
      "Step: 776, Loss: 1.0754953622817993, Accuracy: 0.6875, Computation time: 0.7148778438568115\n",
      "Step: 777, Loss: 1.225543737411499, Accuracy: 0.65625, Computation time: 0.684053897857666\n",
      "Step: 778, Loss: 1.33708655834198, Accuracy: 0.65625, Computation time: 0.7653548717498779\n",
      "Step: 779, Loss: 1.4409433603286743, Accuracy: 0.5, Computation time: 0.7191691398620605\n",
      "Step: 780, Loss: 1.1346502304077148, Accuracy: 0.6875, Computation time: 0.7700929641723633\n",
      "Step: 781, Loss: 1.2436916828155518, Accuracy: 0.5625, Computation time: 0.6863517761230469\n",
      "Step: 782, Loss: 1.0073598623275757, Accuracy: 0.625, Computation time: 0.73567795753479\n",
      "Step: 783, Loss: 0.8538569808006287, Accuracy: 0.625, Computation time: 0.7232210636138916\n",
      "Step: 784, Loss: 0.8686950206756592, Accuracy: 0.8125, Computation time: 0.8973209857940674\n",
      "Step: 785, Loss: 1.102396011352539, Accuracy: 0.625, Computation time: 6.006722688674927\n",
      "Step: 786, Loss: 1.0554914474487305, Accuracy: 0.65625, Computation time: 0.7621381282806396\n",
      "Step: 787, Loss: 1.2365570068359375, Accuracy: 0.625, Computation time: 0.7490990161895752\n",
      "Step: 788, Loss: 1.0217740535736084, Accuracy: 0.65625, Computation time: 0.846372127532959\n",
      "Step: 789, Loss: 1.047967791557312, Accuracy: 0.71875, Computation time: 0.6863358020782471\n",
      "Step: 790, Loss: 1.1930618286132812, Accuracy: 0.625, Computation time: 0.7000687122344971\n",
      "Step: 791, Loss: 1.3169732093811035, Accuracy: 0.75, Computation time: 0.7370660305023193\n",
      "Step: 792, Loss: 1.0649588108062744, Accuracy: 0.71875, Computation time: 0.7807962894439697\n",
      "Step: 793, Loss: 1.3219900131225586, Accuracy: 0.6875, Computation time: 0.6699419021606445\n",
      "Step: 794, Loss: 1.291993260383606, Accuracy: 0.59375, Computation time: 0.6726400852203369\n",
      "Step: 795, Loss: 1.4586809873580933, Accuracy: 0.65625, Computation time: 0.7988519668579102\n",
      "Step: 796, Loss: 1.4573659896850586, Accuracy: 0.59375, Computation time: 0.7692899703979492\n",
      "Step: 797, Loss: 1.4622899293899536, Accuracy: 0.5, Computation time: 0.7855138778686523\n",
      "Step: 798, Loss: 0.5953484773635864, Accuracy: 0.84375, Computation time: 0.6518173217773438\n",
      "Step: 799, Loss: 1.200426459312439, Accuracy: 0.625, Computation time: 0.6072700023651123\n",
      "Step: 800, Loss: 1.2051736116409302, Accuracy: 0.6875, Computation time: 0.657252311706543\n",
      "Step: 801, Loss: 1.2665355205535889, Accuracy: 0.5625, Computation time: 0.6764988899230957\n",
      "Step: 802, Loss: 0.9812778234481812, Accuracy: 0.65625, Computation time: 0.6186277866363525\n",
      "Step: 803, Loss: 1.0699950456619263, Accuracy: 0.65625, Computation time: 1.0241990089416504\n",
      "Step: 804, Loss: 1.0479985475540161, Accuracy: 0.59375, Computation time: 0.7417469024658203\n",
      "Step: 805, Loss: 1.1575970649719238, Accuracy: 0.625, Computation time: 0.825714111328125\n",
      "Step: 806, Loss: 1.1309748888015747, Accuracy: 0.625, Computation time: 0.7035181522369385\n",
      "Step: 807, Loss: 1.2087031602859497, Accuracy: 0.65625, Computation time: 0.8165230751037598\n",
      "Step: 808, Loss: 1.7233150005340576, Accuracy: 0.46875, Computation time: 0.7357370853424072\n",
      "Step: 809, Loss: 1.2917189598083496, Accuracy: 0.5, Computation time: 0.8268311023712158\n",
      "Step: 810, Loss: 1.0373849868774414, Accuracy: 0.71875, Computation time: 0.8000500202178955\n",
      "Step: 811, Loss: 0.9866837859153748, Accuracy: 0.78125, Computation time: 0.7055189609527588\n",
      "Step: 812, Loss: 1.0666624307632446, Accuracy: 0.65625, Computation time: 0.6851580142974854\n",
      "Step: 813, Loss: 1.3043330907821655, Accuracy: 0.625, Computation time: 0.8397576808929443\n",
      "Step: 814, Loss: 0.9738561511039734, Accuracy: 0.75, Computation time: 0.6265439987182617\n",
      "Step: 815, Loss: 1.153312087059021, Accuracy: 0.65625, Computation time: 0.8405871391296387\n",
      "Step: 816, Loss: 1.5299588441848755, Accuracy: 0.53125, Computation time: 0.8701035976409912\n",
      "Step: 817, Loss: 0.8343382477760315, Accuracy: 0.6875, Computation time: 0.7551250457763672\n",
      "Step: 818, Loss: 1.1105009317398071, Accuracy: 0.59375, Computation time: 0.87298583984375\n",
      "Step: 819, Loss: 0.8595616221427917, Accuracy: 0.6875, Computation time: 0.7675940990447998\n",
      "Step: 820, Loss: 0.7588498592376709, Accuracy: 0.8125, Computation time: 0.6999220848083496\n",
      "Step: 821, Loss: 0.9524171352386475, Accuracy: 0.75, Computation time: 1.4287769794464111\n",
      "Step: 822, Loss: 1.3416937589645386, Accuracy: 0.53125, Computation time: 0.7563619613647461\n",
      "Step: 823, Loss: 1.04929518699646, Accuracy: 0.625, Computation time: 0.8365299701690674\n",
      "Step: 824, Loss: 1.0619112253189087, Accuracy: 0.6875, Computation time: 0.6259341239929199\n",
      "Step: 825, Loss: 0.5998412370681763, Accuracy: 0.90625, Computation time: 0.8575851917266846\n",
      "Step: 826, Loss: 1.1263718605041504, Accuracy: 0.71875, Computation time: 0.7401790618896484\n",
      "Step: 827, Loss: 1.1988688707351685, Accuracy: 0.59375, Computation time: 0.7784359455108643\n",
      "Step: 828, Loss: 1.3345839977264404, Accuracy: 0.5, Computation time: 0.708319902420044\n",
      "Step: 829, Loss: 1.2929315567016602, Accuracy: 0.6875, Computation time: 0.7883589267730713\n",
      "Step: 830, Loss: 0.9042661190032959, Accuracy: 0.75, Computation time: 0.9315931797027588\n",
      "Step: 831, Loss: 1.33546781539917, Accuracy: 0.6875, Computation time: 0.7240772247314453\n",
      "Step: 832, Loss: 1.391240119934082, Accuracy: 0.5625, Computation time: 0.858802080154419\n",
      "Step: 833, Loss: 0.8244857788085938, Accuracy: 0.8125, Computation time: 0.9223301410675049\n",
      "Step: 834, Loss: 1.260538101196289, Accuracy: 0.53125, Computation time: 0.7356898784637451\n",
      "Step: 835, Loss: 1.3303276300430298, Accuracy: 0.625, Computation time: 0.7181899547576904\n",
      "Step: 836, Loss: 0.9055930376052856, Accuracy: 0.71875, Computation time: 0.6662960052490234\n",
      "Step: 837, Loss: 1.468003273010254, Accuracy: 0.59375, Computation time: 0.7445569038391113\n",
      "Step: 838, Loss: 1.1995972394943237, Accuracy: 0.625, Computation time: 0.9563891887664795\n",
      "Step: 839, Loss: 1.0438661575317383, Accuracy: 0.59375, Computation time: 0.5732748508453369\n",
      "Step: 840, Loss: 1.0291101932525635, Accuracy: 0.65625, Computation time: 0.6435761451721191\n",
      "Step: 841, Loss: 2.0717766284942627, Accuracy: 0.53125, Computation time: 0.8270869255065918\n",
      "Step: 842, Loss: 1.1083831787109375, Accuracy: 0.71875, Computation time: 0.6776859760284424\n",
      "Step: 843, Loss: 0.8650347590446472, Accuracy: 0.78125, Computation time: 0.7590711116790771\n",
      "Step: 844, Loss: 1.47410249710083, Accuracy: 0.53125, Computation time: 0.8200592994689941\n",
      "Step: 845, Loss: 1.5419633388519287, Accuracy: 0.625, Computation time: 1.193195104598999\n",
      "Step: 846, Loss: 0.7482972741127014, Accuracy: 0.71875, Computation time: 0.6997082233428955\n",
      "Step: 847, Loss: 0.9212123155593872, Accuracy: 0.75, Computation time: 0.6122310161590576\n",
      "Step: 848, Loss: 1.1961073875427246, Accuracy: 0.59375, Computation time: 0.7560639381408691\n",
      "Step: 849, Loss: 0.9917073249816895, Accuracy: 0.6875, Computation time: 1.3425688743591309\n",
      "Step: 850, Loss: 1.293958067893982, Accuracy: 0.59375, Computation time: 0.6899950504302979\n",
      "Step: 851, Loss: 0.9215168356895447, Accuracy: 0.6875, Computation time: 0.6773278713226318\n",
      "Step: 852, Loss: 1.0810643434524536, Accuracy: 0.59375, Computation time: 0.6537179946899414\n",
      "Step: 853, Loss: 1.1653438806533813, Accuracy: 0.5625, Computation time: 0.7411019802093506\n",
      "Step: 854, Loss: 0.8781768679618835, Accuracy: 0.75, Computation time: 0.8637280464172363\n",
      "Step: 855, Loss: 0.7351047992706299, Accuracy: 0.78125, Computation time: 0.6736719608306885\n",
      "Step: 856, Loss: 1.206648826599121, Accuracy: 0.71875, Computation time: 0.6921772956848145\n",
      "Step: 857, Loss: 0.7637023329734802, Accuracy: 0.84375, Computation time: 0.7211039066314697\n",
      "Step: 858, Loss: 1.4627231359481812, Accuracy: 0.5625, Computation time: 0.8208630084991455\n",
      "Step: 859, Loss: 1.0295449495315552, Accuracy: 0.65625, Computation time: 0.8289468288421631\n",
      "Step: 860, Loss: 0.9254841804504395, Accuracy: 0.78125, Computation time: 0.845189094543457\n",
      "Step: 861, Loss: 1.1592912673950195, Accuracy: 0.75, Computation time: 0.7961499691009521\n",
      "Step: 862, Loss: 1.3425605297088623, Accuracy: 0.59375, Computation time: 0.7655038833618164\n",
      "Step: 863, Loss: 1.2710723876953125, Accuracy: 0.59375, Computation time: 0.6426057815551758\n",
      "Step: 864, Loss: 0.7768709063529968, Accuracy: 0.75, Computation time: 0.6437301635742188\n",
      "Step: 865, Loss: 0.7444682121276855, Accuracy: 0.78125, Computation time: 0.7114372253417969\n",
      "Step: 866, Loss: 0.8682371973991394, Accuracy: 0.6875, Computation time: 0.8828580379486084\n",
      "Step: 867, Loss: 0.8329261541366577, Accuracy: 0.75, Computation time: 0.7511770725250244\n",
      "Step: 868, Loss: 1.2246851921081543, Accuracy: 0.625, Computation time: 0.681276798248291\n",
      "Step: 869, Loss: 0.9854209423065186, Accuracy: 0.71875, Computation time: 0.9216341972351074\n",
      "Step: 870, Loss: 0.997756838798523, Accuracy: 0.59375, Computation time: 0.6922070980072021\n",
      "Step: 871, Loss: 0.6051120162010193, Accuracy: 0.84375, Computation time: 0.6934361457824707\n",
      "Step: 872, Loss: 1.103352665901184, Accuracy: 0.75, Computation time: 1.0770211219787598\n",
      "Step: 873, Loss: 1.1779603958129883, Accuracy: 0.65625, Computation time: 0.7985448837280273\n",
      "Step: 874, Loss: 0.7668774127960205, Accuracy: 0.8125, Computation time: 0.7783181667327881\n",
      "Step: 875, Loss: 1.1103284358978271, Accuracy: 0.71875, Computation time: 0.7225420475006104\n",
      "Step: 876, Loss: 0.6926866173744202, Accuracy: 0.78125, Computation time: 0.6860620975494385\n",
      "Step: 877, Loss: 0.6603900194168091, Accuracy: 0.78125, Computation time: 0.8597371578216553\n",
      "Step: 878, Loss: 1.3499376773834229, Accuracy: 0.6875, Computation time: 0.797252893447876\n",
      "Step: 879, Loss: 1.0362048149108887, Accuracy: 0.65625, Computation time: 0.5909280776977539\n",
      "Step: 880, Loss: 0.9368140697479248, Accuracy: 0.78125, Computation time: 0.6449291706085205\n",
      "Step: 881, Loss: 0.9073473811149597, Accuracy: 0.65625, Computation time: 0.8093340396881104\n",
      "Step: 882, Loss: 0.8840705752372742, Accuracy: 0.65625, Computation time: 0.7022390365600586\n",
      "Step: 883, Loss: 1.0534237623214722, Accuracy: 0.6875, Computation time: 0.6927738189697266\n",
      "Step: 884, Loss: 0.7334758639335632, Accuracy: 0.78125, Computation time: 1.1300959587097168\n",
      "Step: 885, Loss: 0.9742521047592163, Accuracy: 0.625, Computation time: 0.7439038753509521\n",
      "Step: 886, Loss: 1.1663191318511963, Accuracy: 0.6875, Computation time: 0.8020548820495605\n",
      "Step: 887, Loss: 1.2754968404769897, Accuracy: 0.6875, Computation time: 0.6839189529418945\n",
      "Step: 888, Loss: 1.2087292671203613, Accuracy: 0.53125, Computation time: 0.785506010055542\n",
      "Step: 889, Loss: 0.8480975031852722, Accuracy: 0.75, Computation time: 0.7140867710113525\n",
      "Step: 890, Loss: 0.8991231918334961, Accuracy: 0.6875, Computation time: 0.6422359943389893\n",
      "Step: 891, Loss: 0.8558195233345032, Accuracy: 0.59375, Computation time: 0.8220109939575195\n",
      "Step: 892, Loss: 0.8888742327690125, Accuracy: 0.625, Computation time: 0.9051830768585205\n",
      "Step: 893, Loss: 0.7539418339729309, Accuracy: 0.75, Computation time: 0.7896158695220947\n",
      "Step: 894, Loss: 1.198662519454956, Accuracy: 0.59375, Computation time: 0.8224670886993408\n",
      "Step: 895, Loss: 0.7923216819763184, Accuracy: 0.8125, Computation time: 0.8036837577819824\n",
      "Step: 896, Loss: 0.8562377691268921, Accuracy: 0.78125, Computation time: 0.8661940097808838\n",
      "Step: 897, Loss: 1.2634538412094116, Accuracy: 0.75, Computation time: 0.6982760429382324\n",
      "Step: 898, Loss: 0.8221107125282288, Accuracy: 0.75, Computation time: 0.6845388412475586\n",
      "Step: 899, Loss: 1.1569286584854126, Accuracy: 0.59375, Computation time: 0.6989998817443848\n",
      "Step: 900, Loss: 0.7180414199829102, Accuracy: 0.71875, Computation time: 0.6730668544769287\n",
      "Step: 901, Loss: 1.3373222351074219, Accuracy: 0.59375, Computation time: 0.9584321975708008\n",
      "Step: 902, Loss: 1.0757417678833008, Accuracy: 0.75, Computation time: 0.6817960739135742\n",
      "Step: 903, Loss: 0.9629462361335754, Accuracy: 0.65625, Computation time: 0.6568608283996582\n",
      "Step: 904, Loss: 0.7855626940727234, Accuracy: 0.78125, Computation time: 0.6986188888549805\n",
      "Step: 905, Loss: 1.2551984786987305, Accuracy: 0.59375, Computation time: 0.8610498905181885\n",
      "Step: 906, Loss: 0.6297941207885742, Accuracy: 0.8125, Computation time: 0.6447911262512207\n",
      "Step: 907, Loss: 1.2077603340148926, Accuracy: 0.625, Computation time: 0.8448450565338135\n",
      "Step: 908, Loss: 0.9657992124557495, Accuracy: 0.71875, Computation time: 0.7497267723083496\n",
      "Step: 909, Loss: 1.0619206428527832, Accuracy: 0.5625, Computation time: 0.7237341403961182\n",
      "Step: 910, Loss: 1.2998324632644653, Accuracy: 0.59375, Computation time: 0.7583987712860107\n",
      "Step: 911, Loss: 1.5390702486038208, Accuracy: 0.5625, Computation time: 0.6700167655944824\n",
      "Step: 912, Loss: 1.02426016330719, Accuracy: 0.65625, Computation time: 0.7118179798126221\n",
      "Step: 913, Loss: 1.0325456857681274, Accuracy: 0.78125, Computation time: 0.774493932723999\n",
      "Step: 914, Loss: 1.0473865270614624, Accuracy: 0.71875, Computation time: 0.6793532371520996\n",
      "Step: 915, Loss: 0.9317132830619812, Accuracy: 0.65625, Computation time: 0.7033069133758545\n",
      "Step: 916, Loss: 0.7039150595664978, Accuracy: 0.75, Computation time: 0.6723630428314209\n",
      "Step: 917, Loss: 0.9596361517906189, Accuracy: 0.65625, Computation time: 0.6987977027893066\n",
      "Step: 918, Loss: 0.45240768790245056, Accuracy: 0.90625, Computation time: 0.6652038097381592\n",
      "Step: 919, Loss: 1.4615687131881714, Accuracy: 0.6875, Computation time: 0.61869215965271\n",
      "Step: 920, Loss: 0.7208825945854187, Accuracy: 0.8125, Computation time: 1.276270866394043\n",
      "Step: 921, Loss: 0.6755570769309998, Accuracy: 0.8125, Computation time: 0.7301292419433594\n",
      "Step: 922, Loss: 0.8272320032119751, Accuracy: 0.78125, Computation time: 0.8048458099365234\n",
      "Step: 923, Loss: 0.6387280821800232, Accuracy: 0.75, Computation time: 0.6473219394683838\n",
      "Step: 924, Loss: 1.5212620496749878, Accuracy: 0.53125, Computation time: 0.7049970626831055\n",
      "Step: 925, Loss: 1.004764437675476, Accuracy: 0.78125, Computation time: 0.8642921447753906\n",
      "Step: 926, Loss: 1.1203111410140991, Accuracy: 0.65625, Computation time: 0.6459870338439941\n",
      "Step: 927, Loss: 1.246728539466858, Accuracy: 0.75, Computation time: 0.8277156352996826\n",
      "Step: 928, Loss: 0.8661712408065796, Accuracy: 0.6875, Computation time: 0.693202018737793\n",
      "Step: 929, Loss: 1.3503941297531128, Accuracy: 0.6875, Computation time: 0.8457930088043213\n",
      "Step: 930, Loss: 0.6886715292930603, Accuracy: 0.78125, Computation time: 0.8946743011474609\n",
      "Step: 931, Loss: 0.7243182063102722, Accuracy: 0.75, Computation time: 0.910923957824707\n",
      "Step: 932, Loss: 1.0695247650146484, Accuracy: 0.6875, Computation time: 0.6249840259552002\n",
      "Step: 933, Loss: 0.8605483770370483, Accuracy: 0.65625, Computation time: 0.8189599514007568\n",
      "Step: 934, Loss: 1.1220886707305908, Accuracy: 0.71875, Computation time: 0.786125898361206\n",
      "Step: 935, Loss: 0.8890312314033508, Accuracy: 0.75, Computation time: 1.2960681915283203\n",
      "Step: 936, Loss: 1.316623568534851, Accuracy: 0.625, Computation time: 0.6049668788909912\n",
      "Step: 937, Loss: 1.0027360916137695, Accuracy: 0.65625, Computation time: 0.773514986038208\n",
      "Step: 938, Loss: 0.6532758474349976, Accuracy: 0.8125, Computation time: 0.6527750492095947\n",
      "Step: 939, Loss: 1.3526804447174072, Accuracy: 0.5625, Computation time: 0.7138040065765381\n",
      "Step: 940, Loss: 1.5364429950714111, Accuracy: 0.5625, Computation time: 0.9399852752685547\n",
      "Step: 941, Loss: 0.7695149183273315, Accuracy: 0.8125, Computation time: 0.7975218296051025\n",
      "Step: 942, Loss: 1.0205286741256714, Accuracy: 0.6875, Computation time: 0.6175270080566406\n",
      "Step: 943, Loss: 1.469448208808899, Accuracy: 0.5625, Computation time: 0.8182671070098877\n",
      "Step: 944, Loss: 1.2616664171218872, Accuracy: 0.65625, Computation time: 0.7561569213867188\n",
      "Step: 945, Loss: 1.0285110473632812, Accuracy: 0.65625, Computation time: 0.9393210411071777\n",
      "Step: 946, Loss: 1.1137824058532715, Accuracy: 0.71875, Computation time: 0.7755682468414307\n",
      "Step: 947, Loss: 1.0331830978393555, Accuracy: 0.6875, Computation time: 0.8105502128601074\n",
      "Step: 948, Loss: 1.2861080169677734, Accuracy: 0.6875, Computation time: 0.7415468692779541\n",
      "Step: 949, Loss: 1.1990302801132202, Accuracy: 0.625, Computation time: 0.7391097545623779\n",
      "Step: 950, Loss: 1.0280277729034424, Accuracy: 0.71875, Computation time: 0.8552119731903076\n",
      "Step: 951, Loss: 0.7157871127128601, Accuracy: 0.8125, Computation time: 0.7372407913208008\n",
      "Step: 952, Loss: 0.5908631086349487, Accuracy: 0.8125, Computation time: 0.736210823059082\n",
      "Step: 953, Loss: 1.3020708560943604, Accuracy: 0.5625, Computation time: 1.2169427871704102\n",
      "Step: 954, Loss: 0.8136788606643677, Accuracy: 0.71875, Computation time: 0.62972092628479\n",
      "Step: 955, Loss: 1.1349842548370361, Accuracy: 0.71875, Computation time: 0.9570660591125488\n",
      "Step: 956, Loss: 1.129621148109436, Accuracy: 0.625, Computation time: 0.7264227867126465\n",
      "Step: 957, Loss: 0.7635658979415894, Accuracy: 0.78125, Computation time: 1.0209269523620605\n",
      "Step: 958, Loss: 1.535849690437317, Accuracy: 0.65625, Computation time: 0.8603231906890869\n",
      "Step: 959, Loss: 1.0364861488342285, Accuracy: 0.65625, Computation time: 0.7638101577758789\n",
      "Step: 960, Loss: 0.9896056056022644, Accuracy: 0.71875, Computation time: 0.7581250667572021\n",
      "Step: 961, Loss: 0.962368369102478, Accuracy: 0.75, Computation time: 0.8482067584991455\n",
      "Step: 962, Loss: 1.4667965173721313, Accuracy: 0.53125, Computation time: 0.9056177139282227\n",
      "Step: 963, Loss: 1.2256883382797241, Accuracy: 0.6875, Computation time: 0.9432199001312256\n",
      "Step: 964, Loss: 0.8923006057739258, Accuracy: 0.6875, Computation time: 0.7008311748504639\n",
      "Step: 965, Loss: 1.033158779144287, Accuracy: 0.71875, Computation time: 0.7255051136016846\n",
      "Step: 966, Loss: 0.7152330875396729, Accuracy: 0.78125, Computation time: 0.8430118560791016\n",
      "Step: 967, Loss: 0.7456539869308472, Accuracy: 0.6875, Computation time: 0.6863229274749756\n",
      "Step: 968, Loss: 0.6589488983154297, Accuracy: 0.84375, Computation time: 0.8216571807861328\n",
      "Step: 969, Loss: 1.0655670166015625, Accuracy: 0.625, Computation time: 0.7875950336456299\n",
      "Step: 970, Loss: 1.0808299779891968, Accuracy: 0.75, Computation time: 0.7716541290283203\n",
      "Step: 971, Loss: 1.180798053741455, Accuracy: 0.625, Computation time: 0.8492062091827393\n",
      "Step: 972, Loss: 1.08964204788208, Accuracy: 0.71875, Computation time: 0.9112780094146729\n",
      "Step: 973, Loss: 0.650562047958374, Accuracy: 0.78125, Computation time: 0.8671600818634033\n",
      "Step: 974, Loss: 1.2740271091461182, Accuracy: 0.65625, Computation time: 0.7986187934875488\n",
      "Step: 975, Loss: 0.8138989806175232, Accuracy: 0.6875, Computation time: 0.743786096572876\n",
      "Step: 976, Loss: 0.7459940314292908, Accuracy: 0.78125, Computation time: 0.7496311664581299\n",
      "Step: 977, Loss: 0.9070160388946533, Accuracy: 0.65625, Computation time: 0.7646059989929199\n",
      "Step: 978, Loss: 1.06827974319458, Accuracy: 0.71875, Computation time: 0.6628239154815674\n",
      "Step: 979, Loss: 0.929103434085846, Accuracy: 0.65625, Computation time: 0.7580270767211914\n",
      "Step: 980, Loss: 0.9292020201683044, Accuracy: 0.6875, Computation time: 0.8067231178283691\n",
      "Step: 981, Loss: 1.0423197746276855, Accuracy: 0.65625, Computation time: 0.8673951625823975\n",
      "Step: 982, Loss: 0.9090837240219116, Accuracy: 0.6875, Computation time: 0.6780881881713867\n",
      "Step: 983, Loss: 0.9824427366256714, Accuracy: 0.6875, Computation time: 0.7382509708404541\n",
      "Step: 984, Loss: 1.2864272594451904, Accuracy: 0.65625, Computation time: 0.6387200355529785\n",
      "Step: 985, Loss: 0.991740345954895, Accuracy: 0.625, Computation time: 0.7045669555664062\n",
      "Step: 986, Loss: 0.7125094532966614, Accuracy: 0.75, Computation time: 0.8212118148803711\n",
      "Step: 987, Loss: 0.6076171398162842, Accuracy: 0.84375, Computation time: 1.0334253311157227\n",
      "Step: 988, Loss: 1.3348095417022705, Accuracy: 0.625, Computation time: 0.7569580078125\n",
      "Step: 989, Loss: 1.0360535383224487, Accuracy: 0.71875, Computation time: 0.5887479782104492\n",
      "Step: 990, Loss: 1.2954517602920532, Accuracy: 0.65625, Computation time: 0.8368349075317383\n",
      "Step: 991, Loss: 1.150542140007019, Accuracy: 0.6875, Computation time: 0.7262630462646484\n",
      "Step: 992, Loss: 1.0932230949401855, Accuracy: 0.65625, Computation time: 0.6623449325561523\n",
      "Step: 993, Loss: 0.9404230117797852, Accuracy: 0.71875, Computation time: 0.751326322555542\n",
      "Step: 994, Loss: 1.4378230571746826, Accuracy: 0.65625, Computation time: 0.7070021629333496\n",
      "Step: 995, Loss: 1.014574408531189, Accuracy: 0.71875, Computation time: 0.8088278770446777\n",
      "Step: 996, Loss: 1.2704559564590454, Accuracy: 0.65625, Computation time: 1.0267999172210693\n",
      "Step: 997, Loss: 0.7252717614173889, Accuracy: 0.8125, Computation time: 0.7812128067016602\n",
      "Step: 998, Loss: 1.0253013372421265, Accuracy: 0.5625, Computation time: 0.7790708541870117\n",
      "Step: 999, Loss: 0.8330105543136597, Accuracy: 0.71875, Computation time: 0.9138081073760986\n",
      "Step: 1000, Loss: 0.9885929226875305, Accuracy: 0.6875, Computation time: 0.830543041229248\n",
      "Step: 1001, Loss: 0.5905242562294006, Accuracy: 0.8125, Computation time: 0.8164620399475098\n",
      "Step: 1002, Loss: 0.8594399094581604, Accuracy: 0.71875, Computation time: 0.7187941074371338\n",
      "Step: 1003, Loss: 1.0952262878417969, Accuracy: 0.625, Computation time: 0.7652678489685059\n",
      "Step: 1004, Loss: 0.930451512336731, Accuracy: 0.71875, Computation time: 0.8352422714233398\n",
      "Step: 1005, Loss: 1.1051771640777588, Accuracy: 0.65625, Computation time: 0.7002890110015869\n",
      "Step: 1006, Loss: 1.4072363376617432, Accuracy: 0.53125, Computation time: 0.6937961578369141\n",
      "Step: 1007, Loss: 0.6870160102844238, Accuracy: 0.75, Computation time: 0.7138569355010986\n",
      "Step: 1008, Loss: 1.5463258028030396, Accuracy: 0.65625, Computation time: 0.6985001564025879\n",
      "Step: 1009, Loss: 0.8419992327690125, Accuracy: 0.65625, Computation time: 0.892888069152832\n",
      "Step: 1010, Loss: 1.3103290796279907, Accuracy: 0.6875, Computation time: 0.6693329811096191\n",
      "Step: 1011, Loss: 1.1231333017349243, Accuracy: 0.625, Computation time: 0.6937739849090576\n",
      "Step: 1012, Loss: 0.8352165222167969, Accuracy: 0.75, Computation time: 0.7369439601898193\n",
      "Step: 1013, Loss: 1.1771180629730225, Accuracy: 0.65625, Computation time: 0.7640109062194824\n",
      "Step: 1014, Loss: 1.1679232120513916, Accuracy: 0.6875, Computation time: 0.8709061145782471\n",
      "Step: 1015, Loss: 0.6329621076583862, Accuracy: 0.78125, Computation time: 0.6835658550262451\n",
      "Step: 1016, Loss: 1.050645112991333, Accuracy: 0.6875, Computation time: 0.7232000827789307\n",
      "Step: 1017, Loss: 0.7370527982711792, Accuracy: 0.71875, Computation time: 0.7791779041290283\n",
      "Step: 1018, Loss: 1.1521074771881104, Accuracy: 0.625, Computation time: 0.6879720687866211\n",
      "Step: 1019, Loss: 0.8934044241905212, Accuracy: 0.78125, Computation time: 0.7256782054901123\n",
      "Step: 1020, Loss: 1.038504958152771, Accuracy: 0.625, Computation time: 0.8740930557250977\n",
      "Step: 1021, Loss: 0.863853931427002, Accuracy: 0.71875, Computation time: 0.7055790424346924\n",
      "Step: 1022, Loss: 0.8547762036323547, Accuracy: 0.75, Computation time: 1.0018031597137451\n",
      "Step: 1023, Loss: 0.986023485660553, Accuracy: 0.71875, Computation time: 0.8632121086120605\n",
      "Step: 1024, Loss: 0.6697293519973755, Accuracy: 0.8125, Computation time: 0.8005869388580322\n",
      "Step: 1025, Loss: 1.13921320438385, Accuracy: 0.65625, Computation time: 0.7497289180755615\n",
      "Step: 1026, Loss: 0.9828494787216187, Accuracy: 0.65625, Computation time: 0.7197520732879639\n",
      "Step: 1027, Loss: 1.0042227506637573, Accuracy: 0.71875, Computation time: 0.6052320003509521\n",
      "Step: 1028, Loss: 0.6718826293945312, Accuracy: 0.78125, Computation time: 0.8709278106689453\n",
      "Step: 1029, Loss: 0.9032720923423767, Accuracy: 0.71875, Computation time: 0.762559175491333\n",
      "Step: 1030, Loss: 1.0240237712860107, Accuracy: 0.59375, Computation time: 0.7475810050964355\n",
      "Step: 1031, Loss: 1.0034432411193848, Accuracy: 0.78125, Computation time: 0.7102041244506836\n",
      "Step: 1032, Loss: 0.6902764439582825, Accuracy: 0.84375, Computation time: 0.8709330558776855\n",
      "Step: 1033, Loss: 1.122045874595642, Accuracy: 0.6875, Computation time: 0.7105040550231934\n",
      "Step: 1034, Loss: 0.8378175497055054, Accuracy: 0.75, Computation time: 0.8675980567932129\n",
      "Step: 1035, Loss: 0.8047518134117126, Accuracy: 0.6875, Computation time: 0.867844820022583\n",
      "Step: 1036, Loss: 0.9166516065597534, Accuracy: 0.71875, Computation time: 0.7833178043365479\n",
      "Step: 1037, Loss: 0.8106825947761536, Accuracy: 0.84375, Computation time: 0.6622161865234375\n",
      "Step: 1038, Loss: 0.6970990300178528, Accuracy: 0.8125, Computation time: 0.8798220157623291\n",
      "Step: 1039, Loss: 0.9359287619590759, Accuracy: 0.71875, Computation time: 0.8931751251220703\n",
      "Step: 1040, Loss: 0.7695707678794861, Accuracy: 0.75, Computation time: 1.0480520725250244\n",
      "Step: 1041, Loss: 0.5187004208564758, Accuracy: 0.875, Computation time: 0.7111940383911133\n",
      "Step: 1042, Loss: 1.167223572731018, Accuracy: 0.71875, Computation time: 0.6819651126861572\n",
      "Step: 1043, Loss: 0.6418390274047852, Accuracy: 0.78125, Computation time: 0.6264591217041016\n",
      "Step: 1044, Loss: 0.8806096315383911, Accuracy: 0.78125, Computation time: 0.8251371383666992\n",
      "Step: 1045, Loss: 0.9954697489738464, Accuracy: 0.6875, Computation time: 0.7091507911682129\n",
      "Step: 1046, Loss: 0.9103919267654419, Accuracy: 0.75, Computation time: 0.6888470649719238\n",
      "Step: 1047, Loss: 0.7117761969566345, Accuracy: 0.71875, Computation time: 0.6941778659820557\n",
      "Step: 1048, Loss: 0.657174825668335, Accuracy: 0.8125, Computation time: 0.6342618465423584\n",
      "Step: 1049, Loss: 0.9530683755874634, Accuracy: 0.6875, Computation time: 0.6726398468017578\n",
      "Step: 1050, Loss: 1.0043920278549194, Accuracy: 0.625, Computation time: 0.7528738975524902\n",
      "Step: 1051, Loss: 0.9591648578643799, Accuracy: 0.6875, Computation time: 0.5893800258636475\n",
      "Step: 1052, Loss: 0.8182472586631775, Accuracy: 0.75, Computation time: 0.9061791896820068\n",
      "Step: 1053, Loss: 0.7598555088043213, Accuracy: 0.8125, Computation time: 0.8331232070922852\n",
      "Step: 1054, Loss: 1.2167543172836304, Accuracy: 0.65625, Computation time: 0.7950179576873779\n",
      "Step: 1055, Loss: 1.1235836744308472, Accuracy: 0.65625, Computation time: 0.7363049983978271\n",
      "Step: 1056, Loss: 0.6722238659858704, Accuracy: 0.8125, Computation time: 0.7269446849822998\n",
      "Step: 1057, Loss: 0.8455151915550232, Accuracy: 0.6875, Computation time: 1.2383408546447754\n",
      "Step: 1058, Loss: 0.8014010787010193, Accuracy: 0.8125, Computation time: 0.8322019577026367\n",
      "Step: 1059, Loss: 0.8408580422401428, Accuracy: 0.75, Computation time: 0.6891510486602783\n",
      "Step: 1060, Loss: 0.9518024325370789, Accuracy: 0.6875, Computation time: 0.844074010848999\n",
      "Step: 1061, Loss: 0.5928909778594971, Accuracy: 0.84375, Computation time: 0.7187058925628662\n",
      "Step: 1062, Loss: 0.9093272089958191, Accuracy: 0.75, Computation time: 0.8704111576080322\n",
      "Step: 1063, Loss: 0.951133668422699, Accuracy: 0.65625, Computation time: 0.9275720119476318\n",
      "Step: 1064, Loss: 1.0128002166748047, Accuracy: 0.71875, Computation time: 0.9461162090301514\n",
      "Step: 1065, Loss: 1.295275330543518, Accuracy: 0.5625, Computation time: 0.9505422115325928\n",
      "Step: 1066, Loss: 0.8156796097755432, Accuracy: 0.71875, Computation time: 0.7537431716918945\n",
      "Step: 1067, Loss: 1.0415769815444946, Accuracy: 0.71875, Computation time: 0.6193079948425293\n",
      "Step: 1068, Loss: 0.7968865036964417, Accuracy: 0.75, Computation time: 0.7009978294372559\n",
      "Step: 1069, Loss: 1.0694361925125122, Accuracy: 0.6875, Computation time: 0.7283430099487305\n",
      "Step: 1070, Loss: 1.3723565340042114, Accuracy: 0.65625, Computation time: 0.8460640907287598\n",
      "Step: 1071, Loss: 1.0223963260650635, Accuracy: 0.75, Computation time: 0.6830508708953857\n",
      "Step: 1072, Loss: 1.2417761087417603, Accuracy: 0.71875, Computation time: 0.6487331390380859\n",
      "Step: 1073, Loss: 1.3485804796218872, Accuracy: 0.625, Computation time: 0.7553479671478271\n",
      "Step: 1074, Loss: 1.1953985691070557, Accuracy: 0.65625, Computation time: 0.7219719886779785\n",
      "Step: 1075, Loss: 1.0056513547897339, Accuracy: 0.625, Computation time: 1.237705945968628\n",
      "Step: 1076, Loss: 1.331792950630188, Accuracy: 0.6875, Computation time: 0.7669639587402344\n",
      "Step: 1077, Loss: 0.4969351589679718, Accuracy: 0.90625, Computation time: 0.61932373046875\n",
      "Step: 1078, Loss: 1.1349139213562012, Accuracy: 0.75, Computation time: 0.7474050521850586\n",
      "Step: 1079, Loss: 1.0193982124328613, Accuracy: 0.65625, Computation time: 0.7730679512023926\n",
      "Step: 1080, Loss: 0.6632934212684631, Accuracy: 0.84375, Computation time: 0.7665138244628906\n",
      "Step: 1081, Loss: 1.213649034500122, Accuracy: 0.59375, Computation time: 0.7291560173034668\n",
      "Step: 1082, Loss: 0.847493588924408, Accuracy: 0.71875, Computation time: 0.7928812503814697\n",
      "Step: 1083, Loss: 0.5391495227813721, Accuracy: 0.875, Computation time: 0.7760448455810547\n",
      "Step: 1084, Loss: 0.8426016569137573, Accuracy: 0.78125, Computation time: 0.7444870471954346\n",
      "Step: 1085, Loss: 1.0154929161071777, Accuracy: 0.71875, Computation time: 0.7473559379577637\n",
      "Step: 1086, Loss: 0.8297169804573059, Accuracy: 0.71875, Computation time: 0.6804060935974121\n",
      "Step: 1087, Loss: 1.167718529701233, Accuracy: 0.71875, Computation time: 0.9010801315307617\n",
      "Step: 1088, Loss: 1.237207293510437, Accuracy: 0.65625, Computation time: 0.655350923538208\n",
      "Step: 1089, Loss: 0.6790894865989685, Accuracy: 0.8125, Computation time: 0.9515938758850098\n",
      "Step: 1090, Loss: 1.1762447357177734, Accuracy: 0.71875, Computation time: 0.9707858562469482\n",
      "Step: 1091, Loss: 1.1681296825408936, Accuracy: 0.6875, Computation time: 1.231720209121704\n",
      "Step: 1092, Loss: 1.2214843034744263, Accuracy: 0.71875, Computation time: 0.8140559196472168\n",
      "Step: 1093, Loss: 0.8480069041252136, Accuracy: 0.75, Computation time: 0.6772019863128662\n",
      "Step: 1094, Loss: 0.9532396793365479, Accuracy: 0.6875, Computation time: 0.8683960437774658\n",
      "Step: 1095, Loss: 0.8870106339454651, Accuracy: 0.65625, Computation time: 0.7500357627868652\n",
      "Step: 1096, Loss: 0.8365033268928528, Accuracy: 0.8125, Computation time: 0.6120717525482178\n",
      "Step: 1097, Loss: 0.9035610556602478, Accuracy: 0.78125, Computation time: 0.7502069473266602\n",
      "Step: 1098, Loss: 1.0326327085494995, Accuracy: 0.6875, Computation time: 0.7674398422241211\n",
      "Step: 1099, Loss: 0.8340330123901367, Accuracy: 0.71875, Computation time: 0.7677369117736816\n",
      "Step: 1100, Loss: 0.9004513621330261, Accuracy: 0.78125, Computation time: 0.7269890308380127\n",
      "Step: 1101, Loss: 0.9383512139320374, Accuracy: 0.75, Computation time: 0.8201470375061035\n",
      "Step: 1102, Loss: 0.9596289396286011, Accuracy: 0.71875, Computation time: 0.771528959274292\n",
      "Step: 1103, Loss: 0.8343253135681152, Accuracy: 0.71875, Computation time: 0.8613228797912598\n",
      "Step: 1104, Loss: 0.7462596297264099, Accuracy: 0.6875, Computation time: 0.7119317054748535\n",
      "Step: 1105, Loss: 1.013221263885498, Accuracy: 0.75, Computation time: 0.8921988010406494\n",
      "Step: 1106, Loss: 0.809453010559082, Accuracy: 0.84375, Computation time: 0.7833151817321777\n",
      "Step: 1107, Loss: 0.9687961339950562, Accuracy: 0.6875, Computation time: 0.6879386901855469\n",
      "Step: 1108, Loss: 0.8346013426780701, Accuracy: 0.75, Computation time: 0.7541599273681641\n",
      "Step: 1109, Loss: 0.7211164832115173, Accuracy: 0.8125, Computation time: 0.7909219264984131\n",
      "Step: 1110, Loss: 0.8019811511039734, Accuracy: 0.75, Computation time: 0.7536327838897705\n",
      "Step: 1111, Loss: 1.2055597305297852, Accuracy: 0.65625, Computation time: 0.744999885559082\n",
      "Step: 1112, Loss: 1.0888659954071045, Accuracy: 0.625, Computation time: 0.7879559993743896\n",
      "Step: 1113, Loss: 1.455246090888977, Accuracy: 0.53125, Computation time: 0.7907040119171143\n",
      "Step: 1114, Loss: 1.5142321586608887, Accuracy: 0.65625, Computation time: 0.7368111610412598\n",
      "Step: 1115, Loss: 0.7677801251411438, Accuracy: 0.71875, Computation time: 0.7705821990966797\n",
      "Step: 1116, Loss: 0.6438848972320557, Accuracy: 0.78125, Computation time: 0.6979048252105713\n",
      "Step: 1117, Loss: 1.3433854579925537, Accuracy: 0.5625, Computation time: 0.702366828918457\n",
      "Step: 1118, Loss: 1.31257963180542, Accuracy: 0.625, Computation time: 0.806563138961792\n",
      "Step: 1119, Loss: 0.7382388114929199, Accuracy: 0.75, Computation time: 0.7809441089630127\n",
      "Step: 1120, Loss: 1.2724463939666748, Accuracy: 0.5625, Computation time: 0.7481911182403564\n",
      "Step: 1121, Loss: 0.4217427372932434, Accuracy: 0.9375, Computation time: 0.6545419692993164\n",
      "Step: 1122, Loss: 1.3136272430419922, Accuracy: 0.625, Computation time: 0.9692001342773438\n",
      "Step: 1123, Loss: 0.9325903654098511, Accuracy: 0.6875, Computation time: 0.6878838539123535\n",
      "Step: 1124, Loss: 1.3647878170013428, Accuracy: 0.71875, Computation time: 0.8709790706634521\n",
      "Step: 1125, Loss: 0.889573872089386, Accuracy: 0.65625, Computation time: 1.206545114517212\n",
      "Step: 1126, Loss: 0.7495437860488892, Accuracy: 0.8125, Computation time: 0.8932440280914307\n",
      "Step: 1127, Loss: 1.4774185419082642, Accuracy: 0.5625, Computation time: 0.7549691200256348\n",
      "Step: 1128, Loss: 0.9267570972442627, Accuracy: 0.625, Computation time: 0.7695827484130859\n",
      "Step: 1129, Loss: 0.982214629650116, Accuracy: 0.59375, Computation time: 0.7238781452178955\n",
      "Step: 1130, Loss: 1.0575838088989258, Accuracy: 0.6875, Computation time: 0.6321747303009033\n",
      "Step: 1131, Loss: 0.958211362361908, Accuracy: 0.71875, Computation time: 0.7800891399383545\n",
      "Step: 1132, Loss: 0.9639113545417786, Accuracy: 0.65625, Computation time: 0.8127720355987549\n",
      "Step: 1133, Loss: 0.9330198168754578, Accuracy: 0.6875, Computation time: 1.362532138824463\n",
      "Step: 1134, Loss: 1.1524877548217773, Accuracy: 0.6875, Computation time: 0.8682539463043213\n",
      "Step: 1135, Loss: 0.808647632598877, Accuracy: 0.71875, Computation time: 0.7737269401550293\n",
      "Step: 1136, Loss: 0.6049493551254272, Accuracy: 0.84375, Computation time: 0.7664551734924316\n",
      "Step: 1137, Loss: 1.5480273962020874, Accuracy: 0.5625, Computation time: 0.7531969547271729\n",
      "Step: 1138, Loss: 1.2234302759170532, Accuracy: 0.5625, Computation time: 0.8111190795898438\n",
      "Step: 1139, Loss: 0.8588993549346924, Accuracy: 0.65625, Computation time: 0.6502678394317627\n",
      "Step: 1140, Loss: 0.6739457845687866, Accuracy: 0.875, Computation time: 0.8866989612579346\n",
      "Step: 1141, Loss: 0.7592774629592896, Accuracy: 0.71875, Computation time: 0.6328349113464355\n",
      "Step: 1142, Loss: 0.7267480492591858, Accuracy: 0.65625, Computation time: 0.6938879489898682\n",
      "Step: 1143, Loss: 1.2852178812026978, Accuracy: 0.6875, Computation time: 0.9230577945709229\n",
      "Step: 1144, Loss: 0.7873294949531555, Accuracy: 0.65625, Computation time: 0.6240959167480469\n",
      "Step: 1145, Loss: 0.7139703035354614, Accuracy: 0.75, Computation time: 0.5336930751800537\n",
      "Step: 1146, Loss: 0.9596057534217834, Accuracy: 0.6875, Computation time: 0.7661170959472656\n",
      "Step: 1147, Loss: 0.974131166934967, Accuracy: 0.59375, Computation time: 0.9826130867004395\n",
      "Step: 1148, Loss: 1.0887961387634277, Accuracy: 0.71875, Computation time: 0.9557440280914307\n",
      "Step: 1149, Loss: 0.9571504592895508, Accuracy: 0.6875, Computation time: 0.7913579940795898\n",
      "Step: 1150, Loss: 0.8608512282371521, Accuracy: 0.8125, Computation time: 0.7689709663391113\n",
      "Step: 1151, Loss: 1.1334469318389893, Accuracy: 0.65625, Computation time: 0.6440200805664062\n",
      "Step: 1152, Loss: 1.2292275428771973, Accuracy: 0.71875, Computation time: 0.7339410781860352\n",
      "Step: 1153, Loss: 0.9512971043586731, Accuracy: 0.75, Computation time: 0.6800119876861572\n",
      "Step: 1154, Loss: 0.5349301695823669, Accuracy: 0.84375, Computation time: 0.8098349571228027\n",
      "Step: 1155, Loss: 0.7283527255058289, Accuracy: 0.75, Computation time: 0.8154330253601074\n",
      "Step: 1156, Loss: 0.6971229910850525, Accuracy: 0.8125, Computation time: 0.8026268482208252\n",
      "Step: 1157, Loss: 1.3759177923202515, Accuracy: 0.65625, Computation time: 0.7194840908050537\n",
      "Step: 1158, Loss: 0.8179373741149902, Accuracy: 0.65625, Computation time: 0.9201390743255615\n",
      "Step: 1159, Loss: 0.8924615383148193, Accuracy: 0.65625, Computation time: 1.1114890575408936\n",
      "Step: 1160, Loss: 0.895722508430481, Accuracy: 0.71875, Computation time: 0.6465590000152588\n",
      "Step: 1161, Loss: 0.9418566823005676, Accuracy: 0.71875, Computation time: 0.7353219985961914\n",
      "Step: 1162, Loss: 0.4262995421886444, Accuracy: 0.875, Computation time: 0.7175428867340088\n",
      "Step: 1163, Loss: 1.195320725440979, Accuracy: 0.65625, Computation time: 0.7023911476135254\n",
      "Step: 1164, Loss: 0.6209840178489685, Accuracy: 0.8125, Computation time: 0.7176949977874756\n",
      "Step: 1165, Loss: 1.182716965675354, Accuracy: 0.65625, Computation time: 0.8948431015014648\n",
      "Step: 1166, Loss: 1.0097761154174805, Accuracy: 0.6875, Computation time: 0.8313882350921631\n",
      "Step: 1167, Loss: 1.3502405881881714, Accuracy: 0.65625, Computation time: 0.6489288806915283\n",
      "Step: 1168, Loss: 1.2768980264663696, Accuracy: 0.5625, Computation time: 0.6985459327697754\n",
      "Step: 1169, Loss: 1.4786685705184937, Accuracy: 0.625, Computation time: 0.7918341159820557\n",
      "Step: 1170, Loss: 1.056107997894287, Accuracy: 0.71875, Computation time: 0.5951647758483887\n",
      "Step: 1171, Loss: 0.8996609449386597, Accuracy: 0.8125, Computation time: 0.767643928527832\n",
      "Step: 1172, Loss: 1.26340651512146, Accuracy: 0.625, Computation time: 0.9840919971466064\n",
      "Step: 1173, Loss: 0.5556341409683228, Accuracy: 0.8125, Computation time: 0.7388820648193359\n",
      "Step: 1174, Loss: 0.8799645900726318, Accuracy: 0.71875, Computation time: 0.7606000900268555\n",
      "Step: 1175, Loss: 0.6723887324333191, Accuracy: 0.71875, Computation time: 0.796267032623291\n",
      "Step: 1176, Loss: 0.7570414543151855, Accuracy: 0.78125, Computation time: 0.7824680805206299\n",
      "Step: 1177, Loss: 0.7263832688331604, Accuracy: 0.75, Computation time: 0.699547290802002\n",
      "Step: 1178, Loss: 1.0202052593231201, Accuracy: 0.75, Computation time: 0.7620861530303955\n",
      "Step: 1179, Loss: 1.8834704160690308, Accuracy: 0.53125, Computation time: 0.7828309535980225\n",
      "Step: 1180, Loss: 0.6688051819801331, Accuracy: 0.78125, Computation time: 0.696566104888916\n",
      "Step: 1181, Loss: 0.8588213920593262, Accuracy: 0.71875, Computation time: 0.7058920860290527\n",
      "Step: 1182, Loss: 0.7632647752761841, Accuracy: 0.84375, Computation time: 0.6911177635192871\n",
      "Step: 1183, Loss: 0.745880663394928, Accuracy: 0.71875, Computation time: 0.7911522388458252\n",
      "Step: 1184, Loss: 0.6902637481689453, Accuracy: 0.8125, Computation time: 0.7755141258239746\n",
      "Step: 1185, Loss: 0.5662275552749634, Accuracy: 0.84375, Computation time: 0.6805751323699951\n",
      "Step: 1186, Loss: 0.3740745484828949, Accuracy: 0.9375, Computation time: 0.8358221054077148\n",
      "Step: 1187, Loss: 0.9564716815948486, Accuracy: 0.59375, Computation time: 0.8094577789306641\n",
      "Step: 1188, Loss: 0.6357609033584595, Accuracy: 0.8125, Computation time: 1.0614759922027588\n",
      "Step: 1189, Loss: 1.0363311767578125, Accuracy: 0.6875, Computation time: 0.754281759262085\n",
      "Step: 1190, Loss: 0.7030534744262695, Accuracy: 0.84375, Computation time: 0.7668318748474121\n",
      "Step: 1191, Loss: 1.1983692646026611, Accuracy: 0.75, Computation time: 0.9524021148681641\n",
      "Step: 1192, Loss: 0.3763389587402344, Accuracy: 0.875, Computation time: 0.7300159931182861\n",
      "Step: 1193, Loss: 0.7411233186721802, Accuracy: 0.71875, Computation time: 1.1302800178527832\n",
      "Step: 1194, Loss: 0.277261346578598, Accuracy: 0.90625, Computation time: 0.8209278583526611\n",
      "Step: 1195, Loss: 1.0653184652328491, Accuracy: 0.625, Computation time: 0.7928180694580078\n",
      "Step: 1196, Loss: 0.7884412407875061, Accuracy: 0.78125, Computation time: 0.7306151390075684\n",
      "Step: 1197, Loss: 0.9782285094261169, Accuracy: 0.6875, Computation time: 0.7048521041870117\n",
      "Step: 1198, Loss: 0.7763335108757019, Accuracy: 0.78125, Computation time: 0.6656429767608643\n",
      "Step: 1199, Loss: 0.7528713941574097, Accuracy: 0.78125, Computation time: 0.7616729736328125\n",
      "Step: 1200, Loss: 0.97410649061203, Accuracy: 0.6875, Computation time: 0.9327311515808105\n",
      "Step: 1201, Loss: 1.273940086364746, Accuracy: 0.5625, Computation time: 1.0678131580352783\n",
      "Step: 1202, Loss: 0.7390462756156921, Accuracy: 0.8125, Computation time: 0.7222938537597656\n",
      "Step: 1203, Loss: 0.7459033131599426, Accuracy: 0.84375, Computation time: 0.6593289375305176\n",
      "Step: 1204, Loss: 1.184936761856079, Accuracy: 0.65625, Computation time: 0.8269829750061035\n",
      "Step: 1205, Loss: 1.4277288913726807, Accuracy: 0.5625, Computation time: 0.7127938270568848\n",
      "Step: 1206, Loss: 0.6434100866317749, Accuracy: 0.78125, Computation time: 0.8440558910369873\n",
      "Step: 1207, Loss: 0.6490893959999084, Accuracy: 0.8125, Computation time: 1.282829999923706\n",
      "Step: 1208, Loss: 0.8499864935874939, Accuracy: 0.6875, Computation time: 0.8990890979766846\n",
      "Step: 1209, Loss: 1.0653173923492432, Accuracy: 0.625, Computation time: 0.828125\n",
      "Step: 1210, Loss: 0.7683624625205994, Accuracy: 0.75, Computation time: 0.8164339065551758\n",
      "Step: 1211, Loss: 0.9482969045639038, Accuracy: 0.65625, Computation time: 0.7822151184082031\n",
      "Step: 1212, Loss: 1.83646559715271, Accuracy: 0.5, Computation time: 0.7407021522521973\n",
      "Step: 1213, Loss: 0.8454065918922424, Accuracy: 0.65625, Computation time: 0.6675472259521484\n",
      "Step: 1214, Loss: 1.1353596448898315, Accuracy: 0.625, Computation time: 0.6484947204589844\n",
      "Step: 1215, Loss: 0.7493019104003906, Accuracy: 0.8125, Computation time: 0.8842129707336426\n",
      "Step: 1216, Loss: 0.7672860026359558, Accuracy: 0.78125, Computation time: 0.6818540096282959\n",
      "Step: 1217, Loss: 1.2811279296875, Accuracy: 0.59375, Computation time: 0.7417247295379639\n",
      "Step: 1218, Loss: 0.8439379334449768, Accuracy: 0.71875, Computation time: 0.6757519245147705\n",
      "Step: 1219, Loss: 0.6825180649757385, Accuracy: 0.8125, Computation time: 0.6887319087982178\n",
      "Step: 1220, Loss: 1.2575613260269165, Accuracy: 0.6875, Computation time: 0.625885009765625\n",
      "Step: 1221, Loss: 1.0244139432907104, Accuracy: 0.625, Computation time: 0.7272012233734131\n",
      "Step: 1222, Loss: 1.2559161186218262, Accuracy: 0.6875, Computation time: 0.7772893905639648\n",
      "Step: 1223, Loss: 0.6405230164527893, Accuracy: 0.78125, Computation time: 0.6506650447845459\n",
      "Step: 1224, Loss: 0.7229728102684021, Accuracy: 0.8125, Computation time: 0.997934103012085\n",
      "Step: 1225, Loss: 1.268729567527771, Accuracy: 0.5625, Computation time: 0.7121610641479492\n",
      "Step: 1226, Loss: 0.9295139312744141, Accuracy: 0.6875, Computation time: 0.8257300853729248\n",
      "Step: 1227, Loss: 0.46970894932746887, Accuracy: 0.90625, Computation time: 1.173685073852539\n",
      "Step: 1228, Loss: 0.8353213667869568, Accuracy: 0.8125, Computation time: 0.8829710483551025\n",
      "Step: 1229, Loss: 0.9980292320251465, Accuracy: 0.71875, Computation time: 0.7475090026855469\n",
      "Step: 1230, Loss: 0.6081079840660095, Accuracy: 0.78125, Computation time: 0.7066328525543213\n",
      "Step: 1231, Loss: 0.6759917140007019, Accuracy: 0.75, Computation time: 0.8824498653411865\n",
      "Step: 1232, Loss: 0.941903293132782, Accuracy: 0.75, Computation time: 0.6692800521850586\n",
      "Step: 1233, Loss: 1.2466483116149902, Accuracy: 0.6875, Computation time: 0.6949541568756104\n",
      "Step: 1234, Loss: 0.8579150438308716, Accuracy: 0.75, Computation time: 0.767585039138794\n",
      "Step: 1235, Loss: 0.7771451473236084, Accuracy: 0.75, Computation time: 1.021880865097046\n",
      "Step: 1236, Loss: 1.0939486026763916, Accuracy: 0.625, Computation time: 0.7712481021881104\n",
      "Step: 1237, Loss: 0.810990035533905, Accuracy: 0.8125, Computation time: 0.8876953125\n",
      "Step: 1238, Loss: 0.5466936826705933, Accuracy: 0.84375, Computation time: 0.6575708389282227\n",
      "Step: 1239, Loss: 1.3656713962554932, Accuracy: 0.71875, Computation time: 0.7628028392791748\n",
      "Step: 1240, Loss: 0.7976173758506775, Accuracy: 0.75, Computation time: 0.7675991058349609\n",
      "Step: 1241, Loss: 0.5621976256370544, Accuracy: 0.84375, Computation time: 0.6546509265899658\n",
      "Step: 1242, Loss: 0.9499751329421997, Accuracy: 0.625, Computation time: 0.6889698505401611\n",
      "Step: 1243, Loss: 0.5183628797531128, Accuracy: 0.84375, Computation time: 0.7353529930114746\n",
      "Step: 1244, Loss: 0.4960896074771881, Accuracy: 0.84375, Computation time: 0.8399639129638672\n",
      "Step: 1245, Loss: 0.6591593623161316, Accuracy: 0.84375, Computation time: 0.6969661712646484\n",
      "Step: 1246, Loss: 0.8149727582931519, Accuracy: 0.71875, Computation time: 0.8227016925811768\n",
      "Step: 1247, Loss: 0.6030523777008057, Accuracy: 0.8125, Computation time: 0.7822790145874023\n",
      "Step: 1248, Loss: 0.6002706289291382, Accuracy: 0.84375, Computation time: 0.6721129417419434\n",
      "Step: 1249, Loss: 0.8038138151168823, Accuracy: 0.71875, Computation time: 0.738677978515625\n",
      "Step: 1250, Loss: 0.7426160573959351, Accuracy: 0.6875, Computation time: 0.8468179702758789\n",
      "Step: 1251, Loss: 0.8288995623588562, Accuracy: 0.75, Computation time: 0.6682171821594238\n",
      "Step: 1252, Loss: 0.8638083934783936, Accuracy: 0.78125, Computation time: 0.7924249172210693\n",
      "Step: 1253, Loss: 0.838151752948761, Accuracy: 0.71875, Computation time: 0.7788228988647461\n",
      "Step: 1254, Loss: 0.7758849859237671, Accuracy: 0.71875, Computation time: 0.6325860023498535\n",
      "Step: 1255, Loss: 0.752004086971283, Accuracy: 0.75, Computation time: 0.8596241474151611\n",
      "Step: 1256, Loss: 0.8922528028488159, Accuracy: 0.75, Computation time: 0.7903411388397217\n",
      "Step: 1257, Loss: 0.8019810914993286, Accuracy: 0.75, Computation time: 0.7898521423339844\n",
      "Step: 1258, Loss: 0.6372854709625244, Accuracy: 0.71875, Computation time: 0.7411289215087891\n",
      "Step: 1259, Loss: 0.9506301879882812, Accuracy: 0.75, Computation time: 0.662841796875\n",
      "Step: 1260, Loss: 0.9367286562919617, Accuracy: 0.625, Computation time: 0.7997481822967529\n",
      "Step: 1261, Loss: 0.9487894177436829, Accuracy: 0.71875, Computation time: 0.8051106929779053\n",
      "Step: 1262, Loss: 0.6228774189949036, Accuracy: 0.84375, Computation time: 1.167964220046997\n",
      "Step: 1263, Loss: 0.7230300903320312, Accuracy: 0.78125, Computation time: 0.7099471092224121\n",
      "Step: 1264, Loss: 0.6793104410171509, Accuracy: 0.8125, Computation time: 0.7723348140716553\n",
      "Step: 1265, Loss: 0.6708876490592957, Accuracy: 0.90625, Computation time: 0.6804440021514893\n",
      "Step: 1266, Loss: 1.0212124586105347, Accuracy: 0.65625, Computation time: 0.8306920528411865\n",
      "Step: 1267, Loss: 0.8887092471122742, Accuracy: 0.6875, Computation time: 0.8429450988769531\n",
      "Step: 1268, Loss: 1.0717049837112427, Accuracy: 0.65625, Computation time: 0.9865918159484863\n",
      "Step: 1269, Loss: 0.49041253328323364, Accuracy: 0.84375, Computation time: 0.6779756546020508\n",
      "Step: 1270, Loss: 1.038415551185608, Accuracy: 0.75, Computation time: 0.8542640209197998\n",
      "Step: 1271, Loss: 0.47397381067276, Accuracy: 0.875, Computation time: 0.6735842227935791\n",
      "Step: 1272, Loss: 0.717366635799408, Accuracy: 0.71875, Computation time: 0.8566460609436035\n",
      "Step: 1273, Loss: 0.9118680953979492, Accuracy: 0.75, Computation time: 0.745042085647583\n",
      "Step: 1274, Loss: 1.0350595712661743, Accuracy: 0.71875, Computation time: 0.8405561447143555\n",
      "Step: 1275, Loss: 0.45205816626548767, Accuracy: 0.875, Computation time: 0.7028207778930664\n",
      "Step: 1276, Loss: 0.9252474308013916, Accuracy: 0.71875, Computation time: 1.0078389644622803\n",
      "Step: 1277, Loss: 0.9477476477622986, Accuracy: 0.71875, Computation time: 0.8686511516571045\n",
      "Step: 1278, Loss: 0.9380996823310852, Accuracy: 0.71875, Computation time: 0.6916971206665039\n",
      "Step: 1279, Loss: 1.1382795572280884, Accuracy: 0.75, Computation time: 0.8229701519012451\n",
      "Step: 1280, Loss: 0.7396175861358643, Accuracy: 0.78125, Computation time: 0.7010378837585449\n",
      "Step: 1281, Loss: 0.9407669305801392, Accuracy: 0.78125, Computation time: 0.8622899055480957\n",
      "Step: 1282, Loss: 0.672058641910553, Accuracy: 0.8125, Computation time: 0.9216630458831787\n",
      "Step: 1283, Loss: 1.1626865863800049, Accuracy: 0.5625, Computation time: 0.7295961380004883\n",
      "Step: 1284, Loss: 0.575519859790802, Accuracy: 0.78125, Computation time: 0.8526651859283447\n",
      "Step: 1285, Loss: 0.6365289092063904, Accuracy: 0.78125, Computation time: 0.8515231609344482\n",
      "Step: 1286, Loss: 0.5882427096366882, Accuracy: 0.90625, Computation time: 0.8895719051361084\n",
      "Step: 1287, Loss: 0.7034921050071716, Accuracy: 0.8125, Computation time: 0.6749978065490723\n",
      "Step: 1288, Loss: 0.7307889461517334, Accuracy: 0.75, Computation time: 0.6630358695983887\n",
      "Step: 1289, Loss: 0.6581324934959412, Accuracy: 0.84375, Computation time: 0.8205759525299072\n",
      "Step: 1290, Loss: 0.6871523261070251, Accuracy: 0.78125, Computation time: 0.7601263523101807\n",
      "Step: 1291, Loss: 1.0322519540786743, Accuracy: 0.6875, Computation time: 0.7979910373687744\n",
      "Step: 1292, Loss: 0.8871947526931763, Accuracy: 0.71875, Computation time: 0.9629480838775635\n",
      "Step: 1293, Loss: 1.016794204711914, Accuracy: 0.75, Computation time: 0.7178149223327637\n",
      "Step: 1294, Loss: 0.819150447845459, Accuracy: 0.75, Computation time: 1.145010232925415\n",
      "Step: 1295, Loss: 1.2166202068328857, Accuracy: 0.71875, Computation time: 1.2682068347930908\n",
      "Step: 1296, Loss: 0.9700278639793396, Accuracy: 0.6875, Computation time: 0.8113009929656982\n",
      "Step: 1297, Loss: 0.47631481289863586, Accuracy: 0.78125, Computation time: 0.7262921333312988\n",
      "Step: 1298, Loss: 0.5971634984016418, Accuracy: 0.875, Computation time: 0.6216769218444824\n",
      "Step: 1299, Loss: 0.6140384078025818, Accuracy: 0.78125, Computation time: 1.1034269332885742\n",
      "Step: 1300, Loss: 0.5768723487854004, Accuracy: 0.8125, Computation time: 0.7128877639770508\n",
      "Step: 1301, Loss: 0.5696909427642822, Accuracy: 0.84375, Computation time: 0.742048978805542\n",
      "Step: 1302, Loss: 0.7973203063011169, Accuracy: 0.78125, Computation time: 0.9155449867248535\n",
      "Step: 1303, Loss: 0.4791066348552704, Accuracy: 0.84375, Computation time: 0.9000289440155029\n",
      "Step: 1304, Loss: 0.5415205359458923, Accuracy: 0.84375, Computation time: 0.689359188079834\n",
      "Step: 1305, Loss: 1.0384927988052368, Accuracy: 0.75, Computation time: 0.7203147411346436\n",
      "Step: 1306, Loss: 0.7160730361938477, Accuracy: 0.71875, Computation time: 0.8867168426513672\n",
      "Step: 1307, Loss: 0.75051349401474, Accuracy: 0.78125, Computation time: 0.9425132274627686\n",
      "Step: 1308, Loss: 0.6744762063026428, Accuracy: 0.71875, Computation time: 0.6536200046539307\n",
      "Step: 1309, Loss: 0.7339447140693665, Accuracy: 0.71875, Computation time: 0.7304568290710449\n",
      "Step: 1310, Loss: 0.7212657332420349, Accuracy: 0.71875, Computation time: 0.6763231754302979\n",
      "Step: 1311, Loss: 0.9300083518028259, Accuracy: 0.8125, Computation time: 0.8204798698425293\n",
      "Step: 1312, Loss: 1.0585905313491821, Accuracy: 0.71875, Computation time: 0.6251389980316162\n",
      "Step: 1313, Loss: 0.727786123752594, Accuracy: 0.71875, Computation time: 0.7797718048095703\n",
      "Step: 1314, Loss: 1.0851157903671265, Accuracy: 0.75, Computation time: 0.8600900173187256\n",
      "Step: 1315, Loss: 0.9489226341247559, Accuracy: 0.625, Computation time: 0.7517271041870117\n",
      "Step: 1316, Loss: 0.6313090324401855, Accuracy: 0.78125, Computation time: 0.7504880428314209\n",
      "Step: 1317, Loss: 0.7174312472343445, Accuracy: 0.71875, Computation time: 0.7048361301422119\n",
      "Step: 1318, Loss: 0.5323470234870911, Accuracy: 0.84375, Computation time: 0.6852066516876221\n",
      "Step: 1319, Loss: 1.154911994934082, Accuracy: 0.6875, Computation time: 0.7726666927337646\n",
      "Step: 1320, Loss: 0.8712041974067688, Accuracy: 0.78125, Computation time: 0.8001511096954346\n",
      "Step: 1321, Loss: 1.0405070781707764, Accuracy: 0.65625, Computation time: 0.7019550800323486\n",
      "Step: 1322, Loss: 0.8254016637802124, Accuracy: 0.75, Computation time: 0.9505691528320312\n",
      "Step: 1323, Loss: 0.8974846005439758, Accuracy: 0.78125, Computation time: 0.7447640895843506\n",
      "Step: 1324, Loss: 0.7322124242782593, Accuracy: 0.78125, Computation time: 0.7737338542938232\n",
      "Step: 1325, Loss: 0.549406886100769, Accuracy: 0.8125, Computation time: 0.903397798538208\n",
      "Step: 1326, Loss: 0.7531828880310059, Accuracy: 0.75, Computation time: 0.7779510021209717\n",
      "Step: 1327, Loss: 0.7815287113189697, Accuracy: 0.75, Computation time: 0.7801599502563477\n",
      "Step: 1328, Loss: 0.7946179509162903, Accuracy: 0.71875, Computation time: 0.8172180652618408\n",
      "Step: 1329, Loss: 0.8162018656730652, Accuracy: 0.6875, Computation time: 1.3475759029388428\n",
      "Step: 1330, Loss: 1.0926437377929688, Accuracy: 0.65625, Computation time: 0.807379961013794\n",
      "Step: 1331, Loss: 1.0759798288345337, Accuracy: 0.65625, Computation time: 0.7127459049224854\n",
      "Step: 1332, Loss: 0.5401734113693237, Accuracy: 0.84375, Computation time: 0.8655340671539307\n",
      "Step: 1333, Loss: 0.8435279726982117, Accuracy: 0.8125, Computation time: 0.8094482421875\n",
      "Step: 1334, Loss: 1.2700062990188599, Accuracy: 0.71875, Computation time: 0.7306041717529297\n",
      "Step: 1335, Loss: 0.7246351838111877, Accuracy: 0.84375, Computation time: 0.7199821472167969\n",
      "Step: 1336, Loss: 0.6465542316436768, Accuracy: 0.75, Computation time: 0.6609737873077393\n",
      "Step: 1337, Loss: 0.730854332447052, Accuracy: 0.84375, Computation time: 0.7099640369415283\n",
      "Step: 1338, Loss: 1.0946592092514038, Accuracy: 0.75, Computation time: 0.6769580841064453\n",
      "Step: 1339, Loss: 1.034735083580017, Accuracy: 0.6875, Computation time: 0.6642062664031982\n",
      "Step: 1340, Loss: 0.7040358781814575, Accuracy: 0.75, Computation time: 0.750511884689331\n",
      "Step: 1341, Loss: 0.7680543065071106, Accuracy: 0.6875, Computation time: 0.7385220527648926\n",
      "Step: 1342, Loss: 1.090315341949463, Accuracy: 0.6875, Computation time: 0.7996988296508789\n",
      "Step: 1343, Loss: 0.638031542301178, Accuracy: 0.78125, Computation time: 1.0572800636291504\n",
      "Step: 1344, Loss: 0.8230064511299133, Accuracy: 0.75, Computation time: 0.8904109001159668\n",
      "Step: 1345, Loss: 0.8168576955795288, Accuracy: 0.71875, Computation time: 0.7083582878112793\n",
      "Step: 1346, Loss: 1.0226157903671265, Accuracy: 0.75, Computation time: 0.816472053527832\n",
      "Step: 1347, Loss: 0.44843217730522156, Accuracy: 0.875, Computation time: 0.7792119979858398\n",
      "Step: 1348, Loss: 0.5495717525482178, Accuracy: 0.78125, Computation time: 0.8860909938812256\n",
      "Step: 1349, Loss: 1.2211668491363525, Accuracy: 0.625, Computation time: 0.8887088298797607\n",
      "Step: 1350, Loss: 0.7842866778373718, Accuracy: 0.84375, Computation time: 0.6622569561004639\n",
      "Step: 1351, Loss: 0.5572595596313477, Accuracy: 0.84375, Computation time: 0.7964541912078857\n",
      "Step: 1352, Loss: 0.9497022032737732, Accuracy: 0.6875, Computation time: 0.9201159477233887\n",
      "Step: 1353, Loss: 0.6784732937812805, Accuracy: 0.8125, Computation time: 0.8247189521789551\n",
      "Step: 1354, Loss: 1.1827152967453003, Accuracy: 0.625, Computation time: 0.9965691566467285\n",
      "Step: 1355, Loss: 0.891262948513031, Accuracy: 0.71875, Computation time: 0.7384262084960938\n",
      "Step: 1356, Loss: 0.6408149600028992, Accuracy: 0.8125, Computation time: 0.6969611644744873\n",
      "Step: 1357, Loss: 0.17818215489387512, Accuracy: 0.96875, Computation time: 0.8549220561981201\n",
      "Step: 1358, Loss: 0.9965096712112427, Accuracy: 0.78125, Computation time: 0.7793331146240234\n",
      "Step: 1359, Loss: 0.4774875342845917, Accuracy: 0.8125, Computation time: 0.7948567867279053\n",
      "Step: 1360, Loss: 0.7760009765625, Accuracy: 0.78125, Computation time: 0.9450139999389648\n",
      "Step: 1361, Loss: 0.428956538438797, Accuracy: 0.84375, Computation time: 0.814939022064209\n",
      "Step: 1362, Loss: 0.7814943790435791, Accuracy: 0.6875, Computation time: 1.0534331798553467\n",
      "Step: 1363, Loss: 0.8498297929763794, Accuracy: 0.71875, Computation time: 0.7783708572387695\n",
      "Step: 1364, Loss: 0.41510942578315735, Accuracy: 0.875, Computation time: 0.6637430191040039\n",
      "Step: 1365, Loss: 0.5706546306610107, Accuracy: 0.75, Computation time: 0.7793519496917725\n",
      "Step: 1366, Loss: 1.0093717575073242, Accuracy: 0.78125, Computation time: 0.7225229740142822\n",
      "Step: 1367, Loss: 1.157416582107544, Accuracy: 0.6875, Computation time: 0.8189170360565186\n",
      "Step: 1368, Loss: 1.358760952949524, Accuracy: 0.625, Computation time: 0.6869840621948242\n",
      "Step: 1369, Loss: 1.0705047845840454, Accuracy: 0.65625, Computation time: 0.8271629810333252\n",
      "Step: 1370, Loss: 0.5984240174293518, Accuracy: 0.78125, Computation time: 0.8219339847564697\n",
      "Step: 1371, Loss: 0.8103974461555481, Accuracy: 0.6875, Computation time: 0.8082318305969238\n",
      "Step: 1372, Loss: 0.6728092432022095, Accuracy: 0.75, Computation time: 0.7802071571350098\n",
      "Step: 1373, Loss: 0.9544976949691772, Accuracy: 0.625, Computation time: 0.7791290283203125\n",
      "Step: 1374, Loss: 0.6268904805183411, Accuracy: 0.78125, Computation time: 0.7735400199890137\n",
      "Step: 1375, Loss: 0.6935988664627075, Accuracy: 0.71875, Computation time: 0.8574380874633789\n",
      "Step: 1376, Loss: 0.6560590863227844, Accuracy: 0.84375, Computation time: 0.7976429462432861\n",
      "Step: 1377, Loss: 0.6040082573890686, Accuracy: 0.78125, Computation time: 0.7177519798278809\n",
      "Step: 1378, Loss: 0.5828163027763367, Accuracy: 0.90625, Computation time: 0.7470481395721436\n",
      "Step: 1379, Loss: 0.832817792892456, Accuracy: 0.71875, Computation time: 1.1547660827636719\n",
      "Step: 1380, Loss: 0.7258967757225037, Accuracy: 0.78125, Computation time: 0.9084031581878662\n",
      "Step: 1381, Loss: 0.6001890301704407, Accuracy: 0.84375, Computation time: 0.7307467460632324\n",
      "Step: 1382, Loss: 1.1876369714736938, Accuracy: 0.65625, Computation time: 0.7434380054473877\n",
      "Step: 1383, Loss: 0.6135945916175842, Accuracy: 0.8125, Computation time: 1.0180439949035645\n",
      "Step: 1384, Loss: 1.2022613286972046, Accuracy: 0.625, Computation time: 0.8850100040435791\n",
      "Step: 1385, Loss: 0.6850066184997559, Accuracy: 0.78125, Computation time: 4.491098880767822\n",
      "Step: 1386, Loss: 0.9512706398963928, Accuracy: 0.71875, Computation time: 0.8223707675933838\n",
      "Step: 1387, Loss: 0.48810574412345886, Accuracy: 0.8125, Computation time: 0.6333699226379395\n",
      "Step: 1388, Loss: 0.4259467124938965, Accuracy: 0.875, Computation time: 0.7463691234588623\n",
      "Step: 1389, Loss: 1.0162407159805298, Accuracy: 0.75, Computation time: 1.0690548419952393\n",
      "Step: 1390, Loss: 0.5114894509315491, Accuracy: 0.8125, Computation time: 1.3152871131896973\n",
      "Step: 1391, Loss: 0.7128896713256836, Accuracy: 0.78125, Computation time: 0.8099851608276367\n",
      "Step: 1392, Loss: 1.4214046001434326, Accuracy: 0.75, Computation time: 1.280226230621338\n",
      "Step: 1393, Loss: 0.7017565369606018, Accuracy: 0.75, Computation time: 0.7834439277648926\n",
      "Step: 1394, Loss: 0.9322156310081482, Accuracy: 0.71875, Computation time: 0.7351469993591309\n",
      "Step: 1395, Loss: 0.614018976688385, Accuracy: 0.75, Computation time: 0.8171961307525635\n",
      "Step: 1396, Loss: 0.8731793165206909, Accuracy: 0.75, Computation time: 0.6624367237091064\n",
      "Step: 1397, Loss: 1.1288400888442993, Accuracy: 0.6875, Computation time: 0.9619660377502441\n",
      "Step: 1398, Loss: 0.6274250745773315, Accuracy: 0.78125, Computation time: 0.8097360134124756\n",
      "Step: 1399, Loss: 1.5160090923309326, Accuracy: 0.65625, Computation time: 0.7443788051605225\n",
      "Step: 1400, Loss: 0.6441863775253296, Accuracy: 0.8125, Computation time: 0.7972440719604492\n",
      "Step: 1401, Loss: 0.9041993618011475, Accuracy: 0.78125, Computation time: 0.7703430652618408\n",
      "Step: 1402, Loss: 0.8350272178649902, Accuracy: 0.71875, Computation time: 0.7240419387817383\n",
      "Step: 1403, Loss: 0.9447173476219177, Accuracy: 0.6875, Computation time: 0.656660795211792\n",
      "Step: 1404, Loss: 1.1912199258804321, Accuracy: 0.71875, Computation time: 0.7212979793548584\n",
      "Step: 1405, Loss: 0.5993396639823914, Accuracy: 0.84375, Computation time: 1.008836030960083\n",
      "Step: 1406, Loss: 0.6160567402839661, Accuracy: 0.71875, Computation time: 0.6739850044250488\n",
      "Step: 1407, Loss: 0.7783386707305908, Accuracy: 0.78125, Computation time: 0.7453081607818604\n",
      "Step: 1408, Loss: 0.8943807482719421, Accuracy: 0.75, Computation time: 0.9420239925384521\n",
      "Step: 1409, Loss: 1.4724916219711304, Accuracy: 0.6875, Computation time: 0.8365838527679443\n",
      "Step: 1410, Loss: 0.6685540080070496, Accuracy: 0.78125, Computation time: 0.7816488742828369\n",
      "Step: 1411, Loss: 0.9339768886566162, Accuracy: 0.75, Computation time: 0.6843371391296387\n",
      "Step: 1412, Loss: 1.0172110795974731, Accuracy: 0.78125, Computation time: 0.980431079864502\n",
      "Step: 1413, Loss: 0.7194437384605408, Accuracy: 0.75, Computation time: 0.7712891101837158\n",
      "Step: 1414, Loss: 0.6789167523384094, Accuracy: 0.71875, Computation time: 0.7763619422912598\n",
      "Step: 1415, Loss: 0.6712082028388977, Accuracy: 0.78125, Computation time: 0.7558591365814209\n",
      "Step: 1416, Loss: 0.6055362224578857, Accuracy: 0.8125, Computation time: 0.704686164855957\n",
      "Step: 1417, Loss: 1.1878278255462646, Accuracy: 0.6875, Computation time: 0.7788560390472412\n",
      "Step: 1418, Loss: 0.7218281030654907, Accuracy: 0.8125, Computation time: 0.7746438980102539\n",
      "Step: 1419, Loss: 0.9624502062797546, Accuracy: 0.75, Computation time: 0.7911801338195801\n",
      "Step: 1420, Loss: 0.946834146976471, Accuracy: 0.75, Computation time: 0.7660207748413086\n",
      "Step: 1421, Loss: 0.7796056270599365, Accuracy: 0.71875, Computation time: 0.8160958290100098\n",
      "Step: 1422, Loss: 0.9194220304489136, Accuracy: 0.6875, Computation time: 0.6259939670562744\n",
      "Step: 1423, Loss: 0.6159377694129944, Accuracy: 0.8125, Computation time: 0.8300178050994873\n",
      "Step: 1424, Loss: 0.7277997136116028, Accuracy: 0.8125, Computation time: 0.9248769283294678\n",
      "Step: 1425, Loss: 1.0661430358886719, Accuracy: 0.5625, Computation time: 0.7516920566558838\n",
      "Step: 1426, Loss: 0.8585544228553772, Accuracy: 0.65625, Computation time: 0.895758867263794\n",
      "Step: 1427, Loss: 0.7004532814025879, Accuracy: 0.75, Computation time: 0.7668070793151855\n",
      "Step: 1428, Loss: 1.6414121389389038, Accuracy: 0.59375, Computation time: 0.7069430351257324\n",
      "Step: 1429, Loss: 1.2921210527420044, Accuracy: 0.625, Computation time: 0.8040692806243896\n",
      "Step: 1430, Loss: 1.3540016412734985, Accuracy: 0.75, Computation time: 0.8332858085632324\n",
      "Step: 1431, Loss: 1.078710675239563, Accuracy: 0.625, Computation time: 0.9642150402069092\n",
      "Step: 1432, Loss: 0.7123790383338928, Accuracy: 0.78125, Computation time: 0.6856162548065186\n",
      "Step: 1433, Loss: 1.2057538032531738, Accuracy: 0.65625, Computation time: 0.7708768844604492\n",
      "Step: 1434, Loss: 1.1886862516403198, Accuracy: 0.625, Computation time: 0.6755671501159668\n",
      "Step: 1435, Loss: 1.2049936056137085, Accuracy: 0.6875, Computation time: 0.7962145805358887\n",
      "Step: 1436, Loss: 0.9468092918395996, Accuracy: 0.65625, Computation time: 0.9874234199523926\n",
      "Step: 1437, Loss: 0.8363781571388245, Accuracy: 0.75, Computation time: 0.8735558986663818\n",
      "Step: 1438, Loss: 0.7905188798904419, Accuracy: 0.71875, Computation time: 0.7429018020629883\n",
      "Step: 1439, Loss: 1.1030125617980957, Accuracy: 0.65625, Computation time: 0.6992740631103516\n",
      "Step: 1440, Loss: 0.8371607065200806, Accuracy: 0.65625, Computation time: 0.6249129772186279\n",
      "Step: 1441, Loss: 0.6879477500915527, Accuracy: 0.8125, Computation time: 0.6420118808746338\n",
      "Step: 1442, Loss: 0.5442690849304199, Accuracy: 0.8125, Computation time: 0.7875452041625977\n",
      "Step: 1443, Loss: 0.765460729598999, Accuracy: 0.75, Computation time: 0.6841700077056885\n",
      "Step: 1444, Loss: 0.731767475605011, Accuracy: 0.84375, Computation time: 0.6034867763519287\n",
      "Step: 1445, Loss: 1.1077511310577393, Accuracy: 0.75, Computation time: 0.7639601230621338\n",
      "Step: 1446, Loss: 0.940519392490387, Accuracy: 0.78125, Computation time: 0.72037672996521\n",
      "Step: 1447, Loss: 1.027692437171936, Accuracy: 0.65625, Computation time: 0.7682089805603027\n",
      "Step: 1448, Loss: 0.7793433666229248, Accuracy: 0.6875, Computation time: 0.8347020149230957\n",
      "Step: 1449, Loss: 0.8159102201461792, Accuracy: 0.8125, Computation time: 0.9084689617156982\n",
      "Step: 1450, Loss: 0.8735717535018921, Accuracy: 0.6875, Computation time: 1.0145800113677979\n",
      "Step: 1451, Loss: 0.6120401620864868, Accuracy: 0.84375, Computation time: 0.7037267684936523\n",
      "Step: 1452, Loss: 0.755486786365509, Accuracy: 0.71875, Computation time: 0.6925151348114014\n",
      "Step: 1453, Loss: 0.4201987385749817, Accuracy: 0.875, Computation time: 0.6816933155059814\n",
      "Step: 1454, Loss: 0.8946950435638428, Accuracy: 0.6875, Computation time: 0.8396739959716797\n",
      "Step: 1455, Loss: 0.7892018556594849, Accuracy: 0.78125, Computation time: 0.6826088428497314\n",
      "Step: 1456, Loss: 0.8907593488693237, Accuracy: 0.6875, Computation time: 0.7505550384521484\n",
      "Step: 1457, Loss: 1.1220680475234985, Accuracy: 0.65625, Computation time: 0.9503509998321533\n",
      "Step: 1458, Loss: 0.9917154908180237, Accuracy: 0.71875, Computation time: 1.0748307704925537\n",
      "Step: 1459, Loss: 1.089190125465393, Accuracy: 0.75, Computation time: 0.8349637985229492\n",
      "Step: 1460, Loss: 0.49922457337379456, Accuracy: 0.875, Computation time: 0.6595110893249512\n",
      "Step: 1461, Loss: 0.6000373959541321, Accuracy: 0.875, Computation time: 0.9261090755462646\n",
      "Step: 1462, Loss: 0.7007479667663574, Accuracy: 0.8125, Computation time: 0.7635278701782227\n",
      "Step: 1463, Loss: 1.1835945844650269, Accuracy: 0.59375, Computation time: 0.8132579326629639\n",
      "Step: 1464, Loss: 0.5085868835449219, Accuracy: 0.90625, Computation time: 0.6444201469421387\n",
      "Step: 1465, Loss: 0.4416956603527069, Accuracy: 0.90625, Computation time: 0.7731399536132812\n",
      "Step: 1466, Loss: 0.6980888843536377, Accuracy: 0.84375, Computation time: 0.6325156688690186\n",
      "Step: 1467, Loss: 0.6563794612884521, Accuracy: 0.84375, Computation time: 0.6922469139099121\n",
      "Step: 1468, Loss: 0.3002479672431946, Accuracy: 0.90625, Computation time: 0.6630640029907227\n",
      "Step: 1469, Loss: 1.0136010646820068, Accuracy: 0.65625, Computation time: 0.7762050628662109\n",
      "Step: 1470, Loss: 0.9939399361610413, Accuracy: 0.71875, Computation time: 1.0580229759216309\n",
      "Step: 1471, Loss: 0.5367596745491028, Accuracy: 0.84375, Computation time: 0.9752299785614014\n",
      "Step: 1472, Loss: 0.6039276123046875, Accuracy: 0.75, Computation time: 0.710064172744751\n",
      "Step: 1473, Loss: 0.47692933678627014, Accuracy: 0.84375, Computation time: 0.7832796573638916\n",
      "Step: 1474, Loss: 0.7289162278175354, Accuracy: 0.8125, Computation time: 0.9077112674713135\n",
      "Step: 1475, Loss: 0.8209101557731628, Accuracy: 0.78125, Computation time: 0.6523709297180176\n",
      "Step: 1476, Loss: 0.4403528571128845, Accuracy: 0.90625, Computation time: 0.7551918029785156\n",
      "Step: 1477, Loss: 0.7415376305580139, Accuracy: 0.84375, Computation time: 0.7261121273040771\n",
      "Step: 1478, Loss: 1.2561289072036743, Accuracy: 0.65625, Computation time: 7.468240976333618\n",
      "Step: 1479, Loss: 0.5255081653594971, Accuracy: 0.84375, Computation time: 0.6736798286437988\n",
      "Step: 1480, Loss: 1.0196959972381592, Accuracy: 0.71875, Computation time: 0.8108930587768555\n",
      "Step: 1481, Loss: 0.8887742161750793, Accuracy: 0.6875, Computation time: 0.7781651020050049\n",
      "Step: 1482, Loss: 1.267161250114441, Accuracy: 0.71875, Computation time: 0.7568750381469727\n",
      "Step: 1483, Loss: 1.0852506160736084, Accuracy: 0.625, Computation time: 0.921234130859375\n",
      "Step: 1484, Loss: 0.7664863467216492, Accuracy: 0.71875, Computation time: 1.1214301586151123\n",
      "Step: 1485, Loss: 0.6693468689918518, Accuracy: 0.75, Computation time: 0.7821099758148193\n",
      "Step: 1486, Loss: 0.5687221884727478, Accuracy: 0.8125, Computation time: 0.7080881595611572\n",
      "Step: 1487, Loss: 0.6017718315124512, Accuracy: 0.8125, Computation time: 0.7126803398132324\n",
      "Step: 1488, Loss: 0.3797609508037567, Accuracy: 0.9375, Computation time: 0.6986238956451416\n",
      "Step: 1489, Loss: 0.8144420385360718, Accuracy: 0.71875, Computation time: 0.7184922695159912\n",
      "Step: 1490, Loss: 0.7731567621231079, Accuracy: 0.8125, Computation time: 0.7064869403839111\n",
      "Step: 1491, Loss: 0.507948637008667, Accuracy: 0.84375, Computation time: 0.7314467430114746\n",
      "Step: 1492, Loss: 0.5423055291175842, Accuracy: 0.90625, Computation time: 0.7077338695526123\n",
      "Step: 1493, Loss: 1.1860082149505615, Accuracy: 0.65625, Computation time: 0.7715258598327637\n",
      "Step: 1494, Loss: 0.9838651418685913, Accuracy: 0.6875, Computation time: 0.7176980972290039\n",
      "Step: 1495, Loss: 0.5352070927619934, Accuracy: 0.84375, Computation time: 0.7650518417358398\n",
      "Step: 1496, Loss: 0.5684502124786377, Accuracy: 0.84375, Computation time: 0.7175610065460205\n",
      "Step: 1497, Loss: 0.737678050994873, Accuracy: 0.75, Computation time: 0.8400728702545166\n",
      "Step: 1498, Loss: 0.5390064120292664, Accuracy: 0.90625, Computation time: 0.6813421249389648\n",
      "Step: 1499, Loss: 1.3111486434936523, Accuracy: 0.625, Computation time: 0.9394228458404541\n",
      "Step: 1500, Loss: 1.0606309175491333, Accuracy: 0.71875, Computation time: 1.026378870010376\n",
      "Step: 1501, Loss: 0.6713752746582031, Accuracy: 0.78125, Computation time: 0.794605016708374\n",
      "Step: 1502, Loss: 0.9478806257247925, Accuracy: 0.75, Computation time: 0.7387571334838867\n",
      "Step: 1503, Loss: 1.1773645877838135, Accuracy: 0.75, Computation time: 0.6966640949249268\n",
      "Step: 1504, Loss: 0.855064868927002, Accuracy: 0.84375, Computation time: 0.6450488567352295\n",
      "Step: 1505, Loss: 0.8953605890274048, Accuracy: 0.75, Computation time: 0.8244049549102783\n",
      "Step: 1506, Loss: 0.7464439272880554, Accuracy: 0.75, Computation time: 0.7074649333953857\n",
      "Step: 1507, Loss: 1.0704963207244873, Accuracy: 0.75, Computation time: 0.8954169750213623\n",
      "Step: 1508, Loss: 0.9190673828125, Accuracy: 0.78125, Computation time: 0.6874213218688965\n",
      "Step: 1509, Loss: 0.737281322479248, Accuracy: 0.71875, Computation time: 0.7360849380493164\n",
      "Step: 1510, Loss: 0.633087158203125, Accuracy: 0.75, Computation time: 0.8647780418395996\n",
      "Step: 1511, Loss: 0.8857223987579346, Accuracy: 0.75, Computation time: 0.8033039569854736\n",
      "Step: 1512, Loss: 0.8827427625656128, Accuracy: 0.6875, Computation time: 0.7041411399841309\n",
      "Step: 1513, Loss: 0.7058303356170654, Accuracy: 0.71875, Computation time: 0.7455270290374756\n",
      "Step: 1514, Loss: 0.5156949758529663, Accuracy: 0.875, Computation time: 0.7092571258544922\n",
      "Step: 1515, Loss: 0.842295229434967, Accuracy: 0.8125, Computation time: 0.776313066482544\n",
      "Step: 1516, Loss: 0.7056357860565186, Accuracy: 0.875, Computation time: 0.8271441459655762\n",
      "Step: 1517, Loss: 0.4903111457824707, Accuracy: 0.78125, Computation time: 0.8604700565338135\n",
      "Step: 1518, Loss: 1.196219563484192, Accuracy: 0.75, Computation time: 0.7802219390869141\n",
      "Step: 1519, Loss: 0.9962975382804871, Accuracy: 0.71875, Computation time: 1.2595851421356201\n",
      "Step: 1520, Loss: 0.6963523030281067, Accuracy: 0.75, Computation time: 0.6744909286499023\n",
      "Step: 1521, Loss: 0.6770983934402466, Accuracy: 0.71875, Computation time: 0.6689789295196533\n",
      "Step: 1522, Loss: 0.8848893642425537, Accuracy: 0.75, Computation time: 0.8465931415557861\n",
      "Step: 1523, Loss: 0.5479258298873901, Accuracy: 0.875, Computation time: 0.7752580642700195\n",
      "Step: 1524, Loss: 0.5723028779029846, Accuracy: 0.84375, Computation time: 0.6616458892822266\n",
      "Step: 1525, Loss: 0.5949763655662537, Accuracy: 0.75, Computation time: 0.7297840118408203\n",
      "Step: 1526, Loss: 0.7742911577224731, Accuracy: 0.71875, Computation time: 0.819674015045166\n",
      "Step: 1527, Loss: 1.1414036750793457, Accuracy: 0.65625, Computation time: 0.8965260982513428\n",
      "Step: 1528, Loss: 0.6536573767662048, Accuracy: 0.8125, Computation time: 0.8296451568603516\n",
      "Step: 1529, Loss: 0.7232980132102966, Accuracy: 0.8125, Computation time: 0.9537827968597412\n",
      "Step: 1530, Loss: 0.6864456534385681, Accuracy: 0.78125, Computation time: 0.8281421661376953\n",
      "Step: 1531, Loss: 1.1475669145584106, Accuracy: 0.75, Computation time: 0.839587926864624\n",
      "Step: 1532, Loss: 0.7371905446052551, Accuracy: 0.75, Computation time: 0.7688827514648438\n",
      "Step: 1533, Loss: 0.5720007419586182, Accuracy: 0.8125, Computation time: 0.7921779155731201\n",
      "Step: 1534, Loss: 0.5007132291793823, Accuracy: 0.875, Computation time: 0.7057230472564697\n",
      "Step: 1535, Loss: 0.9356672763824463, Accuracy: 0.71875, Computation time: 0.7120921611785889\n",
      "Step: 1536, Loss: 0.8151817917823792, Accuracy: 0.84375, Computation time: 0.860414981842041\n",
      "Step: 1537, Loss: 0.9248368740081787, Accuracy: 0.78125, Computation time: 0.7572851181030273\n",
      "Step: 1538, Loss: 1.2822200059890747, Accuracy: 0.71875, Computation time: 0.8354527950286865\n",
      "Step: 1539, Loss: 1.05420982837677, Accuracy: 0.75, Computation time: 0.6894958019256592\n",
      "Step: 1540, Loss: 0.7518536448478699, Accuracy: 0.75, Computation time: 0.6155972480773926\n",
      "Step: 1541, Loss: 1.3519145250320435, Accuracy: 0.6875, Computation time: 0.7838428020477295\n",
      "Step: 1542, Loss: 0.8907937407493591, Accuracy: 0.78125, Computation time: 0.8990740776062012\n",
      "Step: 1543, Loss: 1.164974331855774, Accuracy: 0.59375, Computation time: 0.656174898147583\n",
      "Step: 1544, Loss: 0.8415074348449707, Accuracy: 0.84375, Computation time: 0.7421071529388428\n",
      "Step: 1545, Loss: 0.872177243232727, Accuracy: 0.78125, Computation time: 0.7022349834442139\n",
      "Step: 1546, Loss: 0.9543679356575012, Accuracy: 0.6875, Computation time: 0.7039299011230469\n",
      "Step: 1547, Loss: 0.7352694869041443, Accuracy: 0.84375, Computation time: 0.7673709392547607\n",
      "Step: 1548, Loss: 0.6316925287246704, Accuracy: 0.78125, Computation time: 0.719386100769043\n",
      "Step: 1549, Loss: 1.199299931526184, Accuracy: 0.65625, Computation time: 0.7921779155731201\n",
      "Step: 1550, Loss: 1.126823902130127, Accuracy: 0.6875, Computation time: 0.7714979648590088\n",
      "Step: 1551, Loss: 0.4981396198272705, Accuracy: 0.84375, Computation time: 0.6856770515441895\n",
      "Step: 1552, Loss: 0.6840484142303467, Accuracy: 0.75, Computation time: 0.8828768730163574\n",
      "Step: 1553, Loss: 1.1608664989471436, Accuracy: 0.6875, Computation time: 0.7449731826782227\n",
      "Step: 1554, Loss: 0.9783759713172913, Accuracy: 0.78125, Computation time: 0.7085361480712891\n",
      "Step: 1555, Loss: 0.9684402942657471, Accuracy: 0.71875, Computation time: 0.7674140930175781\n",
      "Step: 1556, Loss: 0.7701622247695923, Accuracy: 0.8125, Computation time: 0.7035121917724609\n",
      "Step: 1557, Loss: 0.8468754291534424, Accuracy: 0.71875, Computation time: 0.7072570323944092\n",
      "Step: 1558, Loss: 0.7363309264183044, Accuracy: 0.8125, Computation time: 0.7730381488800049\n",
      "Step: 1559, Loss: 0.8003965020179749, Accuracy: 0.78125, Computation time: 0.8086390495300293\n",
      "Step: 1560, Loss: 0.851577877998352, Accuracy: 0.65625, Computation time: 1.1338961124420166\n",
      "Step: 1561, Loss: 0.7391257286071777, Accuracy: 0.71875, Computation time: 0.7615151405334473\n",
      "Step: 1562, Loss: 0.8774091005325317, Accuracy: 0.71875, Computation time: 0.6365928649902344\n",
      "Step: 1563, Loss: 0.3704187870025635, Accuracy: 0.90625, Computation time: 0.7550070285797119\n",
      "Step: 1564, Loss: 0.979517936706543, Accuracy: 0.6875, Computation time: 0.881782054901123\n",
      "Step: 1565, Loss: 0.9582785367965698, Accuracy: 0.78125, Computation time: 0.770554780960083\n",
      "Step: 1566, Loss: 0.9500896334648132, Accuracy: 0.625, Computation time: 0.7424499988555908\n",
      "Step: 1567, Loss: 0.5890997648239136, Accuracy: 0.90625, Computation time: 0.6774227619171143\n",
      "Step: 1568, Loss: 0.8745089173316956, Accuracy: 0.625, Computation time: 0.7116968631744385\n",
      "Step: 1569, Loss: 1.1312814950942993, Accuracy: 0.5625, Computation time: 0.751000165939331\n",
      "Step: 1570, Loss: 0.5074285268783569, Accuracy: 0.8125, Computation time: 0.7140991687774658\n",
      "Step: 1571, Loss: 1.026167392730713, Accuracy: 0.71875, Computation time: 0.8036751747131348\n",
      "Step: 1572, Loss: 0.8094381093978882, Accuracy: 0.78125, Computation time: 0.7847020626068115\n",
      "Step: 1573, Loss: 0.4080705940723419, Accuracy: 0.90625, Computation time: 0.9322359561920166\n",
      "Step: 1574, Loss: 0.826069176197052, Accuracy: 0.6875, Computation time: 0.7667520046234131\n",
      "Step: 1575, Loss: 0.7176138162612915, Accuracy: 0.75, Computation time: 0.8446338176727295\n",
      "Step: 1576, Loss: 0.6940175294876099, Accuracy: 0.75, Computation time: 0.8220911026000977\n",
      "Step: 1577, Loss: 0.6846877932548523, Accuracy: 0.75, Computation time: 0.843250036239624\n",
      "Step: 1578, Loss: 1.2708306312561035, Accuracy: 0.71875, Computation time: 0.7529022693634033\n",
      "Step: 1579, Loss: 0.4446573257446289, Accuracy: 0.84375, Computation time: 0.7478139400482178\n",
      "Step: 1580, Loss: 0.8384701013565063, Accuracy: 0.78125, Computation time: 0.6803629398345947\n",
      "Step: 1581, Loss: 1.2640230655670166, Accuracy: 0.625, Computation time: 0.7272000312805176\n",
      "Step: 1582, Loss: 0.6926988959312439, Accuracy: 0.84375, Computation time: 0.7349822521209717\n",
      "Step: 1583, Loss: 1.2396857738494873, Accuracy: 0.625, Computation time: 0.8915331363677979\n",
      "Step: 1584, Loss: 0.6618770956993103, Accuracy: 0.78125, Computation time: 0.688079833984375\n",
      "Step: 1585, Loss: 0.8685218095779419, Accuracy: 0.71875, Computation time: 0.6786627769470215\n",
      "Step: 1586, Loss: 0.5013408064842224, Accuracy: 0.8125, Computation time: 0.8118829727172852\n",
      "Step: 1587, Loss: 0.5078520774841309, Accuracy: 0.78125, Computation time: 0.7322518825531006\n",
      "Step: 1588, Loss: 0.27606794238090515, Accuracy: 0.9375, Computation time: 0.9098758697509766\n",
      "Step: 1589, Loss: 0.6456794738769531, Accuracy: 0.875, Computation time: 0.801016092300415\n",
      "Step: 1590, Loss: 0.7303979396820068, Accuracy: 0.71875, Computation time: 0.6890418529510498\n",
      "Step: 1591, Loss: 1.0587540864944458, Accuracy: 0.78125, Computation time: 0.9869911670684814\n",
      "Step: 1592, Loss: 0.7116664052009583, Accuracy: 0.65625, Computation time: 0.8192391395568848\n",
      "Step: 1593, Loss: 0.7956728339195251, Accuracy: 0.65625, Computation time: 0.810053825378418\n",
      "Step: 1594, Loss: 0.32566505670547485, Accuracy: 0.90625, Computation time: 0.9121520519256592\n",
      "Step: 1595, Loss: 0.5074468851089478, Accuracy: 0.84375, Computation time: 0.8161637783050537\n",
      "Step: 1596, Loss: 0.8678271174430847, Accuracy: 0.75, Computation time: 0.6983568668365479\n",
      "Step: 1597, Loss: 0.8436261415481567, Accuracy: 0.75, Computation time: 0.7340958118438721\n",
      "Step: 1598, Loss: 1.1663824319839478, Accuracy: 0.65625, Computation time: 0.6305148601531982\n",
      "Step: 1599, Loss: 0.8302314281463623, Accuracy: 0.8125, Computation time: 0.6552650928497314\n",
      "Step: 1600, Loss: 1.0279057025909424, Accuracy: 0.6875, Computation time: 1.197835922241211\n",
      "Step: 1601, Loss: 0.7255904674530029, Accuracy: 0.78125, Computation time: 0.7745800018310547\n",
      "Step: 1602, Loss: 0.9873157143592834, Accuracy: 0.75, Computation time: 0.727449893951416\n",
      "Step: 1603, Loss: 0.9233049154281616, Accuracy: 0.8125, Computation time: 0.7008216381072998\n",
      "Step: 1604, Loss: 1.009199619293213, Accuracy: 0.6875, Computation time: 1.1056547164916992\n",
      "Step: 1605, Loss: 1.0358275175094604, Accuracy: 0.65625, Computation time: 0.8088819980621338\n",
      "Step: 1606, Loss: 0.7782527208328247, Accuracy: 0.8125, Computation time: 0.7980151176452637\n",
      "Step: 1607, Loss: 0.3923145532608032, Accuracy: 0.96875, Computation time: 0.7817237377166748\n",
      "Step: 1608, Loss: 0.6885803937911987, Accuracy: 0.75, Computation time: 0.7369630336761475\n",
      "Step: 1609, Loss: 0.521882176399231, Accuracy: 0.875, Computation time: 0.6752760410308838\n",
      "Step: 1610, Loss: 0.4330889880657196, Accuracy: 0.90625, Computation time: 0.9010400772094727\n",
      "Step: 1611, Loss: 0.573282778263092, Accuracy: 0.8125, Computation time: 0.6877398490905762\n",
      "Step: 1612, Loss: 0.6662448644638062, Accuracy: 0.78125, Computation time: 0.696678876876831\n",
      "Step: 1613, Loss: 0.5402940511703491, Accuracy: 0.875, Computation time: 0.7169399261474609\n",
      "Step: 1614, Loss: 0.6567732095718384, Accuracy: 0.84375, Computation time: 0.7657692432403564\n",
      "Step: 1615, Loss: 1.0060278177261353, Accuracy: 0.6875, Computation time: 0.835820198059082\n",
      "Step: 1616, Loss: 0.845585286617279, Accuracy: 0.6875, Computation time: 0.6992299556732178\n",
      "Step: 1617, Loss: 1.1031213998794556, Accuracy: 0.65625, Computation time: 0.8619880676269531\n",
      "Step: 1618, Loss: 0.4445566236972809, Accuracy: 0.84375, Computation time: 0.848365068435669\n",
      "Step: 1619, Loss: 0.9662341475486755, Accuracy: 0.75, Computation time: 0.6989083290100098\n",
      "Step: 1620, Loss: 0.8490415811538696, Accuracy: 0.78125, Computation time: 0.7387640476226807\n",
      "Step: 1621, Loss: 0.47381508350372314, Accuracy: 0.84375, Computation time: 0.9892792701721191\n",
      "Step: 1622, Loss: 0.9688441753387451, Accuracy: 0.75, Computation time: 0.7851638793945312\n",
      "Step: 1623, Loss: 0.6973772644996643, Accuracy: 0.8125, Computation time: 0.739617109298706\n",
      "Step: 1624, Loss: 0.8843281269073486, Accuracy: 0.65625, Computation time: 0.7717611789703369\n",
      "Step: 1625, Loss: 0.953657329082489, Accuracy: 0.65625, Computation time: 0.7842891216278076\n",
      "Step: 1626, Loss: 0.7005772590637207, Accuracy: 0.71875, Computation time: 0.7808921337127686\n",
      "Step: 1627, Loss: 0.9202361106872559, Accuracy: 0.71875, Computation time: 0.6886439323425293\n",
      "Step: 1628, Loss: 0.5533351898193359, Accuracy: 0.875, Computation time: 0.9000961780548096\n",
      "Step: 1629, Loss: 0.8756242990493774, Accuracy: 0.71875, Computation time: 0.7555861473083496\n",
      "Step: 1630, Loss: 1.1595382690429688, Accuracy: 0.59375, Computation time: 0.8570408821105957\n",
      "Step: 1631, Loss: 0.8310835361480713, Accuracy: 0.75, Computation time: 0.7912440299987793\n",
      "Step: 1632, Loss: 0.8870275020599365, Accuracy: 0.75, Computation time: 0.7787179946899414\n",
      "Step: 1633, Loss: 0.7519694566726685, Accuracy: 0.75, Computation time: 0.672827959060669\n",
      "Step: 1634, Loss: 0.8792217373847961, Accuracy: 0.65625, Computation time: 0.7568609714508057\n",
      "Step: 1635, Loss: 1.2129151821136475, Accuracy: 0.53125, Computation time: 0.9441542625427246\n",
      "Step: 1636, Loss: 1.2757798433303833, Accuracy: 0.6875, Computation time: 1.0556252002716064\n",
      "Step: 1637, Loss: 0.9207702279090881, Accuracy: 0.78125, Computation time: 0.8278272151947021\n",
      "Step: 1638, Loss: 0.9188801646232605, Accuracy: 0.75, Computation time: 0.8908681869506836\n",
      "Step: 1639, Loss: 0.6252914071083069, Accuracy: 0.8125, Computation time: 0.668442964553833\n",
      "Step: 1640, Loss: 0.7500714063644409, Accuracy: 0.71875, Computation time: 0.7065122127532959\n",
      "Step: 1641, Loss: 0.5677796006202698, Accuracy: 0.8125, Computation time: 0.7514753341674805\n",
      "Step: 1642, Loss: 1.0321698188781738, Accuracy: 0.625, Computation time: 0.7761831283569336\n",
      "Step: 1643, Loss: 0.7546898722648621, Accuracy: 0.71875, Computation time: 0.941572904586792\n",
      "Step: 1644, Loss: 0.8861879110336304, Accuracy: 0.71875, Computation time: 0.7685379981994629\n",
      "Step: 1645, Loss: 1.0775614976882935, Accuracy: 0.65625, Computation time: 0.7635869979858398\n",
      "Step: 1646, Loss: 0.7453175187110901, Accuracy: 0.75, Computation time: 0.8957393169403076\n",
      "Step: 1647, Loss: 0.9189856052398682, Accuracy: 0.75, Computation time: 0.6304371356964111\n",
      "Step: 1648, Loss: 1.0688886642456055, Accuracy: 0.71875, Computation time: 5.715921878814697\n",
      "Step: 1649, Loss: 0.7913588285446167, Accuracy: 0.78125, Computation time: 1.3072781562805176\n",
      "Step: 1650, Loss: 0.9362378716468811, Accuracy: 0.71875, Computation time: 0.804664134979248\n",
      "Step: 1651, Loss: 0.625080943107605, Accuracy: 0.84375, Computation time: 0.7258260250091553\n",
      "Step: 1652, Loss: 0.45693227648735046, Accuracy: 0.875, Computation time: 0.9543368816375732\n",
      "Step: 1653, Loss: 0.5013455152511597, Accuracy: 0.8125, Computation time: 1.1369826793670654\n",
      "Step: 1654, Loss: 0.5845971703529358, Accuracy: 0.78125, Computation time: 0.7636642456054688\n",
      "Step: 1655, Loss: 0.8858626484870911, Accuracy: 0.71875, Computation time: 0.8794879913330078\n",
      "Step: 1656, Loss: 0.4970819354057312, Accuracy: 0.84375, Computation time: 0.6624011993408203\n",
      "Step: 1657, Loss: 0.8946554064750671, Accuracy: 0.78125, Computation time: 1.0508501529693604\n",
      "Step: 1658, Loss: 0.9824325442314148, Accuracy: 0.65625, Computation time: 0.714871883392334\n",
      "Step: 1659, Loss: 1.0706051588058472, Accuracy: 0.59375, Computation time: 0.6883561611175537\n",
      "Step: 1660, Loss: 0.8296622037887573, Accuracy: 0.75, Computation time: 0.7810280323028564\n",
      "Step: 1661, Loss: 0.3080514669418335, Accuracy: 0.84375, Computation time: 0.7708859443664551\n",
      "Step: 1662, Loss: 0.5370061993598938, Accuracy: 0.8125, Computation time: 0.7988667488098145\n",
      "Step: 1663, Loss: 1.5284643173217773, Accuracy: 0.53125, Computation time: 0.8257501125335693\n",
      "Step: 1664, Loss: 0.831461489200592, Accuracy: 0.8125, Computation time: 0.7575819492340088\n",
      "Step: 1665, Loss: 0.3896770477294922, Accuracy: 0.90625, Computation time: 0.6501622200012207\n",
      "Step: 1666, Loss: 0.6786803007125854, Accuracy: 0.78125, Computation time: 0.7073979377746582\n",
      "Step: 1667, Loss: 0.5459176301956177, Accuracy: 0.90625, Computation time: 0.7966136932373047\n",
      "Step: 1668, Loss: 0.8315983414649963, Accuracy: 0.78125, Computation time: 0.8943657875061035\n",
      "Step: 1669, Loss: 0.833870530128479, Accuracy: 0.71875, Computation time: 0.7159271240234375\n",
      "Step: 1670, Loss: 0.6275066137313843, Accuracy: 0.71875, Computation time: 0.6387240886688232\n",
      "Step: 1671, Loss: 0.3684016764163971, Accuracy: 0.84375, Computation time: 0.7298920154571533\n",
      "Step: 1672, Loss: 0.3215751349925995, Accuracy: 0.90625, Computation time: 0.9159760475158691\n",
      "Step: 1673, Loss: 1.3236804008483887, Accuracy: 0.625, Computation time: 0.7905447483062744\n",
      "Step: 1674, Loss: 0.570595920085907, Accuracy: 0.78125, Computation time: 0.7334091663360596\n",
      "Step: 1675, Loss: 0.5540293455123901, Accuracy: 0.84375, Computation time: 0.6746599674224854\n",
      "Step: 1676, Loss: 0.42805904150009155, Accuracy: 0.84375, Computation time: 0.7875449657440186\n",
      "Step: 1677, Loss: 0.5879717469215393, Accuracy: 0.78125, Computation time: 0.7414782047271729\n",
      "Step: 1678, Loss: 0.784816563129425, Accuracy: 0.8125, Computation time: 0.8764379024505615\n",
      "Step: 1679, Loss: 0.8233439922332764, Accuracy: 0.71875, Computation time: 0.7088978290557861\n",
      "Step: 1680, Loss: 0.8309256434440613, Accuracy: 0.71875, Computation time: 0.87200927734375\n",
      "Step: 1681, Loss: 0.6112008094787598, Accuracy: 0.8125, Computation time: 0.8142621517181396\n",
      "Step: 1682, Loss: 1.1556458473205566, Accuracy: 0.625, Computation time: 1.0363349914550781\n",
      "Step: 1683, Loss: 1.0302151441574097, Accuracy: 0.65625, Computation time: 0.8372740745544434\n",
      "Step: 1684, Loss: 1.2201972007751465, Accuracy: 0.65625, Computation time: 0.948667049407959\n",
      "Step: 1685, Loss: 1.1570686101913452, Accuracy: 0.65625, Computation time: 0.7420060634613037\n",
      "Step: 1686, Loss: 0.7732399106025696, Accuracy: 0.84375, Computation time: 0.8602101802825928\n",
      "Step: 1687, Loss: 0.7525108456611633, Accuracy: 0.71875, Computation time: 0.7966442108154297\n",
      "Step: 1688, Loss: 0.4530518054962158, Accuracy: 0.875, Computation time: 0.7665660381317139\n",
      "Step: 1689, Loss: 0.5230095386505127, Accuracy: 0.8125, Computation time: 0.6628637313842773\n",
      "Step: 1690, Loss: 0.7060818672180176, Accuracy: 0.75, Computation time: 0.5943620204925537\n",
      "Step: 1691, Loss: 0.7974776029586792, Accuracy: 0.75, Computation time: 0.6676018238067627\n",
      "Step: 1692, Loss: 0.8073782920837402, Accuracy: 0.75, Computation time: 0.6691310405731201\n",
      "Step: 1693, Loss: 0.47125595808029175, Accuracy: 0.8125, Computation time: 0.9877898693084717\n",
      "Step: 1694, Loss: 0.536012589931488, Accuracy: 0.875, Computation time: 0.7553720474243164\n",
      "Step: 1695, Loss: 0.4471874237060547, Accuracy: 0.875, Computation time: 0.7931382656097412\n",
      "Step: 1696, Loss: 0.9578329920768738, Accuracy: 0.65625, Computation time: 0.8364920616149902\n",
      "Step: 1697, Loss: 0.6581498384475708, Accuracy: 0.8125, Computation time: 0.7989099025726318\n",
      "Step: 1698, Loss: 0.9090131521224976, Accuracy: 0.75, Computation time: 0.8407800197601318\n",
      "Step: 1699, Loss: 0.3929439187049866, Accuracy: 0.90625, Computation time: 0.7324299812316895\n",
      "Step: 1700, Loss: 0.6883012652397156, Accuracy: 0.71875, Computation time: 0.9638001918792725\n",
      "Step: 1701, Loss: 1.4223952293395996, Accuracy: 0.75, Computation time: 0.9203572273254395\n",
      "Step: 1702, Loss: 1.040522813796997, Accuracy: 0.6875, Computation time: 1.1740150451660156\n",
      "Step: 1703, Loss: 0.7475574016571045, Accuracy: 0.8125, Computation time: 0.6608703136444092\n",
      "Step: 1704, Loss: 0.7737582921981812, Accuracy: 0.6875, Computation time: 0.7244658470153809\n",
      "Step: 1705, Loss: 0.6707420349121094, Accuracy: 0.84375, Computation time: 0.8118047714233398\n",
      "Step: 1706, Loss: 0.7249487042427063, Accuracy: 0.8125, Computation time: 0.8188800811767578\n",
      "Step: 1707, Loss: 1.1897374391555786, Accuracy: 0.65625, Computation time: 0.8303122520446777\n",
      "Step: 1708, Loss: 0.7467852830886841, Accuracy: 0.8125, Computation time: 0.7031559944152832\n",
      "Step: 1709, Loss: 0.9889264106750488, Accuracy: 0.65625, Computation time: 0.8244011402130127\n",
      "Step: 1710, Loss: 0.7940386533737183, Accuracy: 0.71875, Computation time: 0.774601936340332\n",
      "Step: 1711, Loss: 0.40974852442741394, Accuracy: 0.875, Computation time: 0.6601459980010986\n",
      "Step: 1712, Loss: 0.5618783831596375, Accuracy: 0.78125, Computation time: 0.772737979888916\n",
      "Step: 1713, Loss: 1.0824025869369507, Accuracy: 0.71875, Computation time: 0.7280979156494141\n",
      "Step: 1714, Loss: 0.6083094477653503, Accuracy: 0.78125, Computation time: 0.6576981544494629\n",
      "Step: 1715, Loss: 0.9850853681564331, Accuracy: 0.71875, Computation time: 0.9346010684967041\n",
      "Step: 1716, Loss: 0.5373585224151611, Accuracy: 0.8125, Computation time: 1.390448808670044\n",
      "Step: 1717, Loss: 0.7044214606285095, Accuracy: 0.75, Computation time: 0.823685884475708\n",
      "Step: 1718, Loss: 0.5548707246780396, Accuracy: 0.90625, Computation time: 0.6902179718017578\n",
      "Step: 1719, Loss: 0.6374387741088867, Accuracy: 0.8125, Computation time: 0.7550361156463623\n",
      "Step: 1720, Loss: 0.7346199750900269, Accuracy: 0.71875, Computation time: 0.6134529113769531\n",
      "Step: 1721, Loss: 0.6566664576530457, Accuracy: 0.84375, Computation time: 0.7681951522827148\n",
      "Step: 1722, Loss: 0.4540744721889496, Accuracy: 0.8125, Computation time: 0.7997539043426514\n",
      "Step: 1723, Loss: 0.7790413498878479, Accuracy: 0.78125, Computation time: 1.176414966583252\n",
      "Step: 1724, Loss: 0.67340087890625, Accuracy: 0.8125, Computation time: 1.289062261581421\n",
      "Step: 1725, Loss: 0.6103615164756775, Accuracy: 0.8125, Computation time: 0.8443570137023926\n",
      "Step: 1726, Loss: 0.9928101301193237, Accuracy: 0.65625, Computation time: 0.7207939624786377\n",
      "Step: 1727, Loss: 0.7046289443969727, Accuracy: 0.8125, Computation time: 0.8597149848937988\n",
      "Step: 1728, Loss: 0.5470632314682007, Accuracy: 0.90625, Computation time: 0.7108569145202637\n",
      "Step: 1729, Loss: 0.49080440402030945, Accuracy: 0.8125, Computation time: 0.8024210929870605\n",
      "Step: 1730, Loss: 0.6268649101257324, Accuracy: 0.875, Computation time: 0.796046257019043\n",
      "Step: 1731, Loss: 0.9218965768814087, Accuracy: 0.75, Computation time: 0.6769039630889893\n",
      "Step: 1732, Loss: 0.741182267665863, Accuracy: 0.78125, Computation time: 0.8613529205322266\n",
      "Step: 1733, Loss: 0.605912983417511, Accuracy: 0.875, Computation time: 0.8404860496520996\n",
      "Step: 1734, Loss: 0.36798572540283203, Accuracy: 0.90625, Computation time: 0.6937692165374756\n",
      "Step: 1735, Loss: 1.1362048387527466, Accuracy: 0.78125, Computation time: 0.8362362384796143\n",
      "Step: 1736, Loss: 0.6561594009399414, Accuracy: 0.8125, Computation time: 0.7427849769592285\n",
      "Step: 1737, Loss: 1.0159083604812622, Accuracy: 0.71875, Computation time: 0.7873861789703369\n",
      "Step: 1738, Loss: 0.529576301574707, Accuracy: 0.875, Computation time: 0.7781050205230713\n",
      "Step: 1739, Loss: 0.5371676683425903, Accuracy: 0.8125, Computation time: 0.7115058898925781\n",
      "Step: 1740, Loss: 0.7751026749610901, Accuracy: 0.8125, Computation time: 0.7062649726867676\n",
      "Step: 1741, Loss: 1.6797465085983276, Accuracy: 0.625, Computation time: 1.00929594039917\n",
      "Step: 1742, Loss: 0.6659175157546997, Accuracy: 0.8125, Computation time: 0.7504801750183105\n",
      "Step: 1743, Loss: 0.5122073888778687, Accuracy: 0.875, Computation time: 0.8349637985229492\n",
      "Step: 1744, Loss: 0.6720510125160217, Accuracy: 0.8125, Computation time: 0.7299771308898926\n",
      "Step: 1745, Loss: 0.7718119025230408, Accuracy: 0.8125, Computation time: 0.6876130104064941\n",
      "Step: 1746, Loss: 0.6826099157333374, Accuracy: 0.84375, Computation time: 0.6810770034790039\n",
      "Step: 1747, Loss: 0.3960980176925659, Accuracy: 0.8125, Computation time: 0.6665527820587158\n",
      "Step: 1748, Loss: 0.5889447331428528, Accuracy: 0.875, Computation time: 0.8050658702850342\n",
      "Step: 1749, Loss: 0.6631026268005371, Accuracy: 0.8125, Computation time: 1.2093181610107422\n",
      "Step: 1750, Loss: 1.0091325044631958, Accuracy: 0.71875, Computation time: 0.910031795501709\n",
      "Step: 1751, Loss: 0.8393855690956116, Accuracy: 0.78125, Computation time: 0.8055038452148438\n",
      "Step: 1752, Loss: 0.9002687931060791, Accuracy: 0.78125, Computation time: 0.7657620906829834\n",
      "Step: 1753, Loss: 0.39796459674835205, Accuracy: 0.9375, Computation time: 0.8063530921936035\n",
      "Step: 1754, Loss: 0.6363518834114075, Accuracy: 0.8125, Computation time: 0.7743330001831055\n",
      "Step: 1755, Loss: 0.3822297155857086, Accuracy: 0.90625, Computation time: 0.6747498512268066\n",
      "Step: 1756, Loss: 0.9963263273239136, Accuracy: 0.65625, Computation time: 0.8162291049957275\n",
      "Step: 1757, Loss: 0.4076528251171112, Accuracy: 0.84375, Computation time: 0.7971169948577881\n",
      "Step: 1758, Loss: 0.7900677919387817, Accuracy: 0.71875, Computation time: 0.7731320858001709\n",
      "Step: 1759, Loss: 0.68467116355896, Accuracy: 0.78125, Computation time: 0.8848967552185059\n",
      "Step: 1760, Loss: 0.619557797908783, Accuracy: 0.84375, Computation time: 0.712907075881958\n",
      "Step: 1761, Loss: 0.4131535291671753, Accuracy: 0.875, Computation time: 0.8354349136352539\n",
      "Step: 1762, Loss: 0.8025665879249573, Accuracy: 0.8125, Computation time: 0.7375438213348389\n",
      "Step: 1763, Loss: 1.037496566772461, Accuracy: 0.71875, Computation time: 0.7904751300811768\n",
      "Step: 1764, Loss: 0.891335666179657, Accuracy: 0.65625, Computation time: 0.933690071105957\n",
      "Step: 1765, Loss: 0.8659913539886475, Accuracy: 0.75, Computation time: 0.8381381034851074\n",
      "Step: 1766, Loss: 1.2496529817581177, Accuracy: 0.625, Computation time: 0.8112070560455322\n",
      "Step: 1767, Loss: 1.0797526836395264, Accuracy: 0.71875, Computation time: 0.7639033794403076\n",
      "Step: 1768, Loss: 1.06899893283844, Accuracy: 0.65625, Computation time: 0.7196202278137207\n",
      "Step: 1769, Loss: 0.8393831253051758, Accuracy: 0.75, Computation time: 1.618056058883667\n",
      "Step: 1770, Loss: 0.7340521812438965, Accuracy: 0.75, Computation time: 0.918665885925293\n",
      "Step: 1771, Loss: 0.594172477722168, Accuracy: 0.84375, Computation time: 0.9044320583343506\n",
      "Step: 1772, Loss: 0.8297302722930908, Accuracy: 0.75, Computation time: 0.6770877838134766\n",
      "Step: 1773, Loss: 0.794419527053833, Accuracy: 0.75, Computation time: 0.6837780475616455\n",
      "Step: 1774, Loss: 0.7740482091903687, Accuracy: 0.71875, Computation time: 0.7927248477935791\n",
      "Step: 1775, Loss: 0.5650357604026794, Accuracy: 0.9375, Computation time: 0.9409546852111816\n",
      "Step: 1776, Loss: 0.8426787853240967, Accuracy: 0.75, Computation time: 0.8155379295349121\n",
      "Step: 1777, Loss: 0.6268622279167175, Accuracy: 0.84375, Computation time: 0.8286089897155762\n",
      "Step: 1778, Loss: 0.8309124112129211, Accuracy: 0.84375, Computation time: 0.82912278175354\n",
      "Step: 1779, Loss: 0.46339982748031616, Accuracy: 0.84375, Computation time: 0.8653309345245361\n",
      "Step: 1780, Loss: 0.5121755599975586, Accuracy: 0.8125, Computation time: 0.7486920356750488\n",
      "Step: 1781, Loss: 0.2799769341945648, Accuracy: 1.0, Computation time: 1.178313970565796\n",
      "Step: 1782, Loss: 1.1644803285598755, Accuracy: 0.65625, Computation time: 0.9911627769470215\n",
      "Step: 1783, Loss: 0.5461875200271606, Accuracy: 0.84375, Computation time: 0.8613419532775879\n",
      "Step: 1784, Loss: 0.6207600235939026, Accuracy: 0.84375, Computation time: 5.742373943328857\n",
      "Step: 1785, Loss: 0.9159127473831177, Accuracy: 0.8125, Computation time: 0.7866649627685547\n",
      "Step: 1786, Loss: 0.976006269454956, Accuracy: 0.6875, Computation time: 0.7509009838104248\n",
      "Step: 1787, Loss: 0.32837438583374023, Accuracy: 0.90625, Computation time: 0.8689436912536621\n",
      "Step: 1788, Loss: 0.7394199967384338, Accuracy: 0.84375, Computation time: 0.7571120262145996\n",
      "Step: 1789, Loss: 0.9808914661407471, Accuracy: 0.84375, Computation time: 0.7004690170288086\n",
      "Step: 1790, Loss: 0.8330941200256348, Accuracy: 0.75, Computation time: 0.8617279529571533\n",
      "Step: 1791, Loss: 0.6063829660415649, Accuracy: 0.84375, Computation time: 0.8002371788024902\n",
      "Step: 1792, Loss: 0.6153551936149597, Accuracy: 0.8125, Computation time: 0.8482909202575684\n",
      "Step: 1793, Loss: 0.5154078006744385, Accuracy: 0.8125, Computation time: 0.7077300548553467\n",
      "Step: 1794, Loss: 0.42424529790878296, Accuracy: 0.90625, Computation time: 0.7631969451904297\n",
      "Step: 1795, Loss: 1.1714096069335938, Accuracy: 0.65625, Computation time: 0.771569013595581\n",
      "Step: 1796, Loss: 0.5795375108718872, Accuracy: 0.78125, Computation time: 0.7009720802307129\n",
      "Step: 1797, Loss: 0.806076169013977, Accuracy: 0.71875, Computation time: 0.8071858882904053\n",
      "Step: 1798, Loss: 0.8228362798690796, Accuracy: 0.6875, Computation time: 0.7445597648620605\n",
      "Step: 1799, Loss: 0.5070610046386719, Accuracy: 0.8125, Computation time: 0.6468322277069092\n",
      "Step: 1800, Loss: 0.642063319683075, Accuracy: 0.78125, Computation time: 0.7599711418151855\n",
      "Step: 1801, Loss: 0.46469175815582275, Accuracy: 0.78125, Computation time: 0.6661629676818848\n",
      "Step: 1802, Loss: 0.7538673281669617, Accuracy: 0.75, Computation time: 0.6912651062011719\n",
      "Step: 1803, Loss: 1.0301775932312012, Accuracy: 0.78125, Computation time: 0.691321849822998\n",
      "Step: 1804, Loss: 0.7013179063796997, Accuracy: 0.6875, Computation time: 0.9872899055480957\n",
      "Step: 1805, Loss: 0.6375592947006226, Accuracy: 0.8125, Computation time: 0.7373969554901123\n",
      "Step: 1806, Loss: 0.5864270329475403, Accuracy: 0.84375, Computation time: 0.8222804069519043\n",
      "Step: 1807, Loss: 0.8200615048408508, Accuracy: 0.75, Computation time: 0.753654956817627\n",
      "Step: 1808, Loss: 0.6636707186698914, Accuracy: 0.78125, Computation time: 0.9207828044891357\n",
      "Step: 1809, Loss: 1.0717267990112305, Accuracy: 0.6875, Computation time: 1.112502098083496\n",
      "Step: 1810, Loss: 0.8790217041969299, Accuracy: 0.78125, Computation time: 0.78432297706604\n",
      "Step: 1811, Loss: 0.708495557308197, Accuracy: 0.8125, Computation time: 0.9410569667816162\n",
      "Step: 1812, Loss: 0.7484091520309448, Accuracy: 0.65625, Computation time: 0.7837467193603516\n",
      "Step: 1813, Loss: 0.5722343921661377, Accuracy: 0.75, Computation time: 0.7245650291442871\n",
      "Step: 1814, Loss: 0.8902296423912048, Accuracy: 0.6875, Computation time: 0.749014139175415\n",
      "Step: 1815, Loss: 1.1872665882110596, Accuracy: 0.6875, Computation time: 0.6766459941864014\n",
      "Step: 1816, Loss: 0.7979373931884766, Accuracy: 0.78125, Computation time: 0.6632771492004395\n",
      "Step: 1817, Loss: 0.9467379450798035, Accuracy: 0.65625, Computation time: 0.7173748016357422\n",
      "Step: 1818, Loss: 0.32970622181892395, Accuracy: 0.90625, Computation time: 0.6731858253479004\n",
      "Step: 1819, Loss: 0.7689312696456909, Accuracy: 0.8125, Computation time: 0.7625460624694824\n",
      "Step: 1820, Loss: 0.5026370882987976, Accuracy: 0.875, Computation time: 0.671454906463623\n",
      "Step: 1821, Loss: 1.0564401149749756, Accuracy: 0.75, Computation time: 0.8175129890441895\n",
      "Step: 1822, Loss: 0.5722241997718811, Accuracy: 0.84375, Computation time: 0.708543062210083\n",
      "Step: 1823, Loss: 0.7094339728355408, Accuracy: 0.78125, Computation time: 0.8484179973602295\n",
      "Step: 1824, Loss: 0.33573728799819946, Accuracy: 0.90625, Computation time: 0.859832763671875\n",
      "Step: 1825, Loss: 0.6869239807128906, Accuracy: 0.84375, Computation time: 1.3220031261444092\n",
      "Step: 1826, Loss: 0.7266997694969177, Accuracy: 0.71875, Computation time: 0.7253203392028809\n",
      "Step: 1827, Loss: 0.40367141366004944, Accuracy: 0.875, Computation time: 0.7515468597412109\n",
      "Step: 1828, Loss: 0.9541857838630676, Accuracy: 0.6875, Computation time: 0.802757740020752\n",
      "Step: 1829, Loss: 0.971931517124176, Accuracy: 0.65625, Computation time: 0.9459466934204102\n",
      "Step: 1830, Loss: 0.7500986456871033, Accuracy: 0.78125, Computation time: 0.7340099811553955\n",
      "Step: 1831, Loss: 0.6702001094818115, Accuracy: 0.8125, Computation time: 0.816519021987915\n",
      "Step: 1832, Loss: 0.5878095626831055, Accuracy: 0.78125, Computation time: 0.7461340427398682\n",
      "Step: 1833, Loss: 0.49050652980804443, Accuracy: 0.78125, Computation time: 0.6720807552337646\n",
      "Step: 1834, Loss: 0.612058162689209, Accuracy: 0.8125, Computation time: 0.8718361854553223\n",
      "Step: 1835, Loss: 0.6539167165756226, Accuracy: 0.75, Computation time: 0.7421269416809082\n",
      "Step: 1836, Loss: 0.4561060965061188, Accuracy: 0.9375, Computation time: 0.8095440864562988\n",
      "Step: 1837, Loss: 0.8383259773254395, Accuracy: 0.78125, Computation time: 0.8410859107971191\n",
      "Step: 1838, Loss: 0.5365152359008789, Accuracy: 0.78125, Computation time: 0.7918550968170166\n",
      "Step: 1839, Loss: 1.406826376914978, Accuracy: 0.625, Computation time: 0.7955310344696045\n",
      "Step: 1840, Loss: 0.8558812141418457, Accuracy: 0.84375, Computation time: 0.7800939083099365\n",
      "Step: 1841, Loss: 0.5019727945327759, Accuracy: 0.84375, Computation time: 0.8028390407562256\n",
      "Step: 1842, Loss: 0.8122739195823669, Accuracy: 0.71875, Computation time: 0.9569888114929199\n",
      "Step: 1843, Loss: 0.7730417251586914, Accuracy: 0.78125, Computation time: 0.7246348857879639\n",
      "Step: 1844, Loss: 0.49540096521377563, Accuracy: 0.875, Computation time: 0.74155592918396\n",
      "Step: 1845, Loss: 0.846373975276947, Accuracy: 0.75, Computation time: 0.8607192039489746\n",
      "Step: 1846, Loss: 0.9913243055343628, Accuracy: 0.75, Computation time: 0.7142500877380371\n",
      "Step: 1847, Loss: 0.6802642345428467, Accuracy: 0.875, Computation time: 0.7846388816833496\n",
      "Step: 1848, Loss: 0.5550183057785034, Accuracy: 0.90625, Computation time: 0.7171111106872559\n",
      "Step: 1849, Loss: 0.4299815595149994, Accuracy: 0.78125, Computation time: 0.7189362049102783\n",
      "Step: 1850, Loss: 1.2341408729553223, Accuracy: 0.6875, Computation time: 0.8559260368347168\n",
      "Step: 1851, Loss: 0.3345920145511627, Accuracy: 0.875, Computation time: 0.685258150100708\n",
      "Step: 1852, Loss: 0.6194455027580261, Accuracy: 0.71875, Computation time: 0.786607027053833\n",
      "Step: 1853, Loss: 0.36073756217956543, Accuracy: 0.9375, Computation time: 0.8102009296417236\n",
      "Step: 1854, Loss: 0.6004269123077393, Accuracy: 0.8125, Computation time: 1.0127079486846924\n",
      "Step: 1855, Loss: 0.2518356144428253, Accuracy: 0.96875, Computation time: 0.7248377799987793\n",
      "Step: 1856, Loss: 0.47866207361221313, Accuracy: 0.90625, Computation time: 0.8409061431884766\n",
      "Step: 1857, Loss: 1.0085376501083374, Accuracy: 0.6875, Computation time: 0.9889259338378906\n",
      "Step: 1858, Loss: 1.0524758100509644, Accuracy: 0.71875, Computation time: 0.744642972946167\n",
      "Step: 1859, Loss: 0.8237730264663696, Accuracy: 0.75, Computation time: 0.6981630325317383\n",
      "Step: 1860, Loss: 0.8142333030700684, Accuracy: 0.78125, Computation time: 0.751312255859375\n",
      "Step: 1861, Loss: 0.9853081107139587, Accuracy: 0.75, Computation time: 0.7806251049041748\n",
      "Step: 1862, Loss: 0.4806102514266968, Accuracy: 0.8125, Computation time: 0.6382081508636475\n",
      "Step: 1863, Loss: 1.0530608892440796, Accuracy: 0.6875, Computation time: 0.7326889038085938\n",
      "Step: 1864, Loss: 0.4870617985725403, Accuracy: 0.84375, Computation time: 0.7807228565216064\n",
      "Step: 1865, Loss: 0.8568346500396729, Accuracy: 0.75, Computation time: 0.6516261100769043\n",
      "Step: 1866, Loss: 0.5280730128288269, Accuracy: 0.875, Computation time: 0.7747678756713867\n",
      "Step: 1867, Loss: 0.8642594218254089, Accuracy: 0.8125, Computation time: 0.8631460666656494\n",
      "Step: 1868, Loss: 0.5734208226203918, Accuracy: 0.84375, Computation time: 0.609501838684082\n",
      "Step: 1869, Loss: 0.7856457233428955, Accuracy: 0.78125, Computation time: 0.7970941066741943\n",
      "Step: 1870, Loss: 0.6484670639038086, Accuracy: 0.8125, Computation time: 0.9206740856170654\n",
      "Step: 1871, Loss: 0.6322077512741089, Accuracy: 0.78125, Computation time: 0.7848081588745117\n",
      "Step: 1872, Loss: 0.5086231827735901, Accuracy: 0.875, Computation time: 0.9561028480529785\n",
      "Step: 1873, Loss: 0.7540004849433899, Accuracy: 0.8125, Computation time: 0.7346768379211426\n",
      "Step: 1874, Loss: 1.1048216819763184, Accuracy: 0.6875, Computation time: 0.760890007019043\n",
      "Step: 1875, Loss: 0.34862765669822693, Accuracy: 0.9375, Computation time: 0.679682731628418\n",
      "Step: 1876, Loss: 0.35421842336654663, Accuracy: 0.9375, Computation time: 0.758673906326294\n",
      "Step: 1877, Loss: 1.1219148635864258, Accuracy: 0.59375, Computation time: 1.2449171543121338\n",
      "Step: 1878, Loss: 0.6087924838066101, Accuracy: 0.78125, Computation time: 0.7126882076263428\n",
      "Step: 1879, Loss: 0.5499862432479858, Accuracy: 0.78125, Computation time: 0.7422547340393066\n",
      "Step: 1880, Loss: 0.903653085231781, Accuracy: 0.71875, Computation time: 0.7837581634521484\n",
      "Step: 1881, Loss: 0.6110019683837891, Accuracy: 0.78125, Computation time: 0.7880880832672119\n",
      "Step: 1882, Loss: 0.37068599462509155, Accuracy: 0.875, Computation time: 0.8231430053710938\n",
      "Step: 1883, Loss: 0.522282063961029, Accuracy: 0.8125, Computation time: 0.7255532741546631\n",
      "Step: 1884, Loss: 0.6868593692779541, Accuracy: 0.71875, Computation time: 0.8658690452575684\n",
      "Step: 1885, Loss: 0.8609836101531982, Accuracy: 0.78125, Computation time: 0.8234760761260986\n",
      "Step: 1886, Loss: 1.128446340560913, Accuracy: 0.6875, Computation time: 0.8333139419555664\n",
      "Step: 1887, Loss: 0.5152230262756348, Accuracy: 0.84375, Computation time: 1.0257468223571777\n",
      "Step: 1888, Loss: 0.6306653618812561, Accuracy: 0.71875, Computation time: 0.7878820896148682\n",
      "Step: 1889, Loss: 0.5589871406555176, Accuracy: 0.84375, Computation time: 0.6986308097839355\n",
      "Step: 1890, Loss: 0.7466952204704285, Accuracy: 0.78125, Computation time: 0.880913257598877\n",
      "Step: 1891, Loss: 0.8235677480697632, Accuracy: 0.75, Computation time: 0.7830801010131836\n",
      "Step: 1892, Loss: 0.8951700329780579, Accuracy: 0.75, Computation time: 0.7342462539672852\n",
      "Step: 1893, Loss: 0.5085030198097229, Accuracy: 0.8125, Computation time: 0.8269398212432861\n",
      "Step: 1894, Loss: 0.5759810209274292, Accuracy: 0.84375, Computation time: 0.7850220203399658\n",
      "Step: 1895, Loss: 0.901273250579834, Accuracy: 0.75, Computation time: 0.8924391269683838\n",
      "Step: 1896, Loss: 0.7076807618141174, Accuracy: 0.78125, Computation time: 0.6460161209106445\n",
      "Step: 1897, Loss: 0.7171408534049988, Accuracy: 0.75, Computation time: 0.8294847011566162\n",
      "Step: 1898, Loss: 0.4960576891899109, Accuracy: 0.84375, Computation time: 0.8000221252441406\n",
      "Step: 1899, Loss: 0.6539493203163147, Accuracy: 0.75, Computation time: 0.8238649368286133\n",
      "Step: 1900, Loss: 0.7989403009414673, Accuracy: 0.78125, Computation time: 0.8107161521911621\n",
      "Step: 1901, Loss: 0.5642865896224976, Accuracy: 0.8125, Computation time: 0.839946985244751\n",
      "Step: 1902, Loss: 0.6385042071342468, Accuracy: 0.75, Computation time: 0.629051923751831\n",
      "Step: 1903, Loss: 0.62745600938797, Accuracy: 0.78125, Computation time: 0.7756948471069336\n",
      "Step: 1904, Loss: 0.9407272934913635, Accuracy: 0.78125, Computation time: 0.8895978927612305\n",
      "Step: 1905, Loss: 0.3313697576522827, Accuracy: 0.875, Computation time: 0.9820070266723633\n",
      "Step: 1906, Loss: 1.1097910404205322, Accuracy: 0.71875, Computation time: 0.674896240234375\n",
      "Step: 1907, Loss: 0.7550379037857056, Accuracy: 0.75, Computation time: 0.9094111919403076\n",
      "Step: 1908, Loss: 0.7127305865287781, Accuracy: 0.71875, Computation time: 0.8724620342254639\n",
      "Step: 1909, Loss: 0.9441813826560974, Accuracy: 0.75, Computation time: 0.7590460777282715\n",
      "Step: 1910, Loss: 0.5571251511573792, Accuracy: 0.78125, Computation time: 1.2851791381835938\n",
      "Step: 1911, Loss: 0.9799266457557678, Accuracy: 0.78125, Computation time: 0.7894682884216309\n",
      "Step: 1912, Loss: 0.528903603553772, Accuracy: 0.875, Computation time: 0.6980957984924316\n",
      "Step: 1913, Loss: 0.8729609251022339, Accuracy: 0.75, Computation time: 0.8213686943054199\n",
      "Step: 1914, Loss: 0.48099714517593384, Accuracy: 0.8125, Computation time: 0.9094970226287842\n",
      "Step: 1915, Loss: 0.468278169631958, Accuracy: 0.875, Computation time: 0.8475682735443115\n",
      "Step: 1916, Loss: 0.26745352149009705, Accuracy: 0.9375, Computation time: 0.7189929485321045\n",
      "Step: 1917, Loss: 1.0074248313903809, Accuracy: 0.78125, Computation time: 0.7425458431243896\n",
      "Step: 1918, Loss: 0.38233739137649536, Accuracy: 0.90625, Computation time: 0.8420350551605225\n",
      "Step: 1919, Loss: 0.5894460678100586, Accuracy: 0.8125, Computation time: 0.9197721481323242\n",
      "Step: 1920, Loss: 1.0843933820724487, Accuracy: 0.75, Computation time: 0.6517109870910645\n",
      "Step: 1921, Loss: 0.5160791277885437, Accuracy: 0.9375, Computation time: 0.8400089740753174\n",
      "Step: 1922, Loss: 0.6236398220062256, Accuracy: 0.875, Computation time: 0.8101792335510254\n",
      "Step: 1923, Loss: 0.6836363673210144, Accuracy: 0.78125, Computation time: 0.7099838256835938\n",
      "Step: 1924, Loss: 0.9631034731864929, Accuracy: 0.71875, Computation time: 0.928898811340332\n",
      "Step: 1925, Loss: 0.46002304553985596, Accuracy: 0.84375, Computation time: 0.7549948692321777\n",
      "Step: 1926, Loss: 0.5994000434875488, Accuracy: 0.78125, Computation time: 0.960845947265625\n",
      "Step: 1927, Loss: 0.7112555503845215, Accuracy: 0.71875, Computation time: 0.7324690818786621\n",
      "Step: 1928, Loss: 0.8292281031608582, Accuracy: 0.71875, Computation time: 0.7799370288848877\n",
      "Step: 1929, Loss: 0.7047098278999329, Accuracy: 0.75, Computation time: 0.8834660053253174\n",
      "Step: 1930, Loss: 0.8526793718338013, Accuracy: 0.78125, Computation time: 0.8067736625671387\n",
      "Step: 1931, Loss: 0.7303832173347473, Accuracy: 0.75, Computation time: 1.0521061420440674\n",
      "Step: 1932, Loss: 0.7970975041389465, Accuracy: 0.78125, Computation time: 0.847628116607666\n",
      "Step: 1933, Loss: 0.8966700434684753, Accuracy: 0.6875, Computation time: 0.8865978717803955\n",
      "Step: 1934, Loss: 0.6487913131713867, Accuracy: 0.8125, Computation time: 0.7547008991241455\n",
      "Step: 1935, Loss: 0.49689361453056335, Accuracy: 0.8125, Computation time: 0.7926697731018066\n",
      "Step: 1936, Loss: 0.6347382664680481, Accuracy: 0.78125, Computation time: 0.783595085144043\n",
      "Step: 1937, Loss: 0.9891422390937805, Accuracy: 0.78125, Computation time: 0.968498945236206\n",
      "Step: 1938, Loss: 0.4492030143737793, Accuracy: 0.8125, Computation time: 0.7720048427581787\n",
      "Step: 1939, Loss: 0.7808527946472168, Accuracy: 0.8125, Computation time: 0.862595796585083\n",
      "Step: 1940, Loss: 1.1796441078186035, Accuracy: 0.71875, Computation time: 0.7795488834381104\n",
      "Step: 1941, Loss: 1.1695396900177002, Accuracy: 0.6875, Computation time: 0.7117600440979004\n",
      "Step: 1942, Loss: 0.3788653016090393, Accuracy: 0.90625, Computation time: 1.215376853942871\n",
      "Step: 1943, Loss: 0.4936745762825012, Accuracy: 0.875, Computation time: 0.7143158912658691\n",
      "Step: 1944, Loss: 0.7151626348495483, Accuracy: 0.75, Computation time: 0.7911891937255859\n",
      "Step: 1945, Loss: 0.966724157333374, Accuracy: 0.59375, Computation time: 0.7749121189117432\n",
      "Step: 1946, Loss: 0.7578945159912109, Accuracy: 0.75, Computation time: 0.8732039928436279\n",
      "Step: 1947, Loss: 0.39897674322128296, Accuracy: 0.90625, Computation time: 0.6686830520629883\n",
      "Step: 1948, Loss: 0.7498971223831177, Accuracy: 0.8125, Computation time: 0.7198050022125244\n",
      "Step: 1949, Loss: 0.9011341333389282, Accuracy: 0.75, Computation time: 0.7911360263824463\n",
      "Step: 1950, Loss: 0.5492438077926636, Accuracy: 0.8125, Computation time: 0.7820570468902588\n",
      "Step: 1951, Loss: 0.39278608560562134, Accuracy: 0.96875, Computation time: 0.8863747119903564\n",
      "Step: 1952, Loss: 0.6424651741981506, Accuracy: 0.8125, Computation time: 0.8648567199707031\n",
      "Step: 1953, Loss: 1.0407408475875854, Accuracy: 0.6875, Computation time: 0.7983019351959229\n",
      "Step: 1954, Loss: 0.5048631429672241, Accuracy: 0.84375, Computation time: 0.7579030990600586\n",
      "Step: 1955, Loss: 0.7329663038253784, Accuracy: 0.78125, Computation time: 0.8044137954711914\n",
      "Step: 1956, Loss: 0.5526085495948792, Accuracy: 0.75, Computation time: 0.8613650798797607\n",
      "Step: 1957, Loss: 0.4492402672767639, Accuracy: 0.84375, Computation time: 0.9098198413848877\n",
      "Step: 1958, Loss: 1.1614594459533691, Accuracy: 0.75, Computation time: 1.033437967300415\n",
      "Step: 1959, Loss: 0.6402963399887085, Accuracy: 0.75, Computation time: 0.7796599864959717\n",
      "Step: 1960, Loss: 0.6775127053260803, Accuracy: 0.71875, Computation time: 0.7648711204528809\n",
      "Step: 1961, Loss: 0.9833836555480957, Accuracy: 0.6875, Computation time: 0.7588150501251221\n",
      "Step: 1962, Loss: 0.4866275489330292, Accuracy: 0.84375, Computation time: 0.8784530162811279\n",
      "Step: 1963, Loss: 0.4720586836338043, Accuracy: 0.8125, Computation time: 0.9120149612426758\n",
      "Step: 1964, Loss: 0.9327862858772278, Accuracy: 0.6875, Computation time: 0.8157780170440674\n",
      "Step: 1965, Loss: 0.7550520300865173, Accuracy: 0.78125, Computation time: 0.813560962677002\n",
      "Step: 1966, Loss: 1.0970826148986816, Accuracy: 0.6875, Computation time: 0.9049878120422363\n",
      "Step: 1967, Loss: 0.483977347612381, Accuracy: 0.8125, Computation time: 0.7473680973052979\n",
      "Step: 1968, Loss: 0.6327162384986877, Accuracy: 0.875, Computation time: 0.701373815536499\n",
      "Step: 1969, Loss: 1.0883004665374756, Accuracy: 0.6875, Computation time: 0.8549318313598633\n",
      "Step: 1970, Loss: 1.2618741989135742, Accuracy: 0.65625, Computation time: 0.7357268333435059\n",
      "Step: 1971, Loss: 1.09970223903656, Accuracy: 0.71875, Computation time: 0.8884329795837402\n",
      "Step: 1972, Loss: 0.4723251760005951, Accuracy: 0.875, Computation time: 0.6764559745788574\n",
      "Step: 1973, Loss: 0.2550351917743683, Accuracy: 0.90625, Computation time: 0.8484258651733398\n",
      "Step: 1974, Loss: 0.8834983706474304, Accuracy: 0.71875, Computation time: 0.8976559638977051\n",
      "Step: 1975, Loss: 0.6097809672355652, Accuracy: 0.8125, Computation time: 1.2051048278808594\n",
      "Step: 1976, Loss: 0.7648791670799255, Accuracy: 0.6875, Computation time: 0.7825050354003906\n",
      "Step: 1977, Loss: 0.4637215733528137, Accuracy: 0.90625, Computation time: 0.7680320739746094\n",
      "Step: 1978, Loss: 0.6854327321052551, Accuracy: 0.78125, Computation time: 0.7376179695129395\n",
      "Step: 1979, Loss: 0.630246102809906, Accuracy: 0.8125, Computation time: 1.0327048301696777\n",
      "Step: 1980, Loss: 0.7725790739059448, Accuracy: 0.75, Computation time: 0.8780529499053955\n",
      "Step: 1981, Loss: 0.5258841514587402, Accuracy: 0.84375, Computation time: 0.7128639221191406\n",
      "Step: 1982, Loss: 0.6754107475280762, Accuracy: 0.78125, Computation time: 0.783390998840332\n",
      "Step: 1983, Loss: 0.6504050493240356, Accuracy: 0.78125, Computation time: 0.8654680252075195\n",
      "Step: 1984, Loss: 0.324149489402771, Accuracy: 0.9375, Computation time: 1.0028908252716064\n",
      "Step: 1985, Loss: 0.9830878973007202, Accuracy: 0.59375, Computation time: 0.7552011013031006\n",
      "Step: 1986, Loss: 0.48126164078712463, Accuracy: 0.8125, Computation time: 0.738619327545166\n",
      "Step: 1987, Loss: 0.5982632637023926, Accuracy: 0.8125, Computation time: 0.8467559814453125\n",
      "Step: 1988, Loss: 0.7088093757629395, Accuracy: 0.8125, Computation time: 0.7653307914733887\n",
      "Step: 1989, Loss: 0.9504706263542175, Accuracy: 0.6875, Computation time: 0.7418701648712158\n",
      "Step: 1990, Loss: 1.2193055152893066, Accuracy: 0.75, Computation time: 0.7962231636047363\n",
      "Step: 1991, Loss: 0.29600635170936584, Accuracy: 0.875, Computation time: 0.7373099327087402\n",
      "Step: 1992, Loss: 0.8031076788902283, Accuracy: 0.6875, Computation time: 0.7630019187927246\n",
      "Step: 1993, Loss: 0.603252112865448, Accuracy: 0.875, Computation time: 0.9722030162811279\n",
      "Step: 1994, Loss: 0.380686491727829, Accuracy: 0.84375, Computation time: 0.7872588634490967\n",
      "Step: 1995, Loss: 0.796370267868042, Accuracy: 0.78125, Computation time: 0.7994990348815918\n",
      "Step: 1996, Loss: 0.5189839601516724, Accuracy: 0.8125, Computation time: 0.9203298091888428\n",
      "Step: 1997, Loss: 0.301550954580307, Accuracy: 0.9375, Computation time: 0.7485451698303223\n",
      "Step: 1998, Loss: 0.6423193216323853, Accuracy: 0.84375, Computation time: 0.9765481948852539\n",
      "Step: 1999, Loss: 0.4545072317123413, Accuracy: 0.875, Computation time: 0.8683080673217773\n",
      "Step: 2000, Loss: 0.806565523147583, Accuracy: 0.84375, Computation time: 0.779578685760498\n",
      "Step: 2001, Loss: 0.8199671506881714, Accuracy: 0.78125, Computation time: 0.7668519020080566\n",
      "Step: 2002, Loss: 0.45069020986557007, Accuracy: 0.875, Computation time: 0.7677912712097168\n",
      "Step: 2003, Loss: 0.4546399414539337, Accuracy: 0.90625, Computation time: 0.807797908782959\n",
      "Step: 2004, Loss: 0.5677167177200317, Accuracy: 0.8125, Computation time: 0.6794118881225586\n",
      "Step: 2005, Loss: 0.8860330581665039, Accuracy: 0.8125, Computation time: 0.7884600162506104\n",
      "Step: 2006, Loss: 0.5604576468467712, Accuracy: 0.8125, Computation time: 0.6360900402069092\n",
      "Step: 2007, Loss: 0.749979555606842, Accuracy: 0.8125, Computation time: 0.7186281681060791\n",
      "Step: 2008, Loss: 0.927002489566803, Accuracy: 0.71875, Computation time: 1.102452039718628\n",
      "Step: 2009, Loss: 0.8412105441093445, Accuracy: 0.71875, Computation time: 0.8365728855133057\n",
      "Step: 2010, Loss: 0.6882609128952026, Accuracy: 0.78125, Computation time: 0.6400449275970459\n",
      "Step: 2011, Loss: 0.7292188405990601, Accuracy: 0.78125, Computation time: 0.9132752418518066\n",
      "Step: 2012, Loss: 0.7975969314575195, Accuracy: 0.6875, Computation time: 0.7631118297576904\n",
      "Step: 2013, Loss: 0.4130486249923706, Accuracy: 0.90625, Computation time: 0.6877429485321045\n",
      "Step: 2014, Loss: 0.6547799110412598, Accuracy: 0.8125, Computation time: 0.7166388034820557\n",
      "Step: 2015, Loss: 0.9127616882324219, Accuracy: 0.75, Computation time: 0.7301859855651855\n",
      "Step: 2016, Loss: 0.7908700108528137, Accuracy: 0.8125, Computation time: 0.7312371730804443\n",
      "Step: 2017, Loss: 0.7897904515266418, Accuracy: 0.78125, Computation time: 0.7948048114776611\n",
      "Step: 2018, Loss: 0.3990069627761841, Accuracy: 0.84375, Computation time: 0.7425551414489746\n",
      "Step: 2019, Loss: 0.9669132232666016, Accuracy: 0.75, Computation time: 0.7320129871368408\n",
      "Step: 2020, Loss: 0.6502417325973511, Accuracy: 0.8125, Computation time: 0.6755619049072266\n",
      "Step: 2021, Loss: 0.8030017614364624, Accuracy: 0.75, Computation time: 0.7127840518951416\n",
      "Step: 2022, Loss: 0.8243094086647034, Accuracy: 0.78125, Computation time: 0.7559468746185303\n",
      "Step: 2023, Loss: 0.9740928411483765, Accuracy: 0.75, Computation time: 0.7562911510467529\n",
      "Step: 2024, Loss: 0.341121107339859, Accuracy: 0.90625, Computation time: 0.7432808876037598\n",
      "Step: 2025, Loss: 0.6288787126541138, Accuracy: 0.84375, Computation time: 0.9420440196990967\n",
      "Step: 2026, Loss: 0.7285449504852295, Accuracy: 0.71875, Computation time: 0.7483019828796387\n",
      "Step: 2027, Loss: 0.3797958791255951, Accuracy: 0.90625, Computation time: 0.6767899990081787\n",
      "Step: 2028, Loss: 0.5457527041435242, Accuracy: 0.78125, Computation time: 0.7345058917999268\n",
      "Step: 2029, Loss: 0.8541637659072876, Accuracy: 0.78125, Computation time: 0.8814680576324463\n",
      "Step: 2030, Loss: 0.3804347515106201, Accuracy: 0.9375, Computation time: 0.7440800666809082\n",
      "Step: 2031, Loss: 0.8402479290962219, Accuracy: 0.75, Computation time: 1.0814709663391113\n",
      "Step: 2032, Loss: 0.6945662498474121, Accuracy: 0.8125, Computation time: 0.7676632404327393\n",
      "Step: 2033, Loss: 0.41787993907928467, Accuracy: 0.84375, Computation time: 0.746448278427124\n",
      "Step: 2034, Loss: 0.9858099818229675, Accuracy: 0.6875, Computation time: 0.8601429462432861\n",
      "Step: 2035, Loss: 0.7218010425567627, Accuracy: 0.8125, Computation time: 0.7900199890136719\n",
      "Step: 2036, Loss: 0.6494473814964294, Accuracy: 0.84375, Computation time: 0.7686142921447754\n",
      "Step: 2037, Loss: 0.6889978647232056, Accuracy: 0.75, Computation time: 0.7866942882537842\n",
      "Step: 2038, Loss: 1.248413324356079, Accuracy: 0.625, Computation time: 0.7647747993469238\n",
      "Step: 2039, Loss: 0.8544219732284546, Accuracy: 0.75, Computation time: 0.8324530124664307\n",
      "Step: 2040, Loss: 0.5835263729095459, Accuracy: 0.8125, Computation time: 0.7363271713256836\n",
      "Step: 2041, Loss: 0.6721101403236389, Accuracy: 0.8125, Computation time: 0.9927098751068115\n",
      "Step: 2042, Loss: 0.5969625115394592, Accuracy: 0.75, Computation time: 1.1596097946166992\n",
      "Step: 2043, Loss: 0.30191493034362793, Accuracy: 0.96875, Computation time: 0.9550199508666992\n",
      "Step: 2044, Loss: 0.8277540802955627, Accuracy: 0.71875, Computation time: 0.9184000492095947\n",
      "Step: 2045, Loss: 0.79246985912323, Accuracy: 0.6875, Computation time: 0.9125828742980957\n",
      "Step: 2046, Loss: 0.6536373496055603, Accuracy: 0.875, Computation time: 0.8096930980682373\n",
      "Step: 2047, Loss: 0.7794636487960815, Accuracy: 0.75, Computation time: 0.8686630725860596\n",
      "Step: 2048, Loss: 0.5198425650596619, Accuracy: 0.84375, Computation time: 0.9245800971984863\n",
      "Step: 2049, Loss: 0.3369446098804474, Accuracy: 0.875, Computation time: 0.6681547164916992\n",
      "Step: 2050, Loss: 0.788398802280426, Accuracy: 0.71875, Computation time: 0.6904828548431396\n",
      "Step: 2051, Loss: 0.6003744006156921, Accuracy: 0.8125, Computation time: 0.7438170909881592\n",
      "Step: 2052, Loss: 0.6936667561531067, Accuracy: 0.78125, Computation time: 1.052259922027588\n",
      "Step: 2053, Loss: 0.4746869206428528, Accuracy: 0.875, Computation time: 0.8474671840667725\n",
      "Step: 2054, Loss: 1.144644856452942, Accuracy: 0.625, Computation time: 1.1077449321746826\n",
      "Step: 2055, Loss: 0.7004457116127014, Accuracy: 0.8125, Computation time: 0.745265007019043\n",
      "Step: 2056, Loss: 0.5508423447608948, Accuracy: 0.8125, Computation time: 0.6817097663879395\n",
      "Step: 2057, Loss: 0.6432759165763855, Accuracy: 0.75, Computation time: 0.8427989482879639\n",
      "Step: 2058, Loss: 0.6847919821739197, Accuracy: 0.8125, Computation time: 0.8058822154998779\n",
      "Step: 2059, Loss: 0.48967987298965454, Accuracy: 0.8125, Computation time: 0.8479917049407959\n",
      "Step: 2060, Loss: 0.6871213316917419, Accuracy: 0.84375, Computation time: 0.7165591716766357\n",
      "Step: 2061, Loss: 0.44144758582115173, Accuracy: 0.875, Computation time: 0.6757190227508545\n",
      "Step: 2062, Loss: 0.8497625589370728, Accuracy: 0.6875, Computation time: 0.7019689083099365\n",
      "Step: 2063, Loss: 0.568938136100769, Accuracy: 0.78125, Computation time: 0.7598280906677246\n",
      "Step: 2064, Loss: 0.9967155456542969, Accuracy: 0.84375, Computation time: 0.8216981887817383\n",
      "Step: 2065, Loss: 1.2589585781097412, Accuracy: 0.71875, Computation time: 0.802314043045044\n",
      "Step: 2066, Loss: 0.7096940875053406, Accuracy: 0.78125, Computation time: 0.7263500690460205\n",
      "Step: 2067, Loss: 0.7728171348571777, Accuracy: 0.78125, Computation time: 0.7913510799407959\n",
      "Step: 2068, Loss: 0.5056238770484924, Accuracy: 0.84375, Computation time: 0.8184521198272705\n",
      "Step: 2069, Loss: 0.3740411698818207, Accuracy: 0.90625, Computation time: 0.6913187503814697\n",
      "Step: 2070, Loss: 0.5476891994476318, Accuracy: 0.8125, Computation time: 0.7422201633453369\n",
      "Step: 2071, Loss: 0.843474268913269, Accuracy: 0.75, Computation time: 0.8255002498626709\n",
      "Step: 2072, Loss: 0.7139672040939331, Accuracy: 0.75, Computation time: 0.809675931930542\n",
      "Step: 2073, Loss: 0.6668984889984131, Accuracy: 0.84375, Computation time: 0.6382052898406982\n",
      "Step: 2074, Loss: 0.6142150163650513, Accuracy: 0.8125, Computation time: 0.8358249664306641\n",
      "Step: 2075, Loss: 0.693027138710022, Accuracy: 0.78125, Computation time: 0.8178749084472656\n",
      "Step: 2076, Loss: 0.6298450231552124, Accuracy: 0.8125, Computation time: 0.8157460689544678\n",
      "Step: 2077, Loss: 0.5253582000732422, Accuracy: 0.78125, Computation time: 0.9840829372406006\n",
      "Step: 2078, Loss: 0.7567476034164429, Accuracy: 0.8125, Computation time: 0.9274828433990479\n",
      "Step: 2079, Loss: 0.655566394329071, Accuracy: 0.875, Computation time: 0.7470090389251709\n",
      "Step: 2080, Loss: 0.6768236756324768, Accuracy: 0.6875, Computation time: 0.6981368064880371\n",
      "Step: 2081, Loss: 0.7237842082977295, Accuracy: 0.75, Computation time: 0.7077779769897461\n",
      "Step: 2082, Loss: 0.7201208472251892, Accuracy: 0.75, Computation time: 0.8263578414916992\n",
      "Step: 2083, Loss: 0.7698784470558167, Accuracy: 0.78125, Computation time: 0.8121967315673828\n",
      "Step: 2084, Loss: 0.7973138689994812, Accuracy: 0.8125, Computation time: 0.6693851947784424\n",
      "Step: 2085, Loss: 0.8342625498771667, Accuracy: 0.78125, Computation time: 0.6790668964385986\n",
      "Step: 2086, Loss: 0.766974687576294, Accuracy: 0.78125, Computation time: 0.7182610034942627\n",
      "Step: 2087, Loss: 0.45716971158981323, Accuracy: 0.84375, Computation time: 0.865178108215332\n",
      "Step: 2088, Loss: 0.8817315101623535, Accuracy: 0.84375, Computation time: 0.7665338516235352\n",
      "Step: 2089, Loss: 0.5427157282829285, Accuracy: 0.8125, Computation time: 0.7287757396697998\n",
      "Step: 2090, Loss: 0.7550294995307922, Accuracy: 0.71875, Computation time: 1.0186970233917236\n",
      "Step: 2091, Loss: 0.48433834314346313, Accuracy: 0.8125, Computation time: 0.8183403015136719\n",
      "Step: 2092, Loss: 0.4691157937049866, Accuracy: 0.875, Computation time: 0.7524552345275879\n",
      "Step: 2093, Loss: 0.7471392750740051, Accuracy: 0.75, Computation time: 0.7058610916137695\n",
      "Step: 2094, Loss: 1.0661873817443848, Accuracy: 0.65625, Computation time: 0.8783259391784668\n",
      "Step: 2095, Loss: 0.721026599407196, Accuracy: 0.75, Computation time: 0.8062610626220703\n",
      "Step: 2096, Loss: 0.5019930005073547, Accuracy: 0.90625, Computation time: 0.9852218627929688\n",
      "Step: 2097, Loss: 0.7523490190505981, Accuracy: 0.8125, Computation time: 0.8055648803710938\n",
      "Step: 2098, Loss: 0.6803609728813171, Accuracy: 0.78125, Computation time: 0.8315010070800781\n",
      "Step: 2099, Loss: 0.6346721053123474, Accuracy: 0.78125, Computation time: 0.801628828048706\n",
      "Step: 2100, Loss: 0.564978837966919, Accuracy: 0.84375, Computation time: 0.7377510070800781\n",
      "Step: 2101, Loss: 0.6878243088722229, Accuracy: 0.78125, Computation time: 0.7613818645477295\n",
      "Step: 2102, Loss: 0.8114613890647888, Accuracy: 0.6875, Computation time: 0.8571341037750244\n",
      "Step: 2103, Loss: 0.6116481423377991, Accuracy: 0.84375, Computation time: 0.960517168045044\n",
      "Step: 2104, Loss: 0.7488832473754883, Accuracy: 0.75, Computation time: 0.8045008182525635\n",
      "Step: 2105, Loss: 0.5211071968078613, Accuracy: 0.84375, Computation time: 0.8799371719360352\n",
      "Step: 2106, Loss: 0.7313970327377319, Accuracy: 0.71875, Computation time: 0.7072458267211914\n",
      "Step: 2107, Loss: 0.909160315990448, Accuracy: 0.71875, Computation time: 0.9863591194152832\n",
      "Step: 2108, Loss: 0.7333680987358093, Accuracy: 0.71875, Computation time: 1.2942898273468018\n",
      "Step: 2109, Loss: 0.4306931793689728, Accuracy: 0.78125, Computation time: 0.7492709159851074\n",
      "Step: 2110, Loss: 0.3781818151473999, Accuracy: 0.90625, Computation time: 0.7677707672119141\n",
      "Step: 2111, Loss: 0.4729091227054596, Accuracy: 0.8125, Computation time: 0.7101790904998779\n",
      "Step: 2112, Loss: 1.013117790222168, Accuracy: 0.6875, Computation time: 0.7728073596954346\n",
      "Step: 2113, Loss: 0.5180610418319702, Accuracy: 0.8125, Computation time: 0.9320371150970459\n",
      "Step: 2114, Loss: 0.8232214450836182, Accuracy: 0.75, Computation time: 0.7433500289916992\n",
      "Step: 2115, Loss: 0.6711386442184448, Accuracy: 0.78125, Computation time: 0.8592259883880615\n",
      "Step: 2116, Loss: 0.7695543766021729, Accuracy: 0.78125, Computation time: 1.2063181400299072\n",
      "Step: 2117, Loss: 0.7855294346809387, Accuracy: 0.75, Computation time: 0.7767910957336426\n",
      "Step: 2118, Loss: 0.551602303981781, Accuracy: 0.875, Computation time: 0.687251091003418\n",
      "Step: 2119, Loss: 0.46792441606521606, Accuracy: 0.8125, Computation time: 0.7735443115234375\n",
      "Step: 2120, Loss: 0.44516339898109436, Accuracy: 0.8125, Computation time: 0.6443841457366943\n",
      "Step: 2121, Loss: 0.5561378598213196, Accuracy: 0.8125, Computation time: 0.7310090065002441\n",
      "Step: 2122, Loss: 0.7069365382194519, Accuracy: 0.75, Computation time: 1.0722932815551758\n",
      "Step: 2123, Loss: 0.47618910670280457, Accuracy: 0.875, Computation time: 0.8604741096496582\n",
      "Step: 2124, Loss: 0.9368650913238525, Accuracy: 0.78125, Computation time: 1.4486348628997803\n",
      "Step: 2125, Loss: 0.4683223068714142, Accuracy: 0.84375, Computation time: 0.7704300880432129\n",
      "Step: 2126, Loss: 0.7269632816314697, Accuracy: 0.75, Computation time: 0.7433500289916992\n",
      "Step: 2127, Loss: 0.3446699380874634, Accuracy: 0.875, Computation time: 0.7555105686187744\n",
      "Step: 2128, Loss: 0.5481206178665161, Accuracy: 0.8125, Computation time: 0.8894100189208984\n",
      "Step: 2129, Loss: 0.6182746887207031, Accuracy: 0.84375, Computation time: 0.7414271831512451\n",
      "Step: 2130, Loss: 0.5473071336746216, Accuracy: 0.78125, Computation time: 0.7380549907684326\n",
      "Step: 2131, Loss: 0.5165116190910339, Accuracy: 0.875, Computation time: 0.7442197799682617\n",
      "Step: 2132, Loss: 0.33550241589546204, Accuracy: 0.90625, Computation time: 0.7979030609130859\n",
      "Step: 2133, Loss: 0.44305655360221863, Accuracy: 0.875, Computation time: 0.7742249965667725\n",
      "Step: 2134, Loss: 0.9931504726409912, Accuracy: 0.6875, Computation time: 0.7444000244140625\n",
      "Step: 2135, Loss: 0.8729159235954285, Accuracy: 0.78125, Computation time: 0.9291858673095703\n",
      "Step: 2136, Loss: 0.35743436217308044, Accuracy: 0.875, Computation time: 0.6630752086639404\n",
      "Step: 2137, Loss: 0.6351220607757568, Accuracy: 0.75, Computation time: 0.8285551071166992\n",
      "Step: 2138, Loss: 0.5747860074043274, Accuracy: 0.8125, Computation time: 0.8046059608459473\n",
      "Step: 2139, Loss: 1.0761855840682983, Accuracy: 0.6875, Computation time: 0.733212947845459\n",
      "Step: 2140, Loss: 1.3650869131088257, Accuracy: 0.71875, Computation time: 0.8487999439239502\n",
      "Step: 2141, Loss: 0.6028174161911011, Accuracy: 0.84375, Computation time: 1.352074146270752\n",
      "Step: 2142, Loss: 0.4535987377166748, Accuracy: 0.84375, Computation time: 0.7766499519348145\n",
      "Step: 2143, Loss: 0.4210144281387329, Accuracy: 0.90625, Computation time: 0.8352530002593994\n",
      "Step: 2144, Loss: 0.5246781706809998, Accuracy: 0.8125, Computation time: 0.7205500602722168\n",
      "Step: 2145, Loss: 0.7176759839057922, Accuracy: 0.78125, Computation time: 0.9009542465209961\n",
      "Step: 2146, Loss: 0.7128705382347107, Accuracy: 0.71875, Computation time: 0.6999759674072266\n",
      "Step: 2147, Loss: 0.3676004111766815, Accuracy: 0.84375, Computation time: 0.7007722854614258\n",
      "Step: 2148, Loss: 0.776972770690918, Accuracy: 0.75, Computation time: 0.8686249256134033\n",
      "Step: 2149, Loss: 0.494524747133255, Accuracy: 0.875, Computation time: 0.8121979236602783\n",
      "Step: 2150, Loss: 0.775181770324707, Accuracy: 0.71875, Computation time: 0.8122079372406006\n",
      "Step: 2151, Loss: 0.7949230670928955, Accuracy: 0.75, Computation time: 0.8350038528442383\n",
      "Step: 2152, Loss: 0.7846449613571167, Accuracy: 0.6875, Computation time: 0.7296850681304932\n",
      "Step: 2153, Loss: 0.6690078377723694, Accuracy: 0.78125, Computation time: 0.7775299549102783\n",
      "Step: 2154, Loss: 0.5981956124305725, Accuracy: 0.84375, Computation time: 0.7114930152893066\n",
      "Step: 2155, Loss: 0.8004987239837646, Accuracy: 0.75, Computation time: 0.834881067276001\n",
      "Step: 2156, Loss: 0.7476452589035034, Accuracy: 0.8125, Computation time: 0.7571969032287598\n",
      "Step: 2157, Loss: 1.1046934127807617, Accuracy: 0.625, Computation time: 0.9061429500579834\n",
      "Step: 2158, Loss: 0.9727380275726318, Accuracy: 0.6875, Computation time: 0.7269189357757568\n",
      "Step: 2159, Loss: 0.7977218627929688, Accuracy: 0.78125, Computation time: 0.7417268753051758\n",
      "Step: 2160, Loss: 0.7947462201118469, Accuracy: 0.75, Computation time: 0.6761641502380371\n",
      "Step: 2161, Loss: 0.7535933256149292, Accuracy: 0.8125, Computation time: 0.8994660377502441\n",
      "Step: 2162, Loss: 0.630145251750946, Accuracy: 0.71875, Computation time: 0.878920316696167\n",
      "Step: 2163, Loss: 0.8372048735618591, Accuracy: 0.6875, Computation time: 1.1432521343231201\n",
      "Step: 2164, Loss: 0.45305541157722473, Accuracy: 0.875, Computation time: 0.888300895690918\n",
      "Step: 2165, Loss: 0.7135208249092102, Accuracy: 0.78125, Computation time: 0.7951738834381104\n",
      "Step: 2166, Loss: 1.1982436180114746, Accuracy: 0.71875, Computation time: 1.5046799182891846\n",
      "Step: 2167, Loss: 0.6085487604141235, Accuracy: 0.84375, Computation time: 0.8760230541229248\n",
      "Step: 2168, Loss: 0.9829585552215576, Accuracy: 0.8125, Computation time: 1.2280378341674805\n",
      "Step: 2169, Loss: 0.4511564373970032, Accuracy: 0.8125, Computation time: 0.7043261528015137\n",
      "Step: 2170, Loss: 0.5027987957000732, Accuracy: 0.90625, Computation time: 0.791999101638794\n",
      "Step: 2171, Loss: 0.30339762568473816, Accuracy: 0.90625, Computation time: 0.9008121490478516\n",
      "Step: 2172, Loss: 0.3643095791339874, Accuracy: 0.84375, Computation time: 1.3351428508758545\n",
      "Step: 2173, Loss: 0.7831423282623291, Accuracy: 0.78125, Computation time: 0.9079937934875488\n",
      "Step: 2174, Loss: 0.8202728629112244, Accuracy: 0.75, Computation time: 1.1195347309112549\n",
      "Step: 2175, Loss: 0.9367702007293701, Accuracy: 0.75, Computation time: 0.9259309768676758\n",
      "Step: 2176, Loss: 0.7249557971954346, Accuracy: 0.875, Computation time: 0.8368089199066162\n",
      "Step: 2177, Loss: 0.7112413644790649, Accuracy: 0.78125, Computation time: 0.8454222679138184\n",
      "Step: 2178, Loss: 0.7843292355537415, Accuracy: 0.8125, Computation time: 0.6738770008087158\n",
      "Step: 2179, Loss: 1.1593536138534546, Accuracy: 0.59375, Computation time: 0.7241227626800537\n",
      "Step: 2180, Loss: 0.43348997831344604, Accuracy: 0.90625, Computation time: 0.7957298755645752\n",
      "Step: 2181, Loss: 0.6254988312721252, Accuracy: 0.75, Computation time: 0.7663471698760986\n",
      "Step: 2182, Loss: 0.8145754337310791, Accuracy: 0.75, Computation time: 0.7248010635375977\n",
      "Step: 2183, Loss: 0.5204039216041565, Accuracy: 0.71875, Computation time: 0.838386058807373\n",
      "Step: 2184, Loss: 0.851261556148529, Accuracy: 0.78125, Computation time: 0.9313218593597412\n",
      "Step: 2185, Loss: 0.3960567116737366, Accuracy: 0.875, Computation time: 0.8541009426116943\n",
      "Step: 2186, Loss: 0.8264638185501099, Accuracy: 0.71875, Computation time: 0.8704352378845215\n",
      "Step: 2187, Loss: 0.6907715797424316, Accuracy: 0.75, Computation time: 0.7464067935943604\n",
      "Step: 2188, Loss: 0.8551058769226074, Accuracy: 0.78125, Computation time: 0.7930030822753906\n",
      "Step: 2189, Loss: 0.4172385036945343, Accuracy: 0.875, Computation time: 0.743405818939209\n",
      "Step: 2190, Loss: 0.618106484413147, Accuracy: 0.78125, Computation time: 0.7783212661743164\n",
      "Step: 2191, Loss: 0.5818936824798584, Accuracy: 0.78125, Computation time: 0.7793920040130615\n",
      "Step: 2192, Loss: 0.5789546370506287, Accuracy: 0.8125, Computation time: 0.6879029273986816\n",
      "Step: 2193, Loss: 1.003907561302185, Accuracy: 0.65625, Computation time: 0.7510771751403809\n",
      "Step: 2194, Loss: 0.9115478992462158, Accuracy: 0.78125, Computation time: 0.8567087650299072\n",
      "Step: 2195, Loss: 1.0621874332427979, Accuracy: 0.65625, Computation time: 0.7487082481384277\n",
      "Step: 2196, Loss: 0.6738910675048828, Accuracy: 0.75, Computation time: 0.7675261497497559\n",
      "Step: 2197, Loss: 0.8938667178153992, Accuracy: 0.75, Computation time: 0.7042720317840576\n",
      "Step: 2198, Loss: 1.0103929042816162, Accuracy: 0.71875, Computation time: 0.764880895614624\n",
      "Step: 2199, Loss: 0.6329049468040466, Accuracy: 0.78125, Computation time: 0.7183880805969238\n",
      "Step: 2200, Loss: 0.8172741532325745, Accuracy: 0.78125, Computation time: 0.9779479503631592\n",
      "Step: 2201, Loss: 0.4620912969112396, Accuracy: 0.875, Computation time: 0.7753159999847412\n",
      "Step: 2202, Loss: 0.659745454788208, Accuracy: 0.71875, Computation time: 0.8481378555297852\n",
      "Step: 2203, Loss: 0.3924078047275543, Accuracy: 0.9375, Computation time: 0.9193716049194336\n",
      "Step: 2204, Loss: 0.4039810001850128, Accuracy: 0.84375, Computation time: 0.8483929634094238\n",
      "Step: 2205, Loss: 0.7970314621925354, Accuracy: 0.75, Computation time: 1.3525118827819824\n",
      "Step: 2206, Loss: 0.6632105112075806, Accuracy: 0.8125, Computation time: 0.6617538928985596\n",
      "Step: 2207, Loss: 0.6189112067222595, Accuracy: 0.875, Computation time: 0.8831710815429688\n",
      "Step: 2208, Loss: 0.5658626556396484, Accuracy: 0.8125, Computation time: 0.7360508441925049\n",
      "Step: 2209, Loss: 0.6105785369873047, Accuracy: 0.8125, Computation time: 0.9626801013946533\n",
      "Step: 2210, Loss: 0.45804038643836975, Accuracy: 0.8125, Computation time: 0.9513940811157227\n",
      "Step: 2211, Loss: 0.8784890174865723, Accuracy: 0.8125, Computation time: 0.995063066482544\n",
      "Step: 2212, Loss: 0.9954016208648682, Accuracy: 0.65625, Computation time: 0.8858692646026611\n",
      "Step: 2213, Loss: 0.6560629606246948, Accuracy: 0.8125, Computation time: 1.0006210803985596\n",
      "Step: 2214, Loss: 0.44156160950660706, Accuracy: 0.875, Computation time: 0.8350260257720947\n",
      "Step: 2215, Loss: 1.3983784914016724, Accuracy: 0.625, Computation time: 0.8341062068939209\n",
      "Step: 2216, Loss: 0.4103163182735443, Accuracy: 0.78125, Computation time: 0.7120239734649658\n",
      "Step: 2217, Loss: 0.5000442862510681, Accuracy: 0.84375, Computation time: 0.7866168022155762\n",
      "Step: 2218, Loss: 1.1152737140655518, Accuracy: 0.75, Computation time: 0.750777006149292\n",
      "Step: 2219, Loss: 0.805952787399292, Accuracy: 0.8125, Computation time: 0.703831672668457\n",
      "Step: 2220, Loss: 0.49611374735832214, Accuracy: 0.84375, Computation time: 0.682013988494873\n",
      "Step: 2221, Loss: 0.24862539768218994, Accuracy: 0.90625, Computation time: 0.8028512001037598\n",
      "Step: 2222, Loss: 0.44568589329719543, Accuracy: 0.875, Computation time: 0.7373702526092529\n",
      "Step: 2223, Loss: 0.2677784562110901, Accuracy: 0.9375, Computation time: 0.840817928314209\n",
      "Step: 2224, Loss: 0.543488621711731, Accuracy: 0.875, Computation time: 0.6784741878509521\n",
      "Step: 2225, Loss: 0.5845186114311218, Accuracy: 0.78125, Computation time: 0.666301965713501\n",
      "Step: 2226, Loss: 1.0128581523895264, Accuracy: 0.6875, Computation time: 1.0858309268951416\n",
      "Step: 2227, Loss: 0.7020307183265686, Accuracy: 0.75, Computation time: 0.7585692405700684\n",
      "Step: 2228, Loss: 0.5365074872970581, Accuracy: 0.78125, Computation time: 0.7211759090423584\n",
      "Step: 2229, Loss: 0.4629307687282562, Accuracy: 0.84375, Computation time: 0.7529189586639404\n",
      "Step: 2230, Loss: 0.4348277151584625, Accuracy: 0.875, Computation time: 0.7879619598388672\n",
      "Step: 2231, Loss: 0.7339588403701782, Accuracy: 0.75, Computation time: 0.9393839836120605\n",
      "Step: 2232, Loss: 0.7512160539627075, Accuracy: 0.65625, Computation time: 0.7513630390167236\n",
      "Step: 2233, Loss: 0.5187091827392578, Accuracy: 0.84375, Computation time: 0.7822849750518799\n",
      "Step: 2234, Loss: 0.5341876745223999, Accuracy: 0.875, Computation time: 1.0938398838043213\n",
      "Step: 2235, Loss: 0.801020085811615, Accuracy: 0.78125, Computation time: 0.7403120994567871\n",
      "Step: 2236, Loss: 0.442853182554245, Accuracy: 0.875, Computation time: 0.8127930164337158\n",
      "Step: 2237, Loss: 0.45366528630256653, Accuracy: 0.8125, Computation time: 0.7308700084686279\n",
      "Step: 2238, Loss: 0.935300886631012, Accuracy: 0.875, Computation time: 1.2852559089660645\n",
      "Step: 2239, Loss: 0.5556721687316895, Accuracy: 0.8125, Computation time: 0.8059420585632324\n",
      "Step: 2240, Loss: 0.4972879886627197, Accuracy: 0.875, Computation time: 0.8149576187133789\n",
      "Step: 2241, Loss: 0.4948256313800812, Accuracy: 0.875, Computation time: 0.7089991569519043\n",
      "Step: 2242, Loss: 0.5180423855781555, Accuracy: 0.84375, Computation time: 0.819706916809082\n",
      "Step: 2243, Loss: 0.536344051361084, Accuracy: 0.8125, Computation time: 0.8096287250518799\n",
      "Step: 2244, Loss: 0.8851936459541321, Accuracy: 0.75, Computation time: 0.9364581108093262\n",
      "Step: 2245, Loss: 1.0002634525299072, Accuracy: 0.78125, Computation time: 1.0151951313018799\n",
      "Step: 2246, Loss: 0.3404898941516876, Accuracy: 0.9375, Computation time: 0.8907828330993652\n",
      "Step: 2247, Loss: 0.8865121006965637, Accuracy: 0.75, Computation time: 0.7944917678833008\n",
      "Step: 2248, Loss: 1.0721145868301392, Accuracy: 0.625, Computation time: 0.8558499813079834\n",
      "Step: 2249, Loss: 0.5046225190162659, Accuracy: 0.84375, Computation time: 1.0539798736572266\n",
      "Step: 2250, Loss: 0.7654699683189392, Accuracy: 0.8125, Computation time: 0.7848320007324219\n",
      "Step: 2251, Loss: 0.6567854881286621, Accuracy: 0.84375, Computation time: 0.8037512302398682\n",
      "Step: 2252, Loss: 0.8535304069519043, Accuracy: 0.75, Computation time: 0.8496639728546143\n",
      "Step: 2253, Loss: 0.7967628836631775, Accuracy: 0.84375, Computation time: 0.9500410556793213\n",
      "Step: 2254, Loss: 0.8762892484664917, Accuracy: 0.78125, Computation time: 0.9660398960113525\n",
      "Step: 2255, Loss: 0.46506714820861816, Accuracy: 0.875, Computation time: 0.696357011795044\n",
      "Step: 2256, Loss: 0.6879140138626099, Accuracy: 0.84375, Computation time: 0.8346171379089355\n",
      "Step: 2257, Loss: 0.6294477581977844, Accuracy: 0.875, Computation time: 0.774183988571167\n",
      "Step: 2258, Loss: 0.9136072993278503, Accuracy: 0.75, Computation time: 0.7072920799255371\n",
      "Step: 2259, Loss: 0.8588964939117432, Accuracy: 0.6875, Computation time: 0.8660378456115723\n",
      "Step: 2260, Loss: 0.8881333470344543, Accuracy: 0.78125, Computation time: 0.7215921878814697\n",
      "Step: 2261, Loss: 0.6188364028930664, Accuracy: 0.75, Computation time: 0.7311079502105713\n",
      "Step: 2262, Loss: 0.5012392997741699, Accuracy: 0.84375, Computation time: 0.706650972366333\n",
      "Step: 2263, Loss: 0.5961079597473145, Accuracy: 0.875, Computation time: 0.7961511611938477\n",
      "Step: 2264, Loss: 0.4348718523979187, Accuracy: 0.875, Computation time: 0.7449281215667725\n",
      "Step: 2265, Loss: 0.7475808262825012, Accuracy: 0.84375, Computation time: 0.7367970943450928\n",
      "Step: 2266, Loss: 0.9022820591926575, Accuracy: 0.75, Computation time: 0.7489199638366699\n",
      "Step: 2267, Loss: 0.7214088439941406, Accuracy: 0.71875, Computation time: 0.7708468437194824\n",
      "Step: 2268, Loss: 0.562064528465271, Accuracy: 0.78125, Computation time: 0.7256150245666504\n",
      "Step: 2269, Loss: 0.8013527393341064, Accuracy: 0.78125, Computation time: 0.839249849319458\n",
      "Step: 2270, Loss: 0.8205112814903259, Accuracy: 0.71875, Computation time: 0.645482063293457\n",
      "Step: 2271, Loss: 0.5682770013809204, Accuracy: 0.84375, Computation time: 0.6986498832702637\n",
      "Step: 2272, Loss: 0.9002625346183777, Accuracy: 0.6875, Computation time: 0.7384998798370361\n",
      "Step: 2273, Loss: 0.6874464154243469, Accuracy: 0.78125, Computation time: 0.7829298973083496\n",
      "Step: 2274, Loss: 0.3662404417991638, Accuracy: 0.90625, Computation time: 0.9116809368133545\n",
      "Step: 2275, Loss: 0.5255365967750549, Accuracy: 0.8125, Computation time: 1.0170259475708008\n",
      "Step: 2276, Loss: 1.4263962507247925, Accuracy: 0.625, Computation time: 0.9454479217529297\n",
      "Step: 2277, Loss: 0.670758068561554, Accuracy: 0.8125, Computation time: 0.7227599620819092\n",
      "Step: 2278, Loss: 0.8720288276672363, Accuracy: 0.75, Computation time: 0.7981038093566895\n",
      "Step: 2279, Loss: 0.3134596645832062, Accuracy: 0.9375, Computation time: 0.7367427349090576\n",
      "Step: 2280, Loss: 0.5577141046524048, Accuracy: 0.875, Computation time: 0.6943149566650391\n",
      "Step: 2281, Loss: 0.6353083252906799, Accuracy: 0.78125, Computation time: 0.6645650863647461\n",
      "Step: 2282, Loss: 0.5447291731834412, Accuracy: 0.8125, Computation time: 0.6737778186798096\n",
      "Step: 2283, Loss: 0.7489088177680969, Accuracy: 0.78125, Computation time: 0.9402563571929932\n",
      "Step: 2284, Loss: 0.2898826599121094, Accuracy: 0.9375, Computation time: 0.8445219993591309\n",
      "Step: 2285, Loss: 0.5241002440452576, Accuracy: 0.78125, Computation time: 0.9459819793701172\n",
      "Step: 2286, Loss: 0.5368524789810181, Accuracy: 0.8125, Computation time: 1.015430212020874\n",
      "Step: 2287, Loss: 0.6466451287269592, Accuracy: 0.875, Computation time: 0.9914710521697998\n",
      "Step: 2288, Loss: 0.4003702700138092, Accuracy: 0.875, Computation time: 0.7007548809051514\n",
      "Step: 2289, Loss: 0.4047955572605133, Accuracy: 0.90625, Computation time: 0.8237838745117188\n",
      "Step: 2290, Loss: 0.4866029918193817, Accuracy: 0.875, Computation time: 1.6416070461273193\n",
      "Step: 2291, Loss: 1.4017587900161743, Accuracy: 0.78125, Computation time: 0.7911970615386963\n",
      "Step: 2292, Loss: 1.0732935667037964, Accuracy: 0.625, Computation time: 0.7585022449493408\n",
      "Step: 2293, Loss: 0.29135555028915405, Accuracy: 0.90625, Computation time: 0.9433538913726807\n",
      "Step: 2294, Loss: 1.2471297979354858, Accuracy: 0.6875, Computation time: 0.7366940975189209\n",
      "Step: 2295, Loss: 0.5795616507530212, Accuracy: 0.84375, Computation time: 0.9282169342041016\n",
      "Step: 2296, Loss: 0.6234719753265381, Accuracy: 0.75, Computation time: 0.6771988868713379\n",
      "Step: 2297, Loss: 0.3217213749885559, Accuracy: 0.90625, Computation time: 0.7903509140014648\n",
      "Step: 2298, Loss: 0.8905171751976013, Accuracy: 0.75, Computation time: 0.6765918731689453\n",
      "Step: 2299, Loss: 1.0739980936050415, Accuracy: 0.75, Computation time: 0.8877520561218262\n",
      "Step: 2300, Loss: 0.702475368976593, Accuracy: 0.71875, Computation time: 0.7817428112030029\n",
      "Step: 2301, Loss: 0.5172661542892456, Accuracy: 0.8125, Computation time: 0.9076950550079346\n",
      "Step: 2302, Loss: 0.5021889209747314, Accuracy: 0.8125, Computation time: 1.074552059173584\n",
      "Step: 2303, Loss: 0.7912776470184326, Accuracy: 0.8125, Computation time: 0.6678512096405029\n",
      "Step: 2304, Loss: 1.0558464527130127, Accuracy: 0.71875, Computation time: 0.9359571933746338\n",
      "Step: 2305, Loss: 0.4271039366722107, Accuracy: 0.84375, Computation time: 0.7512269020080566\n",
      "Step: 2306, Loss: 1.0206475257873535, Accuracy: 0.71875, Computation time: 0.8355410099029541\n",
      "Step: 2307, Loss: 0.5369696617126465, Accuracy: 0.875, Computation time: 0.7302401065826416\n",
      "Step: 2308, Loss: 0.6443050503730774, Accuracy: 0.84375, Computation time: 0.7264928817749023\n",
      "Step: 2309, Loss: 0.6936495900154114, Accuracy: 0.78125, Computation time: 0.64982008934021\n",
      "Step: 2310, Loss: 0.7623841166496277, Accuracy: 0.75, Computation time: 0.9294829368591309\n",
      "Step: 2311, Loss: 0.7963119745254517, Accuracy: 0.8125, Computation time: 0.813079833984375\n",
      "Step: 2312, Loss: 0.521352231502533, Accuracy: 0.8125, Computation time: 0.8308658599853516\n",
      "Step: 2313, Loss: 0.7244752049446106, Accuracy: 0.78125, Computation time: 0.761059045791626\n",
      "Step: 2314, Loss: 0.6411541104316711, Accuracy: 0.78125, Computation time: 0.6677989959716797\n",
      "Step: 2315, Loss: 0.7487351298332214, Accuracy: 0.78125, Computation time: 0.8180298805236816\n",
      "Step: 2316, Loss: 0.5295509696006775, Accuracy: 0.875, Computation time: 0.7540891170501709\n",
      "Step: 2317, Loss: 0.6268810629844666, Accuracy: 0.75, Computation time: 0.7747671604156494\n",
      "Step: 2318, Loss: 0.5410364270210266, Accuracy: 0.875, Computation time: 0.6968600749969482\n",
      "Step: 2319, Loss: 1.3610424995422363, Accuracy: 0.65625, Computation time: 0.8182539939880371\n",
      "Step: 2320, Loss: 0.7195883989334106, Accuracy: 0.875, Computation time: 0.7572338581085205\n",
      "Step: 2321, Loss: 0.5129964351654053, Accuracy: 0.8125, Computation time: 0.7357540130615234\n",
      "Step: 2322, Loss: 0.8104251623153687, Accuracy: 0.75, Computation time: 0.8461906909942627\n",
      "Step: 2323, Loss: 0.8636201620101929, Accuracy: 0.75, Computation time: 0.7964041233062744\n",
      "Step: 2324, Loss: 0.8136665225028992, Accuracy: 0.78125, Computation time: 1.1108818054199219\n",
      "Step: 2325, Loss: 0.792794406414032, Accuracy: 0.78125, Computation time: 0.7450039386749268\n",
      "Step: 2326, Loss: 0.6198832392692566, Accuracy: 0.75, Computation time: 0.7519481182098389\n",
      "Step: 2327, Loss: 0.4413551390171051, Accuracy: 0.84375, Computation time: 0.8020579814910889\n",
      "Step: 2328, Loss: 0.8367950320243835, Accuracy: 0.71875, Computation time: 0.7744531631469727\n",
      "Step: 2329, Loss: 0.4611755907535553, Accuracy: 0.84375, Computation time: 0.7125999927520752\n",
      "Step: 2330, Loss: 0.39556238055229187, Accuracy: 0.84375, Computation time: 0.919450044631958\n",
      "Step: 2331, Loss: 0.5221222043037415, Accuracy: 0.84375, Computation time: 0.729733943939209\n",
      "Step: 2332, Loss: 0.8445152044296265, Accuracy: 0.75, Computation time: 0.7831089496612549\n",
      "Step: 2333, Loss: 0.7386601567268372, Accuracy: 0.75, Computation time: 0.8142862319946289\n",
      "Step: 2334, Loss: 0.7311473488807678, Accuracy: 0.71875, Computation time: 0.7606940269470215\n",
      "Step: 2335, Loss: 0.4135710597038269, Accuracy: 0.8125, Computation time: 0.6660192012786865\n",
      "Step: 2336, Loss: 0.7607654333114624, Accuracy: 0.90625, Computation time: 1.4092381000518799\n",
      "Step: 2337, Loss: 0.7532091736793518, Accuracy: 0.78125, Computation time: 0.709975004196167\n",
      "Step: 2338, Loss: 0.6889889240264893, Accuracy: 0.78125, Computation time: 0.8135280609130859\n",
      "Step: 2339, Loss: 0.7562420964241028, Accuracy: 0.71875, Computation time: 0.9329180717468262\n",
      "Step: 2340, Loss: 0.5594230890274048, Accuracy: 0.90625, Computation time: 0.6022388935089111\n",
      "Step: 2341, Loss: 0.8231526017189026, Accuracy: 0.75, Computation time: 0.8852622509002686\n",
      "Step: 2342, Loss: 0.44718629121780396, Accuracy: 0.90625, Computation time: 1.1373560428619385\n",
      "Step: 2343, Loss: 0.30763113498687744, Accuracy: 0.90625, Computation time: 0.7365200519561768\n",
      "Step: 2344, Loss: 0.5947080254554749, Accuracy: 0.84375, Computation time: 0.9752790927886963\n",
      "Step: 2345, Loss: 0.9200633764266968, Accuracy: 0.75, Computation time: 0.8840410709381104\n",
      "Step: 2346, Loss: 0.39492809772491455, Accuracy: 0.84375, Computation time: 0.6154544353485107\n",
      "Step: 2347, Loss: 0.9094280004501343, Accuracy: 0.6875, Computation time: 0.793586015701294\n",
      "Step: 2348, Loss: 0.8384666442871094, Accuracy: 0.75, Computation time: 0.8045568466186523\n",
      "Step: 2349, Loss: 0.32462579011917114, Accuracy: 0.875, Computation time: 0.9493381977081299\n",
      "Step: 2350, Loss: 0.7006651163101196, Accuracy: 0.84375, Computation time: 0.853480339050293\n",
      "Step: 2351, Loss: 1.0301133394241333, Accuracy: 0.78125, Computation time: 0.7799808979034424\n",
      "Step: 2352, Loss: 0.6375061273574829, Accuracy: 0.78125, Computation time: 0.8346741199493408\n",
      "Step: 2353, Loss: 0.21616537868976593, Accuracy: 0.9375, Computation time: 0.6373617649078369\n",
      "Step: 2354, Loss: 0.7045549154281616, Accuracy: 0.78125, Computation time: 0.6428267955780029\n",
      "Step: 2355, Loss: 0.9382021427154541, Accuracy: 0.6875, Computation time: 0.996567964553833\n",
      "Step: 2356, Loss: 0.5888963937759399, Accuracy: 0.8125, Computation time: 0.8833398818969727\n",
      "Step: 2357, Loss: 0.7646356821060181, Accuracy: 0.75, Computation time: 1.5655369758605957\n",
      "Step: 2358, Loss: 0.6484401822090149, Accuracy: 0.6875, Computation time: 0.7627778053283691\n",
      "Step: 2359, Loss: 0.5484919548034668, Accuracy: 0.75, Computation time: 0.8418130874633789\n",
      "Step: 2360, Loss: 0.5811111330986023, Accuracy: 0.8125, Computation time: 0.8765401840209961\n",
      "Step: 2361, Loss: 0.6324558258056641, Accuracy: 0.90625, Computation time: 0.728355884552002\n",
      "Step: 2362, Loss: 0.7403254508972168, Accuracy: 0.84375, Computation time: 1.054616928100586\n",
      "Step: 2363, Loss: 1.1939911842346191, Accuracy: 0.71875, Computation time: 0.7986030578613281\n",
      "Step: 2364, Loss: 0.5830755829811096, Accuracy: 0.84375, Computation time: 0.7674939632415771\n",
      "Step: 2365, Loss: 0.8605475425720215, Accuracy: 0.71875, Computation time: 0.7147340774536133\n",
      "Step: 2366, Loss: 0.6119465231895447, Accuracy: 0.78125, Computation time: 0.7732090950012207\n",
      "Step: 2367, Loss: 0.7330018281936646, Accuracy: 0.84375, Computation time: 0.8912489414215088\n",
      "Step: 2368, Loss: 0.8338877558708191, Accuracy: 0.75, Computation time: 1.1939139366149902\n",
      "Step: 2369, Loss: 0.45743197202682495, Accuracy: 0.875, Computation time: 0.7719528675079346\n",
      "Step: 2370, Loss: 1.1772886514663696, Accuracy: 0.65625, Computation time: 1.0373799800872803\n",
      "Step: 2371, Loss: 0.8130959272384644, Accuracy: 0.75, Computation time: 0.7363080978393555\n",
      "Step: 2372, Loss: 1.0053958892822266, Accuracy: 0.6875, Computation time: 0.7800159454345703\n",
      "Step: 2373, Loss: 0.4743296205997467, Accuracy: 0.84375, Computation time: 0.8018109798431396\n",
      "Step: 2374, Loss: 0.6291019916534424, Accuracy: 0.8125, Computation time: 0.8614039421081543\n",
      "Step: 2375, Loss: 0.6662306189537048, Accuracy: 0.84375, Computation time: 1.000903844833374\n",
      "Step: 2376, Loss: 0.47787395119667053, Accuracy: 0.84375, Computation time: 0.7675750255584717\n",
      "Step: 2377, Loss: 0.9214950799942017, Accuracy: 0.71875, Computation time: 0.9424729347229004\n",
      "Step: 2378, Loss: 0.9677616357803345, Accuracy: 0.75, Computation time: 0.7366921901702881\n",
      "Step: 2379, Loss: 0.47627073526382446, Accuracy: 0.875, Computation time: 0.688133716583252\n",
      "Step: 2380, Loss: 0.6147087216377258, Accuracy: 0.78125, Computation time: 0.8469228744506836\n",
      "Step: 2381, Loss: 0.6421612501144409, Accuracy: 0.84375, Computation time: 0.6853499412536621\n",
      "Step: 2382, Loss: 0.5142626762390137, Accuracy: 0.8125, Computation time: 0.7158451080322266\n",
      "Step: 2383, Loss: 0.5806830525398254, Accuracy: 0.8125, Computation time: 0.829211950302124\n",
      "Step: 2384, Loss: 0.4392456114292145, Accuracy: 0.875, Computation time: 0.860867977142334\n",
      "Step: 2385, Loss: 0.7556177377700806, Accuracy: 0.6875, Computation time: 0.6904001235961914\n",
      "Step: 2386, Loss: 0.456442266702652, Accuracy: 0.84375, Computation time: 0.9405519962310791\n",
      "Step: 2387, Loss: 0.5926346778869629, Accuracy: 0.78125, Computation time: 0.8812532424926758\n",
      "Step: 2388, Loss: 0.8887085914611816, Accuracy: 0.71875, Computation time: 0.77382493019104\n",
      "Step: 2389, Loss: 0.6994174718856812, Accuracy: 0.8125, Computation time: 0.9677860736846924\n",
      "Step: 2390, Loss: 0.8821406960487366, Accuracy: 0.6875, Computation time: 0.7501471042633057\n",
      "Step: 2391, Loss: 0.5130861401557922, Accuracy: 0.8125, Computation time: 0.7860770225524902\n",
      "Step: 2392, Loss: 0.48276612162590027, Accuracy: 0.8125, Computation time: 0.7095909118652344\n",
      "Step: 2393, Loss: 0.9810091853141785, Accuracy: 0.8125, Computation time: 0.8181419372558594\n",
      "Step: 2394, Loss: 0.7869371175765991, Accuracy: 0.78125, Computation time: 0.7375502586364746\n",
      "Step: 2395, Loss: 0.7653024792671204, Accuracy: 0.84375, Computation time: 0.7588469982147217\n",
      "Step: 2396, Loss: 0.717380940914154, Accuracy: 0.71875, Computation time: 0.7173230648040771\n",
      "Step: 2397, Loss: 0.9576996564865112, Accuracy: 0.75, Computation time: 0.9023783206939697\n",
      "Step: 2398, Loss: 0.9056330323219299, Accuracy: 0.8125, Computation time: 0.8024430274963379\n",
      "Step: 2399, Loss: 0.7954161167144775, Accuracy: 0.8125, Computation time: 0.7934560775756836\n",
      "Step: 2400, Loss: 0.7488604784011841, Accuracy: 0.8125, Computation time: 0.9032998085021973\n",
      "Step: 2401, Loss: 0.363926500082016, Accuracy: 0.90625, Computation time: 1.318678855895996\n",
      "Step: 2402, Loss: 0.7407286763191223, Accuracy: 0.71875, Computation time: 0.7607259750366211\n",
      "Step: 2403, Loss: 0.3697504997253418, Accuracy: 0.875, Computation time: 0.8680191040039062\n",
      "Step: 2404, Loss: 0.4001934826374054, Accuracy: 0.90625, Computation time: 0.8057670593261719\n",
      "Step: 2405, Loss: 1.0415936708450317, Accuracy: 0.71875, Computation time: 0.8456592559814453\n",
      "Step: 2406, Loss: 0.5630447268486023, Accuracy: 0.78125, Computation time: 0.7957980632781982\n",
      "Step: 2407, Loss: 0.25409820675849915, Accuracy: 0.96875, Computation time: 0.8029909133911133\n",
      "Step: 2408, Loss: 0.7882573008537292, Accuracy: 0.8125, Computation time: 1.1999800205230713\n",
      "Step: 2409, Loss: 0.5315154790878296, Accuracy: 0.8125, Computation time: 1.076843023300171\n",
      "Step: 2410, Loss: 1.0546566247940063, Accuracy: 0.65625, Computation time: 0.8448162078857422\n",
      "Step: 2411, Loss: 0.4043406844139099, Accuracy: 0.84375, Computation time: 0.7900588512420654\n",
      "Step: 2412, Loss: 0.5052881836891174, Accuracy: 0.875, Computation time: 0.7068459987640381\n",
      "Step: 2413, Loss: 0.6391406059265137, Accuracy: 0.75, Computation time: 1.1314527988433838\n",
      "Step: 2414, Loss: 0.4596656560897827, Accuracy: 0.8125, Computation time: 0.8712189197540283\n",
      "Step: 2415, Loss: 0.690833568572998, Accuracy: 0.78125, Computation time: 0.7932500839233398\n",
      "Step: 2416, Loss: 0.555992066860199, Accuracy: 0.84375, Computation time: 0.755824089050293\n",
      "Step: 2417, Loss: 0.39116162061691284, Accuracy: 0.875, Computation time: 0.6815268993377686\n",
      "Step: 2418, Loss: 0.8096575736999512, Accuracy: 0.75, Computation time: 0.8063287734985352\n",
      "Step: 2419, Loss: 0.6453010439872742, Accuracy: 0.8125, Computation time: 0.8110859394073486\n",
      "Step: 2420, Loss: 1.1491156816482544, Accuracy: 0.71875, Computation time: 0.7131729125976562\n",
      "Step: 2421, Loss: 0.6247038245201111, Accuracy: 0.84375, Computation time: 0.7327191829681396\n",
      "Step: 2422, Loss: 0.7216589450836182, Accuracy: 0.71875, Computation time: 0.7926161289215088\n",
      "Step: 2423, Loss: 0.7238887548446655, Accuracy: 0.71875, Computation time: 0.7980959415435791\n",
      "Step: 2424, Loss: 0.9069074392318726, Accuracy: 0.78125, Computation time: 0.7561290264129639\n",
      "Step: 2425, Loss: 0.6283074021339417, Accuracy: 0.78125, Computation time: 0.7123360633850098\n",
      "Step: 2426, Loss: 0.6386731863021851, Accuracy: 0.8125, Computation time: 0.7516789436340332\n",
      "Step: 2427, Loss: 0.31831562519073486, Accuracy: 0.90625, Computation time: 0.7970743179321289\n",
      "Step: 2428, Loss: 0.6694450378417969, Accuracy: 0.75, Computation time: 0.9549961090087891\n",
      "Step: 2429, Loss: 0.6323661804199219, Accuracy: 0.84375, Computation time: 0.803447961807251\n",
      "Step: 2430, Loss: 0.73887038230896, Accuracy: 0.84375, Computation time: 0.9180471897125244\n",
      "Step: 2431, Loss: 0.5118483901023865, Accuracy: 0.84375, Computation time: 0.8070700168609619\n",
      "Step: 2432, Loss: 0.9713804721832275, Accuracy: 0.75, Computation time: 0.885066032409668\n",
      "Step: 2433, Loss: 0.6529176831245422, Accuracy: 0.875, Computation time: 1.2034251689910889\n",
      "Step: 2434, Loss: 0.8979763984680176, Accuracy: 0.78125, Computation time: 0.7250699996948242\n",
      "Step: 2435, Loss: 0.48480042815208435, Accuracy: 0.875, Computation time: 0.7716410160064697\n",
      "Step: 2436, Loss: 1.1304019689559937, Accuracy: 0.59375, Computation time: 0.7190773487091064\n",
      "Step: 2437, Loss: 0.6097721457481384, Accuracy: 0.875, Computation time: 0.7905519008636475\n",
      "Step: 2438, Loss: 0.8212738037109375, Accuracy: 0.78125, Computation time: 0.7150542736053467\n",
      "Step: 2439, Loss: 0.5762260556221008, Accuracy: 0.8125, Computation time: 0.9057872295379639\n",
      "Step: 2440, Loss: 0.6915110349655151, Accuracy: 0.71875, Computation time: 0.7309019565582275\n",
      "Step: 2441, Loss: 0.8988598585128784, Accuracy: 0.71875, Computation time: 0.8049411773681641\n",
      "Step: 2442, Loss: 0.5995664000511169, Accuracy: 0.78125, Computation time: 0.8182547092437744\n",
      "Step: 2443, Loss: 0.6705873012542725, Accuracy: 0.8125, Computation time: 0.871117115020752\n",
      "Step: 2444, Loss: 0.6905196309089661, Accuracy: 0.84375, Computation time: 0.8389029502868652\n",
      "Step: 2445, Loss: 0.6033507585525513, Accuracy: 0.8125, Computation time: 0.7044007778167725\n",
      "Step: 2446, Loss: 0.6443907618522644, Accuracy: 0.78125, Computation time: 1.002720832824707\n",
      "Step: 2447, Loss: 0.8017444014549255, Accuracy: 0.8125, Computation time: 0.7691693305969238\n",
      "Step: 2448, Loss: 0.7077825665473938, Accuracy: 0.75, Computation time: 0.7934150695800781\n",
      "Step: 2449, Loss: 0.35566696524620056, Accuracy: 0.9375, Computation time: 0.8248231410980225\n",
      "Step: 2450, Loss: 0.5322117209434509, Accuracy: 0.90625, Computation time: 0.7691440582275391\n",
      "Step: 2451, Loss: 0.5310961008071899, Accuracy: 0.8125, Computation time: 0.6879539489746094\n",
      "Step: 2452, Loss: 0.9515851140022278, Accuracy: 0.78125, Computation time: 0.8371610641479492\n",
      "Step: 2453, Loss: 0.6986730098724365, Accuracy: 0.84375, Computation time: 0.7861897945404053\n",
      "Step: 2454, Loss: 0.3523982763290405, Accuracy: 0.84375, Computation time: 0.7150702476501465\n",
      "Step: 2455, Loss: 1.133643627166748, Accuracy: 0.78125, Computation time: 0.8017909526824951\n",
      "Step: 2456, Loss: 0.5137997269630432, Accuracy: 0.78125, Computation time: 0.7247300148010254\n",
      "Step: 2457, Loss: 0.8166276812553406, Accuracy: 0.75, Computation time: 0.74993896484375\n",
      "Step: 2458, Loss: 0.6810829043388367, Accuracy: 0.8125, Computation time: 0.9576921463012695\n",
      "Step: 2459, Loss: 0.8165329098701477, Accuracy: 0.78125, Computation time: 0.8776688575744629\n",
      "Step: 2460, Loss: 0.7666599750518799, Accuracy: 0.8125, Computation time: 0.7358148097991943\n",
      "Step: 2461, Loss: 0.41892826557159424, Accuracy: 0.875, Computation time: 0.6556777954101562\n",
      "Step: 2462, Loss: 0.47188854217529297, Accuracy: 0.84375, Computation time: 0.640617847442627\n",
      "Step: 2463, Loss: 0.5973140597343445, Accuracy: 0.84375, Computation time: 0.7061920166015625\n",
      "Step: 2464, Loss: 0.23005282878875732, Accuracy: 0.9375, Computation time: 0.8864331245422363\n",
      "Step: 2465, Loss: 0.7902844548225403, Accuracy: 0.65625, Computation time: 0.8828287124633789\n",
      "Step: 2466, Loss: 0.6161640286445618, Accuracy: 0.875, Computation time: 1.2362439632415771\n",
      "Step: 2467, Loss: 0.8972263336181641, Accuracy: 0.6875, Computation time: 0.8545989990234375\n",
      "Step: 2468, Loss: 0.8376715183258057, Accuracy: 0.875, Computation time: 0.7644321918487549\n",
      "Step: 2469, Loss: 0.621147871017456, Accuracy: 0.78125, Computation time: 0.8182909488677979\n",
      "Step: 2470, Loss: 0.4527152180671692, Accuracy: 0.84375, Computation time: 0.7966852188110352\n",
      "Step: 2471, Loss: 0.8258015513420105, Accuracy: 0.75, Computation time: 0.8649477958679199\n",
      "Step: 2472, Loss: 0.3291237950325012, Accuracy: 0.9375, Computation time: 0.8476407527923584\n",
      "Step: 2473, Loss: 0.8780694007873535, Accuracy: 0.75, Computation time: 0.7524302005767822\n",
      "Step: 2474, Loss: 0.5049124360084534, Accuracy: 0.9375, Computation time: 0.8200759887695312\n",
      "Step: 2475, Loss: 0.4526127278804779, Accuracy: 0.90625, Computation time: 1.2658262252807617\n",
      "Step: 2476, Loss: 0.7627754807472229, Accuracy: 0.84375, Computation time: 0.7443678379058838\n",
      "Step: 2477, Loss: 0.7236245274543762, Accuracy: 0.78125, Computation time: 0.8124420642852783\n",
      "Step: 2478, Loss: 0.5535174012184143, Accuracy: 0.84375, Computation time: 0.6957061290740967\n",
      "Step: 2479, Loss: 0.5062395930290222, Accuracy: 0.875, Computation time: 0.7280702590942383\n",
      "Step: 2480, Loss: 0.35837286710739136, Accuracy: 0.875, Computation time: 0.8755269050598145\n",
      "Step: 2481, Loss: 0.6100733280181885, Accuracy: 0.75, Computation time: 0.8792159557342529\n",
      "Step: 2482, Loss: 0.6336174011230469, Accuracy: 0.78125, Computation time: 0.9047050476074219\n",
      "Step: 2483, Loss: 0.4287399649620056, Accuracy: 0.90625, Computation time: 0.8306119441986084\n",
      "Step: 2484, Loss: 0.4370902180671692, Accuracy: 0.875, Computation time: 0.6340160369873047\n",
      "Step: 2485, Loss: 0.9209601879119873, Accuracy: 0.65625, Computation time: 0.7321200370788574\n",
      "Step: 2486, Loss: 0.6159824132919312, Accuracy: 0.8125, Computation time: 0.9759809970855713\n",
      "Step: 2487, Loss: 1.0000762939453125, Accuracy: 0.71875, Computation time: 0.7665081024169922\n",
      "Step: 2488, Loss: 0.538122296333313, Accuracy: 0.78125, Computation time: 0.699394941329956\n",
      "Step: 2489, Loss: 4.307143688201904, Accuracy: 0.78125, Computation time: 0.8773941993713379\n",
      "Step: 2490, Loss: 0.9131826758384705, Accuracy: 0.65625, Computation time: 0.8518316745758057\n",
      "Step: 2491, Loss: 0.2857663631439209, Accuracy: 0.90625, Computation time: 0.9241170883178711\n",
      "Step: 2492, Loss: 0.5162665843963623, Accuracy: 0.78125, Computation time: 0.846045970916748\n",
      "Step: 2493, Loss: 0.38542109727859497, Accuracy: 0.90625, Computation time: 0.8598079681396484\n",
      "Step: 2494, Loss: 1.167791724205017, Accuracy: 0.65625, Computation time: 0.7652091979980469\n",
      "Step: 2495, Loss: 0.7777487635612488, Accuracy: 0.78125, Computation time: 0.8539867401123047\n",
      "Step: 2496, Loss: 0.5881615877151489, Accuracy: 0.84375, Computation time: 0.7959351539611816\n",
      "Step: 2497, Loss: 0.5632339715957642, Accuracy: 0.84375, Computation time: 0.7571001052856445\n",
      "Step: 2498, Loss: 1.0636537075042725, Accuracy: 0.71875, Computation time: 0.8322920799255371\n",
      "Step: 2499, Loss: 1.061632513999939, Accuracy: 0.65625, Computation time: 1.141437292098999\n",
      "Step: 2500, Loss: 0.814414381980896, Accuracy: 0.71875, Computation time: 0.7295820713043213\n",
      "Step: 2501, Loss: 0.5713141560554504, Accuracy: 0.875, Computation time: 0.7314679622650146\n",
      "Step: 2502, Loss: 0.8947934508323669, Accuracy: 0.875, Computation time: 0.8742196559906006\n",
      "Step: 2503, Loss: 0.7375028133392334, Accuracy: 0.75, Computation time: 0.8550739288330078\n",
      "Step: 2504, Loss: 0.662726104259491, Accuracy: 0.875, Computation time: 0.7870478630065918\n",
      "Step: 2505, Loss: 0.5213524699211121, Accuracy: 0.84375, Computation time: 1.0562019348144531\n",
      "Step: 2506, Loss: 0.9939818382263184, Accuracy: 0.71875, Computation time: 0.8450651168823242\n",
      "Step: 2507, Loss: 0.675945520401001, Accuracy: 0.8125, Computation time: 0.9016320705413818\n",
      "Step: 2508, Loss: 0.9329032897949219, Accuracy: 0.6875, Computation time: 0.8718841075897217\n",
      "Step: 2509, Loss: 0.6192635893821716, Accuracy: 0.71875, Computation time: 0.7811141014099121\n",
      "Step: 2510, Loss: 0.6942510604858398, Accuracy: 0.71875, Computation time: 0.8338959217071533\n",
      "Step: 2511, Loss: 0.7824056148529053, Accuracy: 0.8125, Computation time: 1.012188196182251\n",
      "Step: 2512, Loss: 0.5866734981536865, Accuracy: 0.875, Computation time: 0.9261472225189209\n",
      "Step: 2513, Loss: 0.6247687339782715, Accuracy: 0.75, Computation time: 0.9706699848175049\n",
      "Step: 2514, Loss: 0.44941651821136475, Accuracy: 0.90625, Computation time: 0.8258330821990967\n",
      "Step: 2515, Loss: 0.9516373872756958, Accuracy: 0.625, Computation time: 0.6879439353942871\n",
      "Step: 2516, Loss: 0.6766768097877502, Accuracy: 0.8125, Computation time: 0.8759219646453857\n",
      "Step: 2517, Loss: 0.5427881479263306, Accuracy: 0.90625, Computation time: 0.8151507377624512\n",
      "Step: 2518, Loss: 0.9043840169906616, Accuracy: 0.65625, Computation time: 1.2085230350494385\n",
      "Step: 2519, Loss: 0.32314586639404297, Accuracy: 0.875, Computation time: 0.9076850414276123\n",
      "Step: 2520, Loss: 0.5603364109992981, Accuracy: 0.8125, Computation time: 0.8949131965637207\n",
      "Step: 2521, Loss: 0.6508150696754456, Accuracy: 0.78125, Computation time: 0.7962377071380615\n",
      "Step: 2522, Loss: 0.4232911467552185, Accuracy: 0.90625, Computation time: 0.9001789093017578\n",
      "Step: 2523, Loss: 0.8206601738929749, Accuracy: 0.71875, Computation time: 0.828920841217041\n",
      "Step: 2524, Loss: 0.46364426612854004, Accuracy: 0.84375, Computation time: 0.8512289524078369\n",
      "Step: 2525, Loss: 0.3388013541698456, Accuracy: 0.84375, Computation time: 0.7273280620574951\n",
      "Step: 2526, Loss: 0.6032007336616516, Accuracy: 0.8125, Computation time: 0.9179389476776123\n",
      "Step: 2527, Loss: 0.7444164156913757, Accuracy: 0.84375, Computation time: 0.6816720962524414\n",
      "Step: 2528, Loss: 0.48094475269317627, Accuracy: 0.84375, Computation time: 0.7108252048492432\n",
      "Step: 2529, Loss: 0.7692145705223083, Accuracy: 0.75, Computation time: 0.7135248184204102\n",
      "Step: 2530, Loss: 0.5809294581413269, Accuracy: 0.8125, Computation time: 0.7096760272979736\n",
      "Step: 2531, Loss: 0.8003484010696411, Accuracy: 0.78125, Computation time: 0.871906042098999\n",
      "Step: 2532, Loss: 0.7369699478149414, Accuracy: 0.6875, Computation time: 0.9391968250274658\n",
      "Step: 2533, Loss: 0.5275295972824097, Accuracy: 0.8125, Computation time: 0.8937461376190186\n",
      "Step: 2534, Loss: 0.6666932702064514, Accuracy: 0.84375, Computation time: 0.8122189044952393\n",
      "Step: 2535, Loss: 0.558673083782196, Accuracy: 0.84375, Computation time: 1.5375430583953857\n",
      "Step: 2536, Loss: 0.8171007633209229, Accuracy: 0.8125, Computation time: 1.0733866691589355\n",
      "Step: 2537, Loss: 0.8193738460540771, Accuracy: 0.78125, Computation time: 0.7515230178833008\n",
      "Step: 2538, Loss: 0.4795472025871277, Accuracy: 0.875, Computation time: 0.897686243057251\n",
      "Step: 2539, Loss: 0.9738353490829468, Accuracy: 0.8125, Computation time: 0.7537658214569092\n",
      "Step: 2540, Loss: 0.8520791530609131, Accuracy: 0.75, Computation time: 0.9191679954528809\n",
      "Step: 2541, Loss: 0.6539928317070007, Accuracy: 0.8125, Computation time: 0.7629480361938477\n",
      "Step: 2542, Loss: 0.8448960185050964, Accuracy: 0.6875, Computation time: 1.072808027267456\n",
      "Step: 2543, Loss: 0.8016489148139954, Accuracy: 0.75, Computation time: 0.7700278759002686\n",
      "Step: 2544, Loss: 0.5799919366836548, Accuracy: 0.78125, Computation time: 0.8081648349761963\n",
      "Step: 2545, Loss: 0.7165685892105103, Accuracy: 0.75, Computation time: 0.6902050971984863\n",
      "Step: 2546, Loss: 0.31364497542381287, Accuracy: 0.9375, Computation time: 0.9345307350158691\n",
      "Step: 2547, Loss: 0.757839024066925, Accuracy: 0.78125, Computation time: 0.791823148727417\n",
      "Step: 2548, Loss: 0.9787394404411316, Accuracy: 0.65625, Computation time: 0.9784841537475586\n",
      "Step: 2549, Loss: 1.0297653675079346, Accuracy: 0.65625, Computation time: 0.7926690578460693\n",
      "Step: 2550, Loss: 0.81923508644104, Accuracy: 0.78125, Computation time: 0.9206149578094482\n",
      "Step: 2551, Loss: 0.7310152053833008, Accuracy: 0.71875, Computation time: 0.8433928489685059\n",
      "Step: 2552, Loss: 0.4680400788784027, Accuracy: 0.8125, Computation time: 1.1235771179199219\n",
      "Step: 2553, Loss: 0.503933846950531, Accuracy: 0.875, Computation time: 1.164107084274292\n",
      "Step: 2554, Loss: 0.839274525642395, Accuracy: 0.75, Computation time: 0.8647058010101318\n",
      "Step: 2555, Loss: 0.38726747035980225, Accuracy: 0.90625, Computation time: 0.8958559036254883\n",
      "Step: 2556, Loss: 0.7209367156028748, Accuracy: 0.71875, Computation time: 0.7386770248413086\n",
      "Step: 2557, Loss: 0.8364148736000061, Accuracy: 0.71875, Computation time: 0.7972140312194824\n",
      "Step: 2558, Loss: 0.6615684032440186, Accuracy: 0.8125, Computation time: 1.060945987701416\n",
      "Step: 2559, Loss: 0.6339161396026611, Accuracy: 0.6875, Computation time: 0.9061932563781738\n",
      "Step: 2560, Loss: 0.5532775521278381, Accuracy: 0.75, Computation time: 1.3948957920074463\n",
      "Step: 2561, Loss: 0.56735759973526, Accuracy: 0.875, Computation time: 0.768139123916626\n",
      "Step: 2562, Loss: 0.7201455235481262, Accuracy: 0.78125, Computation time: 0.7035603523254395\n",
      "Step: 2563, Loss: 0.7043517827987671, Accuracy: 0.78125, Computation time: 0.892697811126709\n",
      "Step: 2564, Loss: 0.5508449673652649, Accuracy: 0.84375, Computation time: 0.7719290256500244\n",
      "Step: 2565, Loss: 0.5961430668830872, Accuracy: 0.875, Computation time: 0.9685781002044678\n",
      "Step: 2566, Loss: 0.7047888040542603, Accuracy: 0.78125, Computation time: 0.6389338970184326\n",
      "Step: 2567, Loss: 0.42414671182632446, Accuracy: 0.875, Computation time: 0.7809438705444336\n",
      "Step: 2568, Loss: 0.6768566966056824, Accuracy: 0.71875, Computation time: 0.8084549903869629\n",
      "Step: 2569, Loss: 0.41589584946632385, Accuracy: 0.78125, Computation time: 0.8786728382110596\n",
      "Step: 2570, Loss: 0.333248496055603, Accuracy: 0.9375, Computation time: 0.838385820388794\n",
      "Step: 2571, Loss: 0.6956968903541565, Accuracy: 0.8125, Computation time: 0.8048591613769531\n",
      "Step: 2572, Loss: 0.40093299746513367, Accuracy: 0.84375, Computation time: 0.7395460605621338\n",
      "Step: 2573, Loss: 0.2912856936454773, Accuracy: 0.96875, Computation time: 0.6888151168823242\n",
      "Step: 2574, Loss: 0.764539361000061, Accuracy: 0.75, Computation time: 0.7452869415283203\n",
      "Step: 2575, Loss: 0.5531471967697144, Accuracy: 0.8125, Computation time: 0.8605608940124512\n",
      "Step: 2576, Loss: 0.6230773329734802, Accuracy: 0.8125, Computation time: 1.4010629653930664\n",
      "Step: 2577, Loss: 0.465518057346344, Accuracy: 0.875, Computation time: 0.9305989742279053\n",
      "Step: 2578, Loss: 0.6582874059677124, Accuracy: 0.875, Computation time: 0.7849462032318115\n",
      "Step: 2579, Loss: 0.6084862947463989, Accuracy: 0.8125, Computation time: 0.9310550689697266\n",
      "Step: 2580, Loss: 0.67463219165802, Accuracy: 0.8125, Computation time: 0.7790279388427734\n",
      "Step: 2581, Loss: 0.6513943076133728, Accuracy: 0.875, Computation time: 0.7005250453948975\n",
      "Step: 2582, Loss: 0.4952237010002136, Accuracy: 0.875, Computation time: 0.8029470443725586\n",
      "Step: 2583, Loss: 0.806788980960846, Accuracy: 0.71875, Computation time: 0.7149162292480469\n",
      "Step: 2584, Loss: 0.87724769115448, Accuracy: 0.78125, Computation time: 0.695303201675415\n",
      "Step: 2585, Loss: 0.8946871161460876, Accuracy: 0.65625, Computation time: 0.7570912837982178\n",
      "Step: 2586, Loss: 1.0734325647354126, Accuracy: 0.8125, Computation time: 0.7854659557342529\n",
      "Step: 2587, Loss: 0.7147791385650635, Accuracy: 0.78125, Computation time: 0.8201680183410645\n",
      "Step: 2588, Loss: 0.9452173709869385, Accuracy: 0.6875, Computation time: 0.7361290454864502\n",
      "Step: 2589, Loss: 0.8728744387626648, Accuracy: 0.71875, Computation time: 0.8485300540924072\n",
      "Step: 2590, Loss: 0.3055012822151184, Accuracy: 0.9375, Computation time: 0.6654758453369141\n",
      "Step: 2591, Loss: 0.5054334998130798, Accuracy: 0.90625, Computation time: 0.8211820125579834\n",
      "Step: 2592, Loss: 0.42881783843040466, Accuracy: 0.875, Computation time: 0.7802350521087646\n",
      "Step: 2593, Loss: 0.3327268064022064, Accuracy: 0.90625, Computation time: 1.2953898906707764\n",
      "Step: 2594, Loss: 1.0921744108200073, Accuracy: 0.71875, Computation time: 0.9159791469573975\n",
      "Step: 2595, Loss: 0.7834186553955078, Accuracy: 0.78125, Computation time: 0.8261692523956299\n",
      "Step: 2596, Loss: 1.0488688945770264, Accuracy: 0.75, Computation time: 0.8354411125183105\n",
      "Step: 2597, Loss: 0.3757600784301758, Accuracy: 0.84375, Computation time: 0.8841979503631592\n",
      "Step: 2598, Loss: 0.5539065003395081, Accuracy: 0.84375, Computation time: 0.7422070503234863\n",
      "Step: 2599, Loss: 0.9599147439002991, Accuracy: 0.78125, Computation time: 0.8383166790008545\n",
      "Step: 2600, Loss: 0.64485102891922, Accuracy: 0.8125, Computation time: 0.7174210548400879\n",
      "Step: 2601, Loss: 0.6177666187286377, Accuracy: 0.8125, Computation time: 0.7067551612854004\n",
      "Step: 2602, Loss: 0.7247977256774902, Accuracy: 0.71875, Computation time: 0.9062252044677734\n",
      "Step: 2603, Loss: 0.6614216566085815, Accuracy: 0.8125, Computation time: 0.8441169261932373\n",
      "Step: 2604, Loss: 1.0982396602630615, Accuracy: 0.71875, Computation time: 0.8602120876312256\n",
      "Step: 2605, Loss: 0.6467070579528809, Accuracy: 0.84375, Computation time: 0.8505830764770508\n",
      "Step: 2606, Loss: 1.065403938293457, Accuracy: 0.71875, Computation time: 0.8064839839935303\n",
      "Step: 2607, Loss: 0.45505622029304504, Accuracy: 0.875, Computation time: 0.9342038631439209\n",
      "Step: 2608, Loss: 0.7735143899917603, Accuracy: 0.78125, Computation time: 0.9892842769622803\n",
      "Step: 2609, Loss: 0.7143168449401855, Accuracy: 0.8125, Computation time: 0.7540309429168701\n",
      "Step: 2610, Loss: 0.4386468529701233, Accuracy: 0.84375, Computation time: 1.1118950843811035\n",
      "Step: 2611, Loss: 0.6717493534088135, Accuracy: 0.75, Computation time: 0.8262028694152832\n",
      "Step: 2612, Loss: 0.5599743723869324, Accuracy: 0.84375, Computation time: 0.6980957984924316\n",
      "Step: 2613, Loss: 0.8318824768066406, Accuracy: 0.75, Computation time: 0.748114824295044\n",
      "Step: 2614, Loss: 0.7483514547348022, Accuracy: 0.875, Computation time: 0.8384780883789062\n",
      "Step: 2615, Loss: 0.7662978768348694, Accuracy: 0.71875, Computation time: 0.7119512557983398\n",
      "Step: 2616, Loss: 0.9354497194290161, Accuracy: 0.6875, Computation time: 0.8761782646179199\n",
      "Step: 2617, Loss: 0.7858449220657349, Accuracy: 0.75, Computation time: 0.8678948879241943\n",
      "Step: 2618, Loss: 0.40100786089897156, Accuracy: 0.875, Computation time: 0.7724919319152832\n",
      "Step: 2619, Loss: 0.7537854909896851, Accuracy: 0.8125, Computation time: 1.0684008598327637\n",
      "Step: 2620, Loss: 0.7884650826454163, Accuracy: 0.8125, Computation time: 0.8729720115661621\n",
      "Step: 2621, Loss: 0.822026789188385, Accuracy: 0.6875, Computation time: 0.687222957611084\n",
      "Step: 2622, Loss: 1.195589542388916, Accuracy: 0.78125, Computation time: 0.7461471557617188\n",
      "Step: 2623, Loss: 0.719123125076294, Accuracy: 0.78125, Computation time: 0.7622871398925781\n",
      "Step: 2624, Loss: 0.6547120213508606, Accuracy: 0.84375, Computation time: 0.8751790523529053\n",
      "Step: 2625, Loss: 0.8999573588371277, Accuracy: 0.75, Computation time: 0.8159389495849609\n",
      "Step: 2626, Loss: 0.9243149161338806, Accuracy: 0.78125, Computation time: 0.8859467506408691\n",
      "Step: 2627, Loss: 0.28781604766845703, Accuracy: 0.9375, Computation time: 0.777907133102417\n",
      "Step: 2628, Loss: 0.5724858045578003, Accuracy: 0.78125, Computation time: 0.5954980850219727\n",
      "Step: 2629, Loss: 0.4098406732082367, Accuracy: 0.8125, Computation time: 0.6997430324554443\n",
      "Step: 2630, Loss: 0.3793499767780304, Accuracy: 0.875, Computation time: 0.6884200572967529\n",
      "Step: 2631, Loss: 0.801053524017334, Accuracy: 0.75, Computation time: 1.1586811542510986\n",
      "Step: 2632, Loss: 0.32455429434776306, Accuracy: 0.84375, Computation time: 0.6775469779968262\n",
      "Step: 2633, Loss: 0.4193402826786041, Accuracy: 0.90625, Computation time: 0.8549001216888428\n",
      "Step: 2634, Loss: 0.5491281151771545, Accuracy: 0.78125, Computation time: 0.8563439846038818\n",
      "Step: 2635, Loss: 0.8136866688728333, Accuracy: 0.75, Computation time: 0.7722299098968506\n",
      "Step: 2636, Loss: 0.9602119326591492, Accuracy: 0.6875, Computation time: 0.8300480842590332\n",
      "Step: 2637, Loss: 0.773637056350708, Accuracy: 0.78125, Computation time: 0.7836239337921143\n",
      "Step: 2638, Loss: 0.5932278633117676, Accuracy: 0.8125, Computation time: 0.7344748973846436\n",
      "Step: 2639, Loss: 0.5762507915496826, Accuracy: 0.875, Computation time: 0.8067770004272461\n",
      "Step: 2640, Loss: 0.5944281816482544, Accuracy: 0.90625, Computation time: 0.7218058109283447\n",
      "Step: 2641, Loss: 0.6099256277084351, Accuracy: 0.71875, Computation time: 0.9316258430480957\n",
      "Step: 2642, Loss: 0.9750452637672424, Accuracy: 0.71875, Computation time: 0.7813937664031982\n",
      "Step: 2643, Loss: 0.5092777013778687, Accuracy: 0.875, Computation time: 1.4606709480285645\n",
      "Step: 2644, Loss: 0.43649667501449585, Accuracy: 0.8125, Computation time: 0.7684247493743896\n",
      "Step: 2645, Loss: 0.33594635128974915, Accuracy: 0.875, Computation time: 1.001284122467041\n",
      "Step: 2646, Loss: 0.4877360761165619, Accuracy: 0.84375, Computation time: 0.7208690643310547\n",
      "Step: 2647, Loss: 0.512294590473175, Accuracy: 0.78125, Computation time: 0.9133009910583496\n",
      "Step: 2648, Loss: 0.7049037218093872, Accuracy: 0.6875, Computation time: 0.8779289722442627\n",
      "Step: 2649, Loss: 0.49834901094436646, Accuracy: 0.8125, Computation time: 0.7432529926300049\n",
      "Step: 2650, Loss: 0.4351236820220947, Accuracy: 0.84375, Computation time: 0.7286288738250732\n",
      "Step: 2651, Loss: 0.3773137032985687, Accuracy: 0.90625, Computation time: 0.8840732574462891\n",
      "Step: 2652, Loss: 0.5702303051948547, Accuracy: 0.78125, Computation time: 0.8048520088195801\n",
      "Step: 2653, Loss: 0.7695052027702332, Accuracy: 0.75, Computation time: 0.7800939083099365\n",
      "Step: 2654, Loss: 0.9875314235687256, Accuracy: 0.6875, Computation time: 0.9272687435150146\n",
      "Step: 2655, Loss: 0.41099950671195984, Accuracy: 0.9375, Computation time: 0.8930449485778809\n",
      "Step: 2656, Loss: 0.939476490020752, Accuracy: 0.65625, Computation time: 0.7714650630950928\n",
      "Step: 2657, Loss: 1.0416839122772217, Accuracy: 0.65625, Computation time: 0.8626339435577393\n",
      "Step: 2658, Loss: 0.7538453340530396, Accuracy: 0.8125, Computation time: 0.8239002227783203\n",
      "Step: 2659, Loss: 0.662889838218689, Accuracy: 0.84375, Computation time: 0.7643399238586426\n",
      "Step: 2660, Loss: 0.6745021939277649, Accuracy: 0.8125, Computation time: 0.9024500846862793\n",
      "Step: 2661, Loss: 0.5558407306671143, Accuracy: 0.78125, Computation time: 0.7584209442138672\n",
      "Step: 2662, Loss: 0.55023193359375, Accuracy: 0.8125, Computation time: 0.8745391368865967\n",
      "Step: 2663, Loss: 0.7400396466255188, Accuracy: 0.75, Computation time: 0.7471439838409424\n",
      "Step: 2664, Loss: 0.699622631072998, Accuracy: 0.78125, Computation time: 0.9849340915679932\n",
      "Step: 2665, Loss: 0.8012555241584778, Accuracy: 0.8125, Computation time: 0.8317141532897949\n",
      "Step: 2666, Loss: 0.4115217626094818, Accuracy: 0.84375, Computation time: 0.7849531173706055\n",
      "Step: 2667, Loss: 0.36971384286880493, Accuracy: 0.90625, Computation time: 0.8526420593261719\n",
      "Step: 2668, Loss: 0.6721640825271606, Accuracy: 0.75, Computation time: 0.8263599872589111\n",
      "Step: 2669, Loss: 1.019352912902832, Accuracy: 0.75, Computation time: 0.699455976486206\n",
      "Step: 2670, Loss: 0.7170870900154114, Accuracy: 0.90625, Computation time: 1.1522529125213623\n",
      "Step: 2671, Loss: 0.6406121850013733, Accuracy: 0.84375, Computation time: 0.9238920211791992\n",
      "Step: 2672, Loss: 0.5746602416038513, Accuracy: 0.78125, Computation time: 0.735698938369751\n",
      "Step: 2673, Loss: 1.081788420677185, Accuracy: 0.71875, Computation time: 0.7939550876617432\n",
      "Step: 2674, Loss: 0.7385787963867188, Accuracy: 0.78125, Computation time: 0.7524893283843994\n",
      "Step: 2675, Loss: 0.589759349822998, Accuracy: 0.8125, Computation time: 1.1702008247375488\n",
      "Step: 2676, Loss: 0.5168212652206421, Accuracy: 0.84375, Computation time: 1.0152027606964111\n",
      "Step: 2677, Loss: 0.3275904953479767, Accuracy: 0.96875, Computation time: 1.0024919509887695\n",
      "Step: 2678, Loss: 0.9719884991645813, Accuracy: 0.6875, Computation time: 0.7990431785583496\n",
      "Step: 2679, Loss: 0.7027686238288879, Accuracy: 0.84375, Computation time: 0.9655640125274658\n",
      "Step: 2680, Loss: 0.7819435000419617, Accuracy: 0.8125, Computation time: 0.8180530071258545\n",
      "Step: 2681, Loss: 0.7691304683685303, Accuracy: 0.8125, Computation time: 0.9686670303344727\n",
      "Step: 2682, Loss: 0.7619965672492981, Accuracy: 0.8125, Computation time: 0.760155200958252\n",
      "Step: 2683, Loss: 0.3599388897418976, Accuracy: 0.90625, Computation time: 0.8064408302307129\n",
      "Step: 2684, Loss: 0.9816197156906128, Accuracy: 0.6875, Computation time: 0.865898847579956\n",
      "Step: 2685, Loss: 0.8258212804794312, Accuracy: 0.78125, Computation time: 0.8574998378753662\n",
      "Step: 2686, Loss: 0.6977553367614746, Accuracy: 0.78125, Computation time: 0.7306880950927734\n",
      "Step: 2687, Loss: 0.906821072101593, Accuracy: 0.78125, Computation time: 0.8877060413360596\n",
      "Step: 2688, Loss: 0.6883241534233093, Accuracy: 0.75, Computation time: 1.3245658874511719\n",
      "Step: 2689, Loss: 0.3506777286529541, Accuracy: 0.84375, Computation time: 0.7148330211639404\n",
      "Step: 2690, Loss: 0.6450996398925781, Accuracy: 0.8125, Computation time: 0.6190478801727295\n",
      "Step: 2691, Loss: 0.7064363956451416, Accuracy: 0.75, Computation time: 0.774371862411499\n",
      "Step: 2692, Loss: 0.5577143430709839, Accuracy: 0.78125, Computation time: 0.7522070407867432\n",
      "Step: 2693, Loss: 0.5015432238578796, Accuracy: 0.90625, Computation time: 0.7871990203857422\n",
      "Step: 2694, Loss: 0.554314911365509, Accuracy: 0.75, Computation time: 0.6601560115814209\n",
      "Step: 2695, Loss: 0.479605108499527, Accuracy: 0.875, Computation time: 0.8030228614807129\n",
      "Step: 2696, Loss: 0.4941991865634918, Accuracy: 0.84375, Computation time: 0.6690099239349365\n",
      "Step: 2697, Loss: 0.8687621355056763, Accuracy: 0.75, Computation time: 0.8149058818817139\n",
      "Step: 2698, Loss: 0.49891969561576843, Accuracy: 0.78125, Computation time: 0.9138081073760986\n",
      "Step: 2699, Loss: 0.5328544974327087, Accuracy: 0.90625, Computation time: 0.7316060066223145\n",
      "Step: 2700, Loss: 0.37656131386756897, Accuracy: 0.90625, Computation time: 0.7627968788146973\n",
      "Step: 2701, Loss: 0.5621767044067383, Accuracy: 0.875, Computation time: 1.0144381523132324\n",
      "Step: 2702, Loss: 0.4018179774284363, Accuracy: 0.875, Computation time: 0.8674178123474121\n",
      "Step: 2703, Loss: 0.6269755363464355, Accuracy: 0.75, Computation time: 0.8260247707366943\n",
      "Step: 2704, Loss: 0.5674234628677368, Accuracy: 0.8125, Computation time: 0.7693729400634766\n",
      "Step: 2705, Loss: 1.0551458597183228, Accuracy: 0.6875, Computation time: 0.7796211242675781\n",
      "Step: 2706, Loss: 0.579206645488739, Accuracy: 0.8125, Computation time: 0.7667479515075684\n",
      "Step: 2707, Loss: 0.5985291004180908, Accuracy: 0.84375, Computation time: 0.7684900760650635\n",
      "Step: 2708, Loss: 0.6287664175033569, Accuracy: 0.75, Computation time: 0.7400686740875244\n",
      "Step: 2709, Loss: 0.7164431810379028, Accuracy: 0.78125, Computation time: 0.9615111351013184\n",
      "Step: 2710, Loss: 0.7241646647453308, Accuracy: 0.75, Computation time: 0.6960809230804443\n",
      "Step: 2711, Loss: 0.4739554524421692, Accuracy: 0.90625, Computation time: 0.769697904586792\n",
      "Step: 2712, Loss: 0.3292759358882904, Accuracy: 0.90625, Computation time: 0.6688780784606934\n",
      "Step: 2713, Loss: 0.5762472748756409, Accuracy: 0.8125, Computation time: 0.8129370212554932\n",
      "Step: 2714, Loss: 0.2332967072725296, Accuracy: 0.90625, Computation time: 0.7734720706939697\n",
      "Step: 2715, Loss: 0.4952937364578247, Accuracy: 0.78125, Computation time: 0.918266773223877\n",
      "Step: 2716, Loss: 0.586533784866333, Accuracy: 0.84375, Computation time: 0.7820479869842529\n",
      "Step: 2717, Loss: 0.9456544518470764, Accuracy: 0.78125, Computation time: 0.7277231216430664\n",
      "Step: 2718, Loss: 0.609002411365509, Accuracy: 0.75, Computation time: 0.8117899894714355\n",
      "Step: 2719, Loss: 0.3227728307247162, Accuracy: 0.96875, Computation time: 0.9690089225769043\n",
      "Step: 2720, Loss: 0.48293715715408325, Accuracy: 0.8125, Computation time: 0.854931116104126\n",
      "Step: 2721, Loss: 0.9175832271575928, Accuracy: 0.71875, Computation time: 1.3364920616149902\n",
      "Step: 2722, Loss: 0.5291296243667603, Accuracy: 0.8125, Computation time: 0.8040950298309326\n",
      "Step: 2723, Loss: 0.9271335601806641, Accuracy: 0.71875, Computation time: 0.6897962093353271\n",
      "Step: 2724, Loss: 0.9503881931304932, Accuracy: 0.84375, Computation time: 0.6282858848571777\n",
      "Step: 2725, Loss: 1.008246898651123, Accuracy: 0.71875, Computation time: 0.8707420825958252\n",
      "Step: 2726, Loss: 0.43827366828918457, Accuracy: 0.875, Computation time: 1.6051692962646484\n",
      "Step: 2727, Loss: 0.8610958456993103, Accuracy: 0.75, Computation time: 0.9115369319915771\n",
      "Step: 2728, Loss: 0.19102753698825836, Accuracy: 0.96875, Computation time: 0.7631528377532959\n",
      "Step: 2729, Loss: 0.6374555826187134, Accuracy: 0.84375, Computation time: 0.8503129482269287\n",
      "Step: 2730, Loss: 0.5286635756492615, Accuracy: 0.9375, Computation time: 0.7769951820373535\n",
      "Step: 2731, Loss: 0.7575451135635376, Accuracy: 0.8125, Computation time: 0.7600080966949463\n",
      "Step: 2732, Loss: 0.508233368396759, Accuracy: 0.84375, Computation time: 0.743715763092041\n",
      "Step: 2733, Loss: 0.43177148699760437, Accuracy: 0.90625, Computation time: 0.9998757839202881\n",
      "Step: 2734, Loss: 0.6037461757659912, Accuracy: 0.84375, Computation time: 0.8407998085021973\n",
      "Step: 2735, Loss: 0.4636235237121582, Accuracy: 0.875, Computation time: 1.020880937576294\n",
      "Step: 2736, Loss: 0.8690901398658752, Accuracy: 0.71875, Computation time: 0.7171008586883545\n",
      "Step: 2737, Loss: 0.6565649509429932, Accuracy: 0.8125, Computation time: 1.014289140701294\n",
      "Step: 2738, Loss: 0.628179669380188, Accuracy: 0.84375, Computation time: 0.7914371490478516\n",
      "Step: 2739, Loss: 0.6451957821846008, Accuracy: 0.84375, Computation time: 1.002638816833496\n",
      "Step: 2740, Loss: 0.8108861446380615, Accuracy: 0.78125, Computation time: 0.7692558765411377\n",
      "Step: 2741, Loss: 0.46228501200675964, Accuracy: 0.875, Computation time: 0.6991088390350342\n",
      "Step: 2742, Loss: 0.4510619044303894, Accuracy: 0.8125, Computation time: 0.6950829029083252\n",
      "Step: 2743, Loss: 1.050061583518982, Accuracy: 0.75, Computation time: 0.7115521430969238\n",
      "Step: 2744, Loss: 0.805932343006134, Accuracy: 0.6875, Computation time: 0.8300199508666992\n",
      "Step: 2745, Loss: 0.7448644042015076, Accuracy: 0.84375, Computation time: 0.7943699359893799\n",
      "Step: 2746, Loss: 0.3702249825000763, Accuracy: 0.90625, Computation time: 1.0058062076568604\n",
      "Step: 2747, Loss: 0.5350165367126465, Accuracy: 0.875, Computation time: 0.8924648761749268\n",
      "Step: 2748, Loss: 0.5743292570114136, Accuracy: 0.84375, Computation time: 0.8632500171661377\n",
      "Step: 2749, Loss: 0.7491092085838318, Accuracy: 0.8125, Computation time: 0.7951178550720215\n",
      "Step: 2750, Loss: 1.1031692028045654, Accuracy: 0.6875, Computation time: 0.8883869647979736\n",
      "Step: 2751, Loss: 0.7141715884208679, Accuracy: 0.875, Computation time: 0.7729930877685547\n",
      "Step: 2752, Loss: 0.7209886908531189, Accuracy: 0.75, Computation time: 0.8474640846252441\n",
      "Step: 2753, Loss: 0.5524678230285645, Accuracy: 0.8125, Computation time: 1.3857789039611816\n",
      "Step: 2754, Loss: 0.7990268468856812, Accuracy: 0.75, Computation time: 0.8850009441375732\n",
      "Step: 2755, Loss: 0.9328029751777649, Accuracy: 0.65625, Computation time: 0.9829492568969727\n",
      "Step: 2756, Loss: 0.46861767768859863, Accuracy: 0.9375, Computation time: 0.8864278793334961\n",
      "Step: 2757, Loss: 0.5038700103759766, Accuracy: 0.84375, Computation time: 0.897864818572998\n",
      "Step: 2758, Loss: 0.4108671545982361, Accuracy: 0.875, Computation time: 0.8912539482116699\n",
      "Step: 2759, Loss: 0.5315427184104919, Accuracy: 0.8125, Computation time: 0.9205458164215088\n",
      "Step: 2760, Loss: 0.37222111225128174, Accuracy: 0.84375, Computation time: 0.8090550899505615\n",
      "Step: 2761, Loss: 0.6534152030944824, Accuracy: 0.8125, Computation time: 0.8027000427246094\n",
      "Step: 2762, Loss: 1.0341237783432007, Accuracy: 0.71875, Computation time: 0.7420611381530762\n",
      "Step: 2763, Loss: 0.4683170020580292, Accuracy: 0.8125, Computation time: 0.716667890548706\n",
      "Step: 2764, Loss: 0.8041909337043762, Accuracy: 0.75, Computation time: 0.8760781288146973\n",
      "Step: 2765, Loss: 0.797193169593811, Accuracy: 0.71875, Computation time: 0.957179069519043\n",
      "Step: 2766, Loss: 0.24476122856140137, Accuracy: 0.90625, Computation time: 0.7145159244537354\n",
      "Step: 2767, Loss: 0.8721078634262085, Accuracy: 0.71875, Computation time: 0.8087217807769775\n",
      "Step: 2768, Loss: 0.6129691004753113, Accuracy: 0.84375, Computation time: 0.8436579704284668\n",
      "Step: 2769, Loss: 0.8138208389282227, Accuracy: 0.8125, Computation time: 0.882145881652832\n",
      "Step: 2770, Loss: 0.3923385441303253, Accuracy: 0.9375, Computation time: 0.8431789875030518\n",
      "Step: 2771, Loss: 0.7304929494857788, Accuracy: 0.84375, Computation time: 0.9396240711212158\n",
      "Step: 2772, Loss: 0.6012521386146545, Accuracy: 0.78125, Computation time: 0.908750057220459\n",
      "Step: 2773, Loss: 1.0947998762130737, Accuracy: 0.6875, Computation time: 0.8318130970001221\n",
      "Step: 2774, Loss: 0.4647809565067291, Accuracy: 0.875, Computation time: 0.8159611225128174\n",
      "Step: 2775, Loss: 0.787717878818512, Accuracy: 0.78125, Computation time: 0.8297719955444336\n",
      "Step: 2776, Loss: 0.9679209589958191, Accuracy: 0.75, Computation time: 0.9106380939483643\n",
      "Step: 2777, Loss: 0.7265509366989136, Accuracy: 0.8125, Computation time: 0.9096181392669678\n",
      "Step: 2778, Loss: 0.3315638601779938, Accuracy: 0.9375, Computation time: 0.7504138946533203\n",
      "Step: 2779, Loss: 0.716508150100708, Accuracy: 0.78125, Computation time: 0.7863991260528564\n",
      "Step: 2780, Loss: 0.436064213514328, Accuracy: 0.84375, Computation time: 0.9969229698181152\n",
      "Step: 2781, Loss: 0.6032024025917053, Accuracy: 0.875, Computation time: 0.6508610248565674\n",
      "Step: 2782, Loss: 0.6135520339012146, Accuracy: 0.75, Computation time: 1.0089139938354492\n",
      "Step: 2783, Loss: 0.6483398675918579, Accuracy: 0.875, Computation time: 2.0631279945373535\n",
      "Step: 2784, Loss: 0.9468789100646973, Accuracy: 0.84375, Computation time: 0.8299140930175781\n",
      "Step: 2785, Loss: 1.004650354385376, Accuracy: 0.6875, Computation time: 0.8314762115478516\n",
      "Step: 2786, Loss: 0.48042771220207214, Accuracy: 0.875, Computation time: 0.7257499694824219\n",
      "Step: 2787, Loss: 0.4730336666107178, Accuracy: 0.875, Computation time: 0.8126559257507324\n",
      "Step: 2788, Loss: 0.43350040912628174, Accuracy: 0.84375, Computation time: 0.8920540809631348\n",
      "Step: 2789, Loss: 0.695712149143219, Accuracy: 0.84375, Computation time: 0.9492390155792236\n",
      "Step: 2790, Loss: 0.7805825471878052, Accuracy: 0.75, Computation time: 0.750601053237915\n",
      "Step: 2791, Loss: 0.5227286219596863, Accuracy: 0.78125, Computation time: 0.659977912902832\n",
      "Step: 2792, Loss: 0.7360895872116089, Accuracy: 0.78125, Computation time: 0.5745999813079834\n",
      "Step: 2793, Loss: 0.5879762172698975, Accuracy: 0.78125, Computation time: 0.7261240482330322\n",
      "Step: 2794, Loss: 0.47842463850975037, Accuracy: 0.875, Computation time: 0.8528010845184326\n",
      "Step: 2795, Loss: 0.4697744846343994, Accuracy: 0.90625, Computation time: 0.7522032260894775\n",
      "Step: 2796, Loss: 0.7217393517494202, Accuracy: 0.75, Computation time: 0.8444488048553467\n",
      "Step: 2797, Loss: 0.8083162903785706, Accuracy: 0.71875, Computation time: 0.7049989700317383\n",
      "Step: 2798, Loss: 0.8765464425086975, Accuracy: 0.71875, Computation time: 0.7949388027191162\n",
      "Step: 2799, Loss: 0.5751651525497437, Accuracy: 0.84375, Computation time: 0.7906839847564697\n",
      "Step: 2800, Loss: 0.4575154185295105, Accuracy: 0.875, Computation time: 0.7108469009399414\n",
      "Step: 2801, Loss: 0.47172340750694275, Accuracy: 0.90625, Computation time: 0.7570750713348389\n",
      "Step: 2802, Loss: 0.40050145983695984, Accuracy: 0.84375, Computation time: 0.8641810417175293\n",
      "Step: 2803, Loss: 0.9256969690322876, Accuracy: 0.6875, Computation time: 0.842322826385498\n",
      "Step: 2804, Loss: 0.40755122900009155, Accuracy: 0.84375, Computation time: 0.8740279674530029\n",
      "Step: 2805, Loss: 0.246218740940094, Accuracy: 0.9375, Computation time: 0.8920807838439941\n",
      "Step: 2806, Loss: 0.510776162147522, Accuracy: 0.84375, Computation time: 0.7617032527923584\n",
      "Step: 2807, Loss: 0.5935073494911194, Accuracy: 0.78125, Computation time: 0.7371261119842529\n",
      "Step: 2808, Loss: 0.7786655426025391, Accuracy: 0.84375, Computation time: 0.7432200908660889\n",
      "Step: 2809, Loss: 1.0925817489624023, Accuracy: 0.6875, Computation time: 0.8752989768981934\n",
      "Step: 2810, Loss: 0.30446067452430725, Accuracy: 0.9375, Computation time: 0.7749190330505371\n",
      "Step: 2811, Loss: 0.7119894623756409, Accuracy: 0.8125, Computation time: 0.9716808795928955\n",
      "Step: 2812, Loss: 0.8610463738441467, Accuracy: 0.8125, Computation time: 0.6636500358581543\n",
      "Step: 2813, Loss: 0.6422085165977478, Accuracy: 0.8125, Computation time: 1.0515623092651367\n",
      "Step: 2814, Loss: 0.7686519622802734, Accuracy: 0.71875, Computation time: 0.8594691753387451\n",
      "Step: 2815, Loss: 0.674360990524292, Accuracy: 0.8125, Computation time: 0.8268208503723145\n",
      "Step: 2816, Loss: 0.7210617065429688, Accuracy: 0.8125, Computation time: 1.2856969833374023\n",
      "Step: 2817, Loss: 0.52904212474823, Accuracy: 0.875, Computation time: 0.8805909156799316\n",
      "Step: 2818, Loss: 0.3020017147064209, Accuracy: 0.96875, Computation time: 0.8055579662322998\n",
      "Step: 2819, Loss: 0.4745112657546997, Accuracy: 0.84375, Computation time: 0.9523062705993652\n",
      "Step: 2820, Loss: 0.6642487645149231, Accuracy: 0.78125, Computation time: 0.7495400905609131\n",
      "Step: 2821, Loss: 0.5043646097183228, Accuracy: 0.8125, Computation time: 0.8264768123626709\n",
      "Step: 2822, Loss: 0.6009840369224548, Accuracy: 0.75, Computation time: 0.6958169937133789\n",
      "Step: 2823, Loss: 0.8635513782501221, Accuracy: 0.65625, Computation time: 0.7788999080657959\n",
      "Step: 2824, Loss: 0.6154094338417053, Accuracy: 0.75, Computation time: 1.1924140453338623\n",
      "Step: 2825, Loss: 0.830720067024231, Accuracy: 0.78125, Computation time: 0.8719360828399658\n",
      "Step: 2826, Loss: 0.97502601146698, Accuracy: 0.75, Computation time: 0.8583102226257324\n",
      "Step: 2827, Loss: 0.3640576899051666, Accuracy: 0.875, Computation time: 0.811744213104248\n",
      "Step: 2828, Loss: 0.8236978054046631, Accuracy: 0.71875, Computation time: 0.812903881072998\n",
      "Step: 2829, Loss: 0.5377100706100464, Accuracy: 0.8125, Computation time: 0.6992638111114502\n",
      "Step: 2830, Loss: 0.7828431129455566, Accuracy: 0.71875, Computation time: 0.8834068775177002\n",
      "Step: 2831, Loss: 0.7246520519256592, Accuracy: 0.75, Computation time: 0.9821608066558838\n",
      "Step: 2832, Loss: 0.4133603274822235, Accuracy: 0.84375, Computation time: 1.0071918964385986\n",
      "Step: 2833, Loss: 0.67490553855896, Accuracy: 0.8125, Computation time: 0.9848270416259766\n",
      "Step: 2834, Loss: 0.7978863716125488, Accuracy: 0.8125, Computation time: 0.8445570468902588\n",
      "Step: 2835, Loss: 0.6874587535858154, Accuracy: 0.75, Computation time: 0.9725651741027832\n",
      "Step: 2836, Loss: 0.5210912227630615, Accuracy: 0.8125, Computation time: 0.8931670188903809\n",
      "Step: 2837, Loss: 0.8768267631530762, Accuracy: 0.75, Computation time: 1.0987000465393066\n",
      "Step: 2838, Loss: 0.4546181559562683, Accuracy: 0.875, Computation time: 0.7526819705963135\n",
      "Step: 2839, Loss: 0.687762439250946, Accuracy: 0.78125, Computation time: 0.8436992168426514\n",
      "Step: 2840, Loss: 0.5723996758460999, Accuracy: 0.8125, Computation time: 0.8836469650268555\n",
      "Step: 2841, Loss: 0.8119704723358154, Accuracy: 0.8125, Computation time: 0.7462480068206787\n",
      "Step: 2842, Loss: 0.91340571641922, Accuracy: 0.59375, Computation time: 0.7755262851715088\n",
      "Step: 2843, Loss: 0.5263543128967285, Accuracy: 0.84375, Computation time: 0.8023171424865723\n",
      "Step: 2844, Loss: 0.21312302350997925, Accuracy: 0.96875, Computation time: 0.8385248184204102\n",
      "Step: 2845, Loss: 0.42840009927749634, Accuracy: 0.9375, Computation time: 0.7131307125091553\n",
      "Step: 2846, Loss: 0.4303918480873108, Accuracy: 0.875, Computation time: 0.734199047088623\n",
      "Step: 2847, Loss: 0.8901872038841248, Accuracy: 0.75, Computation time: 1.1963019371032715\n",
      "Step: 2848, Loss: 0.33234867453575134, Accuracy: 0.90625, Computation time: 0.7918851375579834\n",
      "Step: 2849, Loss: 0.6034711003303528, Accuracy: 0.84375, Computation time: 1.1055307388305664\n",
      "Step: 2850, Loss: 0.4310299754142761, Accuracy: 0.84375, Computation time: 0.664863109588623\n",
      "Step: 2851, Loss: 0.7021502256393433, Accuracy: 0.75, Computation time: 0.6754231452941895\n",
      "Step: 2852, Loss: 0.5574883818626404, Accuracy: 0.875, Computation time: 0.7315201759338379\n",
      "Step: 2853, Loss: 0.5135895013809204, Accuracy: 0.8125, Computation time: 0.9033079147338867\n",
      "Step: 2854, Loss: 0.6558361053466797, Accuracy: 0.78125, Computation time: 0.8177611827850342\n",
      "Step: 2855, Loss: 0.61723792552948, Accuracy: 0.78125, Computation time: 0.753145694732666\n",
      "Step: 2856, Loss: 0.4080394208431244, Accuracy: 0.90625, Computation time: 0.8261029720306396\n",
      "Step: 2857, Loss: 0.8435559272766113, Accuracy: 0.75, Computation time: 0.7495279312133789\n",
      "Step: 2858, Loss: 0.8079811930656433, Accuracy: 0.65625, Computation time: 0.6956131458282471\n",
      "Step: 2859, Loss: 0.5518423318862915, Accuracy: 0.84375, Computation time: 0.8886990547180176\n",
      "Step: 2860, Loss: 0.3693412244319916, Accuracy: 0.875, Computation time: 0.7465789318084717\n",
      "Step: 2861, Loss: 0.8462514281272888, Accuracy: 0.75, Computation time: 0.7712650299072266\n",
      "Step: 2862, Loss: 0.503063440322876, Accuracy: 0.84375, Computation time: 1.2303431034088135\n",
      "Step: 2863, Loss: 0.5627847909927368, Accuracy: 0.8125, Computation time: 0.806952953338623\n",
      "Step: 2864, Loss: 0.29325151443481445, Accuracy: 0.875, Computation time: 0.8587131500244141\n",
      "Step: 2865, Loss: 0.7624486684799194, Accuracy: 0.71875, Computation time: 0.9660608768463135\n",
      "Step: 2866, Loss: 0.5629798769950867, Accuracy: 0.8125, Computation time: 0.924597978591919\n",
      "Step: 2867, Loss: 0.5449907183647156, Accuracy: 0.75, Computation time: 0.8019042015075684\n",
      "Step: 2868, Loss: 0.6787717342376709, Accuracy: 0.78125, Computation time: 0.6824488639831543\n",
      "Step: 2869, Loss: 0.7222602367401123, Accuracy: 0.84375, Computation time: 0.8039917945861816\n",
      "Step: 2870, Loss: 0.47611477971076965, Accuracy: 0.78125, Computation time: 0.7135388851165771\n",
      "Step: 2871, Loss: 0.6080453395843506, Accuracy: 0.84375, Computation time: 0.9363138675689697\n",
      "Step: 2872, Loss: 0.45895636081695557, Accuracy: 0.875, Computation time: 0.7580769062042236\n",
      "Step: 2873, Loss: 0.6892681121826172, Accuracy: 0.75, Computation time: 0.7954020500183105\n",
      "Step: 2874, Loss: 1.0119738578796387, Accuracy: 0.78125, Computation time: 0.8105709552764893\n",
      "Step: 2875, Loss: 0.5031464695930481, Accuracy: 0.875, Computation time: 0.7008721828460693\n",
      "Step: 2876, Loss: 0.8786996006965637, Accuracy: 0.78125, Computation time: 0.791053056716919\n",
      "Step: 2877, Loss: 0.5146083831787109, Accuracy: 0.84375, Computation time: 0.7292301654815674\n",
      "Step: 2878, Loss: 0.4918602406978607, Accuracy: 0.84375, Computation time: 0.7737789154052734\n",
      "Step: 2879, Loss: 0.7586069107055664, Accuracy: 0.78125, Computation time: 0.8519678115844727\n",
      "Step: 2880, Loss: 0.8175393342971802, Accuracy: 0.84375, Computation time: 1.644258975982666\n",
      "Step: 2881, Loss: 0.3557496964931488, Accuracy: 0.875, Computation time: 0.9495522975921631\n",
      "Step: 2882, Loss: 1.0166736841201782, Accuracy: 0.78125, Computation time: 0.7200722694396973\n",
      "Step: 2883, Loss: 0.8777555227279663, Accuracy: 0.78125, Computation time: 0.8218598365783691\n",
      "Step: 2884, Loss: 0.3372962176799774, Accuracy: 0.875, Computation time: 0.7438218593597412\n",
      "Step: 2885, Loss: 0.546425461769104, Accuracy: 0.84375, Computation time: 0.8445870876312256\n",
      "Step: 2886, Loss: 0.3675595223903656, Accuracy: 0.90625, Computation time: 0.71864914894104\n",
      "Step: 2887, Loss: 0.7802711129188538, Accuracy: 0.875, Computation time: 0.9234440326690674\n",
      "Step: 2888, Loss: 0.5515087246894836, Accuracy: 0.8125, Computation time: 0.7081329822540283\n",
      "Step: 2889, Loss: 0.8437116146087646, Accuracy: 0.6875, Computation time: 0.8585748672485352\n",
      "Step: 2890, Loss: 0.44709312915802, Accuracy: 0.90625, Computation time: 0.8840909004211426\n",
      "Step: 2891, Loss: 0.6475791931152344, Accuracy: 0.84375, Computation time: 0.8206307888031006\n",
      "Step: 2892, Loss: 0.6703949570655823, Accuracy: 0.71875, Computation time: 0.7775802612304688\n",
      "Step: 2893, Loss: 0.6460646390914917, Accuracy: 0.8125, Computation time: 0.7088751792907715\n",
      "Step: 2894, Loss: 0.5543390512466431, Accuracy: 0.84375, Computation time: 0.9023370742797852\n",
      "Step: 2895, Loss: 0.4535409212112427, Accuracy: 0.8125, Computation time: 0.7705731391906738\n",
      "Step: 2896, Loss: 0.3457985818386078, Accuracy: 0.90625, Computation time: 0.6382310390472412\n",
      "Step: 2897, Loss: 0.6172384023666382, Accuracy: 0.75, Computation time: 0.7872841358184814\n",
      "Step: 2898, Loss: 1.2559075355529785, Accuracy: 0.59375, Computation time: 0.9174900054931641\n",
      "Step: 2899, Loss: 0.4166792631149292, Accuracy: 0.90625, Computation time: 0.925469160079956\n",
      "Step: 2900, Loss: 0.32387080788612366, Accuracy: 0.90625, Computation time: 0.8556180000305176\n",
      "Step: 2901, Loss: 0.46478724479675293, Accuracy: 0.8125, Computation time: 0.7115342617034912\n",
      "Step: 2902, Loss: 0.621065616607666, Accuracy: 0.8125, Computation time: 0.9268200397491455\n",
      "Step: 2903, Loss: 0.6292436718940735, Accuracy: 0.84375, Computation time: 1.0061593055725098\n",
      "Step: 2904, Loss: 0.6096218824386597, Accuracy: 0.84375, Computation time: 0.8847761154174805\n",
      "Step: 2905, Loss: 0.2915061116218567, Accuracy: 0.84375, Computation time: 0.868628978729248\n",
      "Step: 2906, Loss: 0.7895147800445557, Accuracy: 0.75, Computation time: 0.9106109142303467\n",
      "Step: 2907, Loss: 0.8495776653289795, Accuracy: 0.71875, Computation time: 0.7150123119354248\n",
      "Step: 2908, Loss: 0.5711851716041565, Accuracy: 0.8125, Computation time: 0.7297248840332031\n",
      "Step: 2909, Loss: 0.9257446527481079, Accuracy: 0.78125, Computation time: 0.7578222751617432\n",
      "Step: 2910, Loss: 0.9660820960998535, Accuracy: 0.75, Computation time: 0.7173550128936768\n",
      "Step: 2911, Loss: 0.6169682741165161, Accuracy: 0.90625, Computation time: 0.8468999862670898\n",
      "Step: 2912, Loss: 0.7599934935569763, Accuracy: 0.78125, Computation time: 1.080840826034546\n",
      "Step: 2913, Loss: 0.82073974609375, Accuracy: 0.75, Computation time: 0.8087859153747559\n",
      "Step: 2914, Loss: 0.6091400980949402, Accuracy: 0.8125, Computation time: 0.9832360744476318\n",
      "Step: 2915, Loss: 0.9384676218032837, Accuracy: 0.71875, Computation time: 0.850538969039917\n",
      "Step: 2916, Loss: 0.3429218828678131, Accuracy: 0.875, Computation time: 0.8721227645874023\n",
      "Step: 2917, Loss: 0.682248055934906, Accuracy: 0.84375, Computation time: 0.9606149196624756\n",
      "Step: 2918, Loss: 0.37406298518180847, Accuracy: 0.90625, Computation time: 0.9665548801422119\n",
      "Step: 2919, Loss: 0.6703392863273621, Accuracy: 0.8125, Computation time: 0.7839899063110352\n",
      "Step: 2920, Loss: 0.6670985817909241, Accuracy: 0.75, Computation time: 0.9006469249725342\n",
      "Step: 2921, Loss: 0.48684266209602356, Accuracy: 0.8125, Computation time: 0.8363258838653564\n",
      "Step: 2922, Loss: 0.3285587430000305, Accuracy: 0.9375, Computation time: 1.0887088775634766\n",
      "Step: 2923, Loss: 0.5325613021850586, Accuracy: 0.84375, Computation time: 0.8521468639373779\n",
      "Step: 2924, Loss: 0.36598074436187744, Accuracy: 0.875, Computation time: 0.9165589809417725\n",
      "Step: 2925, Loss: 0.30225861072540283, Accuracy: 0.90625, Computation time: 0.8656890392303467\n",
      "Step: 2926, Loss: 0.5104933977127075, Accuracy: 0.875, Computation time: 1.243149995803833\n",
      "Step: 2927, Loss: 0.4973872900009155, Accuracy: 0.875, Computation time: 0.9621901512145996\n",
      "Step: 2928, Loss: 0.1358848661184311, Accuracy: 1.0, Computation time: 0.8008933067321777\n",
      "Step: 2929, Loss: 1.351533055305481, Accuracy: 0.78125, Computation time: 1.0193438529968262\n",
      "Step: 2930, Loss: 0.5308933854103088, Accuracy: 0.84375, Computation time: 0.9717879295349121\n",
      "Step: 2931, Loss: 0.6748412847518921, Accuracy: 0.78125, Computation time: 0.9529788494110107\n",
      "Step: 2932, Loss: 0.9092112183570862, Accuracy: 0.75, Computation time: 0.9029941558837891\n",
      "Step: 2933, Loss: 0.8654048442840576, Accuracy: 0.75, Computation time: 2.2187108993530273\n",
      "Step: 2934, Loss: 0.6671936511993408, Accuracy: 0.84375, Computation time: 0.7468461990356445\n",
      "Step: 2935, Loss: 0.5625989437103271, Accuracy: 0.90625, Computation time: 0.9452300071716309\n",
      "Step: 2936, Loss: 1.1986963748931885, Accuracy: 0.625, Computation time: 0.8142240047454834\n",
      "Step: 2937, Loss: 0.5087815523147583, Accuracy: 0.90625, Computation time: 0.9234318733215332\n",
      "Step: 2938, Loss: 0.9734209775924683, Accuracy: 0.75, Computation time: 0.8072559833526611\n",
      "Step: 2939, Loss: 0.7977061867713928, Accuracy: 0.78125, Computation time: 0.6886851787567139\n",
      "Step: 2940, Loss: 1.1049033403396606, Accuracy: 0.71875, Computation time: 1.5824761390686035\n",
      "Step: 2941, Loss: 0.6673320531845093, Accuracy: 0.84375, Computation time: 0.8045639991760254\n",
      "Step: 2942, Loss: 0.6065465211868286, Accuracy: 0.8125, Computation time: 0.8282439708709717\n",
      "Step: 2943, Loss: 0.43238314986228943, Accuracy: 0.875, Computation time: 0.7878658771514893\n",
      "Step: 2944, Loss: 0.7108184695243835, Accuracy: 0.8125, Computation time: 0.8680658340454102\n",
      "Step: 2945, Loss: 0.42236825823783875, Accuracy: 0.84375, Computation time: 0.7996149063110352\n",
      "Step: 2946, Loss: 0.5938940644264221, Accuracy: 0.875, Computation time: 0.8892002105712891\n",
      "Step: 2947, Loss: 1.2205322980880737, Accuracy: 0.75, Computation time: 0.7482020854949951\n",
      "Step: 2948, Loss: 0.699331521987915, Accuracy: 0.84375, Computation time: 0.8964400291442871\n",
      "Step: 2949, Loss: 0.45411837100982666, Accuracy: 0.875, Computation time: 0.8239049911499023\n",
      "Step: 2950, Loss: 0.5797074437141418, Accuracy: 0.8125, Computation time: 0.8312356472015381\n",
      "Step: 2951, Loss: 0.3070741593837738, Accuracy: 0.9375, Computation time: 0.6941981315612793\n",
      "Step: 2952, Loss: 0.4501463770866394, Accuracy: 0.90625, Computation time: 0.8996410369873047\n",
      "Step: 2953, Loss: 0.5369576215744019, Accuracy: 0.875, Computation time: 0.9133422374725342\n",
      "Step: 2954, Loss: 0.52568519115448, Accuracy: 0.84375, Computation time: 0.6947507858276367\n",
      "Step: 2955, Loss: 0.27343636751174927, Accuracy: 0.90625, Computation time: 1.025038242340088\n",
      "Step: 2956, Loss: 0.5767965316772461, Accuracy: 0.75, Computation time: 0.854733943939209\n",
      "Step: 2957, Loss: 0.5865603685379028, Accuracy: 0.78125, Computation time: 0.7979609966278076\n",
      "Step: 2958, Loss: 0.38403555750846863, Accuracy: 0.875, Computation time: 0.7577028274536133\n",
      "Step: 2959, Loss: 0.38094645738601685, Accuracy: 0.90625, Computation time: 0.7253837585449219\n",
      "Step: 2960, Loss: 0.41336292028427124, Accuracy: 0.875, Computation time: 0.7206659317016602\n",
      "Step: 2961, Loss: 0.4525940716266632, Accuracy: 0.9375, Computation time: 0.8026649951934814\n",
      "Step: 2962, Loss: 0.4730006754398346, Accuracy: 0.78125, Computation time: 0.7768902778625488\n",
      "Step: 2963, Loss: 0.26059967279434204, Accuracy: 0.9375, Computation time: 0.8665287494659424\n",
      "Step: 2964, Loss: 0.4047280550003052, Accuracy: 0.84375, Computation time: 0.8164527416229248\n",
      "Step: 2965, Loss: 0.8919488191604614, Accuracy: 0.8125, Computation time: 0.7974510192871094\n",
      "Step: 2966, Loss: 0.6617719531059265, Accuracy: 0.8125, Computation time: 0.7274489402770996\n",
      "Step: 2967, Loss: 0.553946316242218, Accuracy: 0.875, Computation time: 0.8510289192199707\n",
      "Step: 2968, Loss: 0.3592837452888489, Accuracy: 0.875, Computation time: 0.9568600654602051\n",
      "Step: 2969, Loss: 0.7302649021148682, Accuracy: 0.78125, Computation time: 0.9252490997314453\n",
      "Step: 2970, Loss: 0.8377857208251953, Accuracy: 0.8125, Computation time: 0.6907589435577393\n",
      "Step: 2971, Loss: 0.26801350712776184, Accuracy: 0.9375, Computation time: 0.8118317127227783\n",
      "Step: 2972, Loss: 0.5070561766624451, Accuracy: 0.84375, Computation time: 0.8582439422607422\n",
      "Step: 2973, Loss: 0.7867981195449829, Accuracy: 0.75, Computation time: 1.2727749347686768\n",
      "Step: 2974, Loss: 0.5931553244590759, Accuracy: 0.8125, Computation time: 0.8405299186706543\n",
      "Step: 2975, Loss: 0.6628416776657104, Accuracy: 0.8125, Computation time: 0.7554149627685547\n",
      "Step: 2976, Loss: 0.3302418887615204, Accuracy: 0.90625, Computation time: 0.6934258937835693\n",
      "Step: 2977, Loss: 0.9077463150024414, Accuracy: 0.75, Computation time: 0.8316531181335449\n",
      "Step: 2978, Loss: 0.3142984211444855, Accuracy: 0.90625, Computation time: 0.7682490348815918\n",
      "Step: 2979, Loss: 0.5794061422348022, Accuracy: 0.84375, Computation time: 1.002619981765747\n",
      "Step: 2980, Loss: 0.40848901867866516, Accuracy: 0.9375, Computation time: 0.7312939167022705\n",
      "Step: 2981, Loss: 0.4305771291255951, Accuracy: 0.90625, Computation time: 0.8791670799255371\n",
      "Step: 2982, Loss: 0.3218725621700287, Accuracy: 0.9375, Computation time: 0.8515157699584961\n",
      "Step: 2983, Loss: 0.6813350915908813, Accuracy: 0.78125, Computation time: 1.0090429782867432\n",
      "Step: 2984, Loss: 0.7197981476783752, Accuracy: 0.78125, Computation time: 0.8427281379699707\n",
      "Step: 2985, Loss: 0.6990064382553101, Accuracy: 0.8125, Computation time: 0.9206407070159912\n",
      "Step: 2986, Loss: 0.4673342704772949, Accuracy: 0.84375, Computation time: 0.7255308628082275\n",
      "Step: 2987, Loss: 0.6191160678863525, Accuracy: 0.90625, Computation time: 0.7009809017181396\n",
      "Step: 2988, Loss: 0.4866626560688019, Accuracy: 0.84375, Computation time: 0.9877309799194336\n",
      "Step: 2989, Loss: 0.6439694166183472, Accuracy: 0.75, Computation time: 0.8384768962860107\n",
      "Step: 2990, Loss: 0.6271877884864807, Accuracy: 0.90625, Computation time: 0.7667911052703857\n",
      "Step: 2991, Loss: 0.6305088996887207, Accuracy: 0.8125, Computation time: 0.9092390537261963\n",
      "Step: 2992, Loss: 0.5543113350868225, Accuracy: 0.875, Computation time: 0.81632399559021\n",
      "Step: 2993, Loss: 0.5080575346946716, Accuracy: 0.84375, Computation time: 0.8477230072021484\n",
      "Step: 2994, Loss: 0.3323189616203308, Accuracy: 0.9375, Computation time: 0.8242039680480957\n",
      "Step: 2995, Loss: 0.5603331923484802, Accuracy: 0.78125, Computation time: 0.7067649364471436\n",
      "Step: 2996, Loss: 0.19764050841331482, Accuracy: 0.96875, Computation time: 0.7991230487823486\n",
      "Step: 2997, Loss: 0.4988625943660736, Accuracy: 0.875, Computation time: 0.8398470878601074\n",
      "Step: 2998, Loss: 0.5992953181266785, Accuracy: 0.875, Computation time: 0.9084832668304443\n",
      "Step: 2999, Loss: 0.5270505547523499, Accuracy: 0.8125, Computation time: 0.6846489906311035\n",
      "Step: 3000, Loss: 0.7368607521057129, Accuracy: 0.78125, Computation time: 0.8400871753692627\n",
      "Step: 3001, Loss: 0.4397927224636078, Accuracy: 0.875, Computation time: 0.8094489574432373\n",
      "Step: 3002, Loss: 0.5755410194396973, Accuracy: 0.90625, Computation time: 1.0264511108398438\n",
      "Step: 3003, Loss: 0.4608863294124603, Accuracy: 0.90625, Computation time: 0.784106969833374\n",
      "Step: 3004, Loss: 0.5960575938224792, Accuracy: 0.8125, Computation time: 0.8978421688079834\n",
      "Step: 3005, Loss: 0.4040662944316864, Accuracy: 0.90625, Computation time: 359.45387077331543\n",
      "Step: 3006, Loss: 0.990241289138794, Accuracy: 0.78125, Computation time: 0.9922530651092529\n",
      "Step: 3007, Loss: 0.5905596613883972, Accuracy: 0.78125, Computation time: 0.6709718704223633\n",
      "Step: 3008, Loss: 0.6059370636940002, Accuracy: 0.78125, Computation time: 0.8786299228668213\n",
      "Step: 3009, Loss: 0.4131116569042206, Accuracy: 0.84375, Computation time: 0.8660438060760498\n",
      "Step: 3010, Loss: 0.37269827723503113, Accuracy: 0.875, Computation time: 0.6902670860290527\n",
      "Step: 3011, Loss: 1.0388190746307373, Accuracy: 0.625, Computation time: 0.8413641452789307\n",
      "Step: 3012, Loss: 0.6590812802314758, Accuracy: 0.65625, Computation time: 0.9453041553497314\n",
      "Step: 3013, Loss: 0.789890706539154, Accuracy: 0.78125, Computation time: 0.8550961017608643\n",
      "Step: 3014, Loss: 0.4836566746234894, Accuracy: 0.84375, Computation time: 0.8366949558258057\n",
      "Step: 3015, Loss: 0.5032871961593628, Accuracy: 0.78125, Computation time: 0.7999589443206787\n",
      "Step: 3016, Loss: 0.27987831830978394, Accuracy: 0.9375, Computation time: 0.8216378688812256\n",
      "Step: 3017, Loss: 0.5388234853744507, Accuracy: 0.90625, Computation time: 0.9296770095825195\n",
      "Step: 3018, Loss: 0.21789471805095673, Accuracy: 0.9375, Computation time: 0.89121413230896\n",
      "Step: 3019, Loss: 0.7645942568778992, Accuracy: 0.8125, Computation time: 0.857745885848999\n",
      "Step: 3020, Loss: 0.4345313608646393, Accuracy: 0.875, Computation time: 0.6485509872436523\n",
      "Step: 3021, Loss: 0.5791428089141846, Accuracy: 0.78125, Computation time: 0.8968229293823242\n",
      "Step: 3022, Loss: 0.769809365272522, Accuracy: 0.78125, Computation time: 1.9841439723968506\n",
      "Step: 3023, Loss: 0.36990436911582947, Accuracy: 0.90625, Computation time: 0.7566359043121338\n",
      "Step: 3024, Loss: 0.5851173400878906, Accuracy: 0.8125, Computation time: 0.8022551536560059\n",
      "Step: 3025, Loss: 1.122215986251831, Accuracy: 0.78125, Computation time: 0.9525032043457031\n",
      "Step: 3026, Loss: 0.5389314889907837, Accuracy: 0.84375, Computation time: 0.8594460487365723\n",
      "Step: 3027, Loss: 0.19020433723926544, Accuracy: 1.0, Computation time: 0.8274471759796143\n",
      "Step: 3028, Loss: 0.7030528783798218, Accuracy: 0.78125, Computation time: 0.9123072624206543\n",
      "Step: 3029, Loss: 0.63458251953125, Accuracy: 0.84375, Computation time: 0.7893187999725342\n",
      "Step: 3030, Loss: 0.5303439497947693, Accuracy: 0.8125, Computation time: 0.9021146297454834\n",
      "Step: 3031, Loss: 1.0844990015029907, Accuracy: 0.71875, Computation time: 0.8340840339660645\n",
      "Step: 3032, Loss: 1.0851682424545288, Accuracy: 0.78125, Computation time: 0.6998388767242432\n",
      "Step: 3033, Loss: 0.6523414254188538, Accuracy: 0.8125, Computation time: 0.8792569637298584\n",
      "Step: 3034, Loss: 0.6421614289283752, Accuracy: 0.75, Computation time: 0.7699251174926758\n",
      "Step: 3035, Loss: 0.5975379347801208, Accuracy: 0.8125, Computation time: 1.0228407382965088\n",
      "Step: 3036, Loss: 0.4313866198062897, Accuracy: 0.8125, Computation time: 0.8464717864990234\n",
      "Step: 3037, Loss: 0.6564879417419434, Accuracy: 0.6875, Computation time: 0.9043359756469727\n",
      "Step: 3038, Loss: 0.35651612281799316, Accuracy: 0.8125, Computation time: 0.8064849376678467\n",
      "Step: 3039, Loss: 0.5435773134231567, Accuracy: 0.90625, Computation time: 0.8365821838378906\n",
      "Step: 3040, Loss: 0.6313992142677307, Accuracy: 0.75, Computation time: 0.8320367336273193\n",
      "Step: 3041, Loss: 1.197624683380127, Accuracy: 0.84375, Computation time: 0.8727400302886963\n",
      "Step: 3042, Loss: 0.5398983955383301, Accuracy: 0.84375, Computation time: 1.1408019065856934\n",
      "Step: 3043, Loss: 0.6522650718688965, Accuracy: 0.84375, Computation time: 0.8909411430358887\n",
      "Step: 3044, Loss: 0.5772796869277954, Accuracy: 0.84375, Computation time: 0.7507810592651367\n",
      "Step: 3045, Loss: 0.5319235324859619, Accuracy: 0.78125, Computation time: 0.786505937576294\n",
      "Step: 3046, Loss: 0.4955103397369385, Accuracy: 0.875, Computation time: 0.8893008232116699\n",
      "Step: 3047, Loss: 0.31442469358444214, Accuracy: 0.90625, Computation time: 0.7503139972686768\n",
      "Step: 3048, Loss: 0.6797987818717957, Accuracy: 0.875, Computation time: 0.8917121887207031\n",
      "Step: 3049, Loss: 0.8573530912399292, Accuracy: 0.75, Computation time: 0.8330388069152832\n",
      "Step: 3050, Loss: 0.2814311683177948, Accuracy: 0.90625, Computation time: 0.8347477912902832\n",
      "Step: 3051, Loss: 0.841519832611084, Accuracy: 0.71875, Computation time: 0.7354187965393066\n",
      "Step: 3052, Loss: 0.28503382205963135, Accuracy: 0.90625, Computation time: 0.8358242511749268\n",
      "Step: 3053, Loss: 0.7811947464942932, Accuracy: 0.75, Computation time: 0.9129159450531006\n",
      "Step: 3054, Loss: 0.7316614389419556, Accuracy: 0.78125, Computation time: 945.9162330627441\n",
      "Step: 3055, Loss: 0.27996817231178284, Accuracy: 0.875, Computation time: 0.8193058967590332\n",
      "Step: 3056, Loss: 0.4510636031627655, Accuracy: 0.84375, Computation time: 0.922584056854248\n",
      "Step: 3057, Loss: 1.1575934886932373, Accuracy: 0.65625, Computation time: 0.8181271553039551\n",
      "Step: 3058, Loss: 0.7101105451583862, Accuracy: 0.8125, Computation time: 0.7437312602996826\n",
      "Step: 3059, Loss: 0.9553133845329285, Accuracy: 0.75, Computation time: 0.9887161254882812\n",
      "Step: 3060, Loss: 0.17167045176029205, Accuracy: 0.96875, Computation time: 0.717972993850708\n",
      "Step: 3061, Loss: 0.9086347818374634, Accuracy: 0.75, Computation time: 0.940777063369751\n",
      "Step: 3062, Loss: 0.5222872495651245, Accuracy: 0.78125, Computation time: 0.8880751132965088\n",
      "Step: 3063, Loss: 0.7085341811180115, Accuracy: 0.75, Computation time: 0.9243876934051514\n",
      "Step: 3064, Loss: 1.403992772102356, Accuracy: 0.6875, Computation time: 0.6657619476318359\n",
      "Step: 3065, Loss: 0.8675797581672668, Accuracy: 0.6875, Computation time: 1.435241937637329\n",
      "Step: 3066, Loss: 0.6417704224586487, Accuracy: 0.8125, Computation time: 0.775054931640625\n",
      "Step: 3067, Loss: 0.8172189593315125, Accuracy: 0.6875, Computation time: 0.8061301708221436\n",
      "Step: 3068, Loss: 0.8504555225372314, Accuracy: 0.8125, Computation time: 0.7295620441436768\n",
      "Step: 3069, Loss: 0.6211885213851929, Accuracy: 0.75, Computation time: 0.795651912689209\n",
      "Step: 3070, Loss: 0.5180254578590393, Accuracy: 0.8125, Computation time: 0.6769218444824219\n",
      "Step: 3071, Loss: 0.6543759107589722, Accuracy: 0.8125, Computation time: 0.9383449554443359\n",
      "Step: 3072, Loss: 0.6220139861106873, Accuracy: 0.8125, Computation time: 0.8529260158538818\n",
      "Step: 3073, Loss: 0.4060528874397278, Accuracy: 0.90625, Computation time: 0.6382639408111572\n",
      "Step: 3074, Loss: 0.5384934544563293, Accuracy: 0.8125, Computation time: 0.8193941116333008\n",
      "Step: 3075, Loss: 0.4227420389652252, Accuracy: 0.8125, Computation time: 0.8015310764312744\n",
      "Step: 3076, Loss: 0.7129296064376831, Accuracy: 0.8125, Computation time: 0.8186988830566406\n",
      "Step: 3077, Loss: 0.4402933120727539, Accuracy: 0.8125, Computation time: 0.9880530834197998\n",
      "Step: 3078, Loss: 0.85694819688797, Accuracy: 0.75, Computation time: 0.8009331226348877\n",
      "Step: 3079, Loss: 0.5081757307052612, Accuracy: 0.8125, Computation time: 0.9478809833526611\n",
      "Step: 3080, Loss: 0.37364357709884644, Accuracy: 0.875, Computation time: 0.7026638984680176\n",
      "Step: 3081, Loss: 0.7163005471229553, Accuracy: 0.71875, Computation time: 0.7780959606170654\n",
      "Step: 3082, Loss: 0.9243485331535339, Accuracy: 0.78125, Computation time: 0.6527302265167236\n",
      "Step: 3083, Loss: 0.8375769257545471, Accuracy: 0.75, Computation time: 0.7876861095428467\n",
      "Step: 3084, Loss: 0.54341721534729, Accuracy: 0.875, Computation time: 0.89198899269104\n",
      "Step: 3085, Loss: 0.6002008318901062, Accuracy: 0.78125, Computation time: 0.9449846744537354\n",
      "Step: 3086, Loss: 0.6923592686653137, Accuracy: 0.71875, Computation time: 0.7399811744689941\n",
      "Step: 3087, Loss: 0.43418940901756287, Accuracy: 0.84375, Computation time: 0.7614538669586182\n",
      "Step: 3088, Loss: 0.3509208858013153, Accuracy: 0.875, Computation time: 0.7648501396179199\n",
      "Step: 3089, Loss: 0.5332841277122498, Accuracy: 0.78125, Computation time: 0.865062952041626\n",
      "Step: 3090, Loss: 0.8804945945739746, Accuracy: 0.78125, Computation time: 0.9078812599182129\n",
      "Step: 3091, Loss: 0.4111579954624176, Accuracy: 0.875, Computation time: 0.605482816696167\n",
      "Step: 3092, Loss: 0.4153715968132019, Accuracy: 0.84375, Computation time: 0.6497681140899658\n",
      "Step: 3093, Loss: 0.7246805429458618, Accuracy: 0.8125, Computation time: 0.8557040691375732\n",
      "Step: 3094, Loss: 1.0942283868789673, Accuracy: 0.78125, Computation time: 0.8948328495025635\n",
      "Step: 3095, Loss: 0.5287436842918396, Accuracy: 0.8125, Computation time: 0.7260360717773438\n",
      "Step: 3096, Loss: 0.609611451625824, Accuracy: 0.84375, Computation time: 1.1375811100006104\n",
      "Step: 3097, Loss: 0.9710847735404968, Accuracy: 0.78125, Computation time: 0.8673441410064697\n",
      "Step: 3098, Loss: 0.4400109052658081, Accuracy: 0.84375, Computation time: 1.4895668029785156\n",
      "Step: 3099, Loss: 1.241888165473938, Accuracy: 0.75, Computation time: 0.885871171951294\n",
      "Step: 3100, Loss: 0.7547827959060669, Accuracy: 0.75, Computation time: 0.9065260887145996\n",
      "Step: 3101, Loss: 0.7523677349090576, Accuracy: 0.8125, Computation time: 0.8058319091796875\n",
      "Step: 3102, Loss: 0.41929930448532104, Accuracy: 0.90625, Computation time: 0.978766918182373\n",
      "Step: 3103, Loss: 0.4378678798675537, Accuracy: 0.875, Computation time: 0.6687698364257812\n",
      "Step: 3104, Loss: 0.7148289084434509, Accuracy: 0.84375, Computation time: 0.7032120227813721\n",
      "Step: 3105, Loss: 0.6235093474388123, Accuracy: 0.71875, Computation time: 0.7522659301757812\n",
      "Step: 3106, Loss: 0.6492977738380432, Accuracy: 0.8125, Computation time: 0.7310488224029541\n",
      "Step: 3107, Loss: 0.2829199731349945, Accuracy: 0.90625, Computation time: 0.8376047611236572\n",
      "Step: 3108, Loss: 0.5352940559387207, Accuracy: 0.875, Computation time: 0.7478160858154297\n",
      "Step: 3109, Loss: 0.6093848347663879, Accuracy: 0.8125, Computation time: 0.7427871227264404\n",
      "Step: 3110, Loss: 0.7485272884368896, Accuracy: 0.875, Computation time: 1.904008150100708\n",
      "Step: 3111, Loss: 0.7675214409828186, Accuracy: 0.75, Computation time: 0.8756639957427979\n",
      "Step: 3112, Loss: 0.42572441697120667, Accuracy: 0.875, Computation time: 0.8677990436553955\n",
      "Step: 3113, Loss: 0.5940065383911133, Accuracy: 0.84375, Computation time: 0.8942902088165283\n",
      "Step: 3114, Loss: 0.6228533983230591, Accuracy: 0.78125, Computation time: 0.8861939907073975\n",
      "Step: 3115, Loss: 0.7590248584747314, Accuracy: 0.8125, Computation time: 0.9859728813171387\n",
      "Step: 3116, Loss: 0.8630508780479431, Accuracy: 0.78125, Computation time: 0.7734949588775635\n",
      "Step: 3117, Loss: 0.6144753694534302, Accuracy: 0.84375, Computation time: 0.9045660495758057\n",
      "Step: 3118, Loss: 0.8794300556182861, Accuracy: 0.75, Computation time: 0.7083837985992432\n",
      "Step: 3119, Loss: 0.7321344614028931, Accuracy: 0.8125, Computation time: 0.8673510551452637\n",
      "Step: 3120, Loss: 0.8459054827690125, Accuracy: 0.71875, Computation time: 0.8742399215698242\n",
      "Step: 3121, Loss: 0.3172870874404907, Accuracy: 0.90625, Computation time: 0.7155568599700928\n",
      "Step: 3122, Loss: 0.9597583413124084, Accuracy: 0.78125, Computation time: 0.8377640247344971\n",
      "Step: 3123, Loss: 0.6788145303726196, Accuracy: 0.78125, Computation time: 0.930962085723877\n",
      "Step: 3124, Loss: 0.36275938153266907, Accuracy: 0.875, Computation time: 0.7903916835784912\n",
      "Step: 3125, Loss: 0.5763563513755798, Accuracy: 0.875, Computation time: 0.8312239646911621\n",
      "Step: 3126, Loss: 0.7509734630584717, Accuracy: 0.8125, Computation time: 0.8713381290435791\n",
      "Step: 3127, Loss: 1.0194027423858643, Accuracy: 0.75, Computation time: 0.7303760051727295\n",
      "Step: 3128, Loss: 0.5211475491523743, Accuracy: 0.8125, Computation time: 0.8130018711090088\n",
      "Step: 3129, Loss: 0.4973914623260498, Accuracy: 0.8125, Computation time: 1.348917007446289\n",
      "Step: 3130, Loss: 0.7562239766120911, Accuracy: 0.8125, Computation time: 0.7956171035766602\n",
      "Step: 3131, Loss: 0.4450356364250183, Accuracy: 0.8125, Computation time: 0.881202220916748\n",
      "Step: 3132, Loss: 0.48919326066970825, Accuracy: 0.84375, Computation time: 0.8916552066802979\n",
      "Step: 3133, Loss: 0.6285171508789062, Accuracy: 0.90625, Computation time: 0.706063985824585\n",
      "Step: 3134, Loss: 0.5792073607444763, Accuracy: 0.84375, Computation time: 0.8354840278625488\n",
      "Step: 3135, Loss: 0.28165537118911743, Accuracy: 0.90625, Computation time: 0.8198070526123047\n",
      "Step: 3136, Loss: 0.4734953045845032, Accuracy: 0.84375, Computation time: 0.8316679000854492\n",
      "Step: 3137, Loss: 0.4997223913669586, Accuracy: 0.78125, Computation time: 0.7690739631652832\n",
      "Step: 3138, Loss: 0.41837307810783386, Accuracy: 0.84375, Computation time: 0.666985034942627\n",
      "Step: 3139, Loss: 0.354793906211853, Accuracy: 0.90625, Computation time: 0.9019169807434082\n",
      "Step: 3140, Loss: 0.5700883269309998, Accuracy: 0.75, Computation time: 0.8292841911315918\n",
      "Step: 3141, Loss: 0.41464963555336, Accuracy: 0.84375, Computation time: 0.7454252243041992\n",
      "Step: 3142, Loss: 0.8793571591377258, Accuracy: 0.78125, Computation time: 0.8368546962738037\n",
      "Step: 3143, Loss: 0.8462454676628113, Accuracy: 0.78125, Computation time: 0.8553040027618408\n",
      "Step: 3144, Loss: 0.8262230157852173, Accuracy: 0.75, Computation time: 0.866426944732666\n",
      "Step: 3145, Loss: 0.7113993763923645, Accuracy: 0.71875, Computation time: 0.8008689880371094\n",
      "Step: 3146, Loss: 1.0728132724761963, Accuracy: 0.71875, Computation time: 0.8904519081115723\n",
      "Step: 3147, Loss: 0.917157769203186, Accuracy: 0.75, Computation time: 0.8116137981414795\n",
      "Step: 3148, Loss: 0.6649803519248962, Accuracy: 0.75, Computation time: 0.7424061298370361\n",
      "Step: 3149, Loss: 0.40149879455566406, Accuracy: 0.84375, Computation time: 0.8116028308868408\n",
      "Step: 3150, Loss: 0.5023780465126038, Accuracy: 0.875, Computation time: 1.1283419132232666\n",
      "Step: 3151, Loss: 0.35168683528900146, Accuracy: 0.90625, Computation time: 0.701484203338623\n",
      "Step: 3152, Loss: 0.6946595907211304, Accuracy: 0.8125, Computation time: 0.797882080078125\n",
      "Step: 3153, Loss: 0.5227634906768799, Accuracy: 0.84375, Computation time: 0.8958561420440674\n",
      "Step: 3154, Loss: 0.46162721514701843, Accuracy: 0.84375, Computation time: 0.6447899341583252\n",
      "Step: 3155, Loss: 0.574574887752533, Accuracy: 0.875, Computation time: 1.1214048862457275\n",
      "Step: 3156, Loss: 0.8828617334365845, Accuracy: 0.71875, Computation time: 0.8437049388885498\n",
      "Step: 3157, Loss: 0.966572642326355, Accuracy: 0.75, Computation time: 0.908653974533081\n",
      "Step: 3158, Loss: 0.6754133701324463, Accuracy: 0.8125, Computation time: 0.8491659164428711\n",
      "Step: 3159, Loss: 0.31246137619018555, Accuracy: 0.9375, Computation time: 0.7983732223510742\n",
      "Step: 3160, Loss: 0.4309465289115906, Accuracy: 0.875, Computation time: 0.8016250133514404\n",
      "Step: 3161, Loss: 0.6462685465812683, Accuracy: 0.78125, Computation time: 0.7559130191802979\n",
      "Step: 3162, Loss: 0.6632264256477356, Accuracy: 0.78125, Computation time: 0.9412460327148438\n",
      "Step: 3163, Loss: 0.6785624623298645, Accuracy: 0.90625, Computation time: 0.8463239669799805\n",
      "Step: 3164, Loss: 0.6221525073051453, Accuracy: 0.84375, Computation time: 0.7050409317016602\n",
      "Step: 3165, Loss: 0.926913321018219, Accuracy: 0.8125, Computation time: 1.0049238204956055\n",
      "Step: 3166, Loss: 0.4720287024974823, Accuracy: 0.8125, Computation time: 0.8422861099243164\n",
      "Step: 3167, Loss: 0.569383978843689, Accuracy: 0.8125, Computation time: 0.9922821521759033\n",
      "Step: 3168, Loss: 0.44654643535614014, Accuracy: 0.875, Computation time: 0.8633151054382324\n",
      "Step: 3169, Loss: 0.6796041131019592, Accuracy: 0.78125, Computation time: 0.7628400325775146\n",
      "Step: 3170, Loss: 1.051390528678894, Accuracy: 0.75, Computation time: 0.8452568054199219\n",
      "Step: 3171, Loss: 0.561907172203064, Accuracy: 0.84375, Computation time: 1.1806342601776123\n",
      "Step: 3172, Loss: 0.8006982803344727, Accuracy: 0.84375, Computation time: 1.0770750045776367\n",
      "Step: 3173, Loss: 0.5447920560836792, Accuracy: 0.78125, Computation time: 0.7226691246032715\n",
      "Step: 3174, Loss: 0.9940803647041321, Accuracy: 0.71875, Computation time: 0.819390058517456\n",
      "Step: 3175, Loss: 0.8513824343681335, Accuracy: 0.71875, Computation time: 0.8828010559082031\n",
      "Step: 3176, Loss: 0.3877878189086914, Accuracy: 0.90625, Computation time: 0.818310022354126\n",
      "Step: 3177, Loss: 0.5315714478492737, Accuracy: 0.84375, Computation time: 0.9032018184661865\n",
      "Step: 3178, Loss: 0.365212619304657, Accuracy: 0.90625, Computation time: 0.8019998073577881\n",
      "Step: 3179, Loss: 0.523503839969635, Accuracy: 0.8125, Computation time: 0.9481649398803711\n",
      "Step: 3180, Loss: 0.6906509399414062, Accuracy: 0.78125, Computation time: 0.8617119789123535\n",
      "Step: 3181, Loss: 0.5036709308624268, Accuracy: 0.78125, Computation time: 1.1035559177398682\n",
      "Step: 3182, Loss: 0.43963149189949036, Accuracy: 0.875, Computation time: 0.7399380207061768\n",
      "Step: 3183, Loss: 0.46855294704437256, Accuracy: 0.84375, Computation time: 0.6404159069061279\n",
      "Step: 3184, Loss: 0.5114214420318604, Accuracy: 0.875, Computation time: 0.8373088836669922\n",
      "Step: 3185, Loss: 0.4422832727432251, Accuracy: 0.84375, Computation time: 0.8297100067138672\n",
      "Step: 3186, Loss: 0.4219452738761902, Accuracy: 0.75, Computation time: 0.6930007934570312\n",
      "Step: 3187, Loss: 0.39070239663124084, Accuracy: 0.875, Computation time: 0.8398962020874023\n",
      "Step: 3188, Loss: 0.4908713400363922, Accuracy: 0.78125, Computation time: 0.7284412384033203\n",
      "Step: 3189, Loss: 0.5374728441238403, Accuracy: 0.90625, Computation time: 0.8580920696258545\n",
      "Step: 3190, Loss: 0.4452161192893982, Accuracy: 0.8125, Computation time: 0.8036749362945557\n",
      "Step: 3191, Loss: 0.8285419344902039, Accuracy: 0.78125, Computation time: 0.7825798988342285\n",
      "Step: 3192, Loss: 0.7366017699241638, Accuracy: 0.71875, Computation time: 1.3607323169708252\n",
      "Step: 3193, Loss: 0.4344758689403534, Accuracy: 0.90625, Computation time: 0.7935497760772705\n",
      "Step: 3194, Loss: 0.3829403817653656, Accuracy: 0.875, Computation time: 0.7937841415405273\n",
      "Step: 3195, Loss: 0.36954179406166077, Accuracy: 0.90625, Computation time: 0.7913422584533691\n",
      "Step: 3196, Loss: 0.31901127099990845, Accuracy: 0.9375, Computation time: 0.8901829719543457\n",
      "Step: 3197, Loss: 0.29842764139175415, Accuracy: 0.90625, Computation time: 0.7964069843292236\n",
      "Step: 3198, Loss: 0.7739191651344299, Accuracy: 0.8125, Computation time: 0.7965958118438721\n",
      "Step: 3199, Loss: 0.402721643447876, Accuracy: 0.84375, Computation time: 0.7750110626220703\n",
      "Step: 3200, Loss: 0.6311619281768799, Accuracy: 0.84375, Computation time: 1.3793308734893799\n",
      "Step: 3201, Loss: 0.520160973072052, Accuracy: 0.8125, Computation time: 0.9907119274139404\n",
      "Step: 3202, Loss: 0.6851600408554077, Accuracy: 0.75, Computation time: 0.8133559226989746\n",
      "Step: 3203, Loss: 0.4268485903739929, Accuracy: 0.8125, Computation time: 0.665668249130249\n",
      "Step: 3204, Loss: 0.9595562219619751, Accuracy: 0.75, Computation time: 0.718127965927124\n",
      "Step: 3205, Loss: 0.34132495522499084, Accuracy: 0.84375, Computation time: 0.8402369022369385\n",
      "Step: 3206, Loss: 0.47004660964012146, Accuracy: 0.84375, Computation time: 968.556930065155\n",
      "Step: 3207, Loss: 0.720608115196228, Accuracy: 0.8125, Computation time: 0.9586801528930664\n",
      "Step: 3208, Loss: 0.9003897905349731, Accuracy: 0.71875, Computation time: 0.9984030723571777\n",
      "Step: 3209, Loss: 0.34998050332069397, Accuracy: 0.96875, Computation time: 0.9332211017608643\n",
      "Step: 3210, Loss: 0.15761777758598328, Accuracy: 0.96875, Computation time: 0.7455141544342041\n",
      "Step: 3211, Loss: 0.5727265477180481, Accuracy: 0.8125, Computation time: 0.7303769588470459\n",
      "Step: 3212, Loss: 0.7722551226615906, Accuracy: 0.78125, Computation time: 0.7815752029418945\n",
      "Step: 3213, Loss: 1.0922187566757202, Accuracy: 0.84375, Computation time: 0.7992072105407715\n",
      "Step: 3214, Loss: 0.4831666350364685, Accuracy: 0.875, Computation time: 0.743966817855835\n",
      "Step: 3215, Loss: 0.39691027998924255, Accuracy: 0.875, Computation time: 0.9041140079498291\n",
      "Step: 3216, Loss: 0.5389560461044312, Accuracy: 0.84375, Computation time: 0.8539588451385498\n",
      "Step: 3217, Loss: 0.9743862748146057, Accuracy: 0.71875, Computation time: 0.9078452587127686\n",
      "Step: 3218, Loss: 0.6498801708221436, Accuracy: 0.8125, Computation time: 0.7129251956939697\n",
      "Step: 3219, Loss: 0.7995947003364563, Accuracy: 0.8125, Computation time: 0.9084231853485107\n",
      "Step: 3220, Loss: 0.7256550192832947, Accuracy: 0.75, Computation time: 0.87310791015625\n",
      "Step: 3221, Loss: 0.6053136587142944, Accuracy: 0.84375, Computation time: 0.7779388427734375\n",
      "Step: 3222, Loss: 0.778282642364502, Accuracy: 0.75, Computation time: 0.8233528137207031\n",
      "Step: 3223, Loss: 0.518314778804779, Accuracy: 0.875, Computation time: 1.1584320068359375\n",
      "Step: 3224, Loss: 0.5612077116966248, Accuracy: 0.875, Computation time: 0.7946288585662842\n",
      "Step: 3225, Loss: 0.9883068799972534, Accuracy: 0.65625, Computation time: 0.832528829574585\n",
      "Step: 3226, Loss: 0.6389889121055603, Accuracy: 0.875, Computation time: 0.7633202075958252\n",
      "Step: 3227, Loss: 0.6189877390861511, Accuracy: 0.84375, Computation time: 0.705517053604126\n",
      "Step: 3228, Loss: 1.114762783050537, Accuracy: 0.75, Computation time: 0.6835119724273682\n",
      "Step: 3229, Loss: 0.7032856941223145, Accuracy: 0.6875, Computation time: 0.8855390548706055\n",
      "Step: 3230, Loss: 1.4157122373580933, Accuracy: 0.5625, Computation time: 0.7268352508544922\n",
      "Step: 3231, Loss: 0.9046732783317566, Accuracy: 0.6875, Computation time: 0.8448622226715088\n",
      "Step: 3232, Loss: 0.6662048101425171, Accuracy: 0.78125, Computation time: 0.7579941749572754\n",
      "Step: 3233, Loss: 0.7035117149353027, Accuracy: 0.75, Computation time: 0.8786981105804443\n",
      "Step: 3234, Loss: 0.5487427711486816, Accuracy: 0.8125, Computation time: 0.9529168605804443\n",
      "Step: 3235, Loss: 0.27493420243263245, Accuracy: 0.9375, Computation time: 0.8077218532562256\n",
      "Step: 3236, Loss: 1.0683122873306274, Accuracy: 0.75, Computation time: 0.7193160057067871\n",
      "Step: 3237, Loss: 0.7324317097663879, Accuracy: 0.78125, Computation time: 0.9494850635528564\n",
      "Step: 3238, Loss: 0.6099689602851868, Accuracy: 0.90625, Computation time: 0.916701078414917\n",
      "Step: 3239, Loss: 0.4698227345943451, Accuracy: 0.90625, Computation time: 0.8173341751098633\n",
      "Step: 3240, Loss: 0.6927083730697632, Accuracy: 0.8125, Computation time: 0.8599512577056885\n",
      "Step: 3241, Loss: 0.3160948157310486, Accuracy: 0.90625, Computation time: 0.7299349308013916\n",
      "Step: 3242, Loss: 0.37103453278541565, Accuracy: 0.875, Computation time: 0.687636137008667\n",
      "Step: 3243, Loss: 0.3499116599559784, Accuracy: 0.875, Computation time: 0.6768922805786133\n",
      "Step: 3244, Loss: 0.44185778498649597, Accuracy: 0.78125, Computation time: 0.7357749938964844\n",
      "Step: 3245, Loss: 0.4006361663341522, Accuracy: 0.90625, Computation time: 0.7807838916778564\n",
      "Step: 3246, Loss: 1.0257627964019775, Accuracy: 0.6875, Computation time: 0.7102141380310059\n",
      "Step: 3247, Loss: 0.7053848505020142, Accuracy: 0.875, Computation time: 0.7242040634155273\n",
      "Step: 3248, Loss: 0.5179732441902161, Accuracy: 0.84375, Computation time: 0.950066328048706\n",
      "Step: 3249, Loss: 0.5461748242378235, Accuracy: 0.8125, Computation time: 0.9116420745849609\n",
      "Step: 3250, Loss: 0.6854643225669861, Accuracy: 0.8125, Computation time: 0.7087240219116211\n",
      "Step: 3251, Loss: 0.5463032126426697, Accuracy: 0.78125, Computation time: 0.8997049331665039\n",
      "Step: 3252, Loss: 0.5244665145874023, Accuracy: 0.84375, Computation time: 0.6772091388702393\n",
      "Step: 3253, Loss: 0.7564709186553955, Accuracy: 0.78125, Computation time: 0.7330029010772705\n",
      "Step: 3254, Loss: 0.621957004070282, Accuracy: 0.75, Computation time: 0.7746508121490479\n",
      "Step: 3255, Loss: 0.4379553198814392, Accuracy: 0.8125, Computation time: 0.8011729717254639\n",
      "Step: 3256, Loss: 0.6292743682861328, Accuracy: 0.78125, Computation time: 1.3407659530639648\n",
      "Step: 3257, Loss: 0.4603103697299957, Accuracy: 0.875, Computation time: 0.7675719261169434\n",
      "Step: 3258, Loss: 0.3054630756378174, Accuracy: 0.90625, Computation time: 0.8305749893188477\n",
      "Step: 3259, Loss: 0.5385586619377136, Accuracy: 0.78125, Computation time: 1.075314998626709\n",
      "Step: 3260, Loss: 0.8844915628433228, Accuracy: 0.8125, Computation time: 0.7549817562103271\n",
      "Step: 3261, Loss: 0.4406043291091919, Accuracy: 0.84375, Computation time: 0.7578330039978027\n",
      "Step: 3262, Loss: 0.836984395980835, Accuracy: 0.78125, Computation time: 0.8989031314849854\n",
      "Step: 3263, Loss: 0.5094781517982483, Accuracy: 0.8125, Computation time: 0.9951896667480469\n",
      "Step: 3264, Loss: 0.5026733875274658, Accuracy: 0.78125, Computation time: 0.6936192512512207\n",
      "Step: 3265, Loss: 0.7933202385902405, Accuracy: 0.8125, Computation time: 0.7077040672302246\n",
      "Step: 3266, Loss: 0.5798251628875732, Accuracy: 0.875, Computation time: 0.7947220802307129\n",
      "Step: 3267, Loss: 0.3796042501926422, Accuracy: 0.875, Computation time: 0.8783528804779053\n",
      "Step: 3268, Loss: 0.7618808150291443, Accuracy: 0.78125, Computation time: 1.034980058670044\n",
      "Step: 3269, Loss: 0.7793041467666626, Accuracy: 0.8125, Computation time: 0.87337327003479\n",
      "Step: 3270, Loss: 0.5409772992134094, Accuracy: 0.78125, Computation time: 0.8368198871612549\n",
      "Step: 3271, Loss: 0.7626602649688721, Accuracy: 0.8125, Computation time: 0.8701522350311279\n",
      "Step: 3272, Loss: 0.615024983882904, Accuracy: 0.8125, Computation time: 0.8275728225708008\n",
      "Step: 3273, Loss: 0.7011497020721436, Accuracy: 0.8125, Computation time: 0.7239139080047607\n",
      "Step: 3274, Loss: 0.7810105681419373, Accuracy: 0.78125, Computation time: 0.8463408946990967\n",
      "Step: 3275, Loss: 0.5538777112960815, Accuracy: 0.8125, Computation time: 0.8507990837097168\n",
      "Step: 3276, Loss: 0.34041640162467957, Accuracy: 0.90625, Computation time: 0.909156084060669\n",
      "Step: 3277, Loss: 0.6172013282775879, Accuracy: 0.71875, Computation time: 0.8645379543304443\n",
      "Step: 3278, Loss: 0.9209908246994019, Accuracy: 0.75, Computation time: 0.7671399116516113\n",
      "Step: 3279, Loss: 0.5655784010887146, Accuracy: 0.90625, Computation time: 0.9089109897613525\n",
      "Step: 3280, Loss: 0.6036264300346375, Accuracy: 0.8125, Computation time: 0.761361837387085\n",
      "Step: 3281, Loss: 0.5682863593101501, Accuracy: 0.84375, Computation time: 0.721534013748169\n",
      "Step: 3282, Loss: 0.4732079803943634, Accuracy: 0.8125, Computation time: 0.7240839004516602\n",
      "Step: 3283, Loss: 0.4070271849632263, Accuracy: 0.90625, Computation time: 0.7816097736358643\n",
      "Step: 3284, Loss: 0.42357301712036133, Accuracy: 0.84375, Computation time: 0.8988168239593506\n",
      "Step: 3285, Loss: 0.4352228045463562, Accuracy: 0.875, Computation time: 0.8498709201812744\n",
      "Step: 3286, Loss: 0.32315319776535034, Accuracy: 0.90625, Computation time: 0.8732259273529053\n",
      "Step: 3287, Loss: 0.24361278116703033, Accuracy: 0.90625, Computation time: 0.7841131687164307\n",
      "Step: 3288, Loss: 0.4561220407485962, Accuracy: 0.84375, Computation time: 1.278141975402832\n",
      "Step: 3289, Loss: 0.5758907198905945, Accuracy: 0.78125, Computation time: 0.8836591243743896\n",
      "Step: 3290, Loss: 0.39075905084609985, Accuracy: 0.90625, Computation time: 1.0293807983398438\n",
      "Step: 3291, Loss: 0.48482027649879456, Accuracy: 0.875, Computation time: 1.1512329578399658\n",
      "Step: 3292, Loss: 0.37226563692092896, Accuracy: 0.875, Computation time: 0.7866818904876709\n",
      "Step: 3293, Loss: 0.8367689251899719, Accuracy: 0.78125, Computation time: 0.8553247451782227\n",
      "Step: 3294, Loss: 0.992675244808197, Accuracy: 0.71875, Computation time: 0.7726030349731445\n",
      "Step: 3295, Loss: 0.5982916951179504, Accuracy: 0.8125, Computation time: 0.9655170440673828\n",
      "Step: 3296, Loss: 0.4756820499897003, Accuracy: 0.875, Computation time: 1.1053152084350586\n",
      "Step: 3297, Loss: 0.6497070789337158, Accuracy: 0.8125, Computation time: 0.7311811447143555\n",
      "Step: 3298, Loss: 0.47879844903945923, Accuracy: 0.8125, Computation time: 0.7748618125915527\n",
      "Step: 3299, Loss: 0.44588685035705566, Accuracy: 0.875, Computation time: 0.8262290954589844\n",
      "Step: 3300, Loss: 0.35997453331947327, Accuracy: 0.875, Computation time: 0.789607048034668\n",
      "Step: 3301, Loss: 0.5661630034446716, Accuracy: 0.78125, Computation time: 0.8130040168762207\n",
      "Step: 3302, Loss: 1.0850887298583984, Accuracy: 0.78125, Computation time: 0.6416399478912354\n",
      "Step: 3303, Loss: 0.6839179992675781, Accuracy: 0.84375, Computation time: 0.8669948577880859\n",
      "Step: 3304, Loss: 0.17351777851581573, Accuracy: 0.96875, Computation time: 0.897515058517456\n",
      "Step: 3305, Loss: 0.7012235522270203, Accuracy: 0.75, Computation time: 0.991443395614624\n",
      "Step: 3306, Loss: 0.9235491752624512, Accuracy: 0.84375, Computation time: 0.7047040462493896\n",
      "Step: 3307, Loss: 0.7326719164848328, Accuracy: 0.71875, Computation time: 1.0255358219146729\n",
      "Step: 3308, Loss: 0.5035125017166138, Accuracy: 0.84375, Computation time: 0.8074648380279541\n",
      "Step: 3309, Loss: 1.0063725709915161, Accuracy: 0.65625, Computation time: 0.8667070865631104\n",
      "Step: 3310, Loss: 0.3484433889389038, Accuracy: 0.8125, Computation time: 0.6532320976257324\n",
      "Step: 3311, Loss: 0.35402363538742065, Accuracy: 0.875, Computation time: 0.8133189678192139\n",
      "Step: 3312, Loss: 0.6235882639884949, Accuracy: 0.875, Computation time: 0.7748861312866211\n",
      "Step: 3313, Loss: 0.5240407586097717, Accuracy: 0.84375, Computation time: 1.016010046005249\n",
      "Step: 3314, Loss: 0.8739147186279297, Accuracy: 0.8125, Computation time: 0.849877119064331\n",
      "Step: 3315, Loss: 0.4850221574306488, Accuracy: 0.84375, Computation time: 0.8319048881530762\n",
      "Step: 3316, Loss: 0.8891227841377258, Accuracy: 0.8125, Computation time: 0.7138328552246094\n",
      "Step: 3317, Loss: 0.5214406251907349, Accuracy: 0.8125, Computation time: 0.8683767318725586\n",
      "Step: 3318, Loss: 0.5245140194892883, Accuracy: 0.75, Computation time: 0.8676800727844238\n",
      "Step: 3319, Loss: 0.5269693732261658, Accuracy: 0.78125, Computation time: 0.8837890625\n",
      "Step: 3320, Loss: 0.5614068508148193, Accuracy: 0.8125, Computation time: 1.446930170059204\n",
      "Step: 3321, Loss: 0.4741416573524475, Accuracy: 0.8125, Computation time: 0.9140410423278809\n",
      "Step: 3322, Loss: 0.42535126209259033, Accuracy: 0.90625, Computation time: 0.9089920520782471\n",
      "Step: 3323, Loss: 0.7238279581069946, Accuracy: 0.8125, Computation time: 1.0211031436920166\n",
      "Step: 3324, Loss: 0.6852208375930786, Accuracy: 0.84375, Computation time: 0.7689259052276611\n",
      "Step: 3325, Loss: 0.7838781476020813, Accuracy: 0.78125, Computation time: 0.8630690574645996\n",
      "Step: 3326, Loss: 0.5534894466400146, Accuracy: 0.8125, Computation time: 0.8069391250610352\n",
      "Step: 3327, Loss: 0.500352680683136, Accuracy: 0.84375, Computation time: 0.8551561832427979\n",
      "Step: 3328, Loss: 0.6231450438499451, Accuracy: 0.875, Computation time: 0.7662220001220703\n",
      "Step: 3329, Loss: 0.7069639563560486, Accuracy: 0.6875, Computation time: 0.9214990139007568\n",
      "Step: 3330, Loss: 0.5392764210700989, Accuracy: 0.8125, Computation time: 0.7862889766693115\n",
      "Step: 3331, Loss: 0.6469470262527466, Accuracy: 0.8125, Computation time: 0.7092251777648926\n",
      "Step: 3332, Loss: 0.9396695494651794, Accuracy: 0.78125, Computation time: 0.8372199535369873\n",
      "Step: 3333, Loss: 0.43791764974594116, Accuracy: 0.8125, Computation time: 0.7395720481872559\n",
      "Step: 3334, Loss: 0.6460445523262024, Accuracy: 0.8125, Computation time: 0.7768168449401855\n",
      "Step: 3335, Loss: 0.37885451316833496, Accuracy: 0.875, Computation time: 0.8241579532623291\n",
      "Step: 3336, Loss: 0.5718657374382019, Accuracy: 0.78125, Computation time: 0.779771089553833\n",
      "Step: 3337, Loss: 0.7348693609237671, Accuracy: 0.84375, Computation time: 0.8835129737854004\n",
      "Step: 3338, Loss: 0.7545070648193359, Accuracy: 0.75, Computation time: 0.8411519527435303\n",
      "Step: 3339, Loss: 0.15988773107528687, Accuracy: 1.0, Computation time: 0.8305847644805908\n",
      "Step: 3340, Loss: 0.42165011167526245, Accuracy: 0.875, Computation time: 0.8840792179107666\n",
      "Step: 3341, Loss: 0.8818967342376709, Accuracy: 0.78125, Computation time: 0.8433079719543457\n",
      "Step: 3342, Loss: 0.5024067163467407, Accuracy: 0.875, Computation time: 0.7747981548309326\n",
      "Step: 3343, Loss: 0.6654536724090576, Accuracy: 0.8125, Computation time: 0.7726583480834961\n",
      "Step: 3344, Loss: 0.48332107067108154, Accuracy: 0.84375, Computation time: 0.9706828594207764\n",
      "Step: 3345, Loss: 0.4225527346134186, Accuracy: 0.875, Computation time: 0.7938642501831055\n",
      "Step: 3346, Loss: 0.350750207901001, Accuracy: 0.875, Computation time: 0.8914690017700195\n",
      "Step: 3347, Loss: 0.5579748749732971, Accuracy: 0.8125, Computation time: 0.7441070079803467\n",
      "Step: 3348, Loss: 0.2558313012123108, Accuracy: 0.9375, Computation time: 0.7501730918884277\n",
      "Step: 3349, Loss: 0.7137370109558105, Accuracy: 0.8125, Computation time: 0.8895018100738525\n",
      "Step: 3350, Loss: 0.4660947620868683, Accuracy: 0.875, Computation time: 0.8923330307006836\n",
      "Step: 3351, Loss: 0.8375383615493774, Accuracy: 0.71875, Computation time: 1.2397358417510986\n",
      "Step: 3352, Loss: 0.39088112115859985, Accuracy: 0.875, Computation time: 0.8760240077972412\n",
      "Step: 3353, Loss: 0.5563002228736877, Accuracy: 0.84375, Computation time: 0.7779679298400879\n",
      "Step: 3354, Loss: 0.7389366030693054, Accuracy: 0.71875, Computation time: 0.9048409461975098\n",
      "Step: 3355, Loss: 0.7120547294616699, Accuracy: 0.75, Computation time: 0.6975691318511963\n",
      "Step: 3356, Loss: 0.6932686567306519, Accuracy: 0.78125, Computation time: 0.6857259273529053\n",
      "Step: 3357, Loss: 0.3816240727901459, Accuracy: 0.84375, Computation time: 0.7834529876708984\n",
      "Step: 3358, Loss: 0.33383646607398987, Accuracy: 0.9375, Computation time: 0.8896489143371582\n",
      "Step: 3359, Loss: 0.66614830493927, Accuracy: 0.78125, Computation time: 0.7976999282836914\n",
      "Step: 3360, Loss: 0.49502432346343994, Accuracy: 0.84375, Computation time: 0.7979879379272461\n",
      "Step: 3361, Loss: 0.851650059223175, Accuracy: 0.78125, Computation time: 0.9595320224761963\n",
      "Step: 3362, Loss: 0.2542821168899536, Accuracy: 0.9375, Computation time: 0.7246618270874023\n",
      "Step: 3363, Loss: 0.4956963360309601, Accuracy: 0.84375, Computation time: 0.8851158618927002\n",
      "Step: 3364, Loss: 0.7250669598579407, Accuracy: 0.65625, Computation time: 0.7191441059112549\n",
      "Step: 3365, Loss: 0.48008450865745544, Accuracy: 0.90625, Computation time: 0.7470099925994873\n",
      "Step: 3366, Loss: 0.8843730688095093, Accuracy: 0.71875, Computation time: 0.8386869430541992\n",
      "Step: 3367, Loss: 0.6146315336227417, Accuracy: 0.71875, Computation time: 0.727215051651001\n",
      "Step: 3368, Loss: 0.3875155746936798, Accuracy: 0.875, Computation time: 0.787186861038208\n",
      "Step: 3369, Loss: 0.4661228358745575, Accuracy: 0.90625, Computation time: 0.8334829807281494\n",
      "Step: 3370, Loss: 1.0126430988311768, Accuracy: 0.71875, Computation time: 1.2646379470825195\n",
      "Step: 3371, Loss: 0.5587777495384216, Accuracy: 0.78125, Computation time: 0.764847993850708\n",
      "Step: 3372, Loss: 0.4806671142578125, Accuracy: 0.75, Computation time: 0.7451140880584717\n",
      "Step: 3373, Loss: 0.5601970553398132, Accuracy: 0.875, Computation time: 0.7950818538665771\n",
      "Step: 3374, Loss: 0.6913597583770752, Accuracy: 0.8125, Computation time: 1.0620050430297852\n",
      "Step: 3375, Loss: 0.3687005639076233, Accuracy: 0.90625, Computation time: 1.0483169555664062\n",
      "Step: 3376, Loss: 0.5437210202217102, Accuracy: 0.84375, Computation time: 0.8479478359222412\n",
      "Step: 3377, Loss: 1.2450852394104004, Accuracy: 0.65625, Computation time: 0.9016149044036865\n",
      "Step: 3378, Loss: 0.6742637157440186, Accuracy: 0.78125, Computation time: 0.9405958652496338\n",
      "Step: 3379, Loss: 0.6386947631835938, Accuracy: 0.875, Computation time: 0.7292599678039551\n",
      "Step: 3380, Loss: 0.6746813058853149, Accuracy: 0.78125, Computation time: 0.7862372398376465\n",
      "Step: 3381, Loss: 0.4628293514251709, Accuracy: 0.90625, Computation time: 0.826923131942749\n",
      "Step: 3382, Loss: 0.4315592348575592, Accuracy: 0.84375, Computation time: 0.972121000289917\n",
      "Step: 3383, Loss: 0.7164967656135559, Accuracy: 0.78125, Computation time: 1.0353429317474365\n",
      "Step: 3384, Loss: 0.545735239982605, Accuracy: 0.84375, Computation time: 0.748737096786499\n",
      "Step: 3385, Loss: 1.1534395217895508, Accuracy: 0.6875, Computation time: 1.0991528034210205\n",
      "Step: 3386, Loss: 0.39305394887924194, Accuracy: 0.875, Computation time: 0.9045672416687012\n",
      "Step: 3387, Loss: 0.7717891335487366, Accuracy: 0.8125, Computation time: 0.8062760829925537\n",
      "Step: 3388, Loss: 0.9559069871902466, Accuracy: 0.71875, Computation time: 0.7620742321014404\n",
      "Step: 3389, Loss: 0.2747034430503845, Accuracy: 0.9375, Computation time: 0.91996169090271\n",
      "Step: 3390, Loss: 0.3451768159866333, Accuracy: 0.9375, Computation time: 0.7921960353851318\n",
      "Step: 3391, Loss: 0.5366687774658203, Accuracy: 0.875, Computation time: 0.8704559803009033\n",
      "Step: 3392, Loss: 0.43155792355537415, Accuracy: 0.875, Computation time: 902.5149049758911\n",
      "Step: 3393, Loss: 0.36752328276634216, Accuracy: 0.9375, Computation time: 0.7201330661773682\n",
      "Step: 3394, Loss: 0.5319066643714905, Accuracy: 0.84375, Computation time: 0.7373759746551514\n",
      "Step: 3395, Loss: 1.0259305238723755, Accuracy: 0.75, Computation time: 0.8369710445404053\n",
      "Step: 3396, Loss: 0.5996602177619934, Accuracy: 0.75, Computation time: 1.0495100021362305\n",
      "Step: 3397, Loss: 0.6130183935165405, Accuracy: 0.84375, Computation time: 0.7269229888916016\n",
      "Step: 3398, Loss: 0.3650704026222229, Accuracy: 0.9375, Computation time: 0.7147371768951416\n",
      "Step: 3399, Loss: 0.4041420817375183, Accuracy: 0.875, Computation time: 0.9386298656463623\n",
      "Step: 3400, Loss: 0.4721967279911041, Accuracy: 0.90625, Computation time: 0.7774348258972168\n",
      "Step: 3401, Loss: 0.5361626744270325, Accuracy: 0.75, Computation time: 1.0675530433654785\n",
      "Step: 3402, Loss: 0.289852499961853, Accuracy: 0.9375, Computation time: 0.7659447193145752\n",
      "Step: 3403, Loss: 0.33188745379447937, Accuracy: 0.90625, Computation time: 0.8161520957946777\n",
      "Step: 3404, Loss: 0.29883378744125366, Accuracy: 0.875, Computation time: 0.852895975112915\n",
      "Step: 3405, Loss: 0.3776019811630249, Accuracy: 0.90625, Computation time: 0.9626460075378418\n",
      "Step: 3406, Loss: 0.4873882830142975, Accuracy: 0.8125, Computation time: 1.1410331726074219\n",
      "Step: 3407, Loss: 0.6189634203910828, Accuracy: 0.84375, Computation time: 0.8346719741821289\n",
      "Step: 3408, Loss: 0.7499295473098755, Accuracy: 0.8125, Computation time: 0.6587669849395752\n",
      "Step: 3409, Loss: 0.42087557911872864, Accuracy: 0.9375, Computation time: 0.8527050018310547\n",
      "Step: 3410, Loss: 0.6157715916633606, Accuracy: 0.8125, Computation time: 0.9239296913146973\n",
      "Step: 3411, Loss: 0.5364781022071838, Accuracy: 0.84375, Computation time: 0.8329360485076904\n",
      "Step: 3412, Loss: 0.5552040934562683, Accuracy: 0.84375, Computation time: 0.6845479011535645\n",
      "Step: 3413, Loss: 1.18874192237854, Accuracy: 0.65625, Computation time: 0.8061399459838867\n",
      "Step: 3414, Loss: 0.6801930665969849, Accuracy: 0.8125, Computation time: 0.6945569515228271\n",
      "Step: 3415, Loss: 0.39807891845703125, Accuracy: 0.90625, Computation time: 1.2708778381347656\n",
      "Step: 3416, Loss: 0.6543005704879761, Accuracy: 0.84375, Computation time: 0.742509126663208\n",
      "Step: 3417, Loss: 0.5241936445236206, Accuracy: 0.84375, Computation time: 0.728492021560669\n",
      "Step: 3418, Loss: 0.6177736520767212, Accuracy: 0.71875, Computation time: 0.8921961784362793\n",
      "Step: 3419, Loss: 0.33274826407432556, Accuracy: 0.9375, Computation time: 1.4227168560028076\n",
      "Step: 3420, Loss: 0.6638616323471069, Accuracy: 0.78125, Computation time: 0.7208020687103271\n",
      "Step: 3421, Loss: 0.5514020919799805, Accuracy: 0.8125, Computation time: 0.851517915725708\n",
      "Step: 3422, Loss: 0.6576642990112305, Accuracy: 0.78125, Computation time: 0.959263801574707\n",
      "Step: 3423, Loss: 0.5950348377227783, Accuracy: 0.875, Computation time: 1.4395091533660889\n",
      "Step: 3424, Loss: 0.34946107864379883, Accuracy: 0.875, Computation time: 0.7813029289245605\n",
      "Step: 3425, Loss: 0.6447940468788147, Accuracy: 0.75, Computation time: 0.7548849582672119\n",
      "Step: 3426, Loss: 0.6713595390319824, Accuracy: 0.75, Computation time: 0.743614912033081\n",
      "Step: 3427, Loss: 0.4975751042366028, Accuracy: 0.8125, Computation time: 0.7733700275421143\n",
      "Step: 3428, Loss: 0.48634597659111023, Accuracy: 0.875, Computation time: 0.8645739555358887\n",
      "Step: 3429, Loss: 0.41191259026527405, Accuracy: 0.90625, Computation time: 0.8364059925079346\n",
      "Step: 3430, Loss: 0.45363524556159973, Accuracy: 0.875, Computation time: 0.6793978214263916\n",
      "Step: 3431, Loss: 0.4289523959159851, Accuracy: 0.90625, Computation time: 0.844200849533081\n",
      "Step: 3432, Loss: 0.6179589033126831, Accuracy: 0.84375, Computation time: 0.7951240539550781\n",
      "Step: 3433, Loss: 0.933155357837677, Accuracy: 0.78125, Computation time: 0.7355198860168457\n",
      "Step: 3434, Loss: 0.3924877941608429, Accuracy: 0.875, Computation time: 0.8139238357543945\n",
      "Step: 3435, Loss: 0.3657381534576416, Accuracy: 0.875, Computation time: 0.9463870525360107\n",
      "Step: 3436, Loss: 0.4829062819480896, Accuracy: 0.78125, Computation time: 0.8903870582580566\n",
      "Step: 3437, Loss: 1.1866436004638672, Accuracy: 0.6875, Computation time: 0.7878670692443848\n",
      "Step: 3438, Loss: 0.8230755925178528, Accuracy: 0.6875, Computation time: 0.7584612369537354\n",
      "Step: 3439, Loss: 0.7662288546562195, Accuracy: 0.78125, Computation time: 0.7044191360473633\n",
      "Step: 3440, Loss: 0.4652427136898041, Accuracy: 0.90625, Computation time: 1.0193719863891602\n",
      "Step: 3441, Loss: 0.22299273312091827, Accuracy: 0.9375, Computation time: 0.8257348537445068\n",
      "Step: 3442, Loss: 0.47793158888816833, Accuracy: 0.8125, Computation time: 0.8157639503479004\n",
      "Step: 3443, Loss: 0.5525109767913818, Accuracy: 0.78125, Computation time: 0.9021871089935303\n",
      "Step: 3444, Loss: 0.39751771092414856, Accuracy: 0.875, Computation time: 0.8549449443817139\n",
      "Step: 3445, Loss: 0.3966323435306549, Accuracy: 0.84375, Computation time: 0.8892486095428467\n",
      "Step: 3446, Loss: 0.4250338673591614, Accuracy: 0.875, Computation time: 1.080820083618164\n",
      "Step: 3447, Loss: 0.6042206883430481, Accuracy: 0.78125, Computation time: 0.9297828674316406\n",
      "Step: 3448, Loss: 0.38102900981903076, Accuracy: 0.90625, Computation time: 0.7429239749908447\n",
      "Step: 3449, Loss: 0.5733420848846436, Accuracy: 0.8125, Computation time: 0.9827749729156494\n",
      "Step: 3450, Loss: 0.7646579742431641, Accuracy: 0.71875, Computation time: 0.9348311424255371\n",
      "Step: 3451, Loss: 0.28916117548942566, Accuracy: 0.90625, Computation time: 0.8885579109191895\n",
      "Step: 3452, Loss: 0.4309207797050476, Accuracy: 0.84375, Computation time: 0.9931199550628662\n",
      "Step: 3453, Loss: 0.6134223937988281, Accuracy: 0.8125, Computation time: 0.8281190395355225\n",
      "Step: 3454, Loss: 0.6876471042633057, Accuracy: 0.84375, Computation time: 0.742048978805542\n",
      "Step: 3455, Loss: 0.295926570892334, Accuracy: 0.90625, Computation time: 0.8412070274353027\n",
      "Step: 3456, Loss: 0.48083385825157166, Accuracy: 0.8125, Computation time: 0.7458181381225586\n",
      "Step: 3457, Loss: 0.6175729632377625, Accuracy: 0.8125, Computation time: 0.7938559055328369\n",
      "Step: 3458, Loss: 0.5691882371902466, Accuracy: 0.84375, Computation time: 0.6993451118469238\n",
      "Step: 3459, Loss: 0.45015907287597656, Accuracy: 0.875, Computation time: 0.8146820068359375\n",
      "Step: 3460, Loss: 0.5571762323379517, Accuracy: 0.84375, Computation time: 0.7922310829162598\n",
      "Step: 3461, Loss: 0.7933754920959473, Accuracy: 0.78125, Computation time: 0.7400898933410645\n",
      "Step: 3462, Loss: 0.7444964051246643, Accuracy: 0.8125, Computation time: 0.8246810436248779\n",
      "Step: 3463, Loss: 0.4670630991458893, Accuracy: 0.84375, Computation time: 0.948232889175415\n",
      "Step: 3464, Loss: 0.4490637183189392, Accuracy: 0.875, Computation time: 0.9074759483337402\n",
      "Step: 3465, Loss: 0.517139732837677, Accuracy: 0.84375, Computation time: 0.767509937286377\n",
      "Step: 3466, Loss: 0.7438265085220337, Accuracy: 0.84375, Computation time: 0.8028547763824463\n",
      "Step: 3467, Loss: 0.7827484607696533, Accuracy: 0.71875, Computation time: 0.8461482524871826\n",
      "Step: 3468, Loss: 0.48309192061424255, Accuracy: 0.875, Computation time: 0.7724051475524902\n",
      "Step: 3469, Loss: 0.5407531261444092, Accuracy: 0.875, Computation time: 0.824444055557251\n",
      "Step: 3470, Loss: 0.7471029758453369, Accuracy: 0.75, Computation time: 0.8635499477386475\n",
      "Step: 3471, Loss: 0.6584957242012024, Accuracy: 0.75, Computation time: 0.8111801147460938\n",
      "Step: 3472, Loss: 0.32800355553627014, Accuracy: 0.90625, Computation time: 0.7745749950408936\n",
      "Step: 3473, Loss: 0.45000946521759033, Accuracy: 0.9375, Computation time: 0.7215049266815186\n",
      "Step: 3474, Loss: 0.7094400525093079, Accuracy: 0.78125, Computation time: 0.8854818344116211\n",
      "Step: 3475, Loss: 0.3423651158809662, Accuracy: 0.875, Computation time: 0.9277560710906982\n",
      "Step: 3476, Loss: 0.3590456545352936, Accuracy: 0.875, Computation time: 0.9133059978485107\n",
      "Step: 3477, Loss: 0.5930327773094177, Accuracy: 0.75, Computation time: 0.8688111305236816\n",
      "Step: 3478, Loss: 0.30276191234588623, Accuracy: 0.875, Computation time: 1.0430221557617188\n",
      "Step: 3479, Loss: 0.4216083586215973, Accuracy: 0.84375, Computation time: 1.0088517665863037\n",
      "Step: 3480, Loss: 0.4559779465198517, Accuracy: 0.84375, Computation time: 0.8251762390136719\n",
      "Step: 3481, Loss: 0.40161585807800293, Accuracy: 0.84375, Computation time: 0.9307379722595215\n",
      "Step: 3482, Loss: 0.525878369808197, Accuracy: 0.78125, Computation time: 0.9084758758544922\n",
      "Step: 3483, Loss: 0.556735634803772, Accuracy: 0.8125, Computation time: 0.7585511207580566\n",
      "Step: 3484, Loss: 0.5984696745872498, Accuracy: 0.8125, Computation time: 0.8824079036712646\n",
      "Step: 3485, Loss: 0.43889448046684265, Accuracy: 0.8125, Computation time: 0.8070509433746338\n",
      "Step: 3486, Loss: 0.5266039967536926, Accuracy: 0.84375, Computation time: 0.9161882400512695\n",
      "Step: 3487, Loss: 0.6596637964248657, Accuracy: 0.84375, Computation time: 0.7598788738250732\n",
      "Step: 3488, Loss: 0.5271286368370056, Accuracy: 0.8125, Computation time: 0.8163089752197266\n",
      "Step: 3489, Loss: 0.4285765588283539, Accuracy: 0.84375, Computation time: 0.7799620628356934\n",
      "Step: 3490, Loss: 0.5291480422019958, Accuracy: 0.84375, Computation time: 0.8516111373901367\n",
      "Step: 3491, Loss: 0.7087506055831909, Accuracy: 0.8125, Computation time: 0.8450131416320801\n",
      "Step: 3492, Loss: 0.38734400272369385, Accuracy: 0.84375, Computation time: 0.734503984451294\n",
      "Step: 3493, Loss: 0.473688542842865, Accuracy: 0.84375, Computation time: 0.8296341896057129\n",
      "Step: 3494, Loss: 0.41136690974235535, Accuracy: 0.84375, Computation time: 0.8106837272644043\n",
      "Step: 3495, Loss: 0.6099198460578918, Accuracy: 0.84375, Computation time: 0.9405906200408936\n",
      "Step: 3496, Loss: 0.4215347468852997, Accuracy: 0.8125, Computation time: 0.8933570384979248\n",
      "Step: 3497, Loss: 0.3944503366947174, Accuracy: 0.84375, Computation time: 0.9721131324768066\n",
      "Step: 3498, Loss: 0.7780780792236328, Accuracy: 0.78125, Computation time: 0.9457809925079346\n",
      "Step: 3499, Loss: 0.3765365779399872, Accuracy: 0.84375, Computation time: 0.779428243637085\n",
      "Step: 3500, Loss: 0.5119092464447021, Accuracy: 0.78125, Computation time: 0.6616020202636719\n",
      "Step: 3501, Loss: 0.5863320827484131, Accuracy: 0.84375, Computation time: 0.7763051986694336\n",
      "Step: 3502, Loss: 0.4272018074989319, Accuracy: 0.84375, Computation time: 0.9168660640716553\n",
      "Step: 3503, Loss: 0.6689003109931946, Accuracy: 0.8125, Computation time: 0.8844637870788574\n",
      "Step: 3504, Loss: 0.4454430043697357, Accuracy: 0.84375, Computation time: 1.0894787311553955\n",
      "Step: 3505, Loss: 0.5820414423942566, Accuracy: 0.84375, Computation time: 0.9561190605163574\n",
      "Step: 3506, Loss: 0.5215855836868286, Accuracy: 0.8125, Computation time: 0.7138869762420654\n",
      "Step: 3507, Loss: 0.577049732208252, Accuracy: 0.78125, Computation time: 0.799232006072998\n",
      "Step: 3508, Loss: 0.6782492995262146, Accuracy: 0.84375, Computation time: 0.875324010848999\n",
      "Step: 3509, Loss: 0.4337676465511322, Accuracy: 0.875, Computation time: 0.7957231998443604\n",
      "Step: 3510, Loss: 1.015576958656311, Accuracy: 0.8125, Computation time: 1.4651501178741455\n",
      "Step: 3511, Loss: 0.5660123229026794, Accuracy: 0.84375, Computation time: 0.7783007621765137\n",
      "Step: 3512, Loss: 0.4303029179573059, Accuracy: 0.90625, Computation time: 0.7510240077972412\n",
      "Step: 3513, Loss: 0.6408199667930603, Accuracy: 0.8125, Computation time: 0.8409268856048584\n",
      "Step: 3514, Loss: 0.7891688346862793, Accuracy: 0.78125, Computation time: 0.9128880500793457\n",
      "Step: 3515, Loss: 0.7647783756256104, Accuracy: 0.78125, Computation time: 0.7336540222167969\n",
      "Step: 3516, Loss: 0.6335299015045166, Accuracy: 0.84375, Computation time: 0.86586594581604\n",
      "Step: 3517, Loss: 0.5372953414916992, Accuracy: 0.78125, Computation time: 0.6961541175842285\n",
      "Step: 3518, Loss: 0.6538676619529724, Accuracy: 0.78125, Computation time: 0.8033061027526855\n",
      "Step: 3519, Loss: 0.6624629497528076, Accuracy: 0.8125, Computation time: 0.8929080963134766\n",
      "Step: 3520, Loss: 0.5804214477539062, Accuracy: 0.84375, Computation time: 0.8301670551300049\n",
      "Step: 3521, Loss: 0.5016277432441711, Accuracy: 0.875, Computation time: 0.8428380489349365\n",
      "Step: 3522, Loss: 0.6532289981842041, Accuracy: 0.8125, Computation time: 0.8185739517211914\n",
      "Step: 3523, Loss: 0.8088162541389465, Accuracy: 0.6875, Computation time: 0.6886801719665527\n",
      "Step: 3524, Loss: 0.8906025290489197, Accuracy: 0.71875, Computation time: 0.824894905090332\n",
      "Step: 3525, Loss: 0.6811923384666443, Accuracy: 0.84375, Computation time: 0.8649888038635254\n",
      "Step: 3526, Loss: 0.3709666430950165, Accuracy: 0.84375, Computation time: 0.6960411071777344\n",
      "Step: 3527, Loss: 0.6512932777404785, Accuracy: 0.8125, Computation time: 0.8025877475738525\n",
      "Step: 3528, Loss: 0.7731726765632629, Accuracy: 0.6875, Computation time: 0.754223108291626\n",
      "Step: 3529, Loss: 1.0126227140426636, Accuracy: 0.6875, Computation time: 0.831993818283081\n",
      "Step: 3530, Loss: 1.2486598491668701, Accuracy: 0.59375, Computation time: 0.8941929340362549\n",
      "Step: 3531, Loss: 0.958267092704773, Accuracy: 0.75, Computation time: 0.8837661743164062\n",
      "Step: 3532, Loss: 0.9034332633018494, Accuracy: 0.625, Computation time: 0.8527750968933105\n",
      "Step: 3533, Loss: 0.4416373372077942, Accuracy: 0.78125, Computation time: 0.7674870491027832\n",
      "Step: 3534, Loss: 0.3290652930736542, Accuracy: 0.90625, Computation time: 0.7273142337799072\n",
      "Step: 3535, Loss: 0.527824878692627, Accuracy: 0.8125, Computation time: 0.8360528945922852\n",
      "Step: 3536, Loss: 0.5963422656059265, Accuracy: 0.8125, Computation time: 0.9745452404022217\n",
      "Step: 3537, Loss: 0.5530363917350769, Accuracy: 0.875, Computation time: 0.8147482872009277\n",
      "Step: 3538, Loss: 0.5861965417861938, Accuracy: 0.78125, Computation time: 0.7977991104125977\n",
      "Step: 3539, Loss: 0.7581407427787781, Accuracy: 0.84375, Computation time: 0.8372910022735596\n",
      "Step: 3540, Loss: 0.8256231546401978, Accuracy: 0.71875, Computation time: 0.9069287776947021\n",
      "Step: 3541, Loss: 0.8526245355606079, Accuracy: 0.71875, Computation time: 1.742460012435913\n",
      "Step: 3542, Loss: 0.41845524311065674, Accuracy: 0.875, Computation time: 0.7488830089569092\n",
      "Step: 3543, Loss: 0.47518298029899597, Accuracy: 0.8125, Computation time: 0.7919559478759766\n",
      "Step: 3544, Loss: 0.7661232948303223, Accuracy: 0.75, Computation time: 0.6984000205993652\n",
      "Step: 3545, Loss: 0.5370185971260071, Accuracy: 0.8125, Computation time: 0.8479921817779541\n",
      "Step: 3546, Loss: 0.8930021524429321, Accuracy: 0.75, Computation time: 0.6869668960571289\n",
      "Step: 3547, Loss: 0.9787226319313049, Accuracy: 0.75, Computation time: 0.8606541156768799\n",
      "Step: 3548, Loss: 0.6951727867126465, Accuracy: 0.78125, Computation time: 0.7078349590301514\n",
      "Step: 3549, Loss: 0.9026057720184326, Accuracy: 0.8125, Computation time: 0.8140029907226562\n",
      "Step: 3550, Loss: 0.4440104067325592, Accuracy: 0.84375, Computation time: 0.7559912204742432\n",
      "Step: 3551, Loss: 0.583409309387207, Accuracy: 0.84375, Computation time: 0.8556962013244629\n",
      "Step: 3552, Loss: 0.6262430548667908, Accuracy: 0.875, Computation time: 0.7937819957733154\n",
      "Step: 3553, Loss: 0.8133213520050049, Accuracy: 0.75, Computation time: 0.792341947555542\n",
      "Step: 3554, Loss: 0.955965518951416, Accuracy: 0.78125, Computation time: 0.78727126121521\n",
      "Step: 3555, Loss: 0.5709753632545471, Accuracy: 0.84375, Computation time: 1.1591551303863525\n",
      "Step: 3556, Loss: 0.6256150007247925, Accuracy: 0.75, Computation time: 0.9421460628509521\n",
      "Step: 3557, Loss: 0.7232438921928406, Accuracy: 0.71875, Computation time: 0.8586690425872803\n",
      "Step: 3558, Loss: 0.6370770335197449, Accuracy: 0.8125, Computation time: 0.791456937789917\n",
      "Step: 3559, Loss: 0.5357469916343689, Accuracy: 0.84375, Computation time: 0.661736011505127\n",
      "Step: 3560, Loss: 0.6634626388549805, Accuracy: 0.78125, Computation time: 1.0220870971679688\n",
      "Step: 3561, Loss: 0.6668006181716919, Accuracy: 0.78125, Computation time: 0.7482497692108154\n",
      "Step: 3562, Loss: 0.3526690900325775, Accuracy: 0.875, Computation time: 0.7608740329742432\n",
      "Step: 3563, Loss: 0.5323203802108765, Accuracy: 0.875, Computation time: 0.6406261920928955\n",
      "Step: 3564, Loss: 0.4337892532348633, Accuracy: 0.875, Computation time: 0.8131303787231445\n",
      "Step: 3565, Loss: 1.2070019245147705, Accuracy: 0.625, Computation time: 0.8296518325805664\n",
      "Step: 3566, Loss: 0.45839545130729675, Accuracy: 0.875, Computation time: 0.7543520927429199\n",
      "Step: 3567, Loss: 0.4645358622074127, Accuracy: 0.84375, Computation time: 0.7877471446990967\n",
      "Step: 3568, Loss: 0.7767698764801025, Accuracy: 0.75, Computation time: 0.6822590827941895\n",
      "Step: 3569, Loss: 0.35985130071640015, Accuracy: 0.875, Computation time: 0.708197832107544\n",
      "Step: 3570, Loss: 0.5886133313179016, Accuracy: 0.75, Computation time: 0.7179229259490967\n",
      "Step: 3571, Loss: 0.6263434886932373, Accuracy: 0.78125, Computation time: 0.7725131511688232\n",
      "Step: 3572, Loss: 0.374288946390152, Accuracy: 0.875, Computation time: 0.8266189098358154\n",
      "Step: 3573, Loss: 0.6799101829528809, Accuracy: 0.78125, Computation time: 0.774094820022583\n",
      "Step: 3574, Loss: 0.7439529299736023, Accuracy: 0.75, Computation time: 0.8536887168884277\n",
      "Step: 3575, Loss: 0.9134684205055237, Accuracy: 0.75, Computation time: 1.7094731330871582\n",
      "Step: 3576, Loss: 0.6355313658714294, Accuracy: 0.875, Computation time: 0.6490659713745117\n",
      "Step: 3577, Loss: 0.4195963144302368, Accuracy: 0.84375, Computation time: 0.770545244216919\n",
      "Step: 3578, Loss: 0.9251788258552551, Accuracy: 0.78125, Computation time: 0.8438341617584229\n",
      "Step: 3579, Loss: 0.42436888813972473, Accuracy: 0.875, Computation time: 0.8876957893371582\n",
      "Step: 3580, Loss: 0.6928254961967468, Accuracy: 0.78125, Computation time: 0.729266881942749\n",
      "Step: 3581, Loss: 0.815245509147644, Accuracy: 0.75, Computation time: 0.8597171306610107\n",
      "Step: 3582, Loss: 0.6013652086257935, Accuracy: 0.8125, Computation time: 0.7844529151916504\n",
      "Step: 3583, Loss: 0.2824411988258362, Accuracy: 0.9375, Computation time: 0.956345796585083\n",
      "Step: 3584, Loss: 0.5635123252868652, Accuracy: 0.8125, Computation time: 0.8204348087310791\n",
      "Step: 3585, Loss: 0.875541627407074, Accuracy: 0.78125, Computation time: 0.6740751266479492\n",
      "Step: 3586, Loss: 0.3919173777103424, Accuracy: 0.8125, Computation time: 0.7364060878753662\n",
      "Step: 3587, Loss: 0.8985899686813354, Accuracy: 0.71875, Computation time: 0.7650072574615479\n",
      "Step: 3588, Loss: 0.910087525844574, Accuracy: 0.78125, Computation time: 0.9134800434112549\n",
      "Step: 3589, Loss: 0.35153770446777344, Accuracy: 0.90625, Computation time: 0.7921268939971924\n",
      "Step: 3590, Loss: 0.28090959787368774, Accuracy: 0.9375, Computation time: 0.8072209358215332\n",
      "Step: 3591, Loss: 0.7867769002914429, Accuracy: 0.84375, Computation time: 0.9470069408416748\n",
      "Step: 3592, Loss: 0.6891643404960632, Accuracy: 0.8125, Computation time: 0.7955090999603271\n",
      "Step: 3593, Loss: 0.5721327662467957, Accuracy: 0.875, Computation time: 0.8462238311767578\n",
      "Step: 3594, Loss: 0.7112071514129639, Accuracy: 0.75, Computation time: 0.6270959377288818\n",
      "Step: 3595, Loss: 0.3653837740421295, Accuracy: 0.90625, Computation time: 0.8113400936126709\n",
      "Step: 3596, Loss: 0.7766590118408203, Accuracy: 0.84375, Computation time: 0.7857882976531982\n",
      "Step: 3597, Loss: 0.5341932773590088, Accuracy: 0.75, Computation time: 0.6908857822418213\n",
      "Step: 3598, Loss: 1.0735630989074707, Accuracy: 0.6875, Computation time: 0.9151279926300049\n",
      "Step: 3599, Loss: 0.6841965913772583, Accuracy: 0.75, Computation time: 0.944133996963501\n",
      "Step: 3600, Loss: 0.3921084403991699, Accuracy: 0.9375, Computation time: 0.8231379985809326\n",
      "Step: 3601, Loss: 0.7428913116455078, Accuracy: 0.78125, Computation time: 0.8859331607818604\n",
      "Step: 3602, Loss: 0.4533357620239258, Accuracy: 0.84375, Computation time: 1.1277120113372803\n",
      "Step: 3603, Loss: 0.4126313030719757, Accuracy: 0.84375, Computation time: 0.7591228485107422\n",
      "Step: 3604, Loss: 0.2620346248149872, Accuracy: 0.96875, Computation time: 0.8008346557617188\n",
      "Step: 3605, Loss: 0.6731035113334656, Accuracy: 0.8125, Computation time: 0.8979699611663818\n",
      "Step: 3606, Loss: 1.3246203660964966, Accuracy: 0.65625, Computation time: 0.7199020385742188\n",
      "Step: 3607, Loss: 0.41063612699508667, Accuracy: 0.875, Computation time: 1.3395559787750244\n",
      "Step: 3608, Loss: 0.4648997187614441, Accuracy: 0.8125, Computation time: 0.6653139591217041\n",
      "Step: 3609, Loss: 0.545837938785553, Accuracy: 0.8125, Computation time: 0.8097667694091797\n",
      "Step: 3610, Loss: 0.6208429336547852, Accuracy: 0.78125, Computation time: 0.8117749691009521\n",
      "Step: 3611, Loss: 0.5536794066429138, Accuracy: 0.875, Computation time: 0.8058280944824219\n",
      "Step: 3612, Loss: 0.6064630150794983, Accuracy: 0.78125, Computation time: 0.8414061069488525\n",
      "Step: 3613, Loss: 0.6277769804000854, Accuracy: 0.71875, Computation time: 0.763679027557373\n",
      "Step: 3614, Loss: 1.238578200340271, Accuracy: 0.75, Computation time: 0.7194919586181641\n",
      "Step: 3615, Loss: 0.4927973747253418, Accuracy: 0.8125, Computation time: 1.0068840980529785\n",
      "Step: 3616, Loss: 0.80218505859375, Accuracy: 0.84375, Computation time: 0.7741661071777344\n",
      "Step: 3617, Loss: 0.3231744170188904, Accuracy: 0.90625, Computation time: 1.1269466876983643\n",
      "Step: 3618, Loss: 0.3850271701812744, Accuracy: 0.84375, Computation time: 0.6468691825866699\n",
      "Step: 3619, Loss: 0.5090911984443665, Accuracy: 0.78125, Computation time: 0.7666769027709961\n",
      "Step: 3620, Loss: 0.8036457300186157, Accuracy: 0.84375, Computation time: 0.9150881767272949\n",
      "Step: 3621, Loss: 0.4716722071170807, Accuracy: 0.875, Computation time: 0.7521059513092041\n",
      "Step: 3622, Loss: 0.945396900177002, Accuracy: 0.78125, Computation time: 0.9141840934753418\n",
      "Step: 3623, Loss: 0.29627400636672974, Accuracy: 0.875, Computation time: 1.1123740673065186\n",
      "Step: 3624, Loss: 0.7267066240310669, Accuracy: 0.78125, Computation time: 0.7700321674346924\n",
      "Step: 3625, Loss: 0.24009203910827637, Accuracy: 0.96875, Computation time: 0.7856230735778809\n",
      "Step: 3626, Loss: 0.3453986942768097, Accuracy: 0.84375, Computation time: 0.822350263595581\n",
      "Step: 3627, Loss: 0.2745548188686371, Accuracy: 0.9375, Computation time: 0.7805848121643066\n",
      "Step: 3628, Loss: 0.6161988377571106, Accuracy: 0.8125, Computation time: 0.6649510860443115\n",
      "Step: 3629, Loss: 0.4834348261356354, Accuracy: 0.875, Computation time: 0.901695966720581\n",
      "Step: 3630, Loss: 0.6333469152450562, Accuracy: 0.78125, Computation time: 0.7003569602966309\n",
      "Step: 3631, Loss: 1.193925380706787, Accuracy: 0.71875, Computation time: 0.8945369720458984\n",
      "Step: 3632, Loss: 0.5497254133224487, Accuracy: 0.75, Computation time: 0.9097051620483398\n",
      "Step: 3633, Loss: 0.4336356520652771, Accuracy: 0.875, Computation time: 0.7619397640228271\n",
      "Step: 3634, Loss: 0.5802052021026611, Accuracy: 0.75, Computation time: 1.1136329174041748\n",
      "Step: 3635, Loss: 0.37253373861312866, Accuracy: 0.90625, Computation time: 0.7314138412475586\n",
      "Step: 3636, Loss: 0.8038468360900879, Accuracy: 0.84375, Computation time: 0.9322178363800049\n",
      "Step: 3637, Loss: 0.6718165874481201, Accuracy: 0.84375, Computation time: 1.1568009853363037\n",
      "Step: 3638, Loss: 0.5631535053253174, Accuracy: 0.84375, Computation time: 0.7463898658752441\n",
      "Step: 3639, Loss: 1.18464994430542, Accuracy: 0.71875, Computation time: 0.8993000984191895\n",
      "Step: 3640, Loss: 0.7920650243759155, Accuracy: 0.75, Computation time: 0.8415501117706299\n",
      "Step: 3641, Loss: 0.6613657474517822, Accuracy: 0.78125, Computation time: 0.7580502033233643\n",
      "Step: 3642, Loss: 0.7313152551651001, Accuracy: 0.84375, Computation time: 0.7961540222167969\n",
      "Step: 3643, Loss: 0.7077437043190002, Accuracy: 0.8125, Computation time: 0.730571985244751\n",
      "Step: 3644, Loss: 0.7305517196655273, Accuracy: 0.75, Computation time: 0.7760589122772217\n",
      "Step: 3645, Loss: 0.7639753818511963, Accuracy: 0.8125, Computation time: 0.8653481006622314\n",
      "Step: 3646, Loss: 0.3878857493400574, Accuracy: 0.9375, Computation time: 0.7718410491943359\n",
      "Step: 3647, Loss: 1.0781103372573853, Accuracy: 0.71875, Computation time: 0.7823817729949951\n",
      "Step: 3648, Loss: 0.523834228515625, Accuracy: 0.8125, Computation time: 0.9673247337341309\n",
      "Step: 3649, Loss: 0.4175439178943634, Accuracy: 0.84375, Computation time: 1.041489839553833\n",
      "Step: 3650, Loss: 0.3690546452999115, Accuracy: 0.90625, Computation time: 0.7718760967254639\n",
      "Step: 3651, Loss: 0.4373988211154938, Accuracy: 0.8125, Computation time: 1.0014808177947998\n",
      "Step: 3652, Loss: 0.42850416898727417, Accuracy: 0.84375, Computation time: 0.8082399368286133\n",
      "Step: 3653, Loss: 0.9377492666244507, Accuracy: 0.65625, Computation time: 0.8141260147094727\n",
      "Step: 3654, Loss: 0.4772009253501892, Accuracy: 0.84375, Computation time: 0.8542790412902832\n",
      "Step: 3655, Loss: 0.7287400960922241, Accuracy: 0.78125, Computation time: 0.832859992980957\n",
      "Step: 3656, Loss: 0.7998576164245605, Accuracy: 0.8125, Computation time: 0.7758500576019287\n",
      "Step: 3657, Loss: 0.7468351721763611, Accuracy: 0.84375, Computation time: 1.0402870178222656\n",
      "Step: 3658, Loss: 0.5742329359054565, Accuracy: 0.84375, Computation time: 0.8928360939025879\n",
      "Step: 3659, Loss: 0.6198163032531738, Accuracy: 0.875, Computation time: 0.8873631954193115\n",
      "Step: 3660, Loss: 0.5686852335929871, Accuracy: 0.84375, Computation time: 0.7615060806274414\n",
      "Step: 3661, Loss: 0.34312254190444946, Accuracy: 0.875, Computation time: 0.7754979133605957\n",
      "Step: 3662, Loss: 0.28917062282562256, Accuracy: 0.9375, Computation time: 0.7085070610046387\n",
      "Step: 3663, Loss: 0.3457304835319519, Accuracy: 0.84375, Computation time: 0.8567838668823242\n",
      "Step: 3664, Loss: 0.5534078478813171, Accuracy: 0.84375, Computation time: 1.3110079765319824\n",
      "Step: 3665, Loss: 0.7172293066978455, Accuracy: 0.71875, Computation time: 0.6635429859161377\n",
      "Step: 3666, Loss: 0.6348910331726074, Accuracy: 0.8125, Computation time: 0.800635814666748\n",
      "Step: 3667, Loss: 0.68644118309021, Accuracy: 0.84375, Computation time: 0.7533438205718994\n",
      "Step: 3668, Loss: 0.5935904383659363, Accuracy: 0.90625, Computation time: 0.9553630352020264\n",
      "Step: 3669, Loss: 0.7213611602783203, Accuracy: 0.8125, Computation time: 0.7737991809844971\n",
      "Step: 3670, Loss: 0.6549489498138428, Accuracy: 0.78125, Computation time: 1.2393109798431396\n",
      "Step: 3671, Loss: 0.4291429817676544, Accuracy: 0.84375, Computation time: 0.8231618404388428\n",
      "Step: 3672, Loss: 0.5882028937339783, Accuracy: 0.75, Computation time: 0.8626539707183838\n",
      "Step: 3673, Loss: 0.48863154649734497, Accuracy: 0.84375, Computation time: 0.9380552768707275\n",
      "Step: 3674, Loss: 0.5513744354248047, Accuracy: 0.875, Computation time: 0.8423061370849609\n",
      "Step: 3675, Loss: 0.5450450778007507, Accuracy: 0.8125, Computation time: 0.8185379505157471\n",
      "Step: 3676, Loss: 0.48777225613594055, Accuracy: 0.78125, Computation time: 0.7444751262664795\n",
      "Step: 3677, Loss: 0.7797726988792419, Accuracy: 0.875, Computation time: 0.8759281635284424\n",
      "Step: 3678, Loss: 0.3899218440055847, Accuracy: 0.9375, Computation time: 0.8547229766845703\n",
      "Step: 3679, Loss: 0.45475098490715027, Accuracy: 0.875, Computation time: 0.8207991123199463\n",
      "Step: 3680, Loss: 0.5390632152557373, Accuracy: 0.875, Computation time: 0.8224477767944336\n",
      "Step: 3681, Loss: 0.577022135257721, Accuracy: 0.84375, Computation time: 0.8549659252166748\n",
      "Step: 3682, Loss: 0.4703889787197113, Accuracy: 0.875, Computation time: 0.6714410781860352\n",
      "Step: 3683, Loss: 0.6057739853858948, Accuracy: 0.8125, Computation time: 975.0342209339142\n",
      "Step: 3684, Loss: 0.3492330014705658, Accuracy: 0.90625, Computation time: 0.754086971282959\n",
      "Step: 3685, Loss: 0.507886528968811, Accuracy: 0.84375, Computation time: 1.0413408279418945\n",
      "Step: 3686, Loss: 0.3612324595451355, Accuracy: 0.84375, Computation time: 0.9670698642730713\n",
      "Step: 3687, Loss: 0.8977696895599365, Accuracy: 0.6875, Computation time: 0.8585360050201416\n",
      "Step: 3688, Loss: 0.3403128385543823, Accuracy: 0.9375, Computation time: 1.0035390853881836\n",
      "Step: 3689, Loss: 0.6688999533653259, Accuracy: 0.71875, Computation time: 0.8291199207305908\n",
      "Step: 3690, Loss: 0.627314567565918, Accuracy: 0.84375, Computation time: 0.6871709823608398\n",
      "Step: 3691, Loss: 0.7763427495956421, Accuracy: 0.75, Computation time: 0.6634800434112549\n",
      "Step: 3692, Loss: 0.5682596564292908, Accuracy: 0.78125, Computation time: 0.6873250007629395\n",
      "Step: 3693, Loss: 0.9379441738128662, Accuracy: 0.71875, Computation time: 0.7305269241333008\n",
      "Step: 3694, Loss: 0.7285117506980896, Accuracy: 0.8125, Computation time: 0.8479659557342529\n",
      "Step: 3695, Loss: 0.7645170092582703, Accuracy: 0.75, Computation time: 0.907444953918457\n",
      "Step: 3696, Loss: 0.5598649978637695, Accuracy: 0.78125, Computation time: 0.8670437335968018\n",
      "Step: 3697, Loss: 0.4898664653301239, Accuracy: 0.84375, Computation time: 0.8885719776153564\n",
      "Step: 3698, Loss: 0.6239858865737915, Accuracy: 0.875, Computation time: 0.8375051021575928\n",
      "Step: 3699, Loss: 0.4721266031265259, Accuracy: 0.875, Computation time: 0.8924300670623779\n",
      "Step: 3700, Loss: 0.37251707911491394, Accuracy: 0.875, Computation time: 1.0723011493682861\n",
      "Step: 3701, Loss: 0.8650102615356445, Accuracy: 0.75, Computation time: 1.3729281425476074\n",
      "Step: 3702, Loss: 0.5876034498214722, Accuracy: 0.90625, Computation time: 0.9202840328216553\n",
      "Step: 3703, Loss: 0.5603329539299011, Accuracy: 0.84375, Computation time: 0.7835662364959717\n",
      "Step: 3704, Loss: 0.9144914746284485, Accuracy: 0.6875, Computation time: 0.8112509250640869\n",
      "Step: 3705, Loss: 1.0277389287948608, Accuracy: 0.71875, Computation time: 0.8234901428222656\n",
      "Step: 3706, Loss: 0.37844255566596985, Accuracy: 0.90625, Computation time: 0.6697819232940674\n",
      "Step: 3707, Loss: 0.8689339756965637, Accuracy: 0.75, Computation time: 0.8906099796295166\n",
      "Step: 3708, Loss: 0.4989064037799835, Accuracy: 0.8125, Computation time: 0.8997800350189209\n",
      "Step: 3709, Loss: 0.7376852035522461, Accuracy: 0.8125, Computation time: 0.7655460834503174\n",
      "Step: 3710, Loss: 0.3026035726070404, Accuracy: 0.96875, Computation time: 0.7013950347900391\n",
      "Step: 3711, Loss: 0.9308731555938721, Accuracy: 0.8125, Computation time: 0.873344898223877\n",
      "Step: 3712, Loss: 0.6110259294509888, Accuracy: 0.8125, Computation time: 0.8051667213439941\n",
      "Step: 3713, Loss: 0.40738996863365173, Accuracy: 0.875, Computation time: 0.8395571708679199\n",
      "Step: 3714, Loss: 0.3247065544128418, Accuracy: 0.84375, Computation time: 0.7913227081298828\n",
      "Step: 3715, Loss: 0.3137911856174469, Accuracy: 0.9375, Computation time: 0.7735979557037354\n",
      "Step: 3716, Loss: 0.8441596627235413, Accuracy: 0.78125, Computation time: 1.0026960372924805\n",
      "Step: 3717, Loss: 0.9093033075332642, Accuracy: 0.6875, Computation time: 0.8305628299713135\n",
      "Step: 3718, Loss: 0.5531460642814636, Accuracy: 0.8125, Computation time: 0.8738207817077637\n",
      "Step: 3719, Loss: 0.5663912296295166, Accuracy: 0.78125, Computation time: 0.7811031341552734\n",
      "Step: 3720, Loss: 0.6284937858581543, Accuracy: 0.8125, Computation time: 0.8253040313720703\n",
      "Step: 3721, Loss: 0.4560852646827698, Accuracy: 0.90625, Computation time: 0.90785813331604\n",
      "Step: 3722, Loss: 0.7849814891815186, Accuracy: 0.75, Computation time: 0.7928321361541748\n",
      "Step: 3723, Loss: 0.45653021335601807, Accuracy: 0.8125, Computation time: 0.9138059616088867\n",
      "Step: 3724, Loss: 0.5835456848144531, Accuracy: 0.84375, Computation time: 0.8143489360809326\n",
      "Step: 3725, Loss: 0.5148724913597107, Accuracy: 0.875, Computation time: 0.7899739742279053\n",
      "Step: 3726, Loss: 0.46570885181427, Accuracy: 0.84375, Computation time: 0.7086746692657471\n",
      "Step: 3727, Loss: 0.5544942021369934, Accuracy: 0.8125, Computation time: 0.7915980815887451\n",
      "Step: 3728, Loss: 0.8054295182228088, Accuracy: 0.75, Computation time: 0.869797945022583\n",
      "Step: 3729, Loss: 0.650017261505127, Accuracy: 0.875, Computation time: 0.96744704246521\n",
      "Step: 3730, Loss: 0.40769174695014954, Accuracy: 0.8125, Computation time: 0.8972468376159668\n",
      "Step: 3731, Loss: 0.4397074580192566, Accuracy: 0.875, Computation time: 0.7817270755767822\n",
      "Step: 3732, Loss: 0.2655566334724426, Accuracy: 0.9375, Computation time: 0.7715740203857422\n",
      "Step: 3733, Loss: 0.4876690208911896, Accuracy: 0.875, Computation time: 1.561237096786499\n",
      "Step: 3734, Loss: 0.5492257475852966, Accuracy: 0.8125, Computation time: 0.9189198017120361\n",
      "Step: 3735, Loss: 0.70782071352005, Accuracy: 0.75, Computation time: 0.7597219944000244\n",
      "Step: 3736, Loss: 0.3721114993095398, Accuracy: 0.90625, Computation time: 0.9290182590484619\n",
      "Step: 3737, Loss: 0.6034174561500549, Accuracy: 0.78125, Computation time: 0.8319621086120605\n",
      "Step: 3738, Loss: 0.4371243715286255, Accuracy: 0.9375, Computation time: 0.7292661666870117\n",
      "Step: 3739, Loss: 0.6253758072853088, Accuracy: 0.78125, Computation time: 0.8187930583953857\n",
      "Step: 3740, Loss: 0.5310425758361816, Accuracy: 0.78125, Computation time: 0.8734428882598877\n",
      "Step: 3741, Loss: 0.5206697583198547, Accuracy: 0.78125, Computation time: 0.8955080509185791\n",
      "Step: 3742, Loss: 0.5565439462661743, Accuracy: 0.78125, Computation time: 0.7768888473510742\n",
      "Step: 3743, Loss: 0.47458675503730774, Accuracy: 0.90625, Computation time: 0.8793549537658691\n",
      "Step: 3744, Loss: 0.4722936749458313, Accuracy: 0.8125, Computation time: 0.8231801986694336\n",
      "Step: 3745, Loss: 0.6522618532180786, Accuracy: 0.78125, Computation time: 0.8586151599884033\n",
      "Step: 3746, Loss: 0.40242257714271545, Accuracy: 0.90625, Computation time: 0.8139898777008057\n",
      "Step: 3747, Loss: 0.6766229867935181, Accuracy: 0.75, Computation time: 1.1142070293426514\n",
      "Step: 3748, Loss: 0.6601831912994385, Accuracy: 0.78125, Computation time: 1.0362029075622559\n",
      "Step: 3749, Loss: 1.4890416860580444, Accuracy: 0.75, Computation time: 1.0515780448913574\n",
      "Step: 3750, Loss: 1.0293493270874023, Accuracy: 0.6875, Computation time: 0.8141312599182129\n",
      "Step: 3751, Loss: 0.36796772480010986, Accuracy: 0.78125, Computation time: 1.080887794494629\n",
      "Step: 3752, Loss: 0.6131395101547241, Accuracy: 0.8125, Computation time: 0.7924778461456299\n",
      "Step: 3753, Loss: 0.4975195825099945, Accuracy: 0.8125, Computation time: 0.7745347023010254\n",
      "Step: 3754, Loss: 0.467380166053772, Accuracy: 0.8125, Computation time: 0.7420351505279541\n",
      "Step: 3755, Loss: 0.5909101366996765, Accuracy: 0.8125, Computation time: 0.9832377433776855\n",
      "Step: 3756, Loss: 0.2899741232395172, Accuracy: 0.90625, Computation time: 0.7754158973693848\n",
      "Step: 3757, Loss: 0.48002323508262634, Accuracy: 0.84375, Computation time: 0.878166913986206\n",
      "Step: 3758, Loss: 0.3247760236263275, Accuracy: 0.9375, Computation time: 0.7616100311279297\n",
      "Step: 3759, Loss: 0.45209652185440063, Accuracy: 0.875, Computation time: 0.7367608547210693\n",
      "Step: 3760, Loss: 0.705207109451294, Accuracy: 0.71875, Computation time: 0.6492598056793213\n",
      "Step: 3761, Loss: 0.8312097191810608, Accuracy: 0.84375, Computation time: 1.0403800010681152\n",
      "Step: 3762, Loss: 0.7406436800956726, Accuracy: 0.8125, Computation time: 0.9000627994537354\n",
      "Step: 3763, Loss: 0.44193029403686523, Accuracy: 0.8125, Computation time: 0.9348430633544922\n",
      "Step: 3764, Loss: 0.45469382405281067, Accuracy: 0.84375, Computation time: 1.5157561302185059\n",
      "Step: 3765, Loss: 0.7605972290039062, Accuracy: 0.75, Computation time: 0.9609870910644531\n",
      "Step: 3766, Loss: 0.4076988101005554, Accuracy: 0.9375, Computation time: 0.9122271537780762\n",
      "Step: 3767, Loss: 0.47749245166778564, Accuracy: 0.875, Computation time: 0.8980278968811035\n",
      "Step: 3768, Loss: 0.48814716935157776, Accuracy: 0.875, Computation time: 0.8825488090515137\n",
      "Step: 3769, Loss: 0.9381796717643738, Accuracy: 0.6875, Computation time: 1.1093499660491943\n",
      "Step: 3770, Loss: 0.9790746569633484, Accuracy: 0.71875, Computation time: 0.785468339920044\n",
      "Step: 3771, Loss: 0.8659610152244568, Accuracy: 0.78125, Computation time: 0.8362109661102295\n",
      "Step: 3772, Loss: 0.5235118269920349, Accuracy: 0.84375, Computation time: 0.7635762691497803\n",
      "Step: 3773, Loss: 0.5924580097198486, Accuracy: 0.71875, Computation time: 0.7743852138519287\n",
      "Step: 3774, Loss: 0.9330490827560425, Accuracy: 0.75, Computation time: 0.8315131664276123\n",
      "Step: 3775, Loss: 0.9055375456809998, Accuracy: 0.84375, Computation time: 0.748237133026123\n",
      "Step: 3776, Loss: 0.551151692867279, Accuracy: 0.84375, Computation time: 0.7910301685333252\n",
      "Step: 3777, Loss: 0.5076362490653992, Accuracy: 0.8125, Computation time: 0.721724271774292\n",
      "Step: 3778, Loss: 0.6055646538734436, Accuracy: 0.78125, Computation time: 0.7956390380859375\n",
      "Step: 3779, Loss: 0.6263999938964844, Accuracy: 0.75, Computation time: 0.9955880641937256\n",
      "Step: 3780, Loss: 0.5857810974121094, Accuracy: 0.8125, Computation time: 0.8173997402191162\n",
      "Step: 3781, Loss: 0.3689822554588318, Accuracy: 0.875, Computation time: 0.7715160846710205\n",
      "Step: 3782, Loss: 0.33739548921585083, Accuracy: 0.875, Computation time: 0.7568118572235107\n",
      "Step: 3783, Loss: 0.8341089487075806, Accuracy: 0.6875, Computation time: 0.7776088714599609\n",
      "Step: 3784, Loss: 0.4777028560638428, Accuracy: 0.8125, Computation time: 0.7434899806976318\n",
      "Step: 3785, Loss: 0.4344179332256317, Accuracy: 0.8125, Computation time: 0.7728958129882812\n",
      "Step: 3786, Loss: 0.28572720289230347, Accuracy: 0.9375, Computation time: 0.8640580177307129\n",
      "Step: 3787, Loss: 0.5679267644882202, Accuracy: 0.84375, Computation time: 0.7814569473266602\n",
      "Step: 3788, Loss: 0.5986397862434387, Accuracy: 0.8125, Computation time: 0.8596580028533936\n",
      "Step: 3789, Loss: 0.4624032974243164, Accuracy: 0.84375, Computation time: 0.8223822116851807\n",
      "Step: 3790, Loss: 0.9132115244865417, Accuracy: 0.75, Computation time: 0.7471709251403809\n",
      "Step: 3791, Loss: 0.6854870915412903, Accuracy: 0.78125, Computation time: 0.7715640068054199\n",
      "Step: 3792, Loss: 0.5203425288200378, Accuracy: 0.875, Computation time: 0.7922890186309814\n",
      "Step: 3793, Loss: 0.7180057168006897, Accuracy: 0.84375, Computation time: 0.7436997890472412\n",
      "Step: 3794, Loss: 1.0052831172943115, Accuracy: 0.6875, Computation time: 2.7178428173065186\n",
      "Step: 3795, Loss: 0.5192576050758362, Accuracy: 0.875, Computation time: 0.9374830722808838\n",
      "Step: 3796, Loss: 0.4858781695365906, Accuracy: 0.78125, Computation time: 0.8507347106933594\n",
      "Step: 3797, Loss: 0.59718257188797, Accuracy: 0.78125, Computation time: 0.865851879119873\n",
      "Step: 3798, Loss: 0.4815250635147095, Accuracy: 0.875, Computation time: 0.9011919498443604\n",
      "Step: 3799, Loss: 0.501965343952179, Accuracy: 0.875, Computation time: 0.7714519500732422\n",
      "Step: 3800, Loss: 0.5427806377410889, Accuracy: 0.84375, Computation time: 0.7333941459655762\n",
      "Step: 3801, Loss: 0.38770416378974915, Accuracy: 0.875, Computation time: 0.7614669799804688\n",
      "Step: 3802, Loss: 0.9747991561889648, Accuracy: 0.625, Computation time: 0.8257181644439697\n",
      "Step: 3803, Loss: 0.7026604413986206, Accuracy: 0.75, Computation time: 0.7202119827270508\n",
      "Step: 3804, Loss: 0.2715912461280823, Accuracy: 0.90625, Computation time: 0.9671070575714111\n",
      "Step: 3805, Loss: 0.5914954543113708, Accuracy: 0.78125, Computation time: 0.8600008487701416\n",
      "Step: 3806, Loss: 0.2761100232601166, Accuracy: 0.9375, Computation time: 0.8691020011901855\n",
      "Step: 3807, Loss: 0.2734171748161316, Accuracy: 0.90625, Computation time: 0.8204178810119629\n",
      "Step: 3808, Loss: 0.6515110731124878, Accuracy: 0.78125, Computation time: 0.8801929950714111\n",
      "Step: 3809, Loss: 0.6008466482162476, Accuracy: 0.84375, Computation time: 0.8500468730926514\n",
      "Step: 3810, Loss: 0.7027966380119324, Accuracy: 0.78125, Computation time: 0.8285679817199707\n",
      "Step: 3811, Loss: 0.7340348958969116, Accuracy: 0.78125, Computation time: 0.8742191791534424\n",
      "Step: 3812, Loss: 0.6583983898162842, Accuracy: 0.84375, Computation time: 0.8461081981658936\n",
      "Step: 3813, Loss: 0.5317760109901428, Accuracy: 0.90625, Computation time: 0.7868890762329102\n",
      "Step: 3814, Loss: 0.8924098014831543, Accuracy: 0.8125, Computation time: 0.7885379791259766\n",
      "Step: 3815, Loss: 1.0009020566940308, Accuracy: 0.6875, Computation time: 0.7600612640380859\n",
      "Step: 3816, Loss: 0.5770882964134216, Accuracy: 0.84375, Computation time: 0.8947980403900146\n",
      "Step: 3817, Loss: 0.5667115449905396, Accuracy: 0.8125, Computation time: 0.874398946762085\n",
      "Step: 3818, Loss: 0.5534716844558716, Accuracy: 0.84375, Computation time: 0.8356578350067139\n",
      "Step: 3819, Loss: 0.5153748989105225, Accuracy: 0.875, Computation time: 0.774724006652832\n",
      "Step: 3820, Loss: 0.5447865724563599, Accuracy: 0.84375, Computation time: 0.764312744140625\n",
      "Step: 3821, Loss: 0.6062708497047424, Accuracy: 0.6875, Computation time: 0.7996962070465088\n",
      "Step: 3822, Loss: 0.6846799254417419, Accuracy: 0.84375, Computation time: 0.9309282302856445\n",
      "Step: 3823, Loss: 0.7115702033042908, Accuracy: 0.71875, Computation time: 0.7482428550720215\n",
      "Step: 3824, Loss: 0.5874022245407104, Accuracy: 0.78125, Computation time: 0.744560718536377\n",
      "Step: 3825, Loss: 0.5248222947120667, Accuracy: 0.8125, Computation time: 0.7108941078186035\n",
      "Step: 3826, Loss: 0.4882321357727051, Accuracy: 0.84375, Computation time: 0.7479510307312012\n",
      "Step: 3827, Loss: 0.25637170672416687, Accuracy: 0.9375, Computation time: 0.8837308883666992\n",
      "Step: 3828, Loss: 0.40827518701553345, Accuracy: 0.875, Computation time: 0.7600598335266113\n",
      "Step: 3829, Loss: 0.36495956778526306, Accuracy: 0.84375, Computation time: 0.6880009174346924\n",
      "Step: 3830, Loss: 0.3658667802810669, Accuracy: 0.875, Computation time: 0.8401851654052734\n",
      "Step: 3831, Loss: 0.4454071521759033, Accuracy: 0.84375, Computation time: 0.8469879627227783\n",
      "Step: 3832, Loss: 0.8266099691390991, Accuracy: 0.8125, Computation time: 0.7350101470947266\n",
      "Step: 3833, Loss: 0.3631235361099243, Accuracy: 0.875, Computation time: 0.844170093536377\n",
      "Step: 3834, Loss: 0.6865190267562866, Accuracy: 0.84375, Computation time: 0.8551449775695801\n",
      "Step: 3835, Loss: 0.8738787174224854, Accuracy: 0.6875, Computation time: 0.8319680690765381\n",
      "Step: 3836, Loss: 0.7988804578781128, Accuracy: 0.8125, Computation time: 0.7831969261169434\n",
      "Step: 3837, Loss: 0.39111343026161194, Accuracy: 0.84375, Computation time: 0.7896180152893066\n",
      "Step: 3838, Loss: 0.44831031560897827, Accuracy: 0.8125, Computation time: 0.9350700378417969\n",
      "Step: 3839, Loss: 0.7661669254302979, Accuracy: 0.78125, Computation time: 0.7153639793395996\n",
      "Step: 3840, Loss: 0.5685636401176453, Accuracy: 0.84375, Computation time: 0.6958408355712891\n",
      "Step: 3841, Loss: 0.4909574091434479, Accuracy: 0.84375, Computation time: 0.7131621837615967\n",
      "Step: 3842, Loss: 0.47545939683914185, Accuracy: 0.84375, Computation time: 0.8287100791931152\n",
      "Step: 3843, Loss: 0.19539198279380798, Accuracy: 0.96875, Computation time: 1.1070289611816406\n",
      "Step: 3844, Loss: 0.7033460140228271, Accuracy: 0.875, Computation time: 1.0363390445709229\n",
      "Step: 3845, Loss: 0.26778289675712585, Accuracy: 0.90625, Computation time: 0.73907470703125\n",
      "Step: 3846, Loss: 0.34484589099884033, Accuracy: 0.90625, Computation time: 0.8348860740661621\n",
      "Step: 3847, Loss: 0.4910467863082886, Accuracy: 0.875, Computation time: 0.9248719215393066\n",
      "Step: 3848, Loss: 1.0367861986160278, Accuracy: 0.65625, Computation time: 1.1661369800567627\n",
      "Step: 3849, Loss: 0.4431002140045166, Accuracy: 0.875, Computation time: 0.7722868919372559\n",
      "Step: 3850, Loss: 0.6474083662033081, Accuracy: 0.78125, Computation time: 942.2866880893707\n",
      "Step: 3851, Loss: 0.5471685528755188, Accuracy: 0.78125, Computation time: 0.8512632846832275\n",
      "Step: 3852, Loss: 0.3967631757259369, Accuracy: 0.78125, Computation time: 0.8321189880371094\n",
      "Step: 3853, Loss: 0.972624659538269, Accuracy: 0.71875, Computation time: 0.7605328559875488\n",
      "Step: 3854, Loss: 0.3027031421661377, Accuracy: 0.90625, Computation time: 0.798809289932251\n",
      "Step: 3855, Loss: 0.5278509259223938, Accuracy: 0.84375, Computation time: 0.5888271331787109\n",
      "Step: 3856, Loss: 0.6624741554260254, Accuracy: 0.75, Computation time: 0.7822239398956299\n",
      "Step: 3857, Loss: 0.3774964511394501, Accuracy: 0.875, Computation time: 0.8332159519195557\n",
      "Step: 3858, Loss: 0.7322454452514648, Accuracy: 0.78125, Computation time: 1.2954869270324707\n",
      "Step: 3859, Loss: 0.951149582862854, Accuracy: 0.65625, Computation time: 0.7915599346160889\n",
      "Step: 3860, Loss: 0.6016291379928589, Accuracy: 0.78125, Computation time: 0.9734981060028076\n",
      "Step: 3861, Loss: 0.4462989866733551, Accuracy: 0.8125, Computation time: 0.8068668842315674\n",
      "Step: 3862, Loss: 0.6842107772827148, Accuracy: 0.75, Computation time: 0.8455579280853271\n",
      "Step: 3863, Loss: 0.504585325717926, Accuracy: 0.84375, Computation time: 0.816457986831665\n",
      "Step: 3864, Loss: 0.5227499008178711, Accuracy: 0.875, Computation time: 0.6896007061004639\n",
      "Step: 3865, Loss: 0.4466584324836731, Accuracy: 0.84375, Computation time: 1.0613367557525635\n",
      "Step: 3866, Loss: 0.5700576901435852, Accuracy: 0.8125, Computation time: 0.7778317928314209\n",
      "Step: 3867, Loss: 0.6982620358467102, Accuracy: 0.78125, Computation time: 0.8890528678894043\n",
      "Step: 3868, Loss: 0.6568056344985962, Accuracy: 0.875, Computation time: 0.76009202003479\n",
      "Step: 3869, Loss: 0.4486287832260132, Accuracy: 0.90625, Computation time: 0.8176372051239014\n",
      "Step: 3870, Loss: 0.5258380174636841, Accuracy: 0.90625, Computation time: 0.7535758018493652\n",
      "Step: 3871, Loss: 0.2798139750957489, Accuracy: 0.90625, Computation time: 0.8225510120391846\n",
      "Step: 3872, Loss: 0.8751598000526428, Accuracy: 0.78125, Computation time: 0.8124980926513672\n",
      "Step: 3873, Loss: 0.7237939238548279, Accuracy: 0.8125, Computation time: 0.7368829250335693\n",
      "Step: 3874, Loss: 0.7844595313072205, Accuracy: 0.8125, Computation time: 0.8150091171264648\n",
      "Step: 3875, Loss: 0.5358010530471802, Accuracy: 0.84375, Computation time: 1.0229651927947998\n",
      "Step: 3876, Loss: 0.5479205250740051, Accuracy: 0.8125, Computation time: 0.6984608173370361\n",
      "Step: 3877, Loss: 0.4748168885707855, Accuracy: 0.84375, Computation time: 0.7576050758361816\n",
      "Step: 3878, Loss: 0.45604783296585083, Accuracy: 0.84375, Computation time: 0.7868039608001709\n",
      "Step: 3879, Loss: 0.5385422706604004, Accuracy: 0.78125, Computation time: 0.6802849769592285\n",
      "Step: 3880, Loss: 0.38754990696907043, Accuracy: 0.84375, Computation time: 0.8521919250488281\n",
      "Step: 3881, Loss: 0.3723340630531311, Accuracy: 0.90625, Computation time: 0.7720887660980225\n",
      "Step: 3882, Loss: 0.8304829001426697, Accuracy: 0.75, Computation time: 0.9355578422546387\n",
      "Step: 3883, Loss: 0.5262653231620789, Accuracy: 0.75, Computation time: 1.004775047302246\n",
      "Step: 3884, Loss: 0.47868070006370544, Accuracy: 0.875, Computation time: 0.7436261177062988\n",
      "Step: 3885, Loss: 0.4756637513637543, Accuracy: 0.90625, Computation time: 0.8151311874389648\n",
      "Step: 3886, Loss: 0.40261128544807434, Accuracy: 0.875, Computation time: 0.8848690986633301\n",
      "Step: 3887, Loss: 0.5829641819000244, Accuracy: 0.8125, Computation time: 0.9061038494110107\n",
      "Step: 3888, Loss: 0.8158491253852844, Accuracy: 0.84375, Computation time: 0.8124799728393555\n",
      "Step: 3889, Loss: 0.34684258699417114, Accuracy: 0.875, Computation time: 0.888214111328125\n",
      "Step: 3890, Loss: 0.21291498839855194, Accuracy: 0.9375, Computation time: 1.5731682777404785\n",
      "Step: 3891, Loss: 0.4158385097980499, Accuracy: 0.84375, Computation time: 0.7525088787078857\n",
      "Step: 3892, Loss: 0.3438577651977539, Accuracy: 0.875, Computation time: 0.7148749828338623\n",
      "Step: 3893, Loss: 0.4647460877895355, Accuracy: 0.875, Computation time: 0.8752100467681885\n",
      "Step: 3894, Loss: 0.5254455208778381, Accuracy: 0.90625, Computation time: 0.7138650417327881\n",
      "Step: 3895, Loss: 0.2971615195274353, Accuracy: 0.9375, Computation time: 0.805715799331665\n",
      "Step: 3896, Loss: 0.6863362193107605, Accuracy: 0.84375, Computation time: 0.824531078338623\n",
      "Step: 3897, Loss: 0.2607666850090027, Accuracy: 0.9375, Computation time: 0.786884069442749\n",
      "Step: 3898, Loss: 0.7887892723083496, Accuracy: 0.71875, Computation time: 0.7750868797302246\n",
      "Step: 3899, Loss: 0.3829733729362488, Accuracy: 0.78125, Computation time: 0.847728967666626\n",
      "Step: 3900, Loss: 0.6873719692230225, Accuracy: 0.78125, Computation time: 0.7171609401702881\n",
      "Step: 3901, Loss: 0.12368600070476532, Accuracy: 1.0, Computation time: 0.7507820129394531\n",
      "Step: 3902, Loss: 0.6342605352401733, Accuracy: 0.78125, Computation time: 0.7884669303894043\n",
      "Step: 3903, Loss: 0.5388359427452087, Accuracy: 0.875, Computation time: 0.9063510894775391\n",
      "Step: 3904, Loss: 0.5968999266624451, Accuracy: 0.84375, Computation time: 0.8333158493041992\n",
      "Step: 3905, Loss: 0.520482063293457, Accuracy: 0.84375, Computation time: 1.0870921611785889\n",
      "Step: 3906, Loss: 0.6874480247497559, Accuracy: 0.8125, Computation time: 0.8800249099731445\n",
      "Step: 3907, Loss: 0.6328464150428772, Accuracy: 0.8125, Computation time: 0.7924940586090088\n",
      "Step: 3908, Loss: 0.8135805726051331, Accuracy: 0.71875, Computation time: 0.8738689422607422\n",
      "Step: 3909, Loss: 0.6939690709114075, Accuracy: 0.75, Computation time: 0.8523452281951904\n",
      "Step: 3910, Loss: 0.34569504857063293, Accuracy: 0.90625, Computation time: 0.8373031616210938\n",
      "Step: 3911, Loss: 0.8061416745185852, Accuracy: 0.8125, Computation time: 0.7040939331054688\n",
      "Step: 3912, Loss: 0.4192926585674286, Accuracy: 0.875, Computation time: 0.8622171878814697\n",
      "Step: 3913, Loss: 0.5900778770446777, Accuracy: 0.84375, Computation time: 0.9593169689178467\n",
      "Step: 3914, Loss: 0.2048477977514267, Accuracy: 0.875, Computation time: 0.7695879936218262\n",
      "Step: 3915, Loss: 0.6455104947090149, Accuracy: 0.8125, Computation time: 0.8776569366455078\n",
      "Step: 3916, Loss: 0.7582975029945374, Accuracy: 0.75, Computation time: 1.2732229232788086\n",
      "Step: 3917, Loss: 0.6970623135566711, Accuracy: 0.8125, Computation time: 0.7209782600402832\n",
      "Step: 3918, Loss: 0.13103678822517395, Accuracy: 0.96875, Computation time: 0.8097789287567139\n",
      "Step: 3919, Loss: 0.36934953927993774, Accuracy: 0.90625, Computation time: 0.78497314453125\n",
      "Step: 3920, Loss: 0.5289090275764465, Accuracy: 0.875, Computation time: 0.9979820251464844\n",
      "Step: 3921, Loss: 0.27835890650749207, Accuracy: 0.9375, Computation time: 0.7378532886505127\n",
      "Step: 3922, Loss: 0.8682264685630798, Accuracy: 0.71875, Computation time: 1.3541030883789062\n",
      "Step: 3923, Loss: 0.4794120490550995, Accuracy: 0.875, Computation time: 0.9662940502166748\n",
      "Step: 3924, Loss: 0.46492576599121094, Accuracy: 0.84375, Computation time: 1.0905499458312988\n",
      "Step: 3925, Loss: 0.2680695056915283, Accuracy: 0.90625, Computation time: 0.8207871913909912\n",
      "Step: 3926, Loss: 0.23414017260074615, Accuracy: 0.90625, Computation time: 0.9996898174285889\n",
      "Step: 3927, Loss: 0.325378954410553, Accuracy: 0.84375, Computation time: 1.023299217224121\n",
      "Step: 3928, Loss: 0.5957664847373962, Accuracy: 0.8125, Computation time: 0.8069648742675781\n",
      "Step: 3929, Loss: 0.5326361060142517, Accuracy: 0.8125, Computation time: 0.8534841537475586\n",
      "Step: 3930, Loss: 0.504141628742218, Accuracy: 0.875, Computation time: 0.9262959957122803\n",
      "Step: 3931, Loss: 0.4809390902519226, Accuracy: 0.875, Computation time: 1.4827628135681152\n",
      "Step: 3932, Loss: 0.3983485996723175, Accuracy: 0.9375, Computation time: 0.8487639427185059\n",
      "Step: 3933, Loss: 0.5412231683731079, Accuracy: 0.875, Computation time: 0.8499648571014404\n",
      "Step: 3934, Loss: 0.4839431047439575, Accuracy: 0.875, Computation time: 0.8001518249511719\n",
      "Step: 3935, Loss: 0.34021463990211487, Accuracy: 0.875, Computation time: 0.9413678646087646\n",
      "Step: 3936, Loss: 0.5773858428001404, Accuracy: 0.8125, Computation time: 0.8192968368530273\n",
      "Step: 3937, Loss: 1.1967111825942993, Accuracy: 0.6875, Computation time: 0.8289039134979248\n",
      "Step: 3938, Loss: 0.5952920913696289, Accuracy: 0.84375, Computation time: 0.7819719314575195\n",
      "Step: 3939, Loss: 0.5383713245391846, Accuracy: 0.84375, Computation time: 1.2659461498260498\n",
      "Step: 3940, Loss: 0.4228595793247223, Accuracy: 0.875, Computation time: 1.0403611660003662\n",
      "Step: 3941, Loss: 0.7280551195144653, Accuracy: 0.84375, Computation time: 1.790532112121582\n",
      "Step: 3942, Loss: 0.3090257942676544, Accuracy: 0.90625, Computation time: 0.8527200222015381\n",
      "Step: 3943, Loss: 0.645570695400238, Accuracy: 0.8125, Computation time: 0.8341991901397705\n",
      "Step: 3944, Loss: 0.3766825199127197, Accuracy: 0.90625, Computation time: 0.7655110359191895\n",
      "Step: 3945, Loss: 0.7704751491546631, Accuracy: 0.6875, Computation time: 0.9559128284454346\n",
      "Step: 3946, Loss: 0.6589791178703308, Accuracy: 0.84375, Computation time: 0.8844187259674072\n",
      "Step: 3947, Loss: 0.8278079628944397, Accuracy: 0.75, Computation time: 0.7610340118408203\n",
      "Step: 3948, Loss: 1.2227874994277954, Accuracy: 0.65625, Computation time: 0.8112039566040039\n",
      "Step: 3949, Loss: 1.0658328533172607, Accuracy: 0.71875, Computation time: 0.7811448574066162\n",
      "Step: 3950, Loss: 0.41726574301719666, Accuracy: 0.875, Computation time: 1.5809893608093262\n",
      "Step: 3951, Loss: 1.0061300992965698, Accuracy: 0.625, Computation time: 0.8088340759277344\n",
      "Step: 3952, Loss: 0.7365108132362366, Accuracy: 0.78125, Computation time: 0.7737841606140137\n",
      "Step: 3953, Loss: 0.6633310317993164, Accuracy: 0.75, Computation time: 0.898547887802124\n",
      "Step: 3954, Loss: 0.2538600265979767, Accuracy: 0.96875, Computation time: 0.870323896408081\n",
      "Step: 3955, Loss: 0.5260655879974365, Accuracy: 0.875, Computation time: 0.9186890125274658\n",
      "Step: 3956, Loss: 0.3520728349685669, Accuracy: 0.9375, Computation time: 0.9392647743225098\n",
      "Step: 3957, Loss: 0.8271855711936951, Accuracy: 0.78125, Computation time: 0.8158190250396729\n",
      "Step: 3958, Loss: 0.2755621373653412, Accuracy: 0.90625, Computation time: 0.8729357719421387\n",
      "Step: 3959, Loss: 0.537261962890625, Accuracy: 0.84375, Computation time: 0.8005750179290771\n",
      "Step: 3960, Loss: 0.40366584062576294, Accuracy: 0.8125, Computation time: 0.7738702297210693\n",
      "Step: 3961, Loss: 0.634143054485321, Accuracy: 0.875, Computation time: 0.9597082138061523\n",
      "Step: 3962, Loss: 0.35506972670555115, Accuracy: 0.875, Computation time: 0.873690128326416\n",
      "Step: 3963, Loss: 0.3192853629589081, Accuracy: 0.9375, Computation time: 0.8087880611419678\n",
      "Step: 3964, Loss: 0.3247375786304474, Accuracy: 0.90625, Computation time: 0.7481772899627686\n",
      "Step: 3965, Loss: 0.27041393518447876, Accuracy: 0.84375, Computation time: 0.7027840614318848\n",
      "Step: 3966, Loss: 0.6582010388374329, Accuracy: 0.875, Computation time: 0.8542001247406006\n",
      "Step: 3967, Loss: 0.3411000669002533, Accuracy: 0.90625, Computation time: 0.8234691619873047\n",
      "Step: 3968, Loss: 0.3859233260154724, Accuracy: 0.84375, Computation time: 0.8333661556243896\n",
      "Step: 3969, Loss: 0.7755374908447266, Accuracy: 0.78125, Computation time: 0.97003173828125\n",
      "Step: 3970, Loss: 0.6320638656616211, Accuracy: 0.78125, Computation time: 1.0893239974975586\n",
      "Step: 3971, Loss: 0.38527145981788635, Accuracy: 0.90625, Computation time: 0.7312192916870117\n",
      "Step: 3972, Loss: 0.7574301958084106, Accuracy: 0.75, Computation time: 0.872715950012207\n",
      "Step: 3973, Loss: 0.4237774610519409, Accuracy: 0.90625, Computation time: 0.8474831581115723\n",
      "Step: 3974, Loss: 0.4055657684803009, Accuracy: 0.875, Computation time: 0.9503281116485596\n",
      "Step: 3975, Loss: 0.4224439561367035, Accuracy: 0.90625, Computation time: 0.7087080478668213\n",
      "Step: 3976, Loss: 0.3005448579788208, Accuracy: 0.90625, Computation time: 0.9403860569000244\n",
      "Step: 3977, Loss: 0.14610245823860168, Accuracy: 1.0, Computation time: 0.7682750225067139\n",
      "Step: 3978, Loss: 0.18868954479694366, Accuracy: 0.90625, Computation time: 0.8344969749450684\n",
      "Step: 3979, Loss: 0.2154572457075119, Accuracy: 0.96875, Computation time: 0.7245497703552246\n",
      "Step: 3980, Loss: 0.2093292474746704, Accuracy: 0.90625, Computation time: 0.8751659393310547\n",
      "Step: 3981, Loss: 0.5315539836883545, Accuracy: 0.875, Computation time: 0.7882599830627441\n",
      "Step: 3982, Loss: 0.36601150035858154, Accuracy: 0.84375, Computation time: 1.3313066959381104\n",
      "Step: 3983, Loss: 0.4637050926685333, Accuracy: 0.875, Computation time: 0.9338948726654053\n",
      "Step: 3984, Loss: 0.4333730638027191, Accuracy: 0.78125, Computation time: 1.1364197731018066\n",
      "Step: 3985, Loss: 0.7031581401824951, Accuracy: 0.8125, Computation time: 961.2653849124908\n",
      "Step: 3986, Loss: 0.6645346283912659, Accuracy: 0.78125, Computation time: 1.3405277729034424\n",
      "Step: 3987, Loss: 0.3621767461299896, Accuracy: 0.9375, Computation time: 0.8098838329315186\n",
      "Step: 3988, Loss: 0.32760703563690186, Accuracy: 0.875, Computation time: 0.916651725769043\n",
      "Step: 3989, Loss: 0.37187257409095764, Accuracy: 0.9375, Computation time: 0.7338728904724121\n",
      "Step: 3990, Loss: 0.4468863606452942, Accuracy: 0.78125, Computation time: 0.8150420188903809\n",
      "Step: 3991, Loss: 0.6457880139350891, Accuracy: 0.78125, Computation time: 0.8430490493774414\n",
      "Step: 3992, Loss: 0.49710899591445923, Accuracy: 0.8125, Computation time: 0.8058099746704102\n",
      "Step: 3993, Loss: 0.8810028433799744, Accuracy: 0.78125, Computation time: 0.7303621768951416\n",
      "Step: 3994, Loss: 0.4766584634780884, Accuracy: 0.875, Computation time: 0.821296215057373\n",
      "Step: 3995, Loss: 0.570752739906311, Accuracy: 0.8125, Computation time: 0.9871091842651367\n",
      "Step: 3996, Loss: 0.8064830899238586, Accuracy: 0.75, Computation time: 0.8749480247497559\n",
      "Step: 3997, Loss: 0.724510908126831, Accuracy: 0.84375, Computation time: 0.7720189094543457\n",
      "Step: 3998, Loss: 0.6746402978897095, Accuracy: 0.78125, Computation time: 0.7628507614135742\n",
      "Step: 3999, Loss: 0.16242462396621704, Accuracy: 1.0, Computation time: 0.9109811782836914\n",
      "Step: 4000, Loss: 0.8691682815551758, Accuracy: 0.75, Computation time: 0.773223876953125\n",
      "Step: 4001, Loss: 0.6278373003005981, Accuracy: 0.8125, Computation time: 1.0158488750457764\n",
      "Step: 4002, Loss: 0.6143814921379089, Accuracy: 0.78125, Computation time: 0.8492279052734375\n",
      "Step: 4003, Loss: 0.6570569276809692, Accuracy: 0.78125, Computation time: 0.7627511024475098\n",
      "Step: 4004, Loss: 0.8805855512619019, Accuracy: 0.78125, Computation time: 0.7567586898803711\n",
      "Step: 4005, Loss: 0.44251716136932373, Accuracy: 0.84375, Computation time: 0.7939419746398926\n",
      "Step: 4006, Loss: 0.7076520323753357, Accuracy: 0.78125, Computation time: 0.6417281627655029\n",
      "Step: 4007, Loss: 0.4768783152103424, Accuracy: 0.90625, Computation time: 0.7887868881225586\n",
      "Step: 4008, Loss: 0.3415561020374298, Accuracy: 0.90625, Computation time: 0.7967710494995117\n",
      "Step: 4009, Loss: 0.7317143678665161, Accuracy: 0.84375, Computation time: 0.786107063293457\n",
      "Step: 4010, Loss: 0.5289816856384277, Accuracy: 0.8125, Computation time: 0.9488120079040527\n",
      "Step: 4011, Loss: 1.0482144355773926, Accuracy: 0.71875, Computation time: 0.9044859409332275\n",
      "Step: 4012, Loss: 0.5762129426002502, Accuracy: 0.90625, Computation time: 1.52852201461792\n",
      "Step: 4013, Loss: 0.6789698600769043, Accuracy: 0.875, Computation time: 0.7585198879241943\n",
      "Step: 4014, Loss: 0.7892720699310303, Accuracy: 0.78125, Computation time: 0.7393841743469238\n",
      "Step: 4015, Loss: 0.5318307876586914, Accuracy: 0.875, Computation time: 0.7536098957061768\n",
      "Step: 4016, Loss: 0.4608039855957031, Accuracy: 0.8125, Computation time: 0.8023478984832764\n",
      "Step: 4017, Loss: 0.429228276014328, Accuracy: 0.8125, Computation time: 0.7042398452758789\n",
      "Step: 4018, Loss: 0.8060582280158997, Accuracy: 0.875, Computation time: 0.7075388431549072\n",
      "Step: 4019, Loss: 0.34832313656806946, Accuracy: 0.875, Computation time: 0.8784530162811279\n",
      "Step: 4020, Loss: 0.4863254129886627, Accuracy: 0.78125, Computation time: 0.7533888816833496\n",
      "Step: 4021, Loss: 0.9766889214515686, Accuracy: 0.78125, Computation time: 1.124647855758667\n",
      "Step: 4022, Loss: 0.3617100417613983, Accuracy: 0.875, Computation time: 0.6590449810028076\n",
      "Step: 4023, Loss: 0.5061594247817993, Accuracy: 0.9375, Computation time: 0.7716999053955078\n",
      "Step: 4024, Loss: 0.5690799355506897, Accuracy: 0.78125, Computation time: 0.7936158180236816\n",
      "Step: 4025, Loss: 0.4101480543613434, Accuracy: 0.84375, Computation time: 0.8376729488372803\n",
      "Step: 4026, Loss: 0.35627561807632446, Accuracy: 0.90625, Computation time: 0.6682741641998291\n",
      "Step: 4027, Loss: 0.5679885149002075, Accuracy: 0.875, Computation time: 0.9287097454071045\n",
      "Step: 4028, Loss: 0.4209224283695221, Accuracy: 0.84375, Computation time: 0.8659152984619141\n",
      "Step: 4029, Loss: 0.48265984654426575, Accuracy: 0.875, Computation time: 1.0448682308197021\n",
      "Step: 4030, Loss: 0.5569485425949097, Accuracy: 0.84375, Computation time: 0.8080170154571533\n",
      "Step: 4031, Loss: 0.2834548354148865, Accuracy: 0.90625, Computation time: 0.9652900695800781\n",
      "Step: 4032, Loss: 0.4144051969051361, Accuracy: 0.875, Computation time: 0.9494450092315674\n",
      "Step: 4033, Loss: 0.7702996134757996, Accuracy: 0.75, Computation time: 0.8796732425689697\n",
      "Step: 4034, Loss: 0.47099781036376953, Accuracy: 0.8125, Computation time: 0.9355430603027344\n",
      "Step: 4035, Loss: 0.22528229653835297, Accuracy: 0.96875, Computation time: 0.8701629638671875\n",
      "Step: 4036, Loss: 0.44175106287002563, Accuracy: 0.84375, Computation time: 0.8708579540252686\n",
      "Step: 4037, Loss: 0.3916487991809845, Accuracy: 0.90625, Computation time: 0.8323569297790527\n",
      "Step: 4038, Loss: 0.5302068591117859, Accuracy: 0.75, Computation time: 0.8623223304748535\n",
      "Step: 4039, Loss: 0.7363132238388062, Accuracy: 0.71875, Computation time: 0.9016509056091309\n",
      "Step: 4040, Loss: 0.3266798257827759, Accuracy: 0.875, Computation time: 0.8516201972961426\n",
      "Step: 4041, Loss: 0.4954920709133148, Accuracy: 0.875, Computation time: 0.8970932960510254\n",
      "Step: 4042, Loss: 0.3908880949020386, Accuracy: 0.8125, Computation time: 0.9483151435852051\n",
      "Step: 4043, Loss: 0.6407495141029358, Accuracy: 0.8125, Computation time: 0.909722089767456\n",
      "Step: 4044, Loss: 0.6061530709266663, Accuracy: 0.84375, Computation time: 1.5668070316314697\n",
      "Step: 4045, Loss: 0.7743707895278931, Accuracy: 0.84375, Computation time: 0.9368588924407959\n",
      "Step: 4046, Loss: 0.24767979979515076, Accuracy: 0.9375, Computation time: 0.9454288482666016\n",
      "Step: 4047, Loss: 0.3983611762523651, Accuracy: 0.84375, Computation time: 0.7671878337860107\n",
      "Step: 4048, Loss: 0.4416165351867676, Accuracy: 0.84375, Computation time: 0.8435020446777344\n",
      "Step: 4049, Loss: 0.30448856949806213, Accuracy: 0.9375, Computation time: 0.6714286804199219\n",
      "Step: 4050, Loss: 0.24823470413684845, Accuracy: 0.90625, Computation time: 0.7578251361846924\n",
      "Step: 4051, Loss: 0.4700201153755188, Accuracy: 0.84375, Computation time: 0.8664462566375732\n",
      "Step: 4052, Loss: 0.48734256625175476, Accuracy: 0.90625, Computation time: 0.6979310512542725\n",
      "Step: 4053, Loss: 0.8490114212036133, Accuracy: 0.75, Computation time: 0.8954942226409912\n",
      "Step: 4054, Loss: 0.23820336163043976, Accuracy: 0.9375, Computation time: 0.7491450309753418\n",
      "Step: 4055, Loss: 0.8369709253311157, Accuracy: 0.71875, Computation time: 0.990800142288208\n",
      "Step: 4056, Loss: 0.28262588381767273, Accuracy: 0.90625, Computation time: 0.9027090072631836\n",
      "Step: 4057, Loss: 0.7202966213226318, Accuracy: 0.78125, Computation time: 0.9579360485076904\n",
      "Step: 4058, Loss: 0.4063635468482971, Accuracy: 0.90625, Computation time: 0.9222941398620605\n",
      "Step: 4059, Loss: 1.1213957071304321, Accuracy: 0.6875, Computation time: 0.9073357582092285\n",
      "Step: 4060, Loss: 0.6068931818008423, Accuracy: 0.75, Computation time: 0.80684494972229\n",
      "Step: 4061, Loss: 0.7249295115470886, Accuracy: 0.78125, Computation time: 0.6372380256652832\n",
      "Step: 4062, Loss: 0.614610493183136, Accuracy: 0.84375, Computation time: 0.7624421119689941\n",
      "Step: 4063, Loss: 0.45416805148124695, Accuracy: 0.84375, Computation time: 0.9292969703674316\n",
      "Step: 4064, Loss: 0.5470702052116394, Accuracy: 0.8125, Computation time: 0.8667001724243164\n",
      "Step: 4065, Loss: 0.3400903046131134, Accuracy: 0.875, Computation time: 0.7927689552307129\n",
      "Step: 4066, Loss: 0.34089285135269165, Accuracy: 0.90625, Computation time: 0.7251219749450684\n",
      "Step: 4067, Loss: 0.4833570122718811, Accuracy: 0.8125, Computation time: 0.8628683090209961\n",
      "Step: 4068, Loss: 0.6006911993026733, Accuracy: 0.875, Computation time: 0.874309778213501\n",
      "Step: 4069, Loss: 0.6768004894256592, Accuracy: 0.78125, Computation time: 0.8553681373596191\n",
      "Step: 4070, Loss: 0.49071046710014343, Accuracy: 0.875, Computation time: 0.8591370582580566\n",
      "Step: 4071, Loss: 0.7601982355117798, Accuracy: 0.84375, Computation time: 1.0634989738464355\n",
      "Step: 4072, Loss: 0.5955076813697815, Accuracy: 0.78125, Computation time: 0.8459351062774658\n",
      "Step: 4073, Loss: 0.552786111831665, Accuracy: 0.875, Computation time: 0.9704310894012451\n",
      "Step: 4074, Loss: 0.7677708268165588, Accuracy: 0.84375, Computation time: 0.9801878929138184\n",
      "Step: 4075, Loss: 0.4548977315425873, Accuracy: 0.875, Computation time: 1.2166111469268799\n",
      "Step: 4076, Loss: 0.7007193565368652, Accuracy: 0.84375, Computation time: 0.9197909832000732\n",
      "Step: 4077, Loss: 0.25250008702278137, Accuracy: 0.875, Computation time: 0.823016881942749\n",
      "Step: 4078, Loss: 0.3922733664512634, Accuracy: 0.90625, Computation time: 0.819237232208252\n",
      "Step: 4079, Loss: 0.4182499945163727, Accuracy: 0.78125, Computation time: 0.7655999660491943\n",
      "Step: 4080, Loss: 0.4933568835258484, Accuracy: 0.8125, Computation time: 0.9400160312652588\n",
      "Step: 4081, Loss: 0.6601695418357849, Accuracy: 0.8125, Computation time: 0.7797501087188721\n",
      "Step: 4082, Loss: 0.4111241102218628, Accuracy: 0.875, Computation time: 0.7709479331970215\n",
      "Step: 4083, Loss: 0.6148410439491272, Accuracy: 0.75, Computation time: 0.8048269748687744\n",
      "Step: 4084, Loss: 0.3873407244682312, Accuracy: 0.9375, Computation time: 0.9944489002227783\n",
      "Step: 4085, Loss: 0.46773627400398254, Accuracy: 0.84375, Computation time: 0.8275518417358398\n",
      "Step: 4086, Loss: 1.0704100131988525, Accuracy: 0.65625, Computation time: 0.7360010147094727\n",
      "Step: 4087, Loss: 0.31460562348365784, Accuracy: 0.875, Computation time: 0.9000020027160645\n",
      "Step: 4088, Loss: 0.26679715514183044, Accuracy: 0.9375, Computation time: 0.8565430641174316\n",
      "Step: 4089, Loss: 0.5351555347442627, Accuracy: 0.8125, Computation time: 1.090683937072754\n",
      "Step: 4090, Loss: 0.42986243963241577, Accuracy: 0.90625, Computation time: 0.6617488861083984\n",
      "Step: 4091, Loss: 0.6912471055984497, Accuracy: 0.78125, Computation time: 0.8200428485870361\n",
      "Step: 4092, Loss: 0.3451564311981201, Accuracy: 0.90625, Computation time: 0.8465919494628906\n",
      "Step: 4093, Loss: 0.4274017810821533, Accuracy: 0.84375, Computation time: 0.7942969799041748\n",
      "Step: 4094, Loss: 0.587947428226471, Accuracy: 0.8125, Computation time: 0.9531588554382324\n",
      "Step: 4095, Loss: 0.564851701259613, Accuracy: 0.8125, Computation time: 0.8663640022277832\n",
      "Step: 4096, Loss: 0.5024531483650208, Accuracy: 0.84375, Computation time: 1.0995032787322998\n",
      "Step: 4097, Loss: 0.6448221206665039, Accuracy: 0.875, Computation time: 0.8774921894073486\n",
      "Step: 4098, Loss: 0.4501568377017975, Accuracy: 0.84375, Computation time: 0.8233821392059326\n",
      "Step: 4099, Loss: 0.4198968708515167, Accuracy: 0.84375, Computation time: 0.7513859272003174\n",
      "Step: 4100, Loss: 0.666750967502594, Accuracy: 0.84375, Computation time: 0.7820181846618652\n",
      "Step: 4101, Loss: 0.7199891805648804, Accuracy: 0.78125, Computation time: 1.1046979427337646\n",
      "Step: 4102, Loss: 0.36730441451072693, Accuracy: 0.875, Computation time: 0.8114898204803467\n",
      "Step: 4103, Loss: 0.8834630846977234, Accuracy: 0.78125, Computation time: 1.0849957466125488\n",
      "Step: 4104, Loss: 0.7290475368499756, Accuracy: 0.8125, Computation time: 0.8048419952392578\n",
      "Step: 4105, Loss: 0.7110015153884888, Accuracy: 0.78125, Computation time: 0.9699771404266357\n",
      "Step: 4106, Loss: 0.6355209946632385, Accuracy: 0.84375, Computation time: 1.4688751697540283\n",
      "Step: 4107, Loss: 0.6250971555709839, Accuracy: 0.8125, Computation time: 1.0100460052490234\n",
      "Step: 4108, Loss: 0.7223669290542603, Accuracy: 0.8125, Computation time: 0.9301271438598633\n",
      "Step: 4109, Loss: 0.28862708806991577, Accuracy: 0.96875, Computation time: 0.7241578102111816\n",
      "Step: 4110, Loss: 0.3998859226703644, Accuracy: 0.90625, Computation time: 0.9087200164794922\n",
      "Step: 4111, Loss: 0.5767875909805298, Accuracy: 0.8125, Computation time: 0.9358119964599609\n",
      "Step: 4112, Loss: 0.3466714322566986, Accuracy: 0.9375, Computation time: 0.7474708557128906\n",
      "Step: 4113, Loss: 0.3676498234272003, Accuracy: 0.90625, Computation time: 0.9055449962615967\n",
      "Step: 4114, Loss: 0.37009525299072266, Accuracy: 0.875, Computation time: 0.7571289539337158\n",
      "Step: 4115, Loss: 0.34845972061157227, Accuracy: 0.9375, Computation time: 0.847480058670044\n",
      "Step: 4116, Loss: 0.32118409872055054, Accuracy: 0.90625, Computation time: 0.789344072341919\n",
      "Step: 4117, Loss: 0.49381932616233826, Accuracy: 0.84375, Computation time: 0.7602458000183105\n",
      "Step: 4118, Loss: 0.6091827154159546, Accuracy: 0.78125, Computation time: 0.9166500568389893\n",
      "Step: 4119, Loss: 0.37445518374443054, Accuracy: 0.875, Computation time: 0.8763468265533447\n",
      "Step: 4120, Loss: 0.45651975274086, Accuracy: 0.875, Computation time: 0.8082208633422852\n",
      "Step: 4121, Loss: 0.740190863609314, Accuracy: 0.8125, Computation time: 227.27606391906738\n",
      "Step: 4122, Loss: 0.7893991470336914, Accuracy: 0.71875, Computation time: 0.8291480541229248\n",
      "Step: 4123, Loss: 0.25533467531204224, Accuracy: 0.90625, Computation time: 0.7505133152008057\n",
      "Step: 4124, Loss: 0.31978315114974976, Accuracy: 0.875, Computation time: 0.8486850261688232\n",
      "Step: 4125, Loss: 0.7216336727142334, Accuracy: 0.78125, Computation time: 0.7900631427764893\n",
      "Step: 4126, Loss: 0.9014042019844055, Accuracy: 0.71875, Computation time: 0.7728407382965088\n",
      "Step: 4127, Loss: 0.2532302141189575, Accuracy: 0.9375, Computation time: 0.8604738712310791\n",
      "Step: 4128, Loss: 0.41722971200942993, Accuracy: 0.84375, Computation time: 0.8915040493011475\n",
      "Step: 4129, Loss: 0.4705377519130707, Accuracy: 0.84375, Computation time: 0.7689738273620605\n",
      "Step: 4130, Loss: 0.3097918629646301, Accuracy: 0.90625, Computation time: 0.9110579490661621\n",
      "Step: 4131, Loss: 0.6217063069343567, Accuracy: 0.78125, Computation time: 0.7380170822143555\n",
      "Step: 4132, Loss: 0.4509446322917938, Accuracy: 0.875, Computation time: 0.9518897533416748\n",
      "Step: 4133, Loss: 0.4670981764793396, Accuracy: 0.84375, Computation time: 0.7943630218505859\n",
      "Step: 4134, Loss: 0.3540778160095215, Accuracy: 0.84375, Computation time: 0.764981746673584\n",
      "Step: 4135, Loss: 0.5112988948822021, Accuracy: 0.75, Computation time: 0.8660917282104492\n",
      "Step: 4136, Loss: 0.5453823804855347, Accuracy: 0.8125, Computation time: 0.7220859527587891\n",
      "Step: 4137, Loss: 0.3284164071083069, Accuracy: 0.90625, Computation time: 1.2335832118988037\n",
      "Step: 4138, Loss: 0.6642681956291199, Accuracy: 0.78125, Computation time: 0.7204611301422119\n",
      "Step: 4139, Loss: 0.8368507027626038, Accuracy: 0.75, Computation time: 0.8385589122772217\n",
      "Step: 4140, Loss: 0.3684065639972687, Accuracy: 0.875, Computation time: 0.7301039695739746\n",
      "Step: 4141, Loss: 0.5524441003799438, Accuracy: 0.78125, Computation time: 0.7801799774169922\n",
      "Step: 4142, Loss: 0.9797163605690002, Accuracy: 0.6875, Computation time: 0.8705658912658691\n",
      "Step: 4143, Loss: 1.366625189781189, Accuracy: 0.75, Computation time: 0.8764247894287109\n",
      "Step: 4144, Loss: 0.44857707619667053, Accuracy: 0.8125, Computation time: 0.7769699096679688\n",
      "Step: 4145, Loss: 0.3696628510951996, Accuracy: 0.875, Computation time: 1.0724539756774902\n",
      "Step: 4146, Loss: 0.3226042687892914, Accuracy: 0.90625, Computation time: 0.8211989402770996\n",
      "Step: 4147, Loss: 0.5473370552062988, Accuracy: 0.875, Computation time: 1.4297070503234863\n",
      "Step: 4148, Loss: 0.5186678171157837, Accuracy: 0.78125, Computation time: 0.722088098526001\n",
      "Step: 4149, Loss: 0.911536693572998, Accuracy: 0.71875, Computation time: 0.8265950679779053\n",
      "Step: 4150, Loss: 0.32766473293304443, Accuracy: 0.875, Computation time: 0.7462069988250732\n",
      "Step: 4151, Loss: 0.6027471423149109, Accuracy: 0.8125, Computation time: 0.7925131320953369\n",
      "Step: 4152, Loss: 0.45324885845184326, Accuracy: 0.84375, Computation time: 0.8085248470306396\n",
      "Step: 4153, Loss: 0.532488226890564, Accuracy: 0.8125, Computation time: 0.8092348575592041\n",
      "Step: 4154, Loss: 0.4524502158164978, Accuracy: 0.875, Computation time: 0.7702629566192627\n",
      "Step: 4155, Loss: 0.2623862326145172, Accuracy: 0.9375, Computation time: 0.9128227233886719\n",
      "Step: 4156, Loss: 0.7864928245544434, Accuracy: 0.8125, Computation time: 0.7793300151824951\n",
      "Step: 4157, Loss: 0.44351786375045776, Accuracy: 0.90625, Computation time: 0.655620813369751\n",
      "Step: 4158, Loss: 0.24537351727485657, Accuracy: 0.9375, Computation time: 0.7752630710601807\n",
      "Step: 4159, Loss: 0.8439874649047852, Accuracy: 0.8125, Computation time: 0.7190761566162109\n",
      "Step: 4160, Loss: 0.27108344435691833, Accuracy: 0.9375, Computation time: 0.8529410362243652\n",
      "Step: 4161, Loss: 0.3284009099006653, Accuracy: 0.90625, Computation time: 0.7558109760284424\n",
      "Step: 4162, Loss: 0.19520507752895355, Accuracy: 0.96875, Computation time: 0.7260971069335938\n",
      "Step: 4163, Loss: 0.4349167048931122, Accuracy: 0.90625, Computation time: 0.8160982131958008\n",
      "Step: 4164, Loss: 0.4961409568786621, Accuracy: 0.78125, Computation time: 0.763585090637207\n",
      "Step: 4165, Loss: 0.7206767797470093, Accuracy: 0.78125, Computation time: 1.1642141342163086\n",
      "Step: 4166, Loss: 0.3052496314048767, Accuracy: 0.90625, Computation time: 0.7580959796905518\n",
      "Step: 4167, Loss: 0.5226627588272095, Accuracy: 0.84375, Computation time: 0.875532865524292\n",
      "Step: 4168, Loss: 0.414192795753479, Accuracy: 0.84375, Computation time: 0.7895376682281494\n",
      "Step: 4169, Loss: 0.343427449464798, Accuracy: 0.90625, Computation time: 1.4725010395050049\n",
      "Step: 4170, Loss: 0.4368520677089691, Accuracy: 0.90625, Computation time: 0.7547550201416016\n",
      "Step: 4171, Loss: 0.871578574180603, Accuracy: 0.71875, Computation time: 994.0660727024078\n",
      "Step: 4172, Loss: 0.32624489068984985, Accuracy: 0.9375, Computation time: 0.9507720470428467\n",
      "Step: 4173, Loss: 0.8788065314292908, Accuracy: 0.78125, Computation time: 0.7985317707061768\n",
      "Step: 4174, Loss: 0.5906607508659363, Accuracy: 0.78125, Computation time: 0.8278887271881104\n",
      "Step: 4175, Loss: 0.4512380063533783, Accuracy: 0.84375, Computation time: 0.881223201751709\n",
      "Step: 4176, Loss: 0.5199754238128662, Accuracy: 0.90625, Computation time: 0.8230290412902832\n",
      "Step: 4177, Loss: 0.41200482845306396, Accuracy: 0.90625, Computation time: 0.7302150726318359\n",
      "Step: 4178, Loss: 0.5281646251678467, Accuracy: 0.8125, Computation time: 0.8731470108032227\n",
      "Step: 4179, Loss: 0.7021888494491577, Accuracy: 0.8125, Computation time: 0.758796215057373\n",
      "Step: 4180, Loss: 0.5904684066772461, Accuracy: 0.8125, Computation time: 0.8803451061248779\n",
      "Step: 4181, Loss: 0.2679816782474518, Accuracy: 0.9375, Computation time: 0.8248367309570312\n",
      "Step: 4182, Loss: 0.6226375699043274, Accuracy: 0.875, Computation time: 0.8402938842773438\n",
      "Step: 4183, Loss: 0.6420204043388367, Accuracy: 0.84375, Computation time: 0.8134748935699463\n",
      "Step: 4184, Loss: 0.2051556259393692, Accuracy: 0.90625, Computation time: 1.0452322959899902\n",
      "Step: 4185, Loss: 0.41365376114845276, Accuracy: 0.875, Computation time: 0.7476811408996582\n",
      "Step: 4186, Loss: 0.6528208255767822, Accuracy: 0.8125, Computation time: 0.8348701000213623\n",
      "Step: 4187, Loss: 0.22768235206604004, Accuracy: 0.9375, Computation time: 0.9342200756072998\n",
      "Step: 4188, Loss: 0.6175943613052368, Accuracy: 0.84375, Computation time: 0.7186999320983887\n",
      "Step: 4189, Loss: 0.3236589729785919, Accuracy: 0.90625, Computation time: 0.84598708152771\n",
      "Step: 4190, Loss: 0.4253384470939636, Accuracy: 0.84375, Computation time: 0.7711548805236816\n",
      "Step: 4191, Loss: 0.6402106285095215, Accuracy: 0.84375, Computation time: 0.9267539978027344\n",
      "Step: 4192, Loss: 0.7121265530586243, Accuracy: 0.8125, Computation time: 0.7076339721679688\n",
      "Step: 4193, Loss: 0.4625302851200104, Accuracy: 0.8125, Computation time: 0.8193240165710449\n",
      "Step: 4194, Loss: 0.5990258455276489, Accuracy: 0.90625, Computation time: 0.8508570194244385\n",
      "Step: 4195, Loss: 0.5459834933280945, Accuracy: 0.875, Computation time: 0.929610013961792\n",
      "Step: 4196, Loss: 0.6771775484085083, Accuracy: 0.84375, Computation time: 0.8460819721221924\n",
      "Step: 4197, Loss: 0.36402836441993713, Accuracy: 0.875, Computation time: 0.719243049621582\n",
      "Step: 4198, Loss: 0.841499388217926, Accuracy: 0.78125, Computation time: 0.7469601631164551\n",
      "Step: 4199, Loss: 0.9943318367004395, Accuracy: 0.75, Computation time: 0.9221897125244141\n",
      "Step: 4200, Loss: 1.3293495178222656, Accuracy: 0.71875, Computation time: 0.7735059261322021\n",
      "Step: 4201, Loss: 0.2712685465812683, Accuracy: 0.9375, Computation time: 1.6006901264190674\n",
      "Step: 4202, Loss: 0.9233958125114441, Accuracy: 0.75, Computation time: 0.9292910099029541\n",
      "Step: 4203, Loss: 0.9638205766677856, Accuracy: 0.78125, Computation time: 0.8030667304992676\n",
      "Step: 4204, Loss: 0.30556321144104004, Accuracy: 0.90625, Computation time: 0.7444701194763184\n",
      "Step: 4205, Loss: 0.5148426294326782, Accuracy: 0.8125, Computation time: 0.9077451229095459\n",
      "Step: 4206, Loss: 0.5882126092910767, Accuracy: 0.8125, Computation time: 0.8010411262512207\n",
      "Step: 4207, Loss: 0.4275684356689453, Accuracy: 0.78125, Computation time: 0.707183837890625\n",
      "Step: 4208, Loss: 0.3269651532173157, Accuracy: 0.9375, Computation time: 0.9903450012207031\n",
      "Step: 4209, Loss: 0.41032281517982483, Accuracy: 0.90625, Computation time: 0.7324128150939941\n",
      "Step: 4210, Loss: 0.4189716875553131, Accuracy: 0.84375, Computation time: 0.742577075958252\n",
      "Step: 4211, Loss: 1.3851338624954224, Accuracy: 0.65625, Computation time: 0.8819818496704102\n",
      "Step: 4212, Loss: 1.1130030155181885, Accuracy: 0.875, Computation time: 0.8523461818695068\n",
      "Step: 4213, Loss: 0.6062142848968506, Accuracy: 0.8125, Computation time: 0.8268868923187256\n",
      "Step: 4214, Loss: 0.22656621038913727, Accuracy: 0.9375, Computation time: 0.7226600646972656\n",
      "Step: 4215, Loss: 0.5586465001106262, Accuracy: 0.8125, Computation time: 0.9011237621307373\n",
      "Step: 4216, Loss: 0.5855639576911926, Accuracy: 0.875, Computation time: 0.7952761650085449\n",
      "Step: 4217, Loss: 0.4077018201351166, Accuracy: 0.875, Computation time: 0.8499550819396973\n",
      "Step: 4218, Loss: 0.5383228063583374, Accuracy: 0.8125, Computation time: 0.9624948501586914\n",
      "Step: 4219, Loss: 0.5860986113548279, Accuracy: 0.84375, Computation time: 0.8069658279418945\n",
      "Step: 4220, Loss: 0.6015145182609558, Accuracy: 0.8125, Computation time: 0.7146339416503906\n",
      "Step: 4221, Loss: 0.4841732978820801, Accuracy: 0.8125, Computation time: 0.9114491939544678\n",
      "Step: 4222, Loss: 0.5118616223335266, Accuracy: 0.875, Computation time: 1.0549747943878174\n",
      "Step: 4223, Loss: 0.8637662529945374, Accuracy: 0.6875, Computation time: 0.7026119232177734\n",
      "Step: 4224, Loss: 0.9010657072067261, Accuracy: 0.78125, Computation time: 1.046334981918335\n",
      "Step: 4225, Loss: 0.7652822732925415, Accuracy: 0.6875, Computation time: 1.1540300846099854\n",
      "Step: 4226, Loss: 0.7154772281646729, Accuracy: 0.75, Computation time: 0.9573490619659424\n",
      "Step: 4227, Loss: 0.2987141013145447, Accuracy: 0.9375, Computation time: 0.9392569065093994\n",
      "Step: 4228, Loss: 0.690937340259552, Accuracy: 0.75, Computation time: 0.842858076095581\n",
      "Step: 4229, Loss: 0.6823616027832031, Accuracy: 0.71875, Computation time: 0.7895653247833252\n",
      "Step: 4230, Loss: 0.3618900775909424, Accuracy: 0.875, Computation time: 0.8466150760650635\n",
      "Step: 4231, Loss: 0.5341179370880127, Accuracy: 0.78125, Computation time: 0.7494399547576904\n",
      "Step: 4232, Loss: 0.377541184425354, Accuracy: 0.84375, Computation time: 1.7035090923309326\n",
      "Step: 4233, Loss: 0.947439432144165, Accuracy: 0.78125, Computation time: 0.9493141174316406\n",
      "Step: 4234, Loss: 0.5043920874595642, Accuracy: 0.84375, Computation time: 0.7603800296783447\n",
      "Step: 4235, Loss: 0.5688807964324951, Accuracy: 0.78125, Computation time: 0.9798858165740967\n",
      "Step: 4236, Loss: 0.516331136226654, Accuracy: 0.84375, Computation time: 0.9256489276885986\n",
      "Step: 4237, Loss: 0.484153687953949, Accuracy: 0.8125, Computation time: 0.9279689788818359\n",
      "Step: 4238, Loss: 0.41568678617477417, Accuracy: 0.9375, Computation time: 0.8470778465270996\n",
      "Step: 4239, Loss: 0.9318000078201294, Accuracy: 0.78125, Computation time: 0.8798601627349854\n",
      "Step: 4240, Loss: 0.5805029273033142, Accuracy: 0.84375, Computation time: 0.8494539260864258\n",
      "Step: 4241, Loss: 0.7392119765281677, Accuracy: 0.6875, Computation time: 0.9206020832061768\n",
      "Step: 4242, Loss: 0.47064584493637085, Accuracy: 0.78125, Computation time: 0.7813100814819336\n",
      "Step: 4243, Loss: 0.4545431435108185, Accuracy: 0.875, Computation time: 0.7455449104309082\n",
      "Step: 4244, Loss: 0.42602914571762085, Accuracy: 0.90625, Computation time: 0.9579520225524902\n",
      "Step: 4245, Loss: 0.2692067325115204, Accuracy: 0.96875, Computation time: 0.7612500190734863\n",
      "Step: 4246, Loss: 1.0410256385803223, Accuracy: 0.78125, Computation time: 0.9257841110229492\n",
      "Step: 4247, Loss: 0.3186148703098297, Accuracy: 0.90625, Computation time: 0.8316020965576172\n",
      "Step: 4248, Loss: 0.4185883104801178, Accuracy: 0.90625, Computation time: 0.7320981025695801\n",
      "Step: 4249, Loss: 0.5815284848213196, Accuracy: 0.75, Computation time: 0.9372050762176514\n",
      "Step: 4250, Loss: 0.5750572085380554, Accuracy: 0.8125, Computation time: 0.9237701892852783\n",
      "Step: 4251, Loss: 0.28147730231285095, Accuracy: 0.90625, Computation time: 0.6824569702148438\n",
      "Step: 4252, Loss: 0.48682117462158203, Accuracy: 0.84375, Computation time: 0.7687358856201172\n",
      "Step: 4253, Loss: 0.30085480213165283, Accuracy: 0.875, Computation time: 0.683784008026123\n",
      "Step: 4254, Loss: 0.6374287009239197, Accuracy: 0.8125, Computation time: 0.8405778408050537\n",
      "Step: 4255, Loss: 0.41528308391571045, Accuracy: 0.875, Computation time: 0.876650333404541\n",
      "Step: 4256, Loss: 0.2579681873321533, Accuracy: 0.9375, Computation time: 0.9662418365478516\n",
      "Step: 4257, Loss: 0.45062899589538574, Accuracy: 0.875, Computation time: 0.6992552280426025\n",
      "Step: 4258, Loss: 0.5359145402908325, Accuracy: 0.75, Computation time: 0.9502248764038086\n",
      "Step: 4259, Loss: 0.6160100698471069, Accuracy: 0.84375, Computation time: 0.9973959922790527\n",
      "Step: 4260, Loss: 0.5857124328613281, Accuracy: 0.875, Computation time: 0.8049499988555908\n",
      "Step: 4261, Loss: 0.27782052755355835, Accuracy: 0.90625, Computation time: 1.4320900440216064\n",
      "Step: 4262, Loss: 0.702574610710144, Accuracy: 0.875, Computation time: 1.1814219951629639\n",
      "Step: 4263, Loss: 0.21616573631763458, Accuracy: 0.96875, Computation time: 0.8108758926391602\n",
      "Step: 4264, Loss: 0.8217277526855469, Accuracy: 0.6875, Computation time: 0.7353000640869141\n",
      "Step: 4265, Loss: 0.6283627152442932, Accuracy: 0.84375, Computation time: 0.7505159378051758\n",
      "Step: 4266, Loss: 0.4486774504184723, Accuracy: 0.90625, Computation time: 0.811323881149292\n",
      "Step: 4267, Loss: 0.4583558440208435, Accuracy: 0.90625, Computation time: 0.8553080558776855\n",
      "Step: 4268, Loss: 1.1583316326141357, Accuracy: 0.84375, Computation time: 0.90621018409729\n",
      "Step: 4269, Loss: 0.4314727783203125, Accuracy: 0.84375, Computation time: 0.7106397151947021\n",
      "Step: 4270, Loss: 0.6244233846664429, Accuracy: 0.8125, Computation time: 0.9908180236816406\n",
      "Step: 4271, Loss: 0.526343047618866, Accuracy: 0.8125, Computation time: 0.973229169845581\n",
      "Step: 4272, Loss: 0.5866885781288147, Accuracy: 0.8125, Computation time: 0.7871670722961426\n",
      "Step: 4273, Loss: 0.685184121131897, Accuracy: 0.8125, Computation time: 0.8615782260894775\n",
      "Step: 4274, Loss: 0.5599029660224915, Accuracy: 0.84375, Computation time: 0.8393042087554932\n",
      "Step: 4275, Loss: 0.6781675219535828, Accuracy: 0.84375, Computation time: 0.8224368095397949\n",
      "Step: 4276, Loss: 0.4565292000770569, Accuracy: 0.78125, Computation time: 0.8244149684906006\n",
      "Step: 4277, Loss: 0.30350688099861145, Accuracy: 0.96875, Computation time: 0.8513240814208984\n",
      "Step: 4278, Loss: 0.1815686821937561, Accuracy: 0.9375, Computation time: 0.8613579273223877\n",
      "Step: 4279, Loss: 0.4464171230792999, Accuracy: 0.875, Computation time: 0.6962738037109375\n",
      "Step: 4280, Loss: 0.4691234827041626, Accuracy: 0.8125, Computation time: 1.0044217109680176\n",
      "Step: 4281, Loss: 0.4700087606906891, Accuracy: 0.875, Computation time: 0.9228980541229248\n",
      "Step: 4282, Loss: 0.6451611518859863, Accuracy: 0.75, Computation time: 0.8333480358123779\n",
      "Step: 4283, Loss: 0.7674751877784729, Accuracy: 0.78125, Computation time: 1.145981788635254\n",
      "Step: 4284, Loss: 0.6905444860458374, Accuracy: 0.8125, Computation time: 0.8455572128295898\n",
      "Step: 4285, Loss: 0.16086572408676147, Accuracy: 0.96875, Computation time: 0.7713711261749268\n",
      "Step: 4286, Loss: 0.3228003978729248, Accuracy: 0.90625, Computation time: 0.8772311210632324\n",
      "Step: 4287, Loss: 0.6385480761528015, Accuracy: 0.78125, Computation time: 0.7874200344085693\n",
      "Step: 4288, Loss: 0.4431909918785095, Accuracy: 0.78125, Computation time: 0.9487090110778809\n",
      "Step: 4289, Loss: 0.19906918704509735, Accuracy: 0.96875, Computation time: 1.0701968669891357\n",
      "Step: 4290, Loss: 0.8417725563049316, Accuracy: 0.71875, Computation time: 1.2959790229797363\n",
      "Step: 4291, Loss: 0.18525473773479462, Accuracy: 0.96875, Computation time: 0.7875270843505859\n",
      "Step: 4292, Loss: 0.33305883407592773, Accuracy: 0.875, Computation time: 0.8944039344787598\n",
      "Step: 4293, Loss: 0.6559562683105469, Accuracy: 0.84375, Computation time: 1.4369208812713623\n",
      "Step: 4294, Loss: 0.33672457933425903, Accuracy: 0.90625, Computation time: 0.898468017578125\n",
      "Step: 4295, Loss: 0.4691883325576782, Accuracy: 0.90625, Computation time: 0.9935460090637207\n",
      "Step: 4296, Loss: 0.28625941276550293, Accuracy: 0.84375, Computation time: 0.8315200805664062\n",
      "Step: 4297, Loss: 0.39445436000823975, Accuracy: 0.84375, Computation time: 0.6655731201171875\n",
      "Step: 4298, Loss: 0.3935127258300781, Accuracy: 0.84375, Computation time: 0.750831127166748\n",
      "Step: 4299, Loss: 0.5081826448440552, Accuracy: 0.8125, Computation time: 0.790999174118042\n",
      "Step: 4300, Loss: 0.36577171087265015, Accuracy: 0.875, Computation time: 0.7269999980926514\n",
      "Step: 4301, Loss: 0.20273080468177795, Accuracy: 0.96875, Computation time: 0.9154138565063477\n",
      "Step: 4302, Loss: 0.7494931221008301, Accuracy: 0.8125, Computation time: 0.7939858436584473\n",
      "Step: 4303, Loss: 0.4397786855697632, Accuracy: 0.90625, Computation time: 0.8049318790435791\n",
      "Step: 4304, Loss: 0.9624183177947998, Accuracy: 0.75, Computation time: 0.8760550022125244\n",
      "Step: 4305, Loss: 0.37186509370803833, Accuracy: 0.90625, Computation time: 0.8706729412078857\n",
      "Step: 4306, Loss: 0.34510400891304016, Accuracy: 0.90625, Computation time: 0.7206151485443115\n",
      "Step: 4307, Loss: 0.505455732345581, Accuracy: 0.8125, Computation time: 1.1539556980133057\n",
      "Step: 4308, Loss: 0.3244952857494354, Accuracy: 0.875, Computation time: 0.777061939239502\n",
      "Step: 4309, Loss: 0.46499714255332947, Accuracy: 0.84375, Computation time: 0.7969210147857666\n",
      "Step: 4310, Loss: 0.29626014828681946, Accuracy: 0.90625, Computation time: 1.2583539485931396\n",
      "Step: 4311, Loss: 0.4649597406387329, Accuracy: 0.84375, Computation time: 0.728294849395752\n",
      "Step: 4312, Loss: 0.4035918414592743, Accuracy: 0.875, Computation time: 0.9047141075134277\n",
      "Step: 4313, Loss: 0.5295712947845459, Accuracy: 0.8125, Computation time: 0.9840221405029297\n",
      "Step: 4314, Loss: 0.2740004062652588, Accuracy: 0.90625, Computation time: 0.745880126953125\n",
      "Step: 4315, Loss: 0.380114883184433, Accuracy: 0.90625, Computation time: 0.7770960330963135\n",
      "Step: 4316, Loss: 0.18493926525115967, Accuracy: 0.9375, Computation time: 0.900728702545166\n",
      "Step: 4317, Loss: 0.4182890057563782, Accuracy: 0.9375, Computation time: 0.7657871246337891\n",
      "Step: 4318, Loss: 0.915600061416626, Accuracy: 0.75, Computation time: 0.9670689105987549\n",
      "Step: 4319, Loss: 0.5138222575187683, Accuracy: 0.84375, Computation time: 0.9435839653015137\n",
      "Step: 4320, Loss: 0.49090197682380676, Accuracy: 0.875, Computation time: 0.9371800422668457\n",
      "Step: 4321, Loss: 0.2831363081932068, Accuracy: 0.875, Computation time: 0.8435249328613281\n",
      "Step: 4322, Loss: 0.6327597498893738, Accuracy: 0.8125, Computation time: 1.032390832901001\n",
      "Step: 4323, Loss: 0.6280613541603088, Accuracy: 0.84375, Computation time: 1.2177190780639648\n",
      "Step: 4324, Loss: 0.46162083745002747, Accuracy: 0.875, Computation time: 0.843632698059082\n",
      "Step: 4325, Loss: 0.47958970069885254, Accuracy: 0.84375, Computation time: 0.9720578193664551\n",
      "Step: 4326, Loss: 0.30796730518341064, Accuracy: 0.90625, Computation time: 0.8409249782562256\n",
      "Step: 4327, Loss: 0.3608047366142273, Accuracy: 0.875, Computation time: 0.9095282554626465\n",
      "Step: 4328, Loss: 0.386067658662796, Accuracy: 0.875, Computation time: 0.8230020999908447\n",
      "Step: 4329, Loss: 0.3233257830142975, Accuracy: 0.90625, Computation time: 0.6991376876831055\n",
      "Step: 4330, Loss: 0.28090065717697144, Accuracy: 0.90625, Computation time: 0.844167947769165\n",
      "Step: 4331, Loss: 0.13433825969696045, Accuracy: 1.0, Computation time: 0.7605991363525391\n",
      "Step: 4332, Loss: 0.661492109298706, Accuracy: 0.8125, Computation time: 0.793302059173584\n",
      "Step: 4333, Loss: 0.44069841504096985, Accuracy: 0.90625, Computation time: 0.6799840927124023\n",
      "Step: 4334, Loss: 0.44884181022644043, Accuracy: 0.9375, Computation time: 0.7485392093658447\n",
      "Step: 4335, Loss: 0.6067051291465759, Accuracy: 0.8125, Computation time: 0.835064172744751\n",
      "Step: 4336, Loss: 0.1804136037826538, Accuracy: 0.9375, Computation time: 0.9104578495025635\n",
      "Step: 4337, Loss: 0.5175892114639282, Accuracy: 0.8125, Computation time: 0.8274631500244141\n",
      "Step: 4338, Loss: 0.34999319911003113, Accuracy: 0.90625, Computation time: 1.0117042064666748\n",
      "Step: 4339, Loss: 0.386802613735199, Accuracy: 0.875, Computation time: 0.7245440483093262\n",
      "Step: 4340, Loss: 0.24998924136161804, Accuracy: 0.90625, Computation time: 0.9839708805084229\n",
      "Step: 4341, Loss: 0.3915075659751892, Accuracy: 0.84375, Computation time: 0.8047788143157959\n",
      "Step: 4342, Loss: 0.2794628441333771, Accuracy: 0.90625, Computation time: 0.7918481826782227\n",
      "Step: 4343, Loss: 0.31300947070121765, Accuracy: 0.9375, Computation time: 0.8412432670593262\n",
      "Step: 4344, Loss: 0.3567545711994171, Accuracy: 0.875, Computation time: 0.8379559516906738\n",
      "Step: 4345, Loss: 0.5888085961341858, Accuracy: 0.84375, Computation time: 1.0028049945831299\n",
      "Step: 4346, Loss: 0.5970305800437927, Accuracy: 0.78125, Computation time: 0.8298149108886719\n",
      "Step: 4347, Loss: 0.895568311214447, Accuracy: 0.6875, Computation time: 0.9733200073242188\n",
      "Step: 4348, Loss: 0.5910983681678772, Accuracy: 0.75, Computation time: 0.8120768070220947\n",
      "Step: 4349, Loss: 0.49682843685150146, Accuracy: 0.84375, Computation time: 0.8547029495239258\n",
      "Step: 4350, Loss: 0.6053237318992615, Accuracy: 0.84375, Computation time: 0.7647387981414795\n",
      "Step: 4351, Loss: 0.9644139409065247, Accuracy: 0.75, Computation time: 0.9142780303955078\n",
      "Step: 4352, Loss: 0.47940975427627563, Accuracy: 0.8125, Computation time: 0.9654340744018555\n",
      "Step: 4353, Loss: 0.39016836881637573, Accuracy: 0.84375, Computation time: 0.9508249759674072\n",
      "Step: 4354, Loss: 0.6503304839134216, Accuracy: 0.75, Computation time: 0.9504928588867188\n",
      "Step: 4355, Loss: 0.5753644108772278, Accuracy: 0.84375, Computation time: 0.8633811473846436\n",
      "Step: 4356, Loss: 0.42442992329597473, Accuracy: 0.875, Computation time: 0.8636910915374756\n",
      "Step: 4357, Loss: 0.5916652083396912, Accuracy: 0.84375, Computation time: 0.8433630466461182\n",
      "Step: 4358, Loss: 1.0028388500213623, Accuracy: 0.75, Computation time: 0.8228559494018555\n",
      "Step: 4359, Loss: 0.8184006214141846, Accuracy: 0.78125, Computation time: 1.0606110095977783\n",
      "Step: 4360, Loss: 0.9016141891479492, Accuracy: 0.65625, Computation time: 0.9236490726470947\n",
      "Step: 4361, Loss: 0.7307447791099548, Accuracy: 0.71875, Computation time: 0.7532968521118164\n",
      "Step: 4362, Loss: 0.3271266222000122, Accuracy: 0.90625, Computation time: 0.6663417816162109\n",
      "Step: 4363, Loss: 0.5952208638191223, Accuracy: 0.84375, Computation time: 0.8505620956420898\n",
      "Step: 4364, Loss: 0.24719832837581635, Accuracy: 0.90625, Computation time: 0.9527812004089355\n",
      "Step: 4365, Loss: 0.44640323519706726, Accuracy: 0.84375, Computation time: 0.8014709949493408\n",
      "Step: 4366, Loss: 0.5585815906524658, Accuracy: 0.78125, Computation time: 2.2219791412353516\n",
      "Step: 4367, Loss: 0.7269762754440308, Accuracy: 0.78125, Computation time: 0.7731101512908936\n",
      "Step: 4368, Loss: 0.5986666679382324, Accuracy: 0.875, Computation time: 0.8869528770446777\n",
      "Step: 4369, Loss: 0.3362463414669037, Accuracy: 0.90625, Computation time: 0.9059469699859619\n",
      "Step: 4370, Loss: 0.4198298156261444, Accuracy: 0.90625, Computation time: 0.9618439674377441\n",
      "Step: 4371, Loss: 0.7081515192985535, Accuracy: 0.78125, Computation time: 0.8729391098022461\n",
      "Step: 4372, Loss: 0.4802093505859375, Accuracy: 0.9375, Computation time: 0.8651671409606934\n",
      "Step: 4373, Loss: 0.8346123695373535, Accuracy: 0.75, Computation time: 0.8586852550506592\n",
      "Step: 4374, Loss: 0.5476030111312866, Accuracy: 0.84375, Computation time: 0.9044601917266846\n",
      "Step: 4375, Loss: 0.3975447416305542, Accuracy: 0.8125, Computation time: 0.9187350273132324\n",
      "Step: 4376, Loss: 0.9814448952674866, Accuracy: 0.8125, Computation time: 0.8394148349761963\n",
      "Step: 4377, Loss: 0.23452940583229065, Accuracy: 0.90625, Computation time: 0.7711870670318604\n",
      "Step: 4378, Loss: 0.5054445266723633, Accuracy: 0.8125, Computation time: 0.9533071517944336\n",
      "Step: 4379, Loss: 0.4904729723930359, Accuracy: 0.875, Computation time: 1.0482218265533447\n",
      "Step: 4380, Loss: 0.4823625385761261, Accuracy: 0.8125, Computation time: 0.9253451824188232\n",
      "Step: 4381, Loss: 0.7319978475570679, Accuracy: 0.84375, Computation time: 0.739119291305542\n",
      "Step: 4382, Loss: 0.6898522973060608, Accuracy: 0.75, Computation time: 0.7466471195220947\n",
      "Step: 4383, Loss: 0.5921096801757812, Accuracy: 0.875, Computation time: 0.7492010593414307\n",
      "Step: 4384, Loss: 0.21233868598937988, Accuracy: 0.9375, Computation time: 0.7776310443878174\n",
      "Step: 4385, Loss: 0.515245795249939, Accuracy: 0.84375, Computation time: 1.4843661785125732\n",
      "Step: 4386, Loss: 0.6369981169700623, Accuracy: 0.875, Computation time: 0.6999328136444092\n",
      "Step: 4387, Loss: 0.4940575957298279, Accuracy: 0.8125, Computation time: 0.88706374168396\n",
      "Step: 4388, Loss: 0.479749858379364, Accuracy: 0.90625, Computation time: 0.6598048210144043\n",
      "Step: 4389, Loss: 0.6014299988746643, Accuracy: 0.78125, Computation time: 0.7919826507568359\n",
      "Step: 4390, Loss: 0.4101375639438629, Accuracy: 0.84375, Computation time: 0.8558261394500732\n",
      "Step: 4391, Loss: 0.5026503205299377, Accuracy: 0.90625, Computation time: 0.9119079113006592\n",
      "Step: 4392, Loss: 0.5208263993263245, Accuracy: 0.75, Computation time: 0.9607999324798584\n",
      "Step: 4393, Loss: 0.6390358209609985, Accuracy: 0.78125, Computation time: 0.7879018783569336\n",
      "Step: 4394, Loss: 0.5741927027702332, Accuracy: 0.8125, Computation time: 0.742805004119873\n",
      "Step: 4395, Loss: 0.40263932943344116, Accuracy: 0.875, Computation time: 0.9931557178497314\n",
      "Step: 4396, Loss: 1.0225239992141724, Accuracy: 0.6875, Computation time: 0.9583032131195068\n",
      "Step: 4397, Loss: 0.20226624608039856, Accuracy: 0.96875, Computation time: 0.7110450267791748\n",
      "Step: 4398, Loss: 0.5827039480209351, Accuracy: 0.8125, Computation time: 0.8050410747528076\n",
      "Step: 4399, Loss: 0.35535353422164917, Accuracy: 0.875, Computation time: 0.8946852684020996\n",
      "Step: 4400, Loss: 0.4859255850315094, Accuracy: 0.8125, Computation time: 0.709953784942627\n",
      "Step: 4401, Loss: 0.43805819749832153, Accuracy: 0.78125, Computation time: 0.8620107173919678\n",
      "Step: 4402, Loss: 0.46900689601898193, Accuracy: 0.8125, Computation time: 1.5971028804779053\n",
      "Step: 4403, Loss: 0.37018442153930664, Accuracy: 0.84375, Computation time: 0.6997878551483154\n",
      "Step: 4404, Loss: 0.19883596897125244, Accuracy: 0.96875, Computation time: 0.6779041290283203\n",
      "Step: 4405, Loss: 0.7441856861114502, Accuracy: 0.875, Computation time: 0.8396511077880859\n",
      "Step: 4406, Loss: 0.8265346884727478, Accuracy: 0.78125, Computation time: 1.0247061252593994\n",
      "Step: 4407, Loss: 0.4760611653327942, Accuracy: 0.84375, Computation time: 0.8155882358551025\n",
      "Step: 4408, Loss: 0.43683990836143494, Accuracy: 0.8125, Computation time: 1.0968151092529297\n",
      "Step: 4409, Loss: 0.32452845573425293, Accuracy: 0.875, Computation time: 0.7589139938354492\n",
      "Step: 4410, Loss: 0.16337348520755768, Accuracy: 1.0, Computation time: 1.0408408641815186\n",
      "Step: 4411, Loss: 0.3971652686595917, Accuracy: 0.875, Computation time: 0.8604869842529297\n",
      "Step: 4412, Loss: 0.7410173416137695, Accuracy: 0.71875, Computation time: 0.9379479885101318\n",
      "Step: 4413, Loss: 0.46817106008529663, Accuracy: 0.8125, Computation time: 0.8640987873077393\n",
      "Step: 4414, Loss: 0.9340226650238037, Accuracy: 0.6875, Computation time: 0.9089720249176025\n",
      "Step: 4415, Loss: 0.5092538595199585, Accuracy: 0.84375, Computation time: 1.08262300491333\n",
      "Step: 4416, Loss: 0.6272968053817749, Accuracy: 0.84375, Computation time: 0.7655041217803955\n",
      "Step: 4417, Loss: 0.2641344666481018, Accuracy: 0.9375, Computation time: 0.9893641471862793\n",
      "Step: 4418, Loss: 0.20914261043071747, Accuracy: 0.96875, Computation time: 0.9863359928131104\n",
      "Step: 4419, Loss: 0.4946185350418091, Accuracy: 0.875, Computation time: 0.9340808391571045\n",
      "Step: 4420, Loss: 1.2143237590789795, Accuracy: 0.6875, Computation time: 0.8468151092529297\n",
      "Step: 4421, Loss: 0.26590076088905334, Accuracy: 0.90625, Computation time: 0.7867879867553711\n",
      "Step: 4422, Loss: 0.43048155307769775, Accuracy: 0.84375, Computation time: 0.8013854026794434\n",
      "Step: 4423, Loss: 0.8589274883270264, Accuracy: 0.84375, Computation time: 0.6717579364776611\n",
      "Step: 4424, Loss: 0.44306495785713196, Accuracy: 0.875, Computation time: 0.8360388278961182\n",
      "Step: 4425, Loss: 0.4580748975276947, Accuracy: 0.9375, Computation time: 0.702434778213501\n",
      "Step: 4426, Loss: 0.6878648400306702, Accuracy: 0.75, Computation time: 0.8903970718383789\n",
      "Step: 4427, Loss: 0.5771256685256958, Accuracy: 0.8125, Computation time: 0.988900899887085\n",
      "Step: 4428, Loss: 0.2679262161254883, Accuracy: 0.9375, Computation time: 1.0799009799957275\n",
      "Step: 4429, Loss: 0.5660606622695923, Accuracy: 0.875, Computation time: 0.7199909687042236\n",
      "Step: 4430, Loss: 0.5726080536842346, Accuracy: 0.8125, Computation time: 0.7415318489074707\n",
      "Step: 4431, Loss: 0.19743643701076508, Accuracy: 0.96875, Computation time: 0.7148652076721191\n",
      "Step: 4432, Loss: 0.5088485479354858, Accuracy: 0.78125, Computation time: 0.8077559471130371\n",
      "Step: 4433, Loss: 0.4496086835861206, Accuracy: 0.84375, Computation time: 0.8004047870635986\n",
      "Step: 4434, Loss: 0.5599727630615234, Accuracy: 0.78125, Computation time: 0.6904351711273193\n",
      "Step: 4435, Loss: 0.6180263161659241, Accuracy: 0.8125, Computation time: 0.9600646495819092\n",
      "Step: 4436, Loss: 0.669528603553772, Accuracy: 0.84375, Computation time: 0.8143370151519775\n",
      "Step: 4437, Loss: 0.6167539358139038, Accuracy: 0.78125, Computation time: 0.812183141708374\n",
      "Step: 4438, Loss: 0.37423357367515564, Accuracy: 0.8125, Computation time: 0.8930959701538086\n",
      "Step: 4439, Loss: 0.712020218372345, Accuracy: 0.6875, Computation time: 0.8584780693054199\n",
      "Step: 4440, Loss: 0.3588743209838867, Accuracy: 0.875, Computation time: 0.7237670421600342\n",
      "Step: 4441, Loss: 0.7078312635421753, Accuracy: 0.8125, Computation time: 0.703618049621582\n",
      "Step: 4442, Loss: 1.010182499885559, Accuracy: 0.6875, Computation time: 1.0950188636779785\n",
      "Step: 4443, Loss: 0.4947926104068756, Accuracy: 0.8125, Computation time: 0.7807798385620117\n",
      "Step: 4444, Loss: 0.5548374652862549, Accuracy: 0.8125, Computation time: 0.9727108478546143\n",
      "Step: 4445, Loss: 0.7760964035987854, Accuracy: 0.78125, Computation time: 0.7936630249023438\n",
      "Step: 4446, Loss: 0.3758169114589691, Accuracy: 0.90625, Computation time: 0.8758649826049805\n",
      "Step: 4447, Loss: 0.33032479882240295, Accuracy: 0.875, Computation time: 0.8542382717132568\n",
      "Step: 4448, Loss: 0.327027291059494, Accuracy: 0.90625, Computation time: 0.7420978546142578\n",
      "Step: 4449, Loss: 0.2470828741788864, Accuracy: 0.90625, Computation time: 0.6991329193115234\n",
      "Step: 4450, Loss: 0.5391812920570374, Accuracy: 0.84375, Computation time: 0.7950849533081055\n",
      "Step: 4451, Loss: 0.5457952618598938, Accuracy: 0.84375, Computation time: 0.850172758102417\n",
      "Step: 4452, Loss: 0.33637502789497375, Accuracy: 0.90625, Computation time: 0.7972927093505859\n",
      "Step: 4453, Loss: 0.24813544750213623, Accuracy: 0.96875, Computation time: 0.7853362560272217\n",
      "Step: 4454, Loss: 0.3020794689655304, Accuracy: 0.90625, Computation time: 0.8206338882446289\n",
      "Step: 4455, Loss: 0.3574063181877136, Accuracy: 0.90625, Computation time: 0.7349710464477539\n",
      "Step: 4456, Loss: 0.32598677277565, Accuracy: 0.875, Computation time: 0.9565389156341553\n",
      "Step: 4457, Loss: 0.49484938383102417, Accuracy: 0.75, Computation time: 0.7717859745025635\n",
      "Step: 4458, Loss: 0.4343549907207489, Accuracy: 0.84375, Computation time: 0.8881442546844482\n",
      "Step: 4459, Loss: 0.1577141433954239, Accuracy: 0.96875, Computation time: 0.8096611499786377\n",
      "Step: 4460, Loss: 0.45752614736557007, Accuracy: 0.8125, Computation time: 0.6302978992462158\n",
      "Step: 4461, Loss: 0.24049913883209229, Accuracy: 0.875, Computation time: 0.7684149742126465\n",
      "Step: 4462, Loss: 0.37622374296188354, Accuracy: 0.90625, Computation time: 0.8675119876861572\n",
      "Step: 4463, Loss: 0.6014366745948792, Accuracy: 0.84375, Computation time: 0.9488630294799805\n",
      "Step: 4464, Loss: 0.39699864387512207, Accuracy: 0.90625, Computation time: 0.7062129974365234\n",
      "Step: 4465, Loss: 0.42227858304977417, Accuracy: 0.8125, Computation time: 0.8232700824737549\n",
      "Step: 4466, Loss: 0.31244489550590515, Accuracy: 0.90625, Computation time: 0.8893182277679443\n",
      "Step: 4467, Loss: 0.581447958946228, Accuracy: 0.875, Computation time: 0.9090747833251953\n",
      "Step: 4468, Loss: 0.2777252793312073, Accuracy: 0.9375, Computation time: 0.8025908470153809\n",
      "Step: 4469, Loss: 0.37749072909355164, Accuracy: 0.84375, Computation time: 1.1143639087677002\n",
      "Step: 4470, Loss: 0.4495178461074829, Accuracy: 0.8125, Computation time: 0.9428901672363281\n",
      "Step: 4471, Loss: 0.5367337465286255, Accuracy: 0.90625, Computation time: 0.7954268455505371\n",
      "Step: 4472, Loss: 0.2852078378200531, Accuracy: 0.875, Computation time: 0.7530832290649414\n",
      "Step: 4473, Loss: 0.7235199213027954, Accuracy: 0.78125, Computation time: 0.7883939743041992\n",
      "Step: 4474, Loss: 0.2282671332359314, Accuracy: 0.90625, Computation time: 0.7418608665466309\n",
      "Step: 4475, Loss: 0.2591848373413086, Accuracy: 0.90625, Computation time: 0.6865980625152588\n",
      "Step: 4476, Loss: 0.4152929186820984, Accuracy: 0.8125, Computation time: 0.7772190570831299\n",
      "Step: 4477, Loss: 0.4278688430786133, Accuracy: 0.875, Computation time: 0.7736072540283203\n",
      "Step: 4478, Loss: 0.32204532623291016, Accuracy: 0.90625, Computation time: 0.9644479751586914\n",
      "Step: 4479, Loss: 0.2648907005786896, Accuracy: 0.90625, Computation time: 0.8001327514648438\n",
      "Step: 4480, Loss: 0.8380444645881653, Accuracy: 0.71875, Computation time: 1.4475607872009277\n",
      "Step: 4481, Loss: 0.5660772919654846, Accuracy: 0.8125, Computation time: 0.9350278377532959\n",
      "Step: 4482, Loss: 0.27682673931121826, Accuracy: 0.96875, Computation time: 0.7858333587646484\n",
      "Step: 4483, Loss: 0.4606286883354187, Accuracy: 0.8125, Computation time: 909.7726798057556\n",
      "Step: 4484, Loss: 0.5837316513061523, Accuracy: 0.8125, Computation time: 0.8901660442352295\n",
      "Step: 4485, Loss: 0.35638317465782166, Accuracy: 0.90625, Computation time: 0.7004110813140869\n",
      "Step: 4486, Loss: 0.37117451429367065, Accuracy: 0.90625, Computation time: 0.9907419681549072\n",
      "Step: 4487, Loss: 0.4866402745246887, Accuracy: 0.84375, Computation time: 0.8526527881622314\n",
      "Step: 4488, Loss: 0.6519684195518494, Accuracy: 0.8125, Computation time: 0.9258370399475098\n",
      "Step: 4489, Loss: 0.4686335325241089, Accuracy: 0.875, Computation time: 1.1161088943481445\n",
      "Step: 4490, Loss: 0.7996538877487183, Accuracy: 0.84375, Computation time: 0.6287109851837158\n",
      "Step: 4491, Loss: 0.5147212743759155, Accuracy: 0.84375, Computation time: 0.9999549388885498\n",
      "Step: 4492, Loss: 1.1584925651550293, Accuracy: 0.65625, Computation time: 0.941810131072998\n",
      "Step: 4493, Loss: 0.4789603054523468, Accuracy: 0.875, Computation time: 0.8887269496917725\n",
      "Step: 4494, Loss: 0.3292858898639679, Accuracy: 0.875, Computation time: 0.7237591743469238\n",
      "Step: 4495, Loss: 0.4074110686779022, Accuracy: 0.8125, Computation time: 0.6554849147796631\n",
      "Step: 4496, Loss: 0.14826154708862305, Accuracy: 1.0, Computation time: 0.7104918956756592\n",
      "Step: 4497, Loss: 0.5668070912361145, Accuracy: 0.875, Computation time: 0.6676421165466309\n",
      "Step: 4498, Loss: 0.6150034666061401, Accuracy: 0.84375, Computation time: 1.0411489009857178\n",
      "Step: 4499, Loss: 0.5688638091087341, Accuracy: 0.78125, Computation time: 0.743826150894165\n",
      "Step: 4500, Loss: 0.6927216649055481, Accuracy: 0.8125, Computation time: 0.8605060577392578\n",
      "Step: 4501, Loss: 0.20587560534477234, Accuracy: 0.9375, Computation time: 0.7129878997802734\n",
      "Step: 4502, Loss: 0.37932923436164856, Accuracy: 0.875, Computation time: 0.7016921043395996\n",
      "Step: 4503, Loss: 0.7189174294471741, Accuracy: 0.875, Computation time: 1.0252039432525635\n",
      "Step: 4504, Loss: 0.9110676646232605, Accuracy: 0.71875, Computation time: 0.8746979236602783\n",
      "Step: 4505, Loss: 0.7397890090942383, Accuracy: 0.84375, Computation time: 0.7074182033538818\n",
      "Step: 4506, Loss: 0.4495472311973572, Accuracy: 0.8125, Computation time: 0.7329957485198975\n",
      "Step: 4507, Loss: 0.5990961194038391, Accuracy: 0.84375, Computation time: 0.7352190017700195\n",
      "Step: 4508, Loss: 0.27870649099349976, Accuracy: 0.9375, Computation time: 0.7679698467254639\n",
      "Step: 4509, Loss: 0.587762176990509, Accuracy: 0.8125, Computation time: 0.7042081356048584\n",
      "Step: 4510, Loss: 0.45793241262435913, Accuracy: 0.84375, Computation time: 0.8373489379882812\n",
      "Step: 4511, Loss: 0.19785606861114502, Accuracy: 0.90625, Computation time: 0.8109419345855713\n",
      "Step: 4512, Loss: 0.7894090414047241, Accuracy: 0.6875, Computation time: 1.3354790210723877\n",
      "Step: 4513, Loss: 0.5495840907096863, Accuracy: 0.84375, Computation time: 0.8383007049560547\n",
      "Step: 4514, Loss: 0.5081225633621216, Accuracy: 0.8125, Computation time: 0.8572971820831299\n",
      "Step: 4515, Loss: 0.6906262636184692, Accuracy: 0.78125, Computation time: 0.8808057308197021\n",
      "Step: 4516, Loss: 0.574276328086853, Accuracy: 0.84375, Computation time: 0.8734829425811768\n",
      "Step: 4517, Loss: 0.3487984538078308, Accuracy: 0.875, Computation time: 0.8528361320495605\n",
      "Step: 4518, Loss: 0.31617870926856995, Accuracy: 0.9375, Computation time: 0.7987408638000488\n",
      "Step: 4519, Loss: 0.4599072337150574, Accuracy: 0.9375, Computation time: 0.9722590446472168\n",
      "Step: 4520, Loss: 0.5780916810035706, Accuracy: 0.84375, Computation time: 0.8922810554504395\n",
      "Step: 4521, Loss: 0.49165746569633484, Accuracy: 0.84375, Computation time: 0.7710940837860107\n",
      "Step: 4522, Loss: 0.4368487596511841, Accuracy: 0.8125, Computation time: 0.7167618274688721\n",
      "Step: 4523, Loss: 0.7017717361450195, Accuracy: 0.75, Computation time: 0.7966220378875732\n",
      "Step: 4524, Loss: 0.611176609992981, Accuracy: 0.78125, Computation time: 0.9714076519012451\n",
      "Step: 4525, Loss: 0.4152628183364868, Accuracy: 0.84375, Computation time: 0.7299587726593018\n",
      "Step: 4526, Loss: 0.645202100276947, Accuracy: 0.75, Computation time: 0.7655410766601562\n",
      "Step: 4527, Loss: 0.5477790236473083, Accuracy: 0.875, Computation time: 0.84617018699646\n",
      "Step: 4528, Loss: 0.20283935964107513, Accuracy: 0.9375, Computation time: 0.7800807952880859\n",
      "Step: 4529, Loss: 0.34405237436294556, Accuracy: 0.875, Computation time: 0.6932311058044434\n",
      "Step: 4530, Loss: 0.2966472804546356, Accuracy: 0.9375, Computation time: 0.8151810169219971\n",
      "Step: 4531, Loss: 0.22588954865932465, Accuracy: 0.9375, Computation time: 0.8185889720916748\n",
      "Step: 4532, Loss: 0.5361503958702087, Accuracy: 0.8125, Computation time: 0.8872711658477783\n",
      "Step: 4533, Loss: 0.2904147207736969, Accuracy: 0.90625, Computation time: 0.8884811401367188\n",
      "Step: 4534, Loss: 0.23070743680000305, Accuracy: 0.84375, Computation time: 0.9003889560699463\n",
      "Step: 4535, Loss: 0.36100226640701294, Accuracy: 0.9375, Computation time: 0.8113391399383545\n",
      "Step: 4536, Loss: 0.3779964745044708, Accuracy: 0.875, Computation time: 0.8818881511688232\n",
      "Step: 4537, Loss: 0.7067431807518005, Accuracy: 0.71875, Computation time: 0.727654218673706\n",
      "Step: 4538, Loss: 0.41790810227394104, Accuracy: 0.875, Computation time: 0.8565032482147217\n",
      "Step: 4539, Loss: 0.6324688792228699, Accuracy: 0.78125, Computation time: 0.9299190044403076\n",
      "Step: 4540, Loss: 0.5334906578063965, Accuracy: 0.78125, Computation time: 0.9460248947143555\n",
      "Step: 4541, Loss: 0.38415834307670593, Accuracy: 0.90625, Computation time: 0.8403799533843994\n",
      "Step: 4542, Loss: 0.4862695634365082, Accuracy: 0.8125, Computation time: 0.7875750064849854\n",
      "Step: 4543, Loss: 0.4165313243865967, Accuracy: 0.84375, Computation time: 0.7322630882263184\n",
      "Step: 4544, Loss: 0.9595710039138794, Accuracy: 0.8125, Computation time: 1.44035005569458\n",
      "Step: 4545, Loss: 0.8711866140365601, Accuracy: 0.6875, Computation time: 0.8850018978118896\n",
      "Step: 4546, Loss: 0.4303058683872223, Accuracy: 0.875, Computation time: 0.8337981700897217\n",
      "Step: 4547, Loss: 0.5600414872169495, Accuracy: 0.84375, Computation time: 1.4016339778900146\n",
      "Step: 4548, Loss: 0.4119718372821808, Accuracy: 0.84375, Computation time: 1.0196690559387207\n",
      "Step: 4549, Loss: 0.5376424789428711, Accuracy: 0.75, Computation time: 0.741682767868042\n",
      "Step: 4550, Loss: 0.559212863445282, Accuracy: 0.75, Computation time: 0.7841958999633789\n",
      "Step: 4551, Loss: 0.3946506381034851, Accuracy: 0.90625, Computation time: 0.7039968967437744\n",
      "Step: 4552, Loss: 0.31091073155403137, Accuracy: 0.84375, Computation time: 0.7218539714813232\n",
      "Step: 4553, Loss: 0.9115021228790283, Accuracy: 0.71875, Computation time: 0.8429379463195801\n",
      "Step: 4554, Loss: 0.4009244441986084, Accuracy: 0.9375, Computation time: 0.7473268508911133\n",
      "Step: 4555, Loss: 0.6802300810813904, Accuracy: 0.75, Computation time: 0.8157298564910889\n",
      "Step: 4556, Loss: 0.32092222571372986, Accuracy: 0.9375, Computation time: 0.8797798156738281\n",
      "Step: 4557, Loss: 0.6301764249801636, Accuracy: 0.84375, Computation time: 0.725999116897583\n",
      "Step: 4558, Loss: 0.28163474798202515, Accuracy: 0.9375, Computation time: 0.8530168533325195\n",
      "Step: 4559, Loss: 0.49128735065460205, Accuracy: 0.8125, Computation time: 0.9545128345489502\n",
      "Step: 4560, Loss: 0.4762200117111206, Accuracy: 0.875, Computation time: 0.7553222179412842\n",
      "Step: 4561, Loss: 0.44926124811172485, Accuracy: 0.90625, Computation time: 0.9113030433654785\n",
      "Step: 4562, Loss: 0.5450788140296936, Accuracy: 0.78125, Computation time: 0.8691771030426025\n",
      "Step: 4563, Loss: 0.3306616246700287, Accuracy: 0.90625, Computation time: 0.8917269706726074\n",
      "Step: 4564, Loss: 0.7904375195503235, Accuracy: 0.78125, Computation time: 0.9094748497009277\n",
      "Step: 4565, Loss: 0.633319079875946, Accuracy: 0.84375, Computation time: 0.9070017337799072\n",
      "Step: 4566, Loss: 0.5273369550704956, Accuracy: 0.8125, Computation time: 0.8232607841491699\n",
      "Step: 4567, Loss: 0.7064123153686523, Accuracy: 0.8125, Computation time: 0.7093758583068848\n",
      "Step: 4568, Loss: 0.6747671961784363, Accuracy: 0.78125, Computation time: 0.8154487609863281\n",
      "Step: 4569, Loss: 0.6402450799942017, Accuracy: 0.875, Computation time: 0.9464459419250488\n",
      "Step: 4570, Loss: 0.833330512046814, Accuracy: 0.75, Computation time: 0.9400250911712646\n",
      "Step: 4571, Loss: 0.49061575531959534, Accuracy: 0.875, Computation time: 1.0600109100341797\n",
      "Step: 4572, Loss: 0.44474703073501587, Accuracy: 0.84375, Computation time: 0.80271315574646\n",
      "Step: 4573, Loss: 0.541131854057312, Accuracy: 0.8125, Computation time: 0.7571849822998047\n",
      "Step: 4574, Loss: 0.2953534424304962, Accuracy: 0.9375, Computation time: 0.8766930103302002\n",
      "Step: 4575, Loss: 0.6972619295120239, Accuracy: 0.71875, Computation time: 1.223726749420166\n",
      "Step: 4576, Loss: 0.36716488003730774, Accuracy: 0.90625, Computation time: 0.8013591766357422\n",
      "Step: 4577, Loss: 0.5556997060775757, Accuracy: 0.875, Computation time: 0.7859759330749512\n",
      "Step: 4578, Loss: 0.8021244406700134, Accuracy: 0.78125, Computation time: 0.7862949371337891\n",
      "Step: 4579, Loss: 0.6401212215423584, Accuracy: 0.78125, Computation time: 0.7976408004760742\n",
      "Step: 4580, Loss: 0.26078519225120544, Accuracy: 0.90625, Computation time: 0.8433799743652344\n",
      "Step: 4581, Loss: 0.3896833658218384, Accuracy: 0.84375, Computation time: 0.7721209526062012\n",
      "Step: 4582, Loss: 0.3667575418949127, Accuracy: 0.90625, Computation time: 0.8151299953460693\n",
      "Step: 4583, Loss: 0.8654043674468994, Accuracy: 0.71875, Computation time: 1.0955538749694824\n",
      "Step: 4584, Loss: 0.27367112040519714, Accuracy: 0.875, Computation time: 0.8321051597595215\n",
      "Step: 4585, Loss: 0.5202808380126953, Accuracy: 0.8125, Computation time: 0.8717141151428223\n",
      "Step: 4586, Loss: 0.5107556581497192, Accuracy: 0.84375, Computation time: 1.1730177402496338\n",
      "Step: 4587, Loss: 0.5431851148605347, Accuracy: 0.8125, Computation time: 0.7980537414550781\n",
      "Step: 4588, Loss: 0.5430631041526794, Accuracy: 0.875, Computation time: 0.9459447860717773\n",
      "Step: 4589, Loss: 0.3979058861732483, Accuracy: 0.9375, Computation time: 0.8338339328765869\n",
      "Step: 4590, Loss: 0.5345589518547058, Accuracy: 0.875, Computation time: 0.8629801273345947\n",
      "Step: 4591, Loss: 0.3001636266708374, Accuracy: 0.875, Computation time: 0.8496510982513428\n",
      "Step: 4592, Loss: 0.5397881865501404, Accuracy: 0.8125, Computation time: 0.9265091419219971\n",
      "Step: 4593, Loss: 0.3794611394405365, Accuracy: 0.84375, Computation time: 0.8623061180114746\n",
      "Step: 4594, Loss: 0.19555342197418213, Accuracy: 0.96875, Computation time: 0.8420219421386719\n",
      "Step: 4595, Loss: 0.9457226991653442, Accuracy: 0.71875, Computation time: 0.799511194229126\n",
      "Step: 4596, Loss: 0.3525848388671875, Accuracy: 0.875, Computation time: 0.8643720149993896\n",
      "Step: 4597, Loss: 0.1630896031856537, Accuracy: 1.0, Computation time: 0.7861437797546387\n",
      "Step: 4598, Loss: 0.4302697479724884, Accuracy: 0.84375, Computation time: 0.8965740203857422\n",
      "Step: 4599, Loss: 0.3451365828514099, Accuracy: 0.90625, Computation time: 0.9237828254699707\n",
      "Step: 4600, Loss: 0.3873548209667206, Accuracy: 0.84375, Computation time: 0.9152841567993164\n",
      "Step: 4601, Loss: 0.3564123809337616, Accuracy: 0.875, Computation time: 0.8897578716278076\n",
      "Step: 4602, Loss: 0.5459808111190796, Accuracy: 0.84375, Computation time: 0.7582008838653564\n",
      "Step: 4603, Loss: 0.6360887885093689, Accuracy: 0.8125, Computation time: 0.8594470024108887\n",
      "Step: 4604, Loss: 0.24500079452991486, Accuracy: 0.96875, Computation time: 0.7250888347625732\n",
      "Step: 4605, Loss: 0.4032116234302521, Accuracy: 0.90625, Computation time: 2.080679178237915\n",
      "Step: 4606, Loss: 0.4672965407371521, Accuracy: 0.90625, Computation time: 0.9732470512390137\n",
      "Step: 4607, Loss: 0.4687645733356476, Accuracy: 0.84375, Computation time: 0.9483001232147217\n",
      "Step: 4608, Loss: 0.5732877254486084, Accuracy: 0.875, Computation time: 0.6910278797149658\n",
      "Step: 4609, Loss: 0.4629942774772644, Accuracy: 0.8125, Computation time: 0.9881100654602051\n",
      "Step: 4610, Loss: 0.5142518281936646, Accuracy: 0.8125, Computation time: 0.9603030681610107\n",
      "Step: 4611, Loss: 0.565821647644043, Accuracy: 0.875, Computation time: 0.8105127811431885\n",
      "Step: 4612, Loss: 0.3615712821483612, Accuracy: 0.90625, Computation time: 0.9121408462524414\n",
      "Step: 4613, Loss: 0.3673481345176697, Accuracy: 0.90625, Computation time: 0.7690107822418213\n",
      "Step: 4614, Loss: 0.4865412712097168, Accuracy: 0.84375, Computation time: 0.8855679035186768\n",
      "Step: 4615, Loss: 0.3866441249847412, Accuracy: 0.875, Computation time: 0.8980221748352051\n",
      "Step: 4616, Loss: 0.5613038539886475, Accuracy: 0.8125, Computation time: 0.836406946182251\n",
      "Step: 4617, Loss: 0.5428289175033569, Accuracy: 0.8125, Computation time: 0.8088939189910889\n",
      "Step: 4618, Loss: 0.2883017659187317, Accuracy: 0.9375, Computation time: 0.7812938690185547\n",
      "Step: 4619, Loss: 0.23958508670330048, Accuracy: 0.90625, Computation time: 0.7018890380859375\n",
      "Step: 4620, Loss: 0.4114246368408203, Accuracy: 0.84375, Computation time: 0.8367249965667725\n",
      "Step: 4621, Loss: 0.6163458824157715, Accuracy: 0.8125, Computation time: 0.932183027267456\n",
      "Step: 4622, Loss: 0.2806781828403473, Accuracy: 0.875, Computation time: 0.8163151741027832\n",
      "Step: 4623, Loss: 0.6902063488960266, Accuracy: 0.84375, Computation time: 0.76015305519104\n",
      "Step: 4624, Loss: 0.5743865370750427, Accuracy: 0.875, Computation time: 0.8683769702911377\n",
      "Step: 4625, Loss: 0.5474058985710144, Accuracy: 0.8125, Computation time: 0.8355209827423096\n",
      "Step: 4626, Loss: 0.9679903984069824, Accuracy: 0.75, Computation time: 0.7479219436645508\n",
      "Step: 4627, Loss: 0.6846833229064941, Accuracy: 0.8125, Computation time: 0.8706099987030029\n",
      "Step: 4628, Loss: 0.6619423627853394, Accuracy: 0.8125, Computation time: 0.8509922027587891\n",
      "Step: 4629, Loss: 0.47327956557273865, Accuracy: 0.8125, Computation time: 0.8010158538818359\n",
      "Step: 4630, Loss: 0.6056980490684509, Accuracy: 0.84375, Computation time: 0.8320620059967041\n",
      "Step: 4631, Loss: 0.7178884744644165, Accuracy: 0.84375, Computation time: 0.7630152702331543\n",
      "Step: 4632, Loss: 0.9054028391838074, Accuracy: 0.75, Computation time: 0.8933892250061035\n",
      "Step: 4633, Loss: 0.6949702501296997, Accuracy: 0.8125, Computation time: 0.8074753284454346\n",
      "Step: 4634, Loss: 0.26533761620521545, Accuracy: 0.84375, Computation time: 0.8621478080749512\n",
      "Step: 4635, Loss: 1.025421380996704, Accuracy: 0.78125, Computation time: 0.8897109031677246\n",
      "Step: 4636, Loss: 0.5241678357124329, Accuracy: 0.8125, Computation time: 0.7149529457092285\n",
      "Step: 4637, Loss: 0.8086442947387695, Accuracy: 0.75, Computation time: 1.3211290836334229\n",
      "Step: 4638, Loss: 0.4421992301940918, Accuracy: 0.84375, Computation time: 0.837921142578125\n",
      "Step: 4639, Loss: 0.341050386428833, Accuracy: 0.90625, Computation time: 0.7796568870544434\n",
      "Step: 4640, Loss: 0.49422505497932434, Accuracy: 0.78125, Computation time: 0.856342077255249\n",
      "Step: 4641, Loss: 0.7436776757240295, Accuracy: 0.75, Computation time: 0.8253970146179199\n",
      "Step: 4642, Loss: 0.6805328130722046, Accuracy: 0.75, Computation time: 971.9257831573486\n",
      "Step: 4643, Loss: 0.7316123247146606, Accuracy: 0.8125, Computation time: 0.921055793762207\n",
      "Step: 4644, Loss: 0.739156186580658, Accuracy: 0.75, Computation time: 1.1981878280639648\n",
      "Step: 4645, Loss: 0.4917958974838257, Accuracy: 0.8125, Computation time: 0.8333919048309326\n",
      "Step: 4646, Loss: 0.4194134473800659, Accuracy: 0.84375, Computation time: 0.7860660552978516\n",
      "Step: 4647, Loss: 0.3655438721179962, Accuracy: 0.9375, Computation time: 0.7412159442901611\n",
      "Step: 4648, Loss: 0.7738552093505859, Accuracy: 0.78125, Computation time: 0.9372279644012451\n",
      "Step: 4649, Loss: 0.5716564655303955, Accuracy: 0.8125, Computation time: 0.7090802192687988\n",
      "Step: 4650, Loss: 0.6956793069839478, Accuracy: 0.78125, Computation time: 0.8290350437164307\n",
      "Step: 4651, Loss: 0.8217182159423828, Accuracy: 0.84375, Computation time: 0.6961550712585449\n",
      "Step: 4652, Loss: 0.5763236284255981, Accuracy: 0.78125, Computation time: 0.9322571754455566\n",
      "Step: 4653, Loss: 0.4412001371383667, Accuracy: 0.875, Computation time: 0.8842520713806152\n",
      "Step: 4654, Loss: 0.5849611759185791, Accuracy: 0.78125, Computation time: 0.8164308071136475\n",
      "Step: 4655, Loss: 0.317033052444458, Accuracy: 0.90625, Computation time: 0.8451230525970459\n",
      "Step: 4656, Loss: 0.15391723811626434, Accuracy: 0.96875, Computation time: 0.8155059814453125\n",
      "Step: 4657, Loss: 0.3481408357620239, Accuracy: 0.90625, Computation time: 0.9505739212036133\n",
      "Step: 4658, Loss: 0.3285501003265381, Accuracy: 0.875, Computation time: 0.8601219654083252\n",
      "Step: 4659, Loss: 0.9048083424568176, Accuracy: 0.75, Computation time: 0.7869839668273926\n",
      "Step: 4660, Loss: 0.5483983159065247, Accuracy: 0.875, Computation time: 0.7235958576202393\n",
      "Step: 4661, Loss: 0.4415695071220398, Accuracy: 0.875, Computation time: 0.8893182277679443\n",
      "Step: 4662, Loss: 0.5441492199897766, Accuracy: 0.84375, Computation time: 0.9161908626556396\n",
      "Step: 4663, Loss: 0.6401991248130798, Accuracy: 0.75, Computation time: 1.0862720012664795\n",
      "Step: 4664, Loss: 0.6038671135902405, Accuracy: 0.84375, Computation time: 0.8043129444122314\n",
      "Step: 4665, Loss: 0.35444337129592896, Accuracy: 0.9375, Computation time: 0.9173150062561035\n",
      "Step: 4666, Loss: 0.38077685236930847, Accuracy: 0.90625, Computation time: 0.7793338298797607\n",
      "Step: 4667, Loss: 0.6646503806114197, Accuracy: 0.8125, Computation time: 0.889106035232544\n",
      "Step: 4668, Loss: 0.8204407691955566, Accuracy: 0.84375, Computation time: 1.5339982509613037\n",
      "Step: 4669, Loss: 0.7474325299263, Accuracy: 0.8125, Computation time: 0.7894682884216309\n",
      "Step: 4670, Loss: 0.21217241883277893, Accuracy: 0.96875, Computation time: 1.063688039779663\n",
      "Step: 4671, Loss: 0.9557839035987854, Accuracy: 0.6875, Computation time: 1.8018429279327393\n",
      "Step: 4672, Loss: 0.5964980721473694, Accuracy: 0.84375, Computation time: 0.7682969570159912\n",
      "Step: 4673, Loss: 0.2768632471561432, Accuracy: 0.875, Computation time: 0.8036849498748779\n",
      "Step: 4674, Loss: 0.5125818252563477, Accuracy: 0.8125, Computation time: 0.8989238739013672\n",
      "Step: 4675, Loss: 0.6207935810089111, Accuracy: 0.75, Computation time: 0.8755970001220703\n",
      "Step: 4676, Loss: 0.7843739986419678, Accuracy: 0.71875, Computation time: 1.1046788692474365\n",
      "Step: 4677, Loss: 0.3991704285144806, Accuracy: 0.875, Computation time: 1.0053019523620605\n",
      "Step: 4678, Loss: 0.2215268611907959, Accuracy: 0.9375, Computation time: 0.8448431491851807\n",
      "Step: 4679, Loss: 0.35258424282073975, Accuracy: 0.84375, Computation time: 0.8803226947784424\n",
      "Step: 4680, Loss: 0.5489819645881653, Accuracy: 0.8125, Computation time: 0.8890929222106934\n",
      "Step: 4681, Loss: 0.6320995688438416, Accuracy: 0.71875, Computation time: 0.873884916305542\n",
      "Step: 4682, Loss: 0.6782094836235046, Accuracy: 0.8125, Computation time: 0.6673610210418701\n",
      "Step: 4683, Loss: 0.49916762113571167, Accuracy: 0.84375, Computation time: 1.0379929542541504\n",
      "Step: 4684, Loss: 0.6721357703208923, Accuracy: 0.8125, Computation time: 0.7077479362487793\n",
      "Step: 4685, Loss: 0.5013046264648438, Accuracy: 0.8125, Computation time: 0.8002307415008545\n",
      "Step: 4686, Loss: 0.4198196530342102, Accuracy: 0.84375, Computation time: 0.827944278717041\n",
      "Step: 4687, Loss: 0.8959222435951233, Accuracy: 0.75, Computation time: 1.109666109085083\n",
      "Step: 4688, Loss: 0.7715919613838196, Accuracy: 0.84375, Computation time: 0.8545939922332764\n",
      "Step: 4689, Loss: 0.524878203868866, Accuracy: 0.75, Computation time: 1.043389081954956\n",
      "Step: 4690, Loss: 0.9372151494026184, Accuracy: 0.625, Computation time: 0.8603951930999756\n",
      "Step: 4691, Loss: 0.40158963203430176, Accuracy: 0.90625, Computation time: 0.7382769584655762\n",
      "Step: 4692, Loss: 0.7160803079605103, Accuracy: 0.875, Computation time: 0.8598432540893555\n",
      "Step: 4693, Loss: 0.3164871335029602, Accuracy: 0.96875, Computation time: 0.713655948638916\n",
      "Step: 4694, Loss: 0.7153773903846741, Accuracy: 0.8125, Computation time: 0.9977991580963135\n",
      "Step: 4695, Loss: 0.5676401853561401, Accuracy: 0.8125, Computation time: 0.8357388973236084\n",
      "Step: 4696, Loss: 0.5408930778503418, Accuracy: 0.875, Computation time: 0.774169921875\n",
      "Step: 4697, Loss: 0.7621605396270752, Accuracy: 0.78125, Computation time: 1.293515682220459\n",
      "Step: 4698, Loss: 0.566249668598175, Accuracy: 0.75, Computation time: 0.7981581687927246\n",
      "Step: 4699, Loss: 0.544380784034729, Accuracy: 0.84375, Computation time: 0.8832659721374512\n",
      "Step: 4700, Loss: 0.5674068927764893, Accuracy: 0.84375, Computation time: 0.7325191497802734\n",
      "Step: 4701, Loss: 0.2773513197898865, Accuracy: 0.90625, Computation time: 0.8258740901947021\n",
      "Step: 4702, Loss: 0.3113758862018585, Accuracy: 0.90625, Computation time: 0.8147799968719482\n",
      "Step: 4703, Loss: 0.6998710036277771, Accuracy: 0.78125, Computation time: 0.7970380783081055\n",
      "Step: 4704, Loss: 0.5779751539230347, Accuracy: 0.78125, Computation time: 0.9521322250366211\n",
      "Step: 4705, Loss: 0.6447363495826721, Accuracy: 0.78125, Computation time: 0.7341899871826172\n",
      "Step: 4706, Loss: 0.739099383354187, Accuracy: 0.6875, Computation time: 0.7086551189422607\n",
      "Step: 4707, Loss: 0.44749245047569275, Accuracy: 0.84375, Computation time: 0.7357168197631836\n",
      "Step: 4708, Loss: 0.7309055328369141, Accuracy: 0.78125, Computation time: 0.7323253154754639\n",
      "Step: 4709, Loss: 0.6683841943740845, Accuracy: 0.84375, Computation time: 0.8214609622955322\n",
      "Step: 4710, Loss: 0.40187254548072815, Accuracy: 0.84375, Computation time: 0.8009271621704102\n",
      "Step: 4711, Loss: 0.6541593074798584, Accuracy: 0.78125, Computation time: 0.7850151062011719\n",
      "Step: 4712, Loss: 0.7461570501327515, Accuracy: 0.6875, Computation time: 0.6805200576782227\n",
      "Step: 4713, Loss: 0.7435546517372131, Accuracy: 0.875, Computation time: 0.8618090152740479\n",
      "Step: 4714, Loss: 0.3012857437133789, Accuracy: 0.90625, Computation time: 0.8638830184936523\n",
      "Step: 4715, Loss: 0.7422873377799988, Accuracy: 0.75, Computation time: 0.8827409744262695\n",
      "Step: 4716, Loss: 0.3861651122570038, Accuracy: 0.9375, Computation time: 0.8963127136230469\n",
      "Step: 4717, Loss: 0.6859290599822998, Accuracy: 0.84375, Computation time: 0.7800991535186768\n",
      "Step: 4718, Loss: 0.7256009578704834, Accuracy: 0.75, Computation time: 0.924004077911377\n",
      "Step: 4719, Loss: 0.8284494876861572, Accuracy: 0.75, Computation time: 0.6902110576629639\n",
      "Step: 4720, Loss: 0.4918624460697174, Accuracy: 0.84375, Computation time: 0.8165628910064697\n",
      "Step: 4721, Loss: 0.3841018080711365, Accuracy: 0.84375, Computation time: 0.8029508590698242\n",
      "Step: 4722, Loss: 0.8069988489151001, Accuracy: 0.75, Computation time: 0.7792489528656006\n",
      "Step: 4723, Loss: 0.690753161907196, Accuracy: 0.71875, Computation time: 0.8953580856323242\n",
      "Step: 4724, Loss: 0.34493476152420044, Accuracy: 0.84375, Computation time: 0.7089929580688477\n",
      "Step: 4725, Loss: 0.35639941692352295, Accuracy: 0.875, Computation time: 0.8155620098114014\n",
      "Step: 4726, Loss: 0.5217469930648804, Accuracy: 0.875, Computation time: 0.7652442455291748\n",
      "Step: 4727, Loss: 0.8250535726547241, Accuracy: 0.75, Computation time: 0.8079638481140137\n",
      "Step: 4728, Loss: 0.5281754732131958, Accuracy: 0.8125, Computation time: 0.775874137878418\n",
      "Step: 4729, Loss: 0.4113878905773163, Accuracy: 0.875, Computation time: 0.7127296924591064\n",
      "Step: 4730, Loss: 0.35019412636756897, Accuracy: 0.90625, Computation time: 0.8861730098724365\n",
      "Step: 4731, Loss: 0.47000786662101746, Accuracy: 0.875, Computation time: 0.6852512359619141\n",
      "Step: 4732, Loss: 0.6309263706207275, Accuracy: 0.8125, Computation time: 0.7886459827423096\n",
      "Step: 4733, Loss: 0.6952254176139832, Accuracy: 0.8125, Computation time: 0.9907841682434082\n",
      "Step: 4734, Loss: 0.3946741819381714, Accuracy: 0.875, Computation time: 0.8963372707366943\n",
      "Step: 4735, Loss: 0.7387382388114929, Accuracy: 0.8125, Computation time: 0.8177516460418701\n",
      "Step: 4736, Loss: 0.36020636558532715, Accuracy: 0.8125, Computation time: 0.7279510498046875\n",
      "Step: 4737, Loss: 0.42151564359664917, Accuracy: 0.84375, Computation time: 0.82621169090271\n",
      "Step: 4738, Loss: 0.6564456820487976, Accuracy: 0.78125, Computation time: 0.8828117847442627\n",
      "Step: 4739, Loss: 0.4992976486682892, Accuracy: 0.875, Computation time: 1.2469251155853271\n",
      "Step: 4740, Loss: 0.3724968731403351, Accuracy: 0.84375, Computation time: 0.6463732719421387\n",
      "Step: 4741, Loss: 0.5099539756774902, Accuracy: 0.84375, Computation time: 0.8146979808807373\n",
      "Step: 4742, Loss: 0.7886771559715271, Accuracy: 0.78125, Computation time: 0.7551229000091553\n",
      "Step: 4743, Loss: 0.5996022820472717, Accuracy: 0.8125, Computation time: 0.8415820598602295\n",
      "Step: 4744, Loss: 0.18697915971279144, Accuracy: 0.96875, Computation time: 0.6793489456176758\n",
      "Step: 4745, Loss: 0.26749032735824585, Accuracy: 0.9375, Computation time: 0.8267977237701416\n",
      "Step: 4746, Loss: 0.6067224144935608, Accuracy: 0.8125, Computation time: 0.9181399345397949\n",
      "Step: 4747, Loss: 0.4408896863460541, Accuracy: 0.84375, Computation time: 0.889556884765625\n",
      "Step: 4748, Loss: 0.2612091302871704, Accuracy: 0.875, Computation time: 0.7153418064117432\n",
      "Step: 4749, Loss: 0.2571731209754944, Accuracy: 0.9375, Computation time: 0.9033939838409424\n",
      "Step: 4750, Loss: 0.6229309439659119, Accuracy: 0.84375, Computation time: 0.8493521213531494\n",
      "Step: 4751, Loss: 0.3550321161746979, Accuracy: 0.875, Computation time: 0.7653892040252686\n",
      "Step: 4752, Loss: 1.0576859712600708, Accuracy: 0.6875, Computation time: 1.007094144821167\n",
      "Step: 4753, Loss: 0.5866885185241699, Accuracy: 0.78125, Computation time: 0.9417469501495361\n",
      "Step: 4754, Loss: 0.1509968340396881, Accuracy: 0.96875, Computation time: 0.7681729793548584\n",
      "Step: 4755, Loss: 0.542949378490448, Accuracy: 0.8125, Computation time: 0.9186191558837891\n",
      "Step: 4756, Loss: 0.2916225790977478, Accuracy: 0.90625, Computation time: 0.7685351371765137\n",
      "Step: 4757, Loss: 0.26881521940231323, Accuracy: 0.90625, Computation time: 0.8109519481658936\n",
      "Step: 4758, Loss: 0.3988294303417206, Accuracy: 0.875, Computation time: 1.0091361999511719\n",
      "Step: 4759, Loss: 0.39624708890914917, Accuracy: 0.90625, Computation time: 0.9402358531951904\n",
      "Step: 4760, Loss: 0.35833248496055603, Accuracy: 0.84375, Computation time: 0.7902116775512695\n",
      "Step: 4761, Loss: 0.30133986473083496, Accuracy: 0.90625, Computation time: 0.8007500171661377\n",
      "Step: 4762, Loss: 0.4042667746543884, Accuracy: 0.8125, Computation time: 1.5612571239471436\n",
      "Step: 4763, Loss: 0.5308620929718018, Accuracy: 0.84375, Computation time: 0.891575813293457\n",
      "Step: 4764, Loss: 0.3469393253326416, Accuracy: 0.90625, Computation time: 0.76922607421875\n",
      "Step: 4765, Loss: 0.6498011350631714, Accuracy: 0.78125, Computation time: 0.851600170135498\n",
      "Step: 4766, Loss: 0.7871575951576233, Accuracy: 0.84375, Computation time: 0.7840392589569092\n",
      "Step: 4767, Loss: 0.5784358978271484, Accuracy: 0.875, Computation time: 0.8574440479278564\n",
      "Step: 4768, Loss: 0.4401199221611023, Accuracy: 0.84375, Computation time: 1.1490669250488281\n",
      "Step: 4769, Loss: 0.46305006742477417, Accuracy: 0.8125, Computation time: 0.8909571170806885\n",
      "Step: 4770, Loss: 0.33797487616539, Accuracy: 0.90625, Computation time: 0.8384990692138672\n",
      "Step: 4771, Loss: 0.44990846514701843, Accuracy: 0.875, Computation time: 0.6474931240081787\n",
      "Step: 4772, Loss: 0.6083440780639648, Accuracy: 0.8125, Computation time: 0.8053798675537109\n",
      "Step: 4773, Loss: 0.47209200263023376, Accuracy: 0.8125, Computation time: 0.9320907592773438\n",
      "Step: 4774, Loss: 0.8171184659004211, Accuracy: 0.84375, Computation time: 0.9963340759277344\n",
      "Step: 4775, Loss: 0.29477623105049133, Accuracy: 0.875, Computation time: 1.1014456748962402\n",
      "Step: 4776, Loss: 0.33926108479499817, Accuracy: 0.90625, Computation time: 0.7832539081573486\n",
      "Step: 4777, Loss: 0.2976224720478058, Accuracy: 0.96875, Computation time: 0.9479548931121826\n",
      "Step: 4778, Loss: 0.4421374797821045, Accuracy: 0.875, Computation time: 0.8507823944091797\n",
      "Step: 4779, Loss: 0.5307915806770325, Accuracy: 0.84375, Computation time: 0.8402092456817627\n",
      "Step: 4780, Loss: 0.34095025062561035, Accuracy: 0.875, Computation time: 0.9400062561035156\n",
      "Step: 4781, Loss: 0.48816075921058655, Accuracy: 0.875, Computation time: 0.7614281177520752\n",
      "Step: 4782, Loss: 1.1452968120574951, Accuracy: 0.71875, Computation time: 0.9106349945068359\n",
      "Step: 4783, Loss: 0.47951632738113403, Accuracy: 0.84375, Computation time: 0.8009622097015381\n",
      "Step: 4784, Loss: 0.5824860334396362, Accuracy: 0.78125, Computation time: 0.8810837268829346\n",
      "Step: 4785, Loss: 0.6715837717056274, Accuracy: 0.8125, Computation time: 0.7634298801422119\n",
      "Step: 4786, Loss: 0.5114996433258057, Accuracy: 0.8125, Computation time: 0.8420119285583496\n",
      "Step: 4787, Loss: 0.21475893259048462, Accuracy: 0.90625, Computation time: 0.8665368556976318\n",
      "Step: 4788, Loss: 0.47302815318107605, Accuracy: 0.8125, Computation time: 0.9271140098571777\n",
      "Step: 4789, Loss: 0.2727424204349518, Accuracy: 0.875, Computation time: 0.8620328903198242\n",
      "Step: 4790, Loss: 0.3574883043766022, Accuracy: 0.90625, Computation time: 0.7275900840759277\n",
      "Step: 4791, Loss: 0.6063023209571838, Accuracy: 0.8125, Computation time: 0.8391530513763428\n",
      "Step: 4792, Loss: 0.4318976104259491, Accuracy: 0.90625, Computation time: 0.8553791046142578\n",
      "Step: 4793, Loss: 0.510054349899292, Accuracy: 0.78125, Computation time: 1.4727270603179932\n",
      "Step: 4794, Loss: 0.3801528215408325, Accuracy: 0.84375, Computation time: 0.8299620151519775\n",
      "Step: 4795, Loss: 0.34662893414497375, Accuracy: 0.875, Computation time: 0.7753269672393799\n",
      "Step: 4796, Loss: 0.68241286277771, Accuracy: 0.78125, Computation time: 0.9507970809936523\n",
      "Step: 4797, Loss: 0.5575160384178162, Accuracy: 0.84375, Computation time: 0.8127992153167725\n",
      "Step: 4798, Loss: 0.524413526058197, Accuracy: 0.8125, Computation time: 903.8716511726379\n",
      "Step: 4799, Loss: 0.27133581042289734, Accuracy: 0.875, Computation time: 0.8447670936584473\n",
      "Step: 4800, Loss: 0.44072139263153076, Accuracy: 0.90625, Computation time: 0.731208086013794\n",
      "Step: 4801, Loss: 0.43172985315322876, Accuracy: 0.875, Computation time: 0.9616780281066895\n",
      "Step: 4802, Loss: 0.6390979290008545, Accuracy: 0.84375, Computation time: 1.0764641761779785\n",
      "Step: 4803, Loss: 0.38911646604537964, Accuracy: 0.875, Computation time: 0.9132881164550781\n",
      "Step: 4804, Loss: 0.502731442451477, Accuracy: 0.875, Computation time: 0.9335019588470459\n",
      "Step: 4805, Loss: 0.18403662741184235, Accuracy: 0.96875, Computation time: 0.9809579849243164\n",
      "Step: 4806, Loss: 0.6339908838272095, Accuracy: 0.8125, Computation time: 0.7882339954376221\n",
      "Step: 4807, Loss: 0.5292680859565735, Accuracy: 0.84375, Computation time: 0.7631480693817139\n",
      "Step: 4808, Loss: 0.37300020456314087, Accuracy: 0.875, Computation time: 0.862844705581665\n",
      "Step: 4809, Loss: 0.2073502391576767, Accuracy: 0.9375, Computation time: 0.848268985748291\n",
      "Step: 4810, Loss: 0.6074381470680237, Accuracy: 0.875, Computation time: 0.8012490272521973\n",
      "Step: 4811, Loss: 0.4248557388782501, Accuracy: 0.84375, Computation time: 0.8764019012451172\n",
      "Step: 4812, Loss: 1.0721068382263184, Accuracy: 0.78125, Computation time: 0.7884700298309326\n",
      "Step: 4813, Loss: 0.7562515139579773, Accuracy: 0.6875, Computation time: 0.8956458568572998\n",
      "Step: 4814, Loss: 0.4979442059993744, Accuracy: 0.90625, Computation time: 0.829765796661377\n",
      "Step: 4815, Loss: 0.2982723116874695, Accuracy: 0.9375, Computation time: 0.8409619331359863\n",
      "Step: 4816, Loss: 0.5149081349372864, Accuracy: 0.84375, Computation time: 0.7711508274078369\n",
      "Step: 4817, Loss: 0.4728755056858063, Accuracy: 0.8125, Computation time: 0.8074288368225098\n",
      "Step: 4818, Loss: 0.7691715955734253, Accuracy: 0.8125, Computation time: 0.7328939437866211\n",
      "Step: 4819, Loss: 1.1572147607803345, Accuracy: 0.78125, Computation time: 0.7122418880462646\n",
      "Step: 4820, Loss: 0.6711763739585876, Accuracy: 0.8125, Computation time: 0.8221099376678467\n",
      "Step: 4821, Loss: 0.2346397340297699, Accuracy: 0.9375, Computation time: 0.5885789394378662\n",
      "Step: 4822, Loss: 0.23745982348918915, Accuracy: 0.9375, Computation time: 0.8780081272125244\n",
      "Step: 4823, Loss: 0.6156682968139648, Accuracy: 0.71875, Computation time: 0.8395001888275146\n",
      "Step: 4824, Loss: 0.31382566690444946, Accuracy: 0.875, Computation time: 1.620568037033081\n",
      "Step: 4825, Loss: 0.4702976942062378, Accuracy: 0.875, Computation time: 0.6693661212921143\n",
      "Step: 4826, Loss: 0.7766883373260498, Accuracy: 0.78125, Computation time: 0.8735129833221436\n",
      "Step: 4827, Loss: 0.4460330903530121, Accuracy: 0.875, Computation time: 0.9016110897064209\n",
      "Step: 4828, Loss: 0.49965545535087585, Accuracy: 0.84375, Computation time: 1.0098261833190918\n",
      "Step: 4829, Loss: 0.669125497341156, Accuracy: 0.84375, Computation time: 0.8881571292877197\n",
      "Step: 4830, Loss: 0.31381481885910034, Accuracy: 0.875, Computation time: 1.0714609622955322\n",
      "Step: 4831, Loss: 0.5742807984352112, Accuracy: 0.84375, Computation time: 0.8389699459075928\n",
      "Step: 4832, Loss: 0.3676816523075104, Accuracy: 0.90625, Computation time: 0.7781851291656494\n",
      "Step: 4833, Loss: 0.4048953652381897, Accuracy: 0.84375, Computation time: 0.9242627620697021\n",
      "Step: 4834, Loss: 0.5108947157859802, Accuracy: 0.8125, Computation time: 0.7299070358276367\n",
      "Step: 4835, Loss: 0.5612862706184387, Accuracy: 0.8125, Computation time: 0.6960456371307373\n",
      "Step: 4836, Loss: 0.37263011932373047, Accuracy: 0.90625, Computation time: 0.8356280326843262\n",
      "Step: 4837, Loss: 0.5665777921676636, Accuracy: 0.90625, Computation time: 1.0443577766418457\n",
      "Step: 4838, Loss: 0.642142117023468, Accuracy: 0.6875, Computation time: 0.8057417869567871\n",
      "Step: 4839, Loss: 0.6912193894386292, Accuracy: 0.8125, Computation time: 0.8115918636322021\n",
      "Step: 4840, Loss: 0.609550952911377, Accuracy: 0.8125, Computation time: 0.7551848888397217\n",
      "Step: 4841, Loss: 0.5926641821861267, Accuracy: 0.90625, Computation time: 0.8543879985809326\n",
      "Step: 4842, Loss: 0.6039350628852844, Accuracy: 0.8125, Computation time: 0.77825927734375\n",
      "Step: 4843, Loss: 0.5821967124938965, Accuracy: 0.8125, Computation time: 0.7227351665496826\n",
      "Step: 4844, Loss: 0.6627362966537476, Accuracy: 0.8125, Computation time: 0.6820740699768066\n",
      "Step: 4845, Loss: 0.479843407869339, Accuracy: 0.84375, Computation time: 0.7589330673217773\n",
      "Step: 4846, Loss: 0.7465240359306335, Accuracy: 0.6875, Computation time: 0.7713260650634766\n",
      "Step: 4847, Loss: 0.36935484409332275, Accuracy: 0.90625, Computation time: 0.7759261131286621\n",
      "Step: 4848, Loss: 0.18943367898464203, Accuracy: 0.9375, Computation time: 0.7674911022186279\n",
      "Step: 4849, Loss: 0.6997736692428589, Accuracy: 0.75, Computation time: 0.912665843963623\n",
      "Step: 4850, Loss: 0.4940118193626404, Accuracy: 0.875, Computation time: 0.853175163269043\n",
      "Step: 4851, Loss: 0.8127260208129883, Accuracy: 0.78125, Computation time: 0.937680721282959\n",
      "Step: 4852, Loss: 0.7723345160484314, Accuracy: 0.78125, Computation time: 1.0083560943603516\n",
      "Step: 4853, Loss: 0.4631369411945343, Accuracy: 0.875, Computation time: 0.7706520557403564\n",
      "Step: 4854, Loss: 0.5235397815704346, Accuracy: 0.78125, Computation time: 0.7265269756317139\n",
      "Step: 4855, Loss: 0.4943176507949829, Accuracy: 0.90625, Computation time: 0.692864179611206\n",
      "Step: 4856, Loss: 0.582470178604126, Accuracy: 0.875, Computation time: 1.4038782119750977\n",
      "Step: 4857, Loss: 0.5870641469955444, Accuracy: 0.84375, Computation time: 0.7363729476928711\n",
      "Step: 4858, Loss: 0.35580405592918396, Accuracy: 0.9375, Computation time: 0.8930108547210693\n",
      "Step: 4859, Loss: 0.2253958284854889, Accuracy: 0.9375, Computation time: 0.733259916305542\n",
      "Step: 4860, Loss: 0.6232422590255737, Accuracy: 0.71875, Computation time: 0.8746392726898193\n",
      "Step: 4861, Loss: 0.7418171167373657, Accuracy: 0.8125, Computation time: 0.7188971042633057\n",
      "Step: 4862, Loss: 0.8919482827186584, Accuracy: 0.78125, Computation time: 1.0264091491699219\n",
      "Step: 4863, Loss: 0.5880264043807983, Accuracy: 0.875, Computation time: 0.8165297508239746\n",
      "Step: 4864, Loss: 0.5705707669258118, Accuracy: 0.78125, Computation time: 0.8753757476806641\n",
      "Step: 4865, Loss: 0.8109738230705261, Accuracy: 0.78125, Computation time: 1.1312110424041748\n",
      "Step: 4866, Loss: 0.2878970503807068, Accuracy: 0.9375, Computation time: 0.852391242980957\n",
      "Step: 4867, Loss: 0.31252965331077576, Accuracy: 0.9375, Computation time: 0.732295036315918\n",
      "Step: 4868, Loss: 1.2038334608078003, Accuracy: 0.65625, Computation time: 0.9387741088867188\n",
      "Step: 4869, Loss: 0.31138062477111816, Accuracy: 0.90625, Computation time: 0.8718039989471436\n",
      "Step: 4870, Loss: 0.38475707173347473, Accuracy: 0.9375, Computation time: 0.887620210647583\n",
      "Step: 4871, Loss: 0.33546775579452515, Accuracy: 0.875, Computation time: 0.984565019607544\n",
      "Step: 4872, Loss: 0.7888633012771606, Accuracy: 0.78125, Computation time: 1.0838689804077148\n",
      "Step: 4873, Loss: 0.1845162808895111, Accuracy: 0.96875, Computation time: 0.8301272392272949\n",
      "Step: 4874, Loss: 0.3976130485534668, Accuracy: 0.84375, Computation time: 1.0490808486938477\n",
      "Step: 4875, Loss: 0.7715606689453125, Accuracy: 0.78125, Computation time: 1.3888318538665771\n",
      "Step: 4876, Loss: 0.5366721749305725, Accuracy: 0.78125, Computation time: 0.7426068782806396\n",
      "Step: 4877, Loss: 0.6360395550727844, Accuracy: 0.875, Computation time: 0.9109518527984619\n",
      "Step: 4878, Loss: 0.3994135856628418, Accuracy: 0.90625, Computation time: 0.7708847522735596\n",
      "Step: 4879, Loss: 0.5127873420715332, Accuracy: 0.84375, Computation time: 0.8594479560852051\n",
      "Step: 4880, Loss: 0.6532869338989258, Accuracy: 0.8125, Computation time: 0.9683640003204346\n",
      "Step: 4881, Loss: 0.4352808892726898, Accuracy: 0.78125, Computation time: 0.8961210250854492\n",
      "Step: 4882, Loss: 0.5744509100914001, Accuracy: 0.84375, Computation time: 0.7813811302185059\n",
      "Step: 4883, Loss: 0.5336378812789917, Accuracy: 0.84375, Computation time: 0.8518180847167969\n",
      "Step: 4884, Loss: 0.28214776515960693, Accuracy: 0.9375, Computation time: 0.934149980545044\n",
      "Step: 4885, Loss: 0.5808606147766113, Accuracy: 0.84375, Computation time: 0.869318962097168\n",
      "Step: 4886, Loss: 0.7206815481185913, Accuracy: 0.8125, Computation time: 1.589919090270996\n",
      "Step: 4887, Loss: 0.8474692106246948, Accuracy: 0.78125, Computation time: 0.8686089515686035\n",
      "Step: 4888, Loss: 0.5941897034645081, Accuracy: 0.75, Computation time: 0.9671878814697266\n",
      "Step: 4889, Loss: 0.6152756214141846, Accuracy: 0.8125, Computation time: 1.4219717979431152\n",
      "Step: 4890, Loss: 0.4890752136707306, Accuracy: 0.875, Computation time: 0.6888339519500732\n",
      "Step: 4891, Loss: 0.5720098614692688, Accuracy: 0.84375, Computation time: 0.6708657741546631\n",
      "Step: 4892, Loss: 0.2505037188529968, Accuracy: 0.9375, Computation time: 0.809345006942749\n",
      "Step: 4893, Loss: 0.36591383814811707, Accuracy: 0.9375, Computation time: 0.8284809589385986\n",
      "Step: 4894, Loss: 0.4535939693450928, Accuracy: 0.84375, Computation time: 0.9127328395843506\n",
      "Step: 4895, Loss: 0.5224506855010986, Accuracy: 0.8125, Computation time: 0.840939998626709\n",
      "Step: 4896, Loss: 0.2998456060886383, Accuracy: 0.875, Computation time: 0.8122189044952393\n",
      "Step: 4897, Loss: 0.4945794641971588, Accuracy: 0.84375, Computation time: 0.8376860618591309\n",
      "Step: 4898, Loss: 0.5254217386245728, Accuracy: 0.84375, Computation time: 0.7843990325927734\n",
      "Step: 4899, Loss: 0.46295320987701416, Accuracy: 0.84375, Computation time: 0.8390491008758545\n",
      "Step: 4900, Loss: 0.4528436064720154, Accuracy: 0.875, Computation time: 0.7456271648406982\n",
      "Step: 4901, Loss: 0.4502602815628052, Accuracy: 0.875, Computation time: 0.8283798694610596\n",
      "Step: 4902, Loss: 0.27585503458976746, Accuracy: 0.90625, Computation time: 0.8402750492095947\n",
      "Step: 4903, Loss: 0.3834289014339447, Accuracy: 0.875, Computation time: 1.1677141189575195\n",
      "Step: 4904, Loss: 0.5766332149505615, Accuracy: 0.8125, Computation time: 1.2573387622833252\n",
      "Step: 4905, Loss: 0.2236897498369217, Accuracy: 0.9375, Computation time: 1.038435935974121\n",
      "Step: 4906, Loss: 0.3069392144680023, Accuracy: 0.875, Computation time: 0.7703549861907959\n",
      "Step: 4907, Loss: 0.4267675578594208, Accuracy: 0.90625, Computation time: 0.8591437339782715\n",
      "Step: 4908, Loss: 0.39140257239341736, Accuracy: 0.90625, Computation time: 0.760817289352417\n",
      "Step: 4909, Loss: 0.2844722867012024, Accuracy: 0.90625, Computation time: 0.7308547496795654\n",
      "Step: 4910, Loss: 0.2850278317928314, Accuracy: 0.9375, Computation time: 1.0716822147369385\n",
      "Step: 4911, Loss: 0.48798614740371704, Accuracy: 0.84375, Computation time: 0.9100611209869385\n",
      "Step: 4912, Loss: 0.37321770191192627, Accuracy: 0.875, Computation time: 0.7324120998382568\n",
      "Step: 4913, Loss: 0.24674084782600403, Accuracy: 0.90625, Computation time: 0.7862949371337891\n",
      "Step: 4914, Loss: 0.4362063407897949, Accuracy: 0.875, Computation time: 0.8281657695770264\n",
      "Step: 4915, Loss: 0.5353129506111145, Accuracy: 0.75, Computation time: 0.8990869522094727\n",
      "Step: 4916, Loss: 0.3996119201183319, Accuracy: 0.875, Computation time: 1.4742352962493896\n",
      "Step: 4917, Loss: 0.4750978648662567, Accuracy: 0.875, Computation time: 0.9057550430297852\n",
      "Step: 4918, Loss: 0.3502764105796814, Accuracy: 0.875, Computation time: 0.8827230930328369\n",
      "Step: 4919, Loss: 0.5539523959159851, Accuracy: 0.8125, Computation time: 0.7104427814483643\n",
      "Step: 4920, Loss: 1.0354818105697632, Accuracy: 0.71875, Computation time: 0.8549330234527588\n",
      "Step: 4921, Loss: 0.5706915855407715, Accuracy: 0.8125, Computation time: 0.8526198863983154\n",
      "Step: 4922, Loss: 0.8228150606155396, Accuracy: 0.71875, Computation time: 0.7573809623718262\n",
      "Step: 4923, Loss: 0.6031668186187744, Accuracy: 0.84375, Computation time: 0.8093850612640381\n",
      "Step: 4924, Loss: 0.3717208206653595, Accuracy: 0.875, Computation time: 0.7947649955749512\n",
      "Step: 4925, Loss: 0.6771818399429321, Accuracy: 0.8125, Computation time: 0.8861880302429199\n",
      "Step: 4926, Loss: 0.6220266222953796, Accuracy: 0.84375, Computation time: 0.8059377670288086\n",
      "Step: 4927, Loss: 0.16133220493793488, Accuracy: 0.96875, Computation time: 0.7596979141235352\n",
      "Step: 4928, Loss: 0.4105387032032013, Accuracy: 0.84375, Computation time: 0.9981141090393066\n",
      "Step: 4929, Loss: 0.2914207875728607, Accuracy: 0.90625, Computation time: 0.7434737682342529\n",
      "Step: 4930, Loss: 0.8032678961753845, Accuracy: 0.8125, Computation time: 0.8404109477996826\n",
      "Step: 4931, Loss: 0.5286023616790771, Accuracy: 0.8125, Computation time: 0.9466569423675537\n",
      "Step: 4932, Loss: 0.2649066150188446, Accuracy: 0.90625, Computation time: 0.9938647747039795\n",
      "Step: 4933, Loss: 0.3975508511066437, Accuracy: 0.84375, Computation time: 0.8803739547729492\n",
      "Step: 4934, Loss: 0.640313982963562, Accuracy: 0.875, Computation time: 0.8193249702453613\n",
      "Step: 4935, Loss: 0.13860799372196198, Accuracy: 0.9375, Computation time: 0.7939648628234863\n",
      "Step: 4936, Loss: 0.32383260130882263, Accuracy: 0.90625, Computation time: 0.8818058967590332\n",
      "Step: 4937, Loss: 0.5484500527381897, Accuracy: 0.8125, Computation time: 0.6511900424957275\n",
      "Step: 4938, Loss: 0.4203527569770813, Accuracy: 0.875, Computation time: 0.6939032077789307\n",
      "Step: 4939, Loss: 0.2538376450538635, Accuracy: 0.9375, Computation time: 0.7963290214538574\n",
      "Step: 4940, Loss: 0.9212977886199951, Accuracy: 0.6875, Computation time: 0.781404972076416\n",
      "Step: 4941, Loss: 0.34159770607948303, Accuracy: 0.875, Computation time: 0.7099590301513672\n",
      "Step: 4942, Loss: 0.5157559514045715, Accuracy: 0.875, Computation time: 0.9400789737701416\n",
      "Step: 4943, Loss: 0.8278006911277771, Accuracy: 0.625, Computation time: 0.7531731128692627\n",
      "Step: 4944, Loss: 0.47847479581832886, Accuracy: 0.78125, Computation time: 0.9342689514160156\n",
      "Step: 4945, Loss: 0.4397210478782654, Accuracy: 0.78125, Computation time: 0.7948729991912842\n",
      "Step: 4946, Loss: 0.42594248056411743, Accuracy: 0.875, Computation time: 0.9602601528167725\n",
      "Step: 4947, Loss: 0.2612137496471405, Accuracy: 0.90625, Computation time: 0.6596531867980957\n",
      "Step: 4948, Loss: 0.5842009782791138, Accuracy: 0.8125, Computation time: 1.2856287956237793\n",
      "Step: 4949, Loss: 0.27048203349113464, Accuracy: 0.90625, Computation time: 0.7646529674530029\n",
      "Step: 4950, Loss: 0.5769813060760498, Accuracy: 0.84375, Computation time: 0.6863811016082764\n",
      "Step: 4951, Loss: 0.31863558292388916, Accuracy: 0.875, Computation time: 0.9608378410339355\n",
      "Step: 4952, Loss: 0.5145043730735779, Accuracy: 0.84375, Computation time: 0.9227800369262695\n",
      "Step: 4953, Loss: 0.450456827878952, Accuracy: 0.90625, Computation time: 0.8893313407897949\n",
      "Step: 4954, Loss: 0.8778195977210999, Accuracy: 0.8125, Computation time: 0.7813329696655273\n",
      "Step: 4955, Loss: 0.4211156368255615, Accuracy: 0.84375, Computation time: 0.7692170143127441\n",
      "Step: 4956, Loss: 0.598777711391449, Accuracy: 0.875, Computation time: 1.4667119979858398\n",
      "Step: 4957, Loss: 0.37256067991256714, Accuracy: 0.875, Computation time: 0.6722838878631592\n",
      "Step: 4958, Loss: 0.41033148765563965, Accuracy: 0.90625, Computation time: 1.0094809532165527\n",
      "Step: 4959, Loss: 0.3764171600341797, Accuracy: 0.90625, Computation time: 0.8765382766723633\n",
      "Step: 4960, Loss: 0.3821452558040619, Accuracy: 0.90625, Computation time: 0.6597549915313721\n",
      "Step: 4961, Loss: 0.6105799674987793, Accuracy: 0.78125, Computation time: 0.8105559349060059\n",
      "Step: 4962, Loss: 0.3388773500919342, Accuracy: 0.90625, Computation time: 1.1995880603790283\n",
      "Step: 4963, Loss: 0.5682070255279541, Accuracy: 0.78125, Computation time: 0.9232778549194336\n",
      "Step: 4964, Loss: 0.4512239992618561, Accuracy: 0.875, Computation time: 0.84712815284729\n",
      "Step: 4965, Loss: 0.9783543348312378, Accuracy: 0.75, Computation time: 0.8522067070007324\n",
      "Step: 4966, Loss: 0.7160756587982178, Accuracy: 0.8125, Computation time: 0.830773115158081\n",
      "Step: 4967, Loss: 0.5942858457565308, Accuracy: 0.75, Computation time: 0.8601808547973633\n",
      "Step: 4968, Loss: 0.5356307029724121, Accuracy: 0.84375, Computation time: 0.9399702548980713\n",
      "Step: 4969, Loss: 0.3326062262058258, Accuracy: 0.90625, Computation time: 0.899695873260498\n",
      "Step: 4970, Loss: 0.45520105957984924, Accuracy: 0.78125, Computation time: 0.7728722095489502\n",
      "Step: 4971, Loss: 0.4795990586280823, Accuracy: 0.8125, Computation time: 0.750277042388916\n",
      "Step: 4972, Loss: 0.4559142291545868, Accuracy: 0.875, Computation time: 0.7270658016204834\n",
      "Step: 4973, Loss: 0.369225412607193, Accuracy: 0.875, Computation time: 0.7618482112884521\n",
      "Step: 4974, Loss: 0.6143960952758789, Accuracy: 0.84375, Computation time: 0.8142280578613281\n",
      "Step: 4975, Loss: 0.8138926029205322, Accuracy: 0.84375, Computation time: 0.8856608867645264\n",
      "Step: 4976, Loss: 0.33731791377067566, Accuracy: 0.90625, Computation time: 0.7709500789642334\n",
      "Step: 4977, Loss: 0.3619900047779083, Accuracy: 0.875, Computation time: 0.6784970760345459\n",
      "Step: 4978, Loss: 0.4346844255924225, Accuracy: 0.875, Computation time: 0.9796240329742432\n",
      "Step: 4979, Loss: 0.5311912298202515, Accuracy: 0.8125, Computation time: 1.547422170639038\n",
      "Step: 4980, Loss: 0.5649439692497253, Accuracy: 0.8125, Computation time: 0.7369599342346191\n",
      "Step: 4981, Loss: 0.650263249874115, Accuracy: 0.84375, Computation time: 0.8838281631469727\n",
      "Step: 4982, Loss: 0.7262776494026184, Accuracy: 0.8125, Computation time: 0.8880813121795654\n",
      "Step: 4983, Loss: 0.6875118613243103, Accuracy: 0.84375, Computation time: 0.8060948848724365\n",
      "Step: 4984, Loss: 0.22749845683574677, Accuracy: 0.96875, Computation time: 0.8014347553253174\n",
      "Step: 4985, Loss: 0.41960659623146057, Accuracy: 0.84375, Computation time: 0.8635931015014648\n",
      "Step: 4986, Loss: 0.7946709394454956, Accuracy: 0.71875, Computation time: 0.8202817440032959\n",
      "Step: 4987, Loss: 0.5068410038948059, Accuracy: 0.8125, Computation time: 0.926480770111084\n",
      "Step: 4988, Loss: 0.3391636610031128, Accuracy: 0.9375, Computation time: 0.8402969837188721\n",
      "Step: 4989, Loss: 0.8521319031715393, Accuracy: 0.78125, Computation time: 1.996610164642334\n",
      "Step: 4990, Loss: 0.3901554346084595, Accuracy: 0.9375, Computation time: 0.8420422077178955\n",
      "Step: 4991, Loss: 0.2635518014431, Accuracy: 0.90625, Computation time: 0.8221378326416016\n",
      "Step: 4992, Loss: 0.8072002530097961, Accuracy: 0.78125, Computation time: 0.8241889476776123\n",
      "Step: 4993, Loss: 0.35965847969055176, Accuracy: 0.90625, Computation time: 0.7087428569793701\n",
      "Step: 4994, Loss: 0.8774958252906799, Accuracy: 0.71875, Computation time: 0.7694499492645264\n",
      "Step: 4995, Loss: 0.6631378531455994, Accuracy: 0.8125, Computation time: 0.7647271156311035\n",
      "Step: 4996, Loss: 0.5185043215751648, Accuracy: 0.8125, Computation time: 0.9992818832397461\n",
      "Step: 4997, Loss: 0.3229685425758362, Accuracy: 0.90625, Computation time: 0.7793660163879395\n",
      "Step: 4998, Loss: 0.4667196273803711, Accuracy: 0.8125, Computation time: 0.8532059192657471\n",
      "Step: 4999, Loss: 0.6056420207023621, Accuracy: 0.8125, Computation time: 0.7205877304077148\n",
      "Step: 5000, Loss: 0.2329556941986084, Accuracy: 0.90625, Computation time: 0.9675049781799316\n",
      "Step: 5001, Loss: 0.407375693321228, Accuracy: 0.875, Computation time: 1.1547279357910156\n",
      "Step: 5002, Loss: 0.44171959161758423, Accuracy: 0.84375, Computation time: 0.7381598949432373\n",
      "Step: 5003, Loss: 0.30878978967666626, Accuracy: 0.875, Computation time: 0.8983831405639648\n",
      "Step: 5004, Loss: 0.3367706537246704, Accuracy: 0.9375, Computation time: 0.9164149761199951\n",
      "Step: 5005, Loss: 0.3800120949745178, Accuracy: 0.84375, Computation time: 1.010058879852295\n",
      "Step: 5006, Loss: 0.5246260762214661, Accuracy: 0.84375, Computation time: 0.8329899311065674\n",
      "Step: 5007, Loss: 0.21925517916679382, Accuracy: 0.9375, Computation time: 0.8709521293640137\n",
      "Step: 5008, Loss: 0.6126168370246887, Accuracy: 0.875, Computation time: 0.802170991897583\n",
      "Step: 5009, Loss: 0.6894744634628296, Accuracy: 0.8125, Computation time: 1.2182438373565674\n",
      "Step: 5010, Loss: 0.38130298256874084, Accuracy: 0.875, Computation time: 0.8675370216369629\n",
      "Step: 5011, Loss: 0.42398881912231445, Accuracy: 0.8125, Computation time: 0.8255071640014648\n",
      "Step: 5012, Loss: 0.2422480434179306, Accuracy: 0.96875, Computation time: 0.7175300121307373\n",
      "Step: 5013, Loss: 0.2755608856678009, Accuracy: 0.90625, Computation time: 0.921759843826294\n",
      "Step: 5014, Loss: 0.5115971565246582, Accuracy: 0.90625, Computation time: 0.784095048904419\n",
      "Step: 5015, Loss: 0.7095362544059753, Accuracy: 0.8125, Computation time: 0.8197619915008545\n",
      "Step: 5016, Loss: 0.3664669096469879, Accuracy: 0.9375, Computation time: 0.820457935333252\n",
      "Step: 5017, Loss: 0.4791935682296753, Accuracy: 0.875, Computation time: 0.8783760070800781\n",
      "Step: 5018, Loss: 0.4367012679576874, Accuracy: 0.8125, Computation time: 0.9445569515228271\n",
      "Step: 5019, Loss: 0.6278477907180786, Accuracy: 0.84375, Computation time: 0.7863962650299072\n",
      "Step: 5020, Loss: 0.40087226033210754, Accuracy: 0.96875, Computation time: 0.8072690963745117\n",
      "Step: 5021, Loss: 0.609671413898468, Accuracy: 0.84375, Computation time: 0.7742390632629395\n",
      "Step: 5022, Loss: 0.5067625641822815, Accuracy: 0.78125, Computation time: 0.7912089824676514\n",
      "Step: 5023, Loss: 0.4896221458911896, Accuracy: 0.875, Computation time: 0.9865798950195312\n",
      "Step: 5024, Loss: 0.18186107277870178, Accuracy: 0.9375, Computation time: 0.7875621318817139\n",
      "Step: 5025, Loss: 0.328156977891922, Accuracy: 0.875, Computation time: 0.9055488109588623\n",
      "Step: 5026, Loss: 0.1996169090270996, Accuracy: 1.0, Computation time: 0.8743629455566406\n",
      "Step: 5027, Loss: 0.613139808177948, Accuracy: 0.84375, Computation time: 0.7922427654266357\n",
      "Step: 5028, Loss: 0.36376863718032837, Accuracy: 0.90625, Computation time: 0.8039000034332275\n",
      "Step: 5029, Loss: 0.41658124327659607, Accuracy: 0.875, Computation time: 1.0020227432250977\n",
      "Step: 5030, Loss: 0.48818501830101013, Accuracy: 0.84375, Computation time: 0.9676768779754639\n",
      "Step: 5031, Loss: 0.5203708410263062, Accuracy: 0.875, Computation time: 0.9072277545928955\n",
      "Step: 5032, Loss: 0.4132353365421295, Accuracy: 0.875, Computation time: 0.7749199867248535\n",
      "Step: 5033, Loss: 0.40686967968940735, Accuracy: 0.84375, Computation time: 0.9191460609436035\n",
      "Step: 5034, Loss: 0.4016534984111786, Accuracy: 0.90625, Computation time: 0.7273590564727783\n",
      "Step: 5035, Loss: 0.5134933590888977, Accuracy: 0.84375, Computation time: 0.9621238708496094\n",
      "Step: 5036, Loss: 0.4928800165653229, Accuracy: 0.84375, Computation time: 0.9100449085235596\n",
      "Step: 5037, Loss: 1.0037380456924438, Accuracy: 0.8125, Computation time: 0.9925041198730469\n",
      "Step: 5038, Loss: 0.30985027551651, Accuracy: 0.9375, Computation time: 0.7789831161499023\n",
      "Step: 5039, Loss: 0.23789089918136597, Accuracy: 0.9375, Computation time: 0.8070030212402344\n",
      "Step: 5040, Loss: 0.3657132387161255, Accuracy: 0.875, Computation time: 1.638725996017456\n",
      "Step: 5041, Loss: 0.48483651876449585, Accuracy: 0.90625, Computation time: 0.9336581230163574\n",
      "Step: 5042, Loss: 0.5808282494544983, Accuracy: 0.8125, Computation time: 0.8353221416473389\n",
      "Step: 5043, Loss: 0.18920348584651947, Accuracy: 0.96875, Computation time: 0.8909149169921875\n",
      "Step: 5044, Loss: 0.28213557600975037, Accuracy: 0.90625, Computation time: 0.785459041595459\n",
      "Step: 5045, Loss: 0.5503490567207336, Accuracy: 0.84375, Computation time: 0.7956769466400146\n",
      "Step: 5046, Loss: 1.0328654050827026, Accuracy: 0.6875, Computation time: 0.8747498989105225\n",
      "Step: 5047, Loss: 0.4919247627258301, Accuracy: 0.84375, Computation time: 0.8924388885498047\n",
      "Step: 5048, Loss: 0.46368351578712463, Accuracy: 0.875, Computation time: 0.7646892070770264\n",
      "Step: 5049, Loss: 0.6597763895988464, Accuracy: 0.84375, Computation time: 1.0134859085083008\n",
      "Step: 5050, Loss: 0.5795778632164001, Accuracy: 0.8125, Computation time: 0.7423291206359863\n",
      "Step: 5051, Loss: 0.5144708156585693, Accuracy: 0.84375, Computation time: 0.9313220977783203\n",
      "Step: 5052, Loss: 0.7797725796699524, Accuracy: 0.8125, Computation time: 0.9145631790161133\n",
      "Step: 5053, Loss: 0.3473731577396393, Accuracy: 0.875, Computation time: 0.8579690456390381\n",
      "Step: 5054, Loss: 0.36031967401504517, Accuracy: 0.90625, Computation time: 0.762800931930542\n",
      "Step: 5055, Loss: 0.21347004175186157, Accuracy: 0.96875, Computation time: 0.9065637588500977\n",
      "Step: 5056, Loss: 0.6361501812934875, Accuracy: 0.78125, Computation time: 0.70638108253479\n",
      "Step: 5057, Loss: 0.5165746212005615, Accuracy: 0.84375, Computation time: 0.9290471076965332\n",
      "Step: 5058, Loss: 0.34314751625061035, Accuracy: 0.90625, Computation time: 0.7713620662689209\n",
      "Step: 5059, Loss: 0.14195787906646729, Accuracy: 0.9375, Computation time: 0.7661631107330322\n",
      "Step: 5060, Loss: 0.30841299891471863, Accuracy: 0.84375, Computation time: 0.8235492706298828\n",
      "Step: 5061, Loss: 0.27293166518211365, Accuracy: 0.9375, Computation time: 0.8549990653991699\n",
      "Step: 5062, Loss: 0.5620684027671814, Accuracy: 0.875, Computation time: 0.8340210914611816\n",
      "Step: 5063, Loss: 0.28058061003685, Accuracy: 0.9375, Computation time: 0.7525429725646973\n",
      "Step: 5064, Loss: 0.3464128077030182, Accuracy: 0.875, Computation time: 0.8027746677398682\n",
      "Step: 5065, Loss: 0.4759991466999054, Accuracy: 0.875, Computation time: 0.997128963470459\n",
      "Step: 5066, Loss: 0.6172277927398682, Accuracy: 0.8125, Computation time: 1.0084011554718018\n",
      "Step: 5067, Loss: 0.5666036605834961, Accuracy: 0.875, Computation time: 0.8019311428070068\n",
      "Step: 5068, Loss: 0.3589913845062256, Accuracy: 0.875, Computation time: 0.9271929264068604\n",
      "Step: 5069, Loss: 0.4410894513130188, Accuracy: 0.875, Computation time: 0.8487730026245117\n",
      "Step: 5070, Loss: 0.3963043689727783, Accuracy: 0.90625, Computation time: 0.8053748607635498\n",
      "Step: 5071, Loss: 0.4121725559234619, Accuracy: 0.84375, Computation time: 1.6105799674987793\n",
      "Step: 5072, Loss: 0.40485072135925293, Accuracy: 0.90625, Computation time: 0.8814940452575684\n",
      "Step: 5073, Loss: 0.4085806906223297, Accuracy: 0.875, Computation time: 0.8889329433441162\n",
      "Step: 5074, Loss: 0.5888473987579346, Accuracy: 0.75, Computation time: 0.7779788970947266\n",
      "Step: 5075, Loss: 0.6540115475654602, Accuracy: 0.8125, Computation time: 0.8813188076019287\n",
      "Step: 5076, Loss: 1.0024659633636475, Accuracy: 0.65625, Computation time: 0.9665219783782959\n",
      "Step: 5077, Loss: 0.8073481321334839, Accuracy: 0.8125, Computation time: 1.1558561325073242\n",
      "Step: 5078, Loss: 0.3057420253753662, Accuracy: 0.9375, Computation time: 0.7291660308837891\n",
      "Step: 5079, Loss: 0.354821115732193, Accuracy: 0.875, Computation time: 0.9248242378234863\n",
      "Step: 5080, Loss: 0.6558852195739746, Accuracy: 0.78125, Computation time: 0.925623893737793\n",
      "Step: 5081, Loss: 0.8344601988792419, Accuracy: 0.78125, Computation time: 0.7745168209075928\n",
      "Step: 5082, Loss: 0.4826542139053345, Accuracy: 0.78125, Computation time: 0.8071286678314209\n",
      "Step: 5083, Loss: 0.538241446018219, Accuracy: 0.84375, Computation time: 0.9056189060211182\n",
      "Step: 5084, Loss: 0.9497498869895935, Accuracy: 0.6875, Computation time: 0.861565113067627\n",
      "Step: 5085, Loss: 0.42744216322898865, Accuracy: 0.8125, Computation time: 0.8384242057800293\n",
      "Step: 5086, Loss: 0.46177998185157776, Accuracy: 0.84375, Computation time: 0.8743610382080078\n",
      "Step: 5087, Loss: 0.547788143157959, Accuracy: 0.8125, Computation time: 0.8237411975860596\n",
      "Step: 5088, Loss: 0.3801615536212921, Accuracy: 0.875, Computation time: 0.877086877822876\n",
      "Step: 5089, Loss: 0.7436238527297974, Accuracy: 0.78125, Computation time: 0.7932529449462891\n",
      "Step: 5090, Loss: 0.5064114332199097, Accuracy: 0.8125, Computation time: 1.0353426933288574\n",
      "Step: 5091, Loss: 0.7272371053695679, Accuracy: 0.75, Computation time: 0.7502610683441162\n",
      "Step: 5092, Loss: 0.6982343196868896, Accuracy: 0.78125, Computation time: 0.9459600448608398\n",
      "Step: 5093, Loss: 0.49586448073387146, Accuracy: 0.8125, Computation time: 0.9393100738525391\n",
      "Step: 5094, Loss: 0.5637720823287964, Accuracy: 0.78125, Computation time: 0.8905501365661621\n",
      "Step: 5095, Loss: 0.31352466344833374, Accuracy: 0.875, Computation time: 0.7886579036712646\n",
      "Step: 5096, Loss: 0.6036734580993652, Accuracy: 0.84375, Computation time: 0.8522617816925049\n",
      "Step: 5097, Loss: 0.6346696019172668, Accuracy: 0.84375, Computation time: 0.9098191261291504\n",
      "Step: 5098, Loss: 0.7298240065574646, Accuracy: 0.78125, Computation time: 0.8807733058929443\n",
      "Step: 5099, Loss: 0.6647542715072632, Accuracy: 0.78125, Computation time: 0.8951988220214844\n",
      "Step: 5100, Loss: 0.5471457242965698, Accuracy: 0.875, Computation time: 0.8989179134368896\n",
      "Step: 5101, Loss: 0.30215877294540405, Accuracy: 0.90625, Computation time: 1.616908073425293\n",
      "Step: 5102, Loss: 0.5328977108001709, Accuracy: 0.90625, Computation time: 0.7540817260742188\n",
      "Step: 5103, Loss: 0.5525630712509155, Accuracy: 0.78125, Computation time: 0.7990589141845703\n",
      "Step: 5104, Loss: 0.514300525188446, Accuracy: 0.875, Computation time: 0.8186039924621582\n",
      "Step: 5105, Loss: 0.35711669921875, Accuracy: 0.90625, Computation time: 0.8637180328369141\n",
      "Step: 5106, Loss: 0.8930736780166626, Accuracy: 0.8125, Computation time: 0.841447114944458\n",
      "Step: 5107, Loss: 0.45163625478744507, Accuracy: 0.90625, Computation time: 0.9664382934570312\n",
      "Step: 5108, Loss: 0.7049856781959534, Accuracy: 0.75, Computation time: 0.8101949691772461\n",
      "Step: 5109, Loss: 0.27677008509635925, Accuracy: 0.90625, Computation time: 0.8103251457214355\n",
      "Step: 5110, Loss: 0.12316019833087921, Accuracy: 0.96875, Computation time: 0.7638001441955566\n",
      "Step: 5111, Loss: 0.5871276259422302, Accuracy: 0.84375, Computation time: 0.6861639022827148\n",
      "Step: 5112, Loss: 0.5786821246147156, Accuracy: 0.8125, Computation time: 0.7192299365997314\n",
      "Step: 5113, Loss: 0.38056254386901855, Accuracy: 0.84375, Computation time: 0.802570104598999\n",
      "Step: 5114, Loss: 0.2280292510986328, Accuracy: 0.9375, Computation time: 1.028135061264038\n",
      "Step: 5115, Loss: 0.5794947743415833, Accuracy: 0.8125, Computation time: 0.8631610870361328\n",
      "Step: 5116, Loss: 0.5861270427703857, Accuracy: 0.875, Computation time: 0.7546260356903076\n",
      "Step: 5117, Loss: 0.3702643811702728, Accuracy: 0.875, Computation time: 0.7632811069488525\n",
      "Step: 5118, Loss: 0.5962338447570801, Accuracy: 0.875, Computation time: 0.9316060543060303\n",
      "Step: 5119, Loss: 0.6236926317214966, Accuracy: 0.84375, Computation time: 0.8656980991363525\n",
      "Step: 5120, Loss: 0.3652722239494324, Accuracy: 0.875, Computation time: 0.714033842086792\n",
      "Step: 5121, Loss: 0.4676782786846161, Accuracy: 0.8125, Computation time: 0.9016609191894531\n",
      "Step: 5122, Loss: 0.3815455138683319, Accuracy: 0.875, Computation time: 0.8107519149780273\n",
      "Step: 5123, Loss: 0.7181068658828735, Accuracy: 0.75, Computation time: 0.8972480297088623\n",
      "Step: 5124, Loss: 0.5614328384399414, Accuracy: 0.84375, Computation time: 0.8457391262054443\n",
      "Step: 5125, Loss: 0.3696071207523346, Accuracy: 0.84375, Computation time: 1.2914540767669678\n",
      "Step: 5126, Loss: 0.6622345447540283, Accuracy: 0.78125, Computation time: 0.8124439716339111\n",
      "Step: 5127, Loss: 0.9746053814888, Accuracy: 0.71875, Computation time: 0.7182989120483398\n",
      "Step: 5128, Loss: 0.5077660083770752, Accuracy: 0.875, Computation time: 0.8375570774078369\n",
      "Step: 5129, Loss: 0.5708938241004944, Accuracy: 0.8125, Computation time: 0.7814929485321045\n",
      "Step: 5130, Loss: 0.46596843004226685, Accuracy: 0.84375, Computation time: 0.8637018203735352\n",
      "Step: 5131, Loss: 0.4097864329814911, Accuracy: 0.875, Computation time: 0.8790509700775146\n",
      "Step: 5132, Loss: 0.3394332826137543, Accuracy: 0.90625, Computation time: 0.8286657333374023\n",
      "Step: 5133, Loss: 0.4516910910606384, Accuracy: 0.84375, Computation time: 1.5364491939544678\n",
      "Step: 5134, Loss: 0.6988052129745483, Accuracy: 0.84375, Computation time: 0.8006999492645264\n",
      "Step: 5135, Loss: 0.7595138549804688, Accuracy: 0.78125, Computation time: 0.8420617580413818\n",
      "Step: 5136, Loss: 0.7225117087364197, Accuracy: 0.78125, Computation time: 0.8212888240814209\n",
      "Step: 5137, Loss: 0.8227835893630981, Accuracy: 0.71875, Computation time: 0.8015501499176025\n",
      "Step: 5138, Loss: 0.3543300926685333, Accuracy: 0.90625, Computation time: 0.8716309070587158\n",
      "Step: 5139, Loss: 0.24203841388225555, Accuracy: 0.9375, Computation time: 0.8372290134429932\n",
      "Step: 5140, Loss: 0.5176537036895752, Accuracy: 0.90625, Computation time: 0.703620195388794\n",
      "Step: 5141, Loss: 0.587482750415802, Accuracy: 0.75, Computation time: 0.8440761566162109\n",
      "Step: 5142, Loss: 0.614060640335083, Accuracy: 0.875, Computation time: 1.0187759399414062\n",
      "Step: 5143, Loss: 0.8471115827560425, Accuracy: 0.8125, Computation time: 0.9786391258239746\n",
      "Step: 5144, Loss: 0.3736124038696289, Accuracy: 0.875, Computation time: 0.7084782123565674\n",
      "Step: 5145, Loss: 0.41936054825782776, Accuracy: 0.84375, Computation time: 1.0769920349121094\n",
      "Step: 5146, Loss: 0.7910219430923462, Accuracy: 0.78125, Computation time: 0.8907070159912109\n",
      "Step: 5147, Loss: 0.29849469661712646, Accuracy: 0.9375, Computation time: 0.9089231491088867\n",
      "Step: 5148, Loss: 0.4760499894618988, Accuracy: 0.875, Computation time: 0.8483312129974365\n",
      "Step: 5149, Loss: 0.4807007908821106, Accuracy: 0.875, Computation time: 0.8277440071105957\n",
      "Step: 5150, Loss: 0.6909832954406738, Accuracy: 0.75, Computation time: 0.7616221904754639\n",
      "Step: 5151, Loss: 0.19570758938789368, Accuracy: 0.9375, Computation time: 0.8650808334350586\n",
      "Step: 5152, Loss: 0.6055691838264465, Accuracy: 0.78125, Computation time: 0.7542989253997803\n",
      "Step: 5153, Loss: 0.6314141154289246, Accuracy: 0.75, Computation time: 0.9008181095123291\n",
      "Step: 5154, Loss: 0.22565171122550964, Accuracy: 0.90625, Computation time: 0.9708869457244873\n",
      "Step: 5155, Loss: 0.16826485097408295, Accuracy: 0.9375, Computation time: 0.9422788619995117\n",
      "Step: 5156, Loss: 0.8501652479171753, Accuracy: 0.75, Computation time: 0.8669707775115967\n",
      "Step: 5157, Loss: 0.5827963352203369, Accuracy: 0.78125, Computation time: 0.886476993560791\n",
      "Step: 5158, Loss: 0.6905022859573364, Accuracy: 0.90625, Computation time: 0.8542191982269287\n",
      "Step: 5159, Loss: 0.37858113646507263, Accuracy: 0.875, Computation time: 0.8088881969451904\n",
      "Step: 5160, Loss: 0.49203434586524963, Accuracy: 0.84375, Computation time: 1.239983320236206\n",
      "Step: 5161, Loss: 0.3498024344444275, Accuracy: 0.875, Computation time: 0.8985731601715088\n",
      "Step: 5162, Loss: 0.3018571734428406, Accuracy: 0.90625, Computation time: 0.8867919445037842\n",
      "Step: 5163, Loss: 1.0727097988128662, Accuracy: 0.71875, Computation time: 1.372448205947876\n",
      "Step: 5164, Loss: 0.4247726500034332, Accuracy: 0.90625, Computation time: 1.4754579067230225\n",
      "Step: 5165, Loss: 0.9833478927612305, Accuracy: 0.71875, Computation time: 0.6986932754516602\n",
      "Step: 5166, Loss: 0.5918340682983398, Accuracy: 0.8125, Computation time: 0.8085849285125732\n",
      "Step: 5167, Loss: 0.763356626033783, Accuracy: 0.78125, Computation time: 0.9443268775939941\n",
      "Step: 5168, Loss: 0.4525899589061737, Accuracy: 0.90625, Computation time: 0.9539201259613037\n",
      "Step: 5169, Loss: 0.4666498899459839, Accuracy: 0.90625, Computation time: 1.238680124282837\n",
      "Step: 5170, Loss: 0.5524706840515137, Accuracy: 0.84375, Computation time: 0.857266902923584\n",
      "Step: 5171, Loss: 0.5843086242675781, Accuracy: 0.84375, Computation time: 0.8532779216766357\n",
      "Step: 5172, Loss: 0.5441529154777527, Accuracy: 0.8125, Computation time: 0.8960330486297607\n",
      "Step: 5173, Loss: 0.7723875045776367, Accuracy: 0.78125, Computation time: 0.7833302021026611\n",
      "Step: 5174, Loss: 0.7504792213439941, Accuracy: 0.78125, Computation time: 0.7773308753967285\n",
      "Step: 5175, Loss: 0.39169028401374817, Accuracy: 0.90625, Computation time: 0.8529820442199707\n",
      "Step: 5176, Loss: 0.5754594802856445, Accuracy: 0.84375, Computation time: 0.768273115158081\n",
      "Step: 5177, Loss: 0.5455278754234314, Accuracy: 0.8125, Computation time: 0.8418450355529785\n",
      "Step: 5178, Loss: 0.37176719307899475, Accuracy: 0.84375, Computation time: 0.8812158107757568\n",
      "Step: 5179, Loss: 0.7373123168945312, Accuracy: 0.84375, Computation time: 0.8825469017028809\n",
      "Step: 5180, Loss: 1.0787124633789062, Accuracy: 0.75, Computation time: 0.9064247608184814\n",
      "Step: 5181, Loss: 0.6240180730819702, Accuracy: 0.84375, Computation time: 0.8305988311767578\n",
      "Step: 5182, Loss: 0.6023072600364685, Accuracy: 0.8125, Computation time: 0.8445250988006592\n",
      "Step: 5183, Loss: 0.5492737889289856, Accuracy: 0.875, Computation time: 0.9513700008392334\n",
      "Step: 5184, Loss: 0.5355843305587769, Accuracy: 0.84375, Computation time: 0.8660879135131836\n",
      "Step: 5185, Loss: 0.5639877319335938, Accuracy: 0.8125, Computation time: 0.893592119216919\n",
      "Step: 5186, Loss: 0.5519084334373474, Accuracy: 0.84375, Computation time: 0.8059408664703369\n",
      "Step: 5187, Loss: 0.19619813561439514, Accuracy: 0.90625, Computation time: 0.7881128787994385\n",
      "Step: 5188, Loss: 0.24913053214550018, Accuracy: 0.9375, Computation time: 1.0554959774017334\n",
      "Step: 5189, Loss: 0.2932506501674652, Accuracy: 0.9375, Computation time: 0.8167521953582764\n",
      "Step: 5190, Loss: 0.606338620185852, Accuracy: 0.84375, Computation time: 1.3225491046905518\n",
      "Step: 5191, Loss: 0.6689794063568115, Accuracy: 0.78125, Computation time: 0.8472020626068115\n",
      "Step: 5192, Loss: 0.33562228083610535, Accuracy: 0.875, Computation time: 1.108666181564331\n",
      "Step: 5193, Loss: 0.6471996307373047, Accuracy: 0.8125, Computation time: 1.6492931842803955\n",
      "Step: 5194, Loss: 0.5013990998268127, Accuracy: 0.84375, Computation time: 0.7952110767364502\n",
      "Step: 5195, Loss: 0.3068390190601349, Accuracy: 0.9375, Computation time: 0.9309561252593994\n",
      "Step: 5196, Loss: 0.44481855630874634, Accuracy: 0.875, Computation time: 0.8751358985900879\n",
      "Step: 5197, Loss: 0.3902527391910553, Accuracy: 0.84375, Computation time: 1.0152251720428467\n",
      "Step: 5198, Loss: 0.6778767108917236, Accuracy: 0.8125, Computation time: 0.981935977935791\n",
      "Step: 5199, Loss: 0.43883055448532104, Accuracy: 0.9375, Computation time: 0.9030137062072754\n",
      "Step: 5200, Loss: 0.3530827760696411, Accuracy: 0.875, Computation time: 0.7457160949707031\n",
      "Step: 5201, Loss: 0.30441659688949585, Accuracy: 0.9375, Computation time: 0.821760892868042\n",
      "Step: 5202, Loss: 0.5162748098373413, Accuracy: 0.8125, Computation time: 0.7265262603759766\n",
      "Step: 5203, Loss: 0.23752020299434662, Accuracy: 0.9375, Computation time: 0.7941644191741943\n",
      "Step: 5204, Loss: 0.7323246002197266, Accuracy: 0.84375, Computation time: 0.8217122554779053\n",
      "Step: 5205, Loss: 0.30212584137916565, Accuracy: 0.90625, Computation time: 0.8244290351867676\n",
      "Step: 5206, Loss: 0.7174967527389526, Accuracy: 0.84375, Computation time: 0.7592051029205322\n",
      "Step: 5207, Loss: 0.8984648585319519, Accuracy: 0.75, Computation time: 0.7421238422393799\n",
      "Step: 5208, Loss: 0.41806086897850037, Accuracy: 0.875, Computation time: 0.7819151878356934\n",
      "Step: 5209, Loss: 0.8182569742202759, Accuracy: 0.6875, Computation time: 0.7532839775085449\n",
      "Step: 5210, Loss: 0.4332693815231323, Accuracy: 0.875, Computation time: 0.7411611080169678\n",
      "Step: 5211, Loss: 0.40967127680778503, Accuracy: 0.84375, Computation time: 0.6659650802612305\n",
      "Step: 5212, Loss: 0.5600386261940002, Accuracy: 0.84375, Computation time: 0.8745918273925781\n",
      "Step: 5213, Loss: 0.47659897804260254, Accuracy: 0.90625, Computation time: 1.4320807456970215\n",
      "Step: 5214, Loss: 0.21195025742053986, Accuracy: 0.90625, Computation time: 0.9428009986877441\n",
      "Step: 5215, Loss: 0.6525648236274719, Accuracy: 0.8125, Computation time: 0.7970740795135498\n",
      "Step: 5216, Loss: 0.25744178891181946, Accuracy: 0.875, Computation time: 0.9709949493408203\n",
      "Step: 5217, Loss: 0.41437557339668274, Accuracy: 0.875, Computation time: 0.7813758850097656\n",
      "Step: 5218, Loss: 0.3658238649368286, Accuracy: 0.90625, Computation time: 0.8471951484680176\n",
      "Step: 5219, Loss: 0.6729247570037842, Accuracy: 0.78125, Computation time: 0.8991680145263672\n",
      "Step: 5220, Loss: 0.33180949091911316, Accuracy: 0.875, Computation time: 0.9035689830780029\n",
      "Step: 5221, Loss: 0.27353450655937195, Accuracy: 0.9375, Computation time: 0.8783450126647949\n",
      "Step: 5222, Loss: 0.34950488805770874, Accuracy: 0.875, Computation time: 0.9726572036743164\n",
      "Step: 5223, Loss: 0.42464324831962585, Accuracy: 0.90625, Computation time: 1.902566909790039\n",
      "Step: 5224, Loss: 0.24508777260780334, Accuracy: 0.90625, Computation time: 0.900763988494873\n",
      "Step: 5225, Loss: 1.230880618095398, Accuracy: 0.8125, Computation time: 0.9485020637512207\n",
      "Step: 5226, Loss: 0.6912040114402771, Accuracy: 0.78125, Computation time: 0.7455580234527588\n",
      "Step: 5227, Loss: 0.5239420533180237, Accuracy: 0.9375, Computation time: 0.7853891849517822\n",
      "Step: 5228, Loss: 0.4036965072154999, Accuracy: 0.90625, Computation time: 0.8700201511383057\n",
      "Step: 5229, Loss: 0.4661373198032379, Accuracy: 0.84375, Computation time: 787.0623121261597\n",
      "Step: 5230, Loss: 0.3531338572502136, Accuracy: 0.9375, Computation time: 0.7856078147888184\n",
      "Step: 5231, Loss: 0.6801530718803406, Accuracy: 0.84375, Computation time: 0.9474611282348633\n",
      "Step: 5232, Loss: 0.8173324465751648, Accuracy: 0.84375, Computation time: 1.3485102653503418\n",
      "Step: 5233, Loss: 0.3201461434364319, Accuracy: 0.90625, Computation time: 0.9434852600097656\n",
      "Step: 5234, Loss: 0.6647475957870483, Accuracy: 0.71875, Computation time: 0.8062140941619873\n",
      "Step: 5235, Loss: 0.9481304287910461, Accuracy: 0.59375, Computation time: 0.8257100582122803\n",
      "Step: 5236, Loss: 1.0131760835647583, Accuracy: 0.71875, Computation time: 0.8403599262237549\n",
      "Step: 5237, Loss: 0.429035484790802, Accuracy: 0.84375, Computation time: 0.825573205947876\n",
      "Step: 5238, Loss: 0.3870048224925995, Accuracy: 0.875, Computation time: 0.9332540035247803\n",
      "Step: 5239, Loss: 0.3176427483558655, Accuracy: 0.9375, Computation time: 0.7293410301208496\n",
      "Step: 5240, Loss: 1.0083327293395996, Accuracy: 0.75, Computation time: 0.8350532054901123\n",
      "Step: 5241, Loss: 0.6085524559020996, Accuracy: 0.8125, Computation time: 1.0245330333709717\n",
      "Step: 5242, Loss: 0.34003275632858276, Accuracy: 0.9375, Computation time: 0.7539582252502441\n",
      "Step: 5243, Loss: 0.5242835879325867, Accuracy: 0.875, Computation time: 0.8231868743896484\n",
      "Step: 5244, Loss: 0.653433084487915, Accuracy: 0.8125, Computation time: 0.7867000102996826\n",
      "Step: 5245, Loss: 0.4138411581516266, Accuracy: 0.84375, Computation time: 0.8815779685974121\n",
      "Step: 5246, Loss: 0.4406990706920624, Accuracy: 0.90625, Computation time: 0.8659200668334961\n",
      "Step: 5247, Loss: 0.6755868792533875, Accuracy: 0.875, Computation time: 0.8314518928527832\n",
      "Step: 5248, Loss: 1.0528454780578613, Accuracy: 0.71875, Computation time: 0.9546809196472168\n",
      "Step: 5249, Loss: 0.8356473445892334, Accuracy: 0.75, Computation time: 0.7996249198913574\n",
      "Step: 5250, Loss: 0.529441237449646, Accuracy: 0.84375, Computation time: 0.8766541481018066\n",
      "Step: 5251, Loss: 0.8020029067993164, Accuracy: 0.84375, Computation time: 0.7900269031524658\n",
      "Step: 5252, Loss: 0.42554983496665955, Accuracy: 0.875, Computation time: 0.8139777183532715\n",
      "Step: 5253, Loss: 0.4903046786785126, Accuracy: 0.875, Computation time: 1.6740410327911377\n",
      "Step: 5254, Loss: 0.28054487705230713, Accuracy: 0.90625, Computation time: 0.7832469940185547\n",
      "Step: 5255, Loss: 0.4943024814128876, Accuracy: 0.875, Computation time: 0.8454289436340332\n",
      "Step: 5256, Loss: 0.6067723035812378, Accuracy: 0.84375, Computation time: 0.7195460796356201\n",
      "Step: 5257, Loss: 0.5803688764572144, Accuracy: 0.8125, Computation time: 0.8569619655609131\n",
      "Step: 5258, Loss: 0.7086130976676941, Accuracy: 0.84375, Computation time: 0.7844548225402832\n",
      "Step: 5259, Loss: 0.48889461159706116, Accuracy: 0.84375, Computation time: 0.9588842391967773\n",
      "Step: 5260, Loss: 0.4791029095649719, Accuracy: 0.84375, Computation time: 0.8590908050537109\n",
      "Step: 5261, Loss: 0.4977506101131439, Accuracy: 0.875, Computation time: 0.8970749378204346\n",
      "Step: 5262, Loss: 0.5404521226882935, Accuracy: 0.84375, Computation time: 0.9734368324279785\n",
      "Step: 5263, Loss: 0.5801409482955933, Accuracy: 0.875, Computation time: 0.8239700794219971\n",
      "Step: 5264, Loss: 0.6599928736686707, Accuracy: 0.8125, Computation time: 0.9002139568328857\n",
      "Step: 5265, Loss: 0.5181032419204712, Accuracy: 0.84375, Computation time: 0.8605880737304688\n",
      "Step: 5266, Loss: 0.49105140566825867, Accuracy: 0.90625, Computation time: 0.9573431015014648\n",
      "Step: 5267, Loss: 0.4021933674812317, Accuracy: 0.9375, Computation time: 0.688647985458374\n",
      "Step: 5268, Loss: 0.609162449836731, Accuracy: 0.84375, Computation time: 1.1357760429382324\n",
      "Step: 5269, Loss: 0.4831433594226837, Accuracy: 0.875, Computation time: 0.9561679363250732\n",
      "Step: 5270, Loss: 0.32538291811943054, Accuracy: 0.84375, Computation time: 0.800300121307373\n",
      "Step: 5271, Loss: 0.5836130380630493, Accuracy: 0.84375, Computation time: 0.8610951900482178\n",
      "Step: 5272, Loss: 0.3669366240501404, Accuracy: 0.84375, Computation time: 0.9604558944702148\n",
      "Step: 5273, Loss: 0.3992803990840912, Accuracy: 0.84375, Computation time: 0.8365890979766846\n",
      "Step: 5274, Loss: 0.2986816465854645, Accuracy: 0.90625, Computation time: 0.8179078102111816\n",
      "Step: 5275, Loss: 0.472463458776474, Accuracy: 0.84375, Computation time: 0.8009138107299805\n",
      "Step: 5276, Loss: 0.3360074460506439, Accuracy: 0.9375, Computation time: 0.8405940532684326\n",
      "Step: 5277, Loss: 0.3020365536212921, Accuracy: 0.9375, Computation time: 0.781883955001831\n",
      "Step: 5278, Loss: 0.6043828725814819, Accuracy: 0.8125, Computation time: 1.0974559783935547\n",
      "Step: 5279, Loss: 0.3195916414260864, Accuracy: 0.875, Computation time: 0.8507480621337891\n",
      "Step: 5280, Loss: 0.5606878399848938, Accuracy: 0.875, Computation time: 0.9304261207580566\n",
      "Step: 5281, Loss: 0.40034955739974976, Accuracy: 0.84375, Computation time: 0.7887148857116699\n",
      "Step: 5282, Loss: 0.4019559621810913, Accuracy: 0.875, Computation time: 0.881601095199585\n",
      "Step: 5283, Loss: 0.7814300656318665, Accuracy: 0.8125, Computation time: 1.0897698402404785\n",
      "Step: 5284, Loss: 0.4123140275478363, Accuracy: 0.90625, Computation time: 0.9066541194915771\n",
      "Step: 5285, Loss: 0.56649249792099, Accuracy: 0.8125, Computation time: 0.8396492004394531\n",
      "Step: 5286, Loss: 0.20535309612751007, Accuracy: 0.9375, Computation time: 0.9386146068572998\n",
      "Step: 5287, Loss: 0.43484291434288025, Accuracy: 0.875, Computation time: 0.7889320850372314\n",
      "Step: 5288, Loss: 0.5691620111465454, Accuracy: 0.8125, Computation time: 0.7775700092315674\n",
      "Step: 5289, Loss: 0.8461531400680542, Accuracy: 0.78125, Computation time: 0.8820657730102539\n",
      "Step: 5290, Loss: 0.2011989951133728, Accuracy: 0.90625, Computation time: 0.8192081451416016\n",
      "Step: 5291, Loss: 0.36559221148490906, Accuracy: 0.84375, Computation time: 0.8712530136108398\n",
      "Step: 5292, Loss: 0.6554557085037231, Accuracy: 0.8125, Computation time: 0.9202859401702881\n",
      "Step: 5293, Loss: 0.6533551812171936, Accuracy: 0.875, Computation time: 0.8143858909606934\n",
      "Step: 5294, Loss: 0.2822379767894745, Accuracy: 0.84375, Computation time: 0.7719581127166748\n",
      "Step: 5295, Loss: 0.292305052280426, Accuracy: 0.96875, Computation time: 0.7630729675292969\n",
      "Step: 5296, Loss: 0.45874518156051636, Accuracy: 0.8125, Computation time: 0.7379400730133057\n",
      "Step: 5297, Loss: 0.7226458191871643, Accuracy: 0.75, Computation time: 0.8447821140289307\n",
      "Step: 5298, Loss: 0.7430834770202637, Accuracy: 0.84375, Computation time: 0.957902193069458\n",
      "Step: 5299, Loss: 0.4268673062324524, Accuracy: 0.875, Computation time: 0.8481719493865967\n",
      "Step: 5300, Loss: 0.6114438772201538, Accuracy: 0.75, Computation time: 0.9641087055206299\n",
      "Step: 5301, Loss: 0.38801416754722595, Accuracy: 0.8125, Computation time: 1.3847858905792236\n",
      "Step: 5302, Loss: 0.25915420055389404, Accuracy: 0.9375, Computation time: 0.8613600730895996\n",
      "Step: 5303, Loss: 0.6164816617965698, Accuracy: 0.8125, Computation time: 0.8024897575378418\n",
      "Step: 5304, Loss: 0.39472565054893494, Accuracy: 0.875, Computation time: 0.9148609638214111\n",
      "Step: 5305, Loss: 0.6134522557258606, Accuracy: 0.84375, Computation time: 0.725916862487793\n",
      "Step: 5306, Loss: 0.2861863672733307, Accuracy: 0.875, Computation time: 0.9564070701599121\n",
      "Step: 5307, Loss: 0.4542461335659027, Accuracy: 0.9375, Computation time: 0.8029789924621582\n",
      "Step: 5308, Loss: 0.26860398054122925, Accuracy: 0.90625, Computation time: 0.8510921001434326\n",
      "Step: 5309, Loss: 0.7794403433799744, Accuracy: 0.8125, Computation time: 0.944368839263916\n",
      "Step: 5310, Loss: 0.5803241729736328, Accuracy: 0.875, Computation time: 0.8504018783569336\n",
      "Step: 5311, Loss: 0.49912023544311523, Accuracy: 0.8125, Computation time: 0.8256790637969971\n",
      "Step: 5312, Loss: 0.37577033042907715, Accuracy: 0.90625, Computation time: 0.6994450092315674\n",
      "Step: 5313, Loss: 0.6291703581809998, Accuracy: 0.8125, Computation time: 0.7442431449890137\n",
      "Step: 5314, Loss: 0.3572980761528015, Accuracy: 0.90625, Computation time: 1.452559232711792\n",
      "Step: 5315, Loss: 0.43609073758125305, Accuracy: 0.84375, Computation time: 0.8903000354766846\n",
      "Step: 5316, Loss: 0.5280246734619141, Accuracy: 0.84375, Computation time: 0.7828097343444824\n",
      "Step: 5317, Loss: 0.24834345281124115, Accuracy: 0.9375, Computation time: 0.8313348293304443\n",
      "Step: 5318, Loss: 0.7754001617431641, Accuracy: 0.75, Computation time: 1.0870330333709717\n",
      "Step: 5319, Loss: 0.35736942291259766, Accuracy: 0.90625, Computation time: 1.0050268173217773\n",
      "Step: 5320, Loss: 0.5355085730552673, Accuracy: 0.84375, Computation time: 0.7838039398193359\n",
      "Step: 5321, Loss: 0.522423505783081, Accuracy: 0.84375, Computation time: 0.8783140182495117\n",
      "Step: 5322, Loss: 0.5740454792976379, Accuracy: 0.78125, Computation time: 1.4165570735931396\n",
      "Step: 5323, Loss: 0.5015993714332581, Accuracy: 0.84375, Computation time: 0.9447999000549316\n",
      "Step: 5324, Loss: 0.4594014883041382, Accuracy: 0.84375, Computation time: 0.7569212913513184\n",
      "Step: 5325, Loss: 0.518494725227356, Accuracy: 0.90625, Computation time: 0.716041088104248\n",
      "Step: 5326, Loss: 0.4646662175655365, Accuracy: 0.875, Computation time: 0.8147766590118408\n",
      "Step: 5327, Loss: 0.41599905490875244, Accuracy: 0.90625, Computation time: 0.9729840755462646\n",
      "Step: 5328, Loss: 0.23910783231258392, Accuracy: 0.96875, Computation time: 0.9177610874176025\n",
      "Step: 5329, Loss: 0.34122517704963684, Accuracy: 0.90625, Computation time: 1.0465660095214844\n",
      "Step: 5330, Loss: 0.29496732354164124, Accuracy: 0.875, Computation time: 0.8747081756591797\n",
      "Step: 5331, Loss: 0.4797125458717346, Accuracy: 0.8125, Computation time: 0.8091938495635986\n",
      "Step: 5332, Loss: 0.5731541514396667, Accuracy: 0.90625, Computation time: 0.8140978813171387\n",
      "Step: 5333, Loss: 0.9973252415657043, Accuracy: 0.6875, Computation time: 0.7589089870452881\n",
      "Step: 5334, Loss: 0.3691655993461609, Accuracy: 0.96875, Computation time: 0.9504082202911377\n",
      "Step: 5335, Loss: 0.4714730381965637, Accuracy: 0.84375, Computation time: 0.8773541450500488\n",
      "Step: 5336, Loss: 0.5177139639854431, Accuracy: 0.84375, Computation time: 0.9344267845153809\n",
      "Step: 5337, Loss: 0.39201629161834717, Accuracy: 0.90625, Computation time: 0.8169100284576416\n",
      "Step: 5338, Loss: 0.816305935382843, Accuracy: 0.84375, Computation time: 0.7282979488372803\n",
      "Step: 5339, Loss: 0.5558976531028748, Accuracy: 0.875, Computation time: 0.7908170223236084\n",
      "Step: 5340, Loss: 0.8554880619049072, Accuracy: 0.78125, Computation time: 0.8441648483276367\n",
      "Step: 5341, Loss: 0.2939213216304779, Accuracy: 0.90625, Computation time: 0.9504551887512207\n",
      "Step: 5342, Loss: 0.30741026997566223, Accuracy: 0.90625, Computation time: 0.7264978885650635\n",
      "Step: 5343, Loss: 0.25667527318000793, Accuracy: 0.90625, Computation time: 0.8787949085235596\n",
      "Step: 5344, Loss: 0.5971682071685791, Accuracy: 0.8125, Computation time: 0.880565881729126\n",
      "Step: 5345, Loss: 0.27688953280448914, Accuracy: 0.90625, Computation time: 1.312326192855835\n",
      "Step: 5346, Loss: 0.6195187568664551, Accuracy: 0.71875, Computation time: 0.9202511310577393\n",
      "Step: 5347, Loss: 0.25274819135665894, Accuracy: 0.9375, Computation time: 1.048741102218628\n",
      "Step: 5348, Loss: 0.3454868495464325, Accuracy: 0.90625, Computation time: 0.8053841590881348\n",
      "Step: 5349, Loss: 0.5064118504524231, Accuracy: 0.8125, Computation time: 0.8109090328216553\n",
      "Step: 5350, Loss: 0.26954561471939087, Accuracy: 0.90625, Computation time: 1.010101079940796\n",
      "Step: 5351, Loss: 0.7191610336303711, Accuracy: 0.78125, Computation time: 0.8463428020477295\n",
      "Step: 5352, Loss: 0.36491456627845764, Accuracy: 0.84375, Computation time: 0.9013340473175049\n",
      "Step: 5353, Loss: 0.7565510869026184, Accuracy: 0.8125, Computation time: 0.7807450294494629\n",
      "Step: 5354, Loss: 0.49278146028518677, Accuracy: 0.8125, Computation time: 0.8321559429168701\n",
      "Step: 5355, Loss: 0.2429468184709549, Accuracy: 0.96875, Computation time: 0.8098008632659912\n",
      "Step: 5356, Loss: 0.5356934666633606, Accuracy: 0.78125, Computation time: 0.8241808414459229\n",
      "Step: 5357, Loss: 0.49014225602149963, Accuracy: 0.875, Computation time: 0.8992650508880615\n",
      "Step: 5358, Loss: 0.3130594789981842, Accuracy: 0.90625, Computation time: 0.7614681720733643\n",
      "Step: 5359, Loss: 0.4176144599914551, Accuracy: 0.90625, Computation time: 0.721282958984375\n",
      "Step: 5360, Loss: 0.3063862919807434, Accuracy: 0.875, Computation time: 0.7468020915985107\n",
      "Step: 5361, Loss: 0.4929799437522888, Accuracy: 0.84375, Computation time: 0.9211111068725586\n",
      "Step: 5362, Loss: 0.5397762060165405, Accuracy: 0.84375, Computation time: 0.9524240493774414\n",
      "Step: 5363, Loss: 0.373171865940094, Accuracy: 0.875, Computation time: 532.8640022277832\n",
      "Step: 5364, Loss: 0.17407912015914917, Accuracy: 0.9375, Computation time: 0.7547869682312012\n",
      "Step: 5365, Loss: 0.7528718709945679, Accuracy: 0.6875, Computation time: 0.835784912109375\n",
      "Step: 5366, Loss: 0.7516660094261169, Accuracy: 0.8125, Computation time: 0.8694419860839844\n",
      "Step: 5367, Loss: 0.20992816984653473, Accuracy: 0.96875, Computation time: 0.86226487159729\n",
      "Step: 5368, Loss: 0.22316183149814606, Accuracy: 0.9375, Computation time: 0.8783411979675293\n",
      "Step: 5369, Loss: 0.6301441788673401, Accuracy: 0.8125, Computation time: 0.8285031318664551\n",
      "Step: 5370, Loss: 0.19636361300945282, Accuracy: 0.90625, Computation time: 0.9740231037139893\n",
      "Step: 5371, Loss: 0.38339054584503174, Accuracy: 0.90625, Computation time: 0.9342300891876221\n",
      "Step: 5372, Loss: 0.5496503710746765, Accuracy: 0.78125, Computation time: 0.9598269462585449\n",
      "Step: 5373, Loss: 0.42631494998931885, Accuracy: 0.90625, Computation time: 0.7469031810760498\n",
      "Step: 5374, Loss: 0.18526461720466614, Accuracy: 0.9375, Computation time: 0.7981350421905518\n",
      "Step: 5375, Loss: 0.34851646423339844, Accuracy: 0.90625, Computation time: 1.7222411632537842\n",
      "Step: 5376, Loss: 0.3469204902648926, Accuracy: 0.90625, Computation time: 0.7612652778625488\n",
      "Step: 5377, Loss: 0.44741183519363403, Accuracy: 0.875, Computation time: 0.771691083908081\n",
      "Step: 5378, Loss: 0.49924197793006897, Accuracy: 0.8125, Computation time: 0.7608461380004883\n",
      "Step: 5379, Loss: 0.32853588461875916, Accuracy: 0.875, Computation time: 0.9360480308532715\n",
      "Step: 5380, Loss: 0.31395459175109863, Accuracy: 0.9375, Computation time: 0.9862627983093262\n",
      "Step: 5381, Loss: 0.20944422483444214, Accuracy: 0.9375, Computation time: 0.9125649929046631\n",
      "Step: 5382, Loss: 0.5294100642204285, Accuracy: 0.8125, Computation time: 1.1327621936798096\n",
      "Step: 5383, Loss: 0.2867470681667328, Accuracy: 0.90625, Computation time: 0.9001851081848145\n",
      "Step: 5384, Loss: 0.7255058288574219, Accuracy: 0.875, Computation time: 0.8367512226104736\n",
      "Step: 5385, Loss: 0.7209471464157104, Accuracy: 0.75, Computation time: 0.8509030342102051\n",
      "Step: 5386, Loss: 0.8040898442268372, Accuracy: 0.78125, Computation time: 0.863347053527832\n",
      "Step: 5387, Loss: 0.5458481311798096, Accuracy: 0.875, Computation time: 0.8918919563293457\n",
      "Step: 5388, Loss: 0.5894704461097717, Accuracy: 0.8125, Computation time: 0.9007596969604492\n",
      "Step: 5389, Loss: 0.4621647000312805, Accuracy: 0.78125, Computation time: 0.8349621295928955\n",
      "Step: 5390, Loss: 0.4111529290676117, Accuracy: 0.84375, Computation time: 0.9790222644805908\n",
      "Step: 5391, Loss: 0.5657737255096436, Accuracy: 0.875, Computation time: 1.5927867889404297\n",
      "Step: 5392, Loss: 0.49817705154418945, Accuracy: 0.875, Computation time: 0.8588111400604248\n",
      "Step: 5393, Loss: 0.4179481863975525, Accuracy: 0.90625, Computation time: 0.8007521629333496\n",
      "Step: 5394, Loss: 0.265358567237854, Accuracy: 0.9375, Computation time: 0.920464277267456\n",
      "Step: 5395, Loss: 0.5143285393714905, Accuracy: 0.875, Computation time: 0.8849999904632568\n",
      "Step: 5396, Loss: 0.3016816973686218, Accuracy: 0.875, Computation time: 0.7600679397583008\n",
      "Step: 5397, Loss: 0.4259674847126007, Accuracy: 0.875, Computation time: 0.9282329082489014\n",
      "Step: 5398, Loss: 0.40987637639045715, Accuracy: 0.84375, Computation time: 0.9534461498260498\n",
      "Step: 5399, Loss: 0.3930680751800537, Accuracy: 0.90625, Computation time: 0.9471328258514404\n",
      "Step: 5400, Loss: 0.8563418984413147, Accuracy: 0.78125, Computation time: 0.8753740787506104\n",
      "Step: 5401, Loss: 0.1665494441986084, Accuracy: 0.9375, Computation time: 0.7586071491241455\n",
      "Step: 5402, Loss: 0.9884116649627686, Accuracy: 0.71875, Computation time: 0.866379976272583\n",
      "Step: 5403, Loss: 0.4437946677207947, Accuracy: 0.8125, Computation time: 1.0870559215545654\n",
      "Step: 5404, Loss: 0.49155187606811523, Accuracy: 0.90625, Computation time: 1.2374260425567627\n",
      "Step: 5405, Loss: 0.9657156467437744, Accuracy: 0.875, Computation time: 0.8273980617523193\n",
      "Step: 5406, Loss: 0.26032400131225586, Accuracy: 0.9375, Computation time: 0.8081510066986084\n",
      "Step: 5407, Loss: 0.5282197594642639, Accuracy: 0.875, Computation time: 1.130138874053955\n",
      "Step: 5408, Loss: 0.9162716865539551, Accuracy: 0.875, Computation time: 0.9022588729858398\n",
      "Step: 5409, Loss: 0.20393726229667664, Accuracy: 0.9375, Computation time: 0.9039218425750732\n",
      "Step: 5410, Loss: 0.6106328368186951, Accuracy: 0.875, Computation time: 1.0951101779937744\n",
      "Step: 5411, Loss: 0.4705681800842285, Accuracy: 0.90625, Computation time: 0.8463878631591797\n",
      "Step: 5412, Loss: 0.48345986008644104, Accuracy: 0.8125, Computation time: 0.6932060718536377\n",
      "Step: 5413, Loss: 0.34997275471687317, Accuracy: 0.875, Computation time: 0.8907997608184814\n",
      "Step: 5414, Loss: 0.6816034317016602, Accuracy: 0.8125, Computation time: 0.910430908203125\n",
      "Step: 5415, Loss: 0.2431327849626541, Accuracy: 0.96875, Computation time: 0.8468837738037109\n",
      "Step: 5416, Loss: 0.46950602531433105, Accuracy: 0.84375, Computation time: 0.753615140914917\n",
      "Step: 5417, Loss: 0.41197776794433594, Accuracy: 0.84375, Computation time: 0.8514881134033203\n",
      "Step: 5418, Loss: 0.688862681388855, Accuracy: 0.8125, Computation time: 0.8498470783233643\n",
      "Step: 5419, Loss: 0.38194358348846436, Accuracy: 0.90625, Computation time: 0.7736577987670898\n",
      "Step: 5420, Loss: 0.5428562760353088, Accuracy: 0.8125, Computation time: 1.084355115890503\n",
      "Step: 5421, Loss: 0.7955506443977356, Accuracy: 0.8125, Computation time: 0.9140820503234863\n",
      "Step: 5422, Loss: 0.48056718707084656, Accuracy: 0.78125, Computation time: 0.9131860733032227\n",
      "Step: 5423, Loss: 0.521448016166687, Accuracy: 0.84375, Computation time: 1.0767021179199219\n",
      "Step: 5424, Loss: 0.3669082522392273, Accuracy: 0.90625, Computation time: 0.79646897315979\n",
      "Step: 5425, Loss: 0.481848806142807, Accuracy: 0.875, Computation time: 0.7377262115478516\n",
      "Step: 5426, Loss: 0.6729497909545898, Accuracy: 0.75, Computation time: 0.8748128414154053\n",
      "Step: 5427, Loss: 0.3259251117706299, Accuracy: 0.90625, Computation time: 0.8482880592346191\n",
      "Step: 5428, Loss: 0.4082578420639038, Accuracy: 0.875, Computation time: 1.0513849258422852\n",
      "Step: 5429, Loss: 0.5115552544593811, Accuracy: 0.875, Computation time: 0.7623758316040039\n",
      "Step: 5430, Loss: 0.48807206749916077, Accuracy: 0.90625, Computation time: 1.0737152099609375\n",
      "Step: 5431, Loss: 0.5079135298728943, Accuracy: 0.90625, Computation time: 0.9329860210418701\n",
      "Step: 5432, Loss: 0.3840405344963074, Accuracy: 0.84375, Computation time: 0.9708099365234375\n",
      "Step: 5433, Loss: 0.1919962614774704, Accuracy: 0.96875, Computation time: 0.8483631610870361\n",
      "Step: 5434, Loss: 0.42536765336990356, Accuracy: 0.90625, Computation time: 1.3159260749816895\n",
      "Step: 5435, Loss: 0.6483597159385681, Accuracy: 0.84375, Computation time: 0.8809189796447754\n",
      "Step: 5436, Loss: 0.14101439714431763, Accuracy: 0.9375, Computation time: 0.9801456928253174\n",
      "Step: 5437, Loss: 0.6864519715309143, Accuracy: 0.75, Computation time: 0.9300780296325684\n",
      "Step: 5438, Loss: 0.6487420797348022, Accuracy: 0.78125, Computation time: 0.8120787143707275\n",
      "Step: 5439, Loss: 0.43668580055236816, Accuracy: 0.875, Computation time: 0.7559528350830078\n",
      "Step: 5440, Loss: 0.4323357045650482, Accuracy: 0.84375, Computation time: 0.7443220615386963\n",
      "Step: 5441, Loss: 0.33648398518562317, Accuracy: 0.84375, Computation time: 0.8306698799133301\n",
      "Step: 5442, Loss: 0.39670631289482117, Accuracy: 0.96875, Computation time: 1.1449840068817139\n",
      "Step: 5443, Loss: 0.28630828857421875, Accuracy: 0.875, Computation time: 0.9015517234802246\n",
      "Step: 5444, Loss: 0.661578357219696, Accuracy: 0.78125, Computation time: 0.7688641548156738\n",
      "Step: 5445, Loss: 0.4249686896800995, Accuracy: 0.875, Computation time: 0.7687339782714844\n",
      "Step: 5446, Loss: 0.3971652388572693, Accuracy: 0.875, Computation time: 0.7040281295776367\n",
      "Step: 5447, Loss: 0.21922346949577332, Accuracy: 0.9375, Computation time: 0.9592080116271973\n",
      "Step: 5448, Loss: 0.4586450755596161, Accuracy: 0.75, Computation time: 0.7933218479156494\n",
      "Step: 5449, Loss: 0.5472339391708374, Accuracy: 0.90625, Computation time: 0.8592751026153564\n",
      "Step: 5450, Loss: 0.4186939299106598, Accuracy: 0.84375, Computation time: 0.8594000339508057\n",
      "Step: 5451, Loss: 0.5087791085243225, Accuracy: 0.84375, Computation time: 0.7337191104888916\n",
      "Step: 5452, Loss: 0.5637078285217285, Accuracy: 0.8125, Computation time: 0.8417022228240967\n",
      "Step: 5453, Loss: 0.7676494121551514, Accuracy: 0.75, Computation time: 0.8147282600402832\n",
      "Step: 5454, Loss: 0.44835707545280457, Accuracy: 0.875, Computation time: 0.7265510559082031\n",
      "Step: 5455, Loss: 0.3753505349159241, Accuracy: 0.875, Computation time: 0.8595390319824219\n",
      "Step: 5456, Loss: 0.8545125722885132, Accuracy: 0.71875, Computation time: 0.7136039733886719\n",
      "Step: 5457, Loss: 0.3536567687988281, Accuracy: 0.9375, Computation time: 0.9571750164031982\n",
      "Step: 5458, Loss: 0.7905005216598511, Accuracy: 0.8125, Computation time: 0.9190108776092529\n",
      "Step: 5459, Loss: 0.5319505333900452, Accuracy: 0.8125, Computation time: 0.7940700054168701\n",
      "Step: 5460, Loss: 0.4586295187473297, Accuracy: 0.90625, Computation time: 0.8400359153747559\n",
      "Step: 5461, Loss: 0.23749859631061554, Accuracy: 0.96875, Computation time: 0.911085844039917\n",
      "Step: 5462, Loss: 0.7108345031738281, Accuracy: 0.78125, Computation time: 1.0557279586791992\n",
      "Step: 5463, Loss: 0.760607123374939, Accuracy: 0.78125, Computation time: 0.664309024810791\n",
      "Step: 5464, Loss: 0.3120046555995941, Accuracy: 0.90625, Computation time: 0.7127292156219482\n",
      "Step: 5465, Loss: 0.4959394633769989, Accuracy: 0.875, Computation time: 0.8606369495391846\n",
      "Step: 5466, Loss: 0.7078126668930054, Accuracy: 0.78125, Computation time: 1.5636742115020752\n",
      "Step: 5467, Loss: 0.63446044921875, Accuracy: 0.84375, Computation time: 0.8383400440216064\n",
      "Step: 5468, Loss: 0.5046911239624023, Accuracy: 0.90625, Computation time: 1.004244089126587\n",
      "Step: 5469, Loss: 0.8375749588012695, Accuracy: 0.71875, Computation time: 0.943385124206543\n",
      "Step: 5470, Loss: 0.42266845703125, Accuracy: 0.84375, Computation time: 0.7676169872283936\n",
      "Step: 5471, Loss: 0.4613378643989563, Accuracy: 0.90625, Computation time: 0.8970828056335449\n",
      "Step: 5472, Loss: 0.43906062841415405, Accuracy: 0.875, Computation time: 0.8400540351867676\n",
      "Step: 5473, Loss: 0.6336071491241455, Accuracy: 0.8125, Computation time: 0.8269898891448975\n",
      "Step: 5474, Loss: 0.48492658138275146, Accuracy: 0.875, Computation time: 0.9192297458648682\n",
      "Step: 5475, Loss: 0.531313419342041, Accuracy: 0.8125, Computation time: 0.8240821361541748\n",
      "Step: 5476, Loss: 0.6150545477867126, Accuracy: 0.78125, Computation time: 0.9793410301208496\n",
      "Step: 5477, Loss: 0.5722559690475464, Accuracy: 0.84375, Computation time: 0.7466719150543213\n",
      "Step: 5478, Loss: 0.45143479108810425, Accuracy: 0.875, Computation time: 0.9094538688659668\n",
      "Step: 5479, Loss: 0.7916663885116577, Accuracy: 0.84375, Computation time: 1.043053150177002\n",
      "Step: 5480, Loss: 0.30037930607795715, Accuracy: 0.84375, Computation time: 0.754511833190918\n",
      "Step: 5481, Loss: 0.6113712191581726, Accuracy: 0.84375, Computation time: 0.7231290340423584\n",
      "Step: 5482, Loss: 0.5584774613380432, Accuracy: 0.84375, Computation time: 0.9146168231964111\n",
      "Step: 5483, Loss: 0.4536677300930023, Accuracy: 0.90625, Computation time: 1.0416879653930664\n",
      "Step: 5484, Loss: 0.48660212755203247, Accuracy: 0.8125, Computation time: 0.7337520122528076\n",
      "Step: 5485, Loss: 0.4556206464767456, Accuracy: 0.9375, Computation time: 0.9486560821533203\n",
      "Step: 5486, Loss: 0.3001773953437805, Accuracy: 0.9375, Computation time: 0.7641539573669434\n",
      "Step: 5487, Loss: 0.36645206809043884, Accuracy: 0.84375, Computation time: 0.7864990234375\n",
      "Step: 5488, Loss: 0.7906959056854248, Accuracy: 0.6875, Computation time: 0.8829338550567627\n",
      "Step: 5489, Loss: 0.2786339223384857, Accuracy: 0.9375, Computation time: 0.8885819911956787\n",
      "Step: 5490, Loss: 0.8389742374420166, Accuracy: 0.8125, Computation time: 0.7933411598205566\n",
      "Step: 5491, Loss: 0.41475754976272583, Accuracy: 0.84375, Computation time: 0.856553316116333\n",
      "Step: 5492, Loss: 0.3846416771411896, Accuracy: 0.875, Computation time: 0.8282058238983154\n",
      "Step: 5493, Loss: 0.31742221117019653, Accuracy: 0.90625, Computation time: 0.7867991924285889\n",
      "Step: 5494, Loss: 0.42352694272994995, Accuracy: 0.90625, Computation time: 0.7159678936004639\n",
      "Step: 5495, Loss: 0.22694432735443115, Accuracy: 0.96875, Computation time: 0.8438940048217773\n",
      "Step: 5496, Loss: 0.713151216506958, Accuracy: 0.75, Computation time: 0.8288168907165527\n",
      "Step: 5497, Loss: 0.530630886554718, Accuracy: 0.8125, Computation time: 1.612436294555664\n",
      "Step: 5498, Loss: 0.40007638931274414, Accuracy: 0.84375, Computation time: 0.8084688186645508\n",
      "Step: 5499, Loss: 0.37609654664993286, Accuracy: 0.90625, Computation time: 0.8044250011444092\n",
      "Step: 5500, Loss: 0.29794445633888245, Accuracy: 0.90625, Computation time: 0.7629427909851074\n",
      "Step: 5501, Loss: 0.5673236846923828, Accuracy: 0.90625, Computation time: 1.1595699787139893\n",
      "Step: 5502, Loss: 0.5437390804290771, Accuracy: 0.90625, Computation time: 0.8790130615234375\n",
      "Step: 5503, Loss: 0.8868259787559509, Accuracy: 0.6875, Computation time: 0.8869869709014893\n",
      "Step: 5504, Loss: 0.624758780002594, Accuracy: 0.84375, Computation time: 0.7723608016967773\n",
      "Step: 5505, Loss: 0.923952043056488, Accuracy: 0.78125, Computation time: 0.7811110019683838\n",
      "Step: 5506, Loss: 0.5169150829315186, Accuracy: 0.84375, Computation time: 0.8074707984924316\n",
      "Step: 5507, Loss: 1.036739706993103, Accuracy: 0.875, Computation time: 0.7878198623657227\n",
      "Step: 5508, Loss: 0.5430243015289307, Accuracy: 0.84375, Computation time: 1.083510160446167\n",
      "Step: 5509, Loss: 0.45464789867401123, Accuracy: 0.84375, Computation time: 0.8446922302246094\n",
      "Step: 5510, Loss: 0.25720593333244324, Accuracy: 0.9375, Computation time: 0.8159213066101074\n",
      "Step: 5511, Loss: 0.2671590745449066, Accuracy: 0.9375, Computation time: 0.7650589942932129\n",
      "Step: 5512, Loss: 0.3229232430458069, Accuracy: 0.875, Computation time: 0.7553179264068604\n",
      "Step: 5513, Loss: 0.4692218005657196, Accuracy: 0.875, Computation time: 0.990103006362915\n",
      "Step: 5514, Loss: 0.6427955627441406, Accuracy: 0.8125, Computation time: 0.8005020618438721\n",
      "Step: 5515, Loss: 0.46756380796432495, Accuracy: 0.78125, Computation time: 0.7780959606170654\n",
      "Step: 5516, Loss: 0.4329594075679779, Accuracy: 0.90625, Computation time: 1.0589361190795898\n",
      "Step: 5517, Loss: 0.8961408734321594, Accuracy: 0.75, Computation time: 0.8582229614257812\n",
      "Step: 5518, Loss: 0.2628231346607208, Accuracy: 0.9375, Computation time: 0.7538020610809326\n",
      "Step: 5519, Loss: 0.462649941444397, Accuracy: 0.90625, Computation time: 0.7611069679260254\n",
      "Step: 5520, Loss: 0.6517950892448425, Accuracy: 0.84375, Computation time: 0.8863260746002197\n",
      "Step: 5521, Loss: 0.5309719443321228, Accuracy: 0.78125, Computation time: 0.7923679351806641\n",
      "Step: 5522, Loss: 0.4043784439563751, Accuracy: 0.90625, Computation time: 0.8659272193908691\n",
      "Step: 5523, Loss: 0.48677849769592285, Accuracy: 0.875, Computation time: 0.8668651580810547\n",
      "Step: 5524, Loss: 0.4481807053089142, Accuracy: 0.875, Computation time: 0.9949469566345215\n",
      "Step: 5525, Loss: 0.525210976600647, Accuracy: 0.8125, Computation time: 0.7950358390808105\n",
      "Step: 5526, Loss: 0.27352580428123474, Accuracy: 0.875, Computation time: 1.5165016651153564\n",
      "Step: 5527, Loss: 1.2025561332702637, Accuracy: 0.6875, Computation time: 1.246476650238037\n",
      "Step: 5528, Loss: 0.64380943775177, Accuracy: 0.78125, Computation time: 0.8367178440093994\n",
      "Step: 5529, Loss: 0.5551726818084717, Accuracy: 0.875, Computation time: 0.8449921607971191\n",
      "Step: 5530, Loss: 0.2849786579608917, Accuracy: 0.90625, Computation time: 0.8679919242858887\n",
      "Step: 5531, Loss: 0.27867311239242554, Accuracy: 0.875, Computation time: 0.8409559726715088\n",
      "Step: 5532, Loss: 0.5361420512199402, Accuracy: 0.75, Computation time: 0.9557387828826904\n",
      "Step: 5533, Loss: 0.3919389843940735, Accuracy: 0.8125, Computation time: 0.9238259792327881\n",
      "Step: 5534, Loss: 0.6227824687957764, Accuracy: 0.78125, Computation time: 0.7743039131164551\n",
      "Step: 5535, Loss: 0.8278908729553223, Accuracy: 0.78125, Computation time: 0.992326021194458\n",
      "Step: 5536, Loss: 0.5594795942306519, Accuracy: 0.8125, Computation time: 0.7408859729766846\n",
      "Step: 5537, Loss: 0.6073746681213379, Accuracy: 0.78125, Computation time: 0.958672046661377\n",
      "Step: 5538, Loss: 0.5471786260604858, Accuracy: 0.84375, Computation time: 0.824084997177124\n",
      "Step: 5539, Loss: 0.5830363631248474, Accuracy: 0.84375, Computation time: 1.248629093170166\n",
      "Step: 5540, Loss: 0.7233152985572815, Accuracy: 0.875, Computation time: 0.6718721389770508\n",
      "Step: 5541, Loss: 0.3136191666126251, Accuracy: 0.9375, Computation time: 1.0727810859680176\n",
      "Step: 5542, Loss: 0.3375549018383026, Accuracy: 0.875, Computation time: 0.85744309425354\n",
      "Step: 5543, Loss: 0.38318225741386414, Accuracy: 0.90625, Computation time: 0.9044489860534668\n",
      "Step: 5544, Loss: 0.7410439848899841, Accuracy: 0.84375, Computation time: 0.8347759246826172\n",
      "Step: 5545, Loss: 0.5009043216705322, Accuracy: 0.875, Computation time: 0.8654520511627197\n",
      "Step: 5546, Loss: 0.602694034576416, Accuracy: 0.75, Computation time: 0.9889841079711914\n",
      "Step: 5547, Loss: 0.652014434337616, Accuracy: 0.78125, Computation time: 1.0398941040039062\n",
      "Step: 5548, Loss: 0.613211989402771, Accuracy: 0.8125, Computation time: 0.7803690433502197\n",
      "Step: 5549, Loss: 0.5537956953048706, Accuracy: 0.8125, Computation time: 0.8808870315551758\n",
      "Step: 5550, Loss: 0.6094253063201904, Accuracy: 0.75, Computation time: 0.9772772789001465\n",
      "Step: 5551, Loss: 0.5076904296875, Accuracy: 0.8125, Computation time: 0.8696670532226562\n",
      "Step: 5552, Loss: 0.5683136582374573, Accuracy: 0.75, Computation time: 1.1324846744537354\n",
      "Step: 5553, Loss: 0.5611929893493652, Accuracy: 0.84375, Computation time: 1.0373568534851074\n",
      "Step: 5554, Loss: 0.434431254863739, Accuracy: 0.84375, Computation time: 0.782599925994873\n",
      "Step: 5555, Loss: 0.6464776396751404, Accuracy: 0.78125, Computation time: 1.2817883491516113\n",
      "Step: 5556, Loss: 0.3272852301597595, Accuracy: 0.90625, Computation time: 1.3486328125\n",
      "Step: 5557, Loss: 0.5819166898727417, Accuracy: 0.8125, Computation time: 0.7671256065368652\n",
      "Step: 5558, Loss: 0.33555835485458374, Accuracy: 0.90625, Computation time: 0.89054274559021\n",
      "Step: 5559, Loss: 0.8704311847686768, Accuracy: 0.71875, Computation time: 0.819756031036377\n",
      "Step: 5560, Loss: 0.516323447227478, Accuracy: 0.8125, Computation time: 0.9883041381835938\n",
      "Step: 5561, Loss: 0.4859428405761719, Accuracy: 0.84375, Computation time: 0.8172109127044678\n",
      "Step: 5562, Loss: 0.7838308811187744, Accuracy: 0.8125, Computation time: 0.7834591865539551\n",
      "Step: 5563, Loss: 0.5175397396087646, Accuracy: 0.84375, Computation time: 0.9112322330474854\n",
      "Step: 5564, Loss: 0.48931530117988586, Accuracy: 0.875, Computation time: 0.7902090549468994\n",
      "Step: 5565, Loss: 0.7832461595535278, Accuracy: 0.8125, Computation time: 0.9734492301940918\n",
      "Step: 5566, Loss: 0.7384275794029236, Accuracy: 0.875, Computation time: 0.9737069606781006\n",
      "Step: 5567, Loss: 0.4074174463748932, Accuracy: 0.84375, Computation time: 0.7745809555053711\n",
      "Step: 5568, Loss: 0.587224006652832, Accuracy: 0.875, Computation time: 0.97003173828125\n",
      "Step: 5569, Loss: 0.4572392702102661, Accuracy: 0.84375, Computation time: 0.6946189403533936\n",
      "Step: 5570, Loss: 0.7327903509140015, Accuracy: 0.84375, Computation time: 0.7636420726776123\n",
      "Step: 5571, Loss: 0.6061897873878479, Accuracy: 0.78125, Computation time: 0.9371099472045898\n",
      "Step: 5572, Loss: 0.7524109482765198, Accuracy: 0.84375, Computation time: 0.7150671482086182\n",
      "Step: 5573, Loss: 0.8356598615646362, Accuracy: 0.75, Computation time: 0.8603448867797852\n",
      "Step: 5574, Loss: 0.7724847793579102, Accuracy: 0.78125, Computation time: 0.7844560146331787\n",
      "Step: 5575, Loss: 0.7192864418029785, Accuracy: 0.8125, Computation time: 0.8287291526794434\n",
      "Step: 5576, Loss: 0.3309752643108368, Accuracy: 0.875, Computation time: 0.7433149814605713\n",
      "Step: 5577, Loss: 0.5525293350219727, Accuracy: 0.84375, Computation time: 0.7915971279144287\n",
      "Step: 5578, Loss: 0.8004228472709656, Accuracy: 0.71875, Computation time: 0.8942770957946777\n",
      "Step: 5579, Loss: 0.28536996245384216, Accuracy: 0.9375, Computation time: 0.6062710285186768\n",
      "Step: 5580, Loss: 0.4133841395378113, Accuracy: 0.84375, Computation time: 0.7207460403442383\n",
      "Step: 5581, Loss: 0.5391926169395447, Accuracy: 0.84375, Computation time: 0.718433141708374\n",
      "Step: 5582, Loss: 0.682502031326294, Accuracy: 0.75, Computation time: 1.458244800567627\n",
      "Step: 5583, Loss: 0.6509882211685181, Accuracy: 0.8125, Computation time: 0.7067968845367432\n",
      "Step: 5584, Loss: 0.564990222454071, Accuracy: 0.84375, Computation time: 0.977449893951416\n",
      "Step: 5585, Loss: 0.3590347468852997, Accuracy: 0.875, Computation time: 0.8091709613800049\n",
      "Step: 5586, Loss: 0.44932037591934204, Accuracy: 0.875, Computation time: 0.7479031085968018\n",
      "Step: 5587, Loss: 0.5759244561195374, Accuracy: 0.875, Computation time: 0.8917291164398193\n",
      "Step: 5588, Loss: 0.3246467411518097, Accuracy: 0.9375, Computation time: 1.3223769664764404\n",
      "Step: 5589, Loss: 0.6620311737060547, Accuracy: 0.875, Computation time: 0.9296190738677979\n",
      "Step: 5590, Loss: 0.4656931459903717, Accuracy: 0.84375, Computation time: 0.97239089012146\n",
      "Step: 5591, Loss: 0.5351332426071167, Accuracy: 0.875, Computation time: 1.0810413360595703\n",
      "Step: 5592, Loss: 0.38533318042755127, Accuracy: 0.875, Computation time: 1.0519521236419678\n",
      "Step: 5593, Loss: 0.8669330477714539, Accuracy: 0.75, Computation time: 0.8441221714019775\n",
      "Step: 5594, Loss: 0.33273017406463623, Accuracy: 0.875, Computation time: 0.802297830581665\n",
      "Step: 5595, Loss: 0.39528441429138184, Accuracy: 0.875, Computation time: 0.9209892749786377\n",
      "Step: 5596, Loss: 0.6045859456062317, Accuracy: 0.875, Computation time: 0.739192008972168\n",
      "Step: 5597, Loss: 0.5960608124732971, Accuracy: 0.8125, Computation time: 0.8044767379760742\n",
      "Step: 5598, Loss: 0.43829822540283203, Accuracy: 0.875, Computation time: 0.8665618896484375\n",
      "Step: 5599, Loss: 0.6266971826553345, Accuracy: 0.84375, Computation time: 0.8435080051422119\n",
      "Step: 5600, Loss: 0.3417430818080902, Accuracy: 0.90625, Computation time: 1.236725091934204\n",
      "Step: 5601, Loss: 0.6125531792640686, Accuracy: 0.84375, Computation time: 1.113050937652588\n",
      "Step: 5602, Loss: 0.5668203234672546, Accuracy: 0.84375, Computation time: 0.889805793762207\n",
      "Step: 5603, Loss: 0.3306291103363037, Accuracy: 0.90625, Computation time: 0.876823902130127\n",
      "Step: 5604, Loss: 0.735431432723999, Accuracy: 0.78125, Computation time: 0.8322019577026367\n",
      "Step: 5605, Loss: 0.36139076948165894, Accuracy: 0.9375, Computation time: 0.8674602508544922\n",
      "Step: 5606, Loss: 0.3607569932937622, Accuracy: 0.90625, Computation time: 0.7762250900268555\n",
      "Step: 5607, Loss: 0.5117945671081543, Accuracy: 0.84375, Computation time: 0.7978909015655518\n",
      "Step: 5608, Loss: 0.7574030756950378, Accuracy: 0.71875, Computation time: 0.8335192203521729\n",
      "Step: 5609, Loss: 0.3164002001285553, Accuracy: 0.875, Computation time: 0.8055999279022217\n",
      "Step: 5610, Loss: 0.580127477645874, Accuracy: 0.84375, Computation time: 0.8102800846099854\n",
      "Step: 5611, Loss: 0.5750175714492798, Accuracy: 0.78125, Computation time: 0.7984600067138672\n",
      "Step: 5612, Loss: 0.42377352714538574, Accuracy: 0.875, Computation time: 0.9786810874938965\n",
      "Step: 5613, Loss: 0.7965659499168396, Accuracy: 0.71875, Computation time: 0.8401927947998047\n",
      "Step: 5614, Loss: 0.6418460607528687, Accuracy: 0.84375, Computation time: 0.8961300849914551\n",
      "Step: 5615, Loss: 0.4313799738883972, Accuracy: 0.90625, Computation time: 0.8619089126586914\n",
      "Step: 5616, Loss: 0.6715320348739624, Accuracy: 0.8125, Computation time: 0.8608598709106445\n",
      "Step: 5617, Loss: 0.5007567405700684, Accuracy: 0.84375, Computation time: 0.8526999950408936\n",
      "Step: 5618, Loss: 0.33396679162979126, Accuracy: 0.90625, Computation time: 1.4442119598388672\n",
      "Step: 5619, Loss: 0.6504819393157959, Accuracy: 0.8125, Computation time: 0.8323419094085693\n",
      "Step: 5620, Loss: 0.6112897396087646, Accuracy: 0.875, Computation time: 0.8889119625091553\n",
      "Step: 5621, Loss: 0.6699426174163818, Accuracy: 0.84375, Computation time: 0.8245718479156494\n",
      "Step: 5622, Loss: 0.3674159348011017, Accuracy: 0.875, Computation time: 0.8501513004302979\n",
      "Step: 5623, Loss: 0.738816499710083, Accuracy: 0.75, Computation time: 0.8954622745513916\n",
      "Step: 5624, Loss: 0.6019441485404968, Accuracy: 0.78125, Computation time: 0.8384647369384766\n",
      "Step: 5625, Loss: 0.8046897649765015, Accuracy: 0.78125, Computation time: 0.7728745937347412\n",
      "Step: 5626, Loss: 0.22670912742614746, Accuracy: 0.9375, Computation time: 0.9877021312713623\n",
      "Step: 5627, Loss: 0.5760775804519653, Accuracy: 0.8125, Computation time: 1.4151878356933594\n",
      "Step: 5628, Loss: 0.5011526346206665, Accuracy: 0.84375, Computation time: 0.7448928356170654\n",
      "Step: 5629, Loss: 0.781579315662384, Accuracy: 0.75, Computation time: 0.8047208786010742\n",
      "Step: 5630, Loss: 0.4716483950614929, Accuracy: 0.84375, Computation time: 0.9625411033630371\n",
      "Step: 5631, Loss: 0.3158738911151886, Accuracy: 0.84375, Computation time: 0.8364429473876953\n",
      "Step: 5632, Loss: 0.9404903054237366, Accuracy: 0.78125, Computation time: 0.9103498458862305\n",
      "Step: 5633, Loss: 0.7425054907798767, Accuracy: 0.78125, Computation time: 0.7690072059631348\n",
      "Step: 5634, Loss: 0.25091883540153503, Accuracy: 0.90625, Computation time: 0.6939988136291504\n",
      "Step: 5635, Loss: 0.3907722234725952, Accuracy: 0.875, Computation time: 0.7012090682983398\n",
      "Step: 5636, Loss: 0.33417949080467224, Accuracy: 0.875, Computation time: 0.8278279304504395\n",
      "Step: 5637, Loss: 0.4783070385456085, Accuracy: 0.90625, Computation time: 0.7821938991546631\n",
      "Step: 5638, Loss: 0.3438113331794739, Accuracy: 0.90625, Computation time: 0.8170082569122314\n",
      "Step: 5639, Loss: 0.48214221000671387, Accuracy: 0.84375, Computation time: 0.7639710903167725\n",
      "Step: 5640, Loss: 0.5146088600158691, Accuracy: 0.8125, Computation time: 0.8382599353790283\n",
      "Step: 5641, Loss: 0.48247790336608887, Accuracy: 0.84375, Computation time: 0.7656080722808838\n",
      "Step: 5642, Loss: 0.3111238479614258, Accuracy: 0.90625, Computation time: 0.803297758102417\n",
      "Step: 5643, Loss: 0.5208594799041748, Accuracy: 0.875, Computation time: 0.828967809677124\n",
      "Step: 5644, Loss: 0.22899359464645386, Accuracy: 0.9375, Computation time: 0.7932395935058594\n",
      "Step: 5645, Loss: 0.4055517613887787, Accuracy: 0.90625, Computation time: 0.9598309993743896\n",
      "Step: 5646, Loss: 0.6997075080871582, Accuracy: 0.75, Computation time: 1.1567108631134033\n",
      "Step: 5647, Loss: 0.6070032715797424, Accuracy: 0.84375, Computation time: 0.906386137008667\n",
      "Step: 5648, Loss: 0.4228215515613556, Accuracy: 0.875, Computation time: 0.7416949272155762\n",
      "Step: 5649, Loss: 0.4774843752384186, Accuracy: 0.84375, Computation time: 1.063584804534912\n",
      "Step: 5650, Loss: 0.4384162425994873, Accuracy: 0.90625, Computation time: 0.793039083480835\n",
      "Step: 5651, Loss: 0.41215911507606506, Accuracy: 0.875, Computation time: 0.7407150268554688\n",
      "Step: 5652, Loss: 0.4330260455608368, Accuracy: 0.8125, Computation time: 0.8694071769714355\n",
      "Step: 5653, Loss: 0.851713240146637, Accuracy: 0.78125, Computation time: 0.7291839122772217\n",
      "Step: 5654, Loss: 0.6343451738357544, Accuracy: 0.84375, Computation time: 0.826714038848877\n",
      "Step: 5655, Loss: 0.276164174079895, Accuracy: 0.9375, Computation time: 0.8767437934875488\n",
      "Step: 5656, Loss: 0.6668493151664734, Accuracy: 0.78125, Computation time: 1.0417542457580566\n",
      "Step: 5657, Loss: 0.3891103267669678, Accuracy: 0.875, Computation time: 0.6687750816345215\n",
      "Step: 5658, Loss: 0.47303348779678345, Accuracy: 0.84375, Computation time: 0.7467632293701172\n",
      "Step: 5659, Loss: 0.24126110970973969, Accuracy: 0.9375, Computation time: 1.0068268775939941\n",
      "Step: 5660, Loss: 0.20348216593265533, Accuracy: 0.9375, Computation time: 0.746701717376709\n",
      "Step: 5661, Loss: 0.7430384159088135, Accuracy: 0.75, Computation time: 0.9330289363861084\n",
      "Step: 5662, Loss: 0.6347202062606812, Accuracy: 0.84375, Computation time: 0.6913483142852783\n",
      "Step: 5663, Loss: 0.3392595648765564, Accuracy: 0.875, Computation time: 0.791635274887085\n",
      "Step: 5664, Loss: 0.5414818525314331, Accuracy: 0.78125, Computation time: 0.9115359783172607\n",
      "Step: 5665, Loss: 0.5049892067909241, Accuracy: 0.78125, Computation time: 0.8957400321960449\n",
      "Step: 5666, Loss: 0.32434922456741333, Accuracy: 0.9375, Computation time: 0.7874770164489746\n",
      "Step: 5667, Loss: 0.8617388606071472, Accuracy: 0.78125, Computation time: 1.0734188556671143\n",
      "Step: 5668, Loss: 0.2644514739513397, Accuracy: 0.875, Computation time: 0.8520691394805908\n",
      "Step: 5669, Loss: 0.35553163290023804, Accuracy: 0.90625, Computation time: 0.919529914855957\n",
      "Step: 5670, Loss: 0.5733697414398193, Accuracy: 0.875, Computation time: 0.9835958480834961\n",
      "Step: 5671, Loss: 0.3201570212841034, Accuracy: 0.9375, Computation time: 0.9660570621490479\n",
      "Step: 5672, Loss: 0.6244093775749207, Accuracy: 0.8125, Computation time: 1.2553682327270508\n",
      "Step: 5673, Loss: 0.595950722694397, Accuracy: 0.8125, Computation time: 0.9287300109863281\n",
      "Step: 5674, Loss: 0.6326764822006226, Accuracy: 0.84375, Computation time: 0.7748048305511475\n",
      "Step: 5675, Loss: 0.29679182171821594, Accuracy: 0.9375, Computation time: 0.9517147541046143\n",
      "Step: 5676, Loss: 0.6084373593330383, Accuracy: 0.75, Computation time: 0.9050381183624268\n",
      "Step: 5677, Loss: 0.46888604760169983, Accuracy: 0.8125, Computation time: 0.9029140472412109\n",
      "Step: 5678, Loss: 0.27349647879600525, Accuracy: 0.90625, Computation time: 0.8033521175384521\n",
      "Step: 5679, Loss: 0.528305172920227, Accuracy: 0.84375, Computation time: 0.8535962104797363\n",
      "Step: 5680, Loss: 0.6700499057769775, Accuracy: 0.84375, Computation time: 1.2975280284881592\n",
      "Step: 5681, Loss: 0.5280458331108093, Accuracy: 0.84375, Computation time: 0.8509249687194824\n",
      "Step: 5682, Loss: 0.2137778252363205, Accuracy: 0.9375, Computation time: 0.8739290237426758\n",
      "Step: 5683, Loss: 0.5195746421813965, Accuracy: 0.78125, Computation time: 0.8795139789581299\n",
      "Step: 5684, Loss: 0.4007779657840729, Accuracy: 0.875, Computation time: 0.8695509433746338\n",
      "Step: 5685, Loss: 0.6334710121154785, Accuracy: 0.8125, Computation time: 0.7728152275085449\n",
      "Step: 5686, Loss: 0.6016583442687988, Accuracy: 0.84375, Computation time: 0.9457099437713623\n",
      "Step: 5687, Loss: 0.17023254930973053, Accuracy: 0.9375, Computation time: 0.821890115737915\n",
      "Step: 5688, Loss: 1.0221580266952515, Accuracy: 0.71875, Computation time: 0.822551965713501\n",
      "Step: 5689, Loss: 0.1782781183719635, Accuracy: 0.96875, Computation time: 0.7913987636566162\n",
      "Step: 5690, Loss: 0.2396775484085083, Accuracy: 0.9375, Computation time: 0.9390671253204346\n",
      "Step: 5691, Loss: 0.4058493673801422, Accuracy: 0.8125, Computation time: 0.8723206520080566\n",
      "Step: 5692, Loss: 0.6344743967056274, Accuracy: 0.8125, Computation time: 0.905972957611084\n",
      "Step: 5693, Loss: 0.4054783582687378, Accuracy: 0.875, Computation time: 0.7609920501708984\n",
      "Step: 5694, Loss: 0.64558345079422, Accuracy: 0.84375, Computation time: 1.0256001949310303\n",
      "Step: 5695, Loss: 0.23248472809791565, Accuracy: 0.9375, Computation time: 0.8641438484191895\n",
      "Step: 5696, Loss: 0.46502867341041565, Accuracy: 0.875, Computation time: 0.9027369022369385\n",
      "Step: 5697, Loss: 0.5835668444633484, Accuracy: 0.875, Computation time: 0.7488179206848145\n",
      "Step: 5698, Loss: 0.4595779478549957, Accuracy: 0.84375, Computation time: 0.8910918235778809\n",
      "Step: 5699, Loss: 0.5055071115493774, Accuracy: 0.84375, Computation time: 0.77406907081604\n",
      "Step: 5700, Loss: 0.7144424915313721, Accuracy: 0.8125, Computation time: 0.7811667919158936\n",
      "Step: 5701, Loss: 0.5862613916397095, Accuracy: 0.84375, Computation time: 0.8452050685882568\n",
      "Step: 5702, Loss: 0.19990767538547516, Accuracy: 0.90625, Computation time: 0.8593432903289795\n",
      "Step: 5703, Loss: 0.36780545115470886, Accuracy: 0.875, Computation time: 0.7130749225616455\n",
      "Step: 5704, Loss: 0.6432080864906311, Accuracy: 0.78125, Computation time: 0.8844220638275146\n",
      "Step: 5705, Loss: 0.21003931760787964, Accuracy: 0.96875, Computation time: 0.6947510242462158\n",
      "Step: 5706, Loss: 0.39004141092300415, Accuracy: 0.875, Computation time: 0.8880891799926758\n",
      "Step: 5707, Loss: 0.22755523025989532, Accuracy: 0.90625, Computation time: 0.8903899192810059\n",
      "Step: 5708, Loss: 0.15001803636550903, Accuracy: 0.96875, Computation time: 1.12308669090271\n",
      "Step: 5709, Loss: 0.18527436256408691, Accuracy: 0.96875, Computation time: 0.8270621299743652\n",
      "Step: 5710, Loss: 0.41139355301856995, Accuracy: 0.875, Computation time: 0.9809341430664062\n",
      "Step: 5711, Loss: 0.35832729935646057, Accuracy: 0.84375, Computation time: 1.4218008518218994\n",
      "Step: 5712, Loss: 0.22832848131656647, Accuracy: 0.90625, Computation time: 0.828758955001831\n",
      "Step: 5713, Loss: 0.4919281601905823, Accuracy: 0.875, Computation time: 0.823167085647583\n",
      "Step: 5714, Loss: 0.23944614827632904, Accuracy: 0.875, Computation time: 1.0863590240478516\n",
      "Step: 5715, Loss: 0.5513143539428711, Accuracy: 0.78125, Computation time: 0.8431808948516846\n",
      "Step: 5716, Loss: 0.6727785468101501, Accuracy: 0.6875, Computation time: 0.9265637397766113\n",
      "Step: 5717, Loss: 0.5765331983566284, Accuracy: 0.8125, Computation time: 1.0215258598327637\n",
      "Step: 5718, Loss: 0.3587685227394104, Accuracy: 0.875, Computation time: 0.9756951332092285\n",
      "Step: 5719, Loss: 0.3935193717479706, Accuracy: 0.84375, Computation time: 0.8037979602813721\n",
      "Step: 5720, Loss: 0.462033748626709, Accuracy: 0.84375, Computation time: 0.7154760360717773\n",
      "Step: 5721, Loss: 0.5485022068023682, Accuracy: 0.84375, Computation time: 0.884329080581665\n",
      "Step: 5722, Loss: 0.24807679653167725, Accuracy: 0.875, Computation time: 0.9029440879821777\n",
      "Step: 5723, Loss: 0.367178738117218, Accuracy: 0.90625, Computation time: 0.7687060832977295\n",
      "Step: 5724, Loss: 0.2442593276500702, Accuracy: 0.90625, Computation time: 0.8135097026824951\n",
      "Step: 5725, Loss: 0.6422318816184998, Accuracy: 0.78125, Computation time: 1.036937952041626\n",
      "Step: 5726, Loss: 0.16457265615463257, Accuracy: 0.9375, Computation time: 0.8132050037384033\n",
      "Step: 5727, Loss: 0.5718960762023926, Accuracy: 0.8125, Computation time: 0.7248170375823975\n",
      "Step: 5728, Loss: 0.4223780333995819, Accuracy: 0.875, Computation time: 0.9243819713592529\n",
      "Step: 5729, Loss: 0.3972634971141815, Accuracy: 0.84375, Computation time: 0.8492071628570557\n",
      "Step: 5730, Loss: 0.30109503865242004, Accuracy: 0.875, Computation time: 0.8502049446105957\n",
      "Step: 5731, Loss: 0.3257409930229187, Accuracy: 0.875, Computation time: 0.9777872562408447\n",
      "Step: 5732, Loss: 0.7228474617004395, Accuracy: 0.6875, Computation time: 1.1339950561523438\n",
      "Step: 5733, Loss: 0.19539299607276917, Accuracy: 0.9375, Computation time: 0.8382771015167236\n",
      "Step: 5734, Loss: 0.5837156176567078, Accuracy: 0.875, Computation time: 0.8374850749969482\n",
      "Step: 5735, Loss: 0.5797234177589417, Accuracy: 0.8125, Computation time: 0.7971279621124268\n",
      "Step: 5736, Loss: 0.4908030331134796, Accuracy: 0.90625, Computation time: 1.1102259159088135\n",
      "Step: 5737, Loss: 0.35351529717445374, Accuracy: 0.8125, Computation time: 0.7939350605010986\n",
      "Step: 5738, Loss: 0.1197112575173378, Accuracy: 0.9375, Computation time: 0.7132670879364014\n",
      "Step: 5739, Loss: 0.30684909224510193, Accuracy: 0.9375, Computation time: 0.8129842281341553\n",
      "Step: 5740, Loss: 0.5947697162628174, Accuracy: 0.8125, Computation time: 1.2360613346099854\n",
      "Step: 5741, Loss: 0.4934881627559662, Accuracy: 0.8125, Computation time: 1.752803087234497\n",
      "Step: 5742, Loss: 0.4372404217720032, Accuracy: 0.875, Computation time: 0.8324310779571533\n",
      "Step: 5743, Loss: 0.5132734775543213, Accuracy: 0.90625, Computation time: 0.7902870178222656\n",
      "Step: 5744, Loss: 0.4267287254333496, Accuracy: 0.84375, Computation time: 1.046820878982544\n",
      "Step: 5745, Loss: 0.3346300721168518, Accuracy: 0.8125, Computation time: 1.007814884185791\n",
      "Step: 5746, Loss: 0.3305686116218567, Accuracy: 0.9375, Computation time: 0.8075289726257324\n",
      "Step: 5747, Loss: 0.3080778419971466, Accuracy: 0.875, Computation time: 0.7066471576690674\n",
      "Step: 5748, Loss: 0.37728816270828247, Accuracy: 0.84375, Computation time: 0.8940877914428711\n",
      "Step: 5749, Loss: 0.6304720640182495, Accuracy: 0.875, Computation time: 1.1919810771942139\n",
      "Step: 5750, Loss: 0.19406741857528687, Accuracy: 0.9375, Computation time: 0.7155928611755371\n",
      "Step: 5751, Loss: 0.34938758611679077, Accuracy: 0.9375, Computation time: 0.7419729232788086\n",
      "Step: 5752, Loss: 0.46424561738967896, Accuracy: 0.875, Computation time: 0.7376649379730225\n",
      "Step: 5753, Loss: 0.4008594751358032, Accuracy: 0.90625, Computation time: 0.9284927845001221\n",
      "Step: 5754, Loss: 0.24205182492733002, Accuracy: 0.96875, Computation time: 0.9990592002868652\n",
      "Step: 5755, Loss: 0.27911102771759033, Accuracy: 0.90625, Computation time: 1.1579208374023438\n",
      "Step: 5756, Loss: 0.3020728528499603, Accuracy: 0.9375, Computation time: 0.782228946685791\n",
      "Step: 5757, Loss: 0.4761192202568054, Accuracy: 0.8125, Computation time: 1.2773079872131348\n",
      "Step: 5758, Loss: 0.6631621718406677, Accuracy: 0.84375, Computation time: 0.7565720081329346\n",
      "Step: 5759, Loss: 0.8130042552947998, Accuracy: 0.8125, Computation time: 1.3178613185882568\n",
      "Step: 5760, Loss: 0.5021231770515442, Accuracy: 0.84375, Computation time: 0.8752660751342773\n",
      "Step: 5761, Loss: 0.6028403639793396, Accuracy: 0.875, Computation time: 0.740527868270874\n",
      "Step: 5762, Loss: 0.38459715247154236, Accuracy: 0.9375, Computation time: 0.7914080619812012\n",
      "Step: 5763, Loss: 0.40114617347717285, Accuracy: 0.8125, Computation time: 0.7838759422302246\n",
      "Step: 5764, Loss: 0.2943490147590637, Accuracy: 0.90625, Computation time: 0.8042471408843994\n",
      "Step: 5765, Loss: 0.5376273989677429, Accuracy: 0.78125, Computation time: 0.9315450191497803\n",
      "Step: 5766, Loss: 0.8002815246582031, Accuracy: 0.8125, Computation time: 0.9799761772155762\n",
      "Step: 5767, Loss: 0.35083216428756714, Accuracy: 0.875, Computation time: 0.9312360286712646\n",
      "Step: 5768, Loss: 0.3165840804576874, Accuracy: 0.9375, Computation time: 0.8860881328582764\n",
      "Step: 5769, Loss: 0.28920337557792664, Accuracy: 0.84375, Computation time: 0.7760279178619385\n",
      "Step: 5770, Loss: 0.48473885655403137, Accuracy: 0.84375, Computation time: 0.8099923133850098\n",
      "Step: 5771, Loss: 0.4446140229701996, Accuracy: 0.875, Computation time: 0.8387320041656494\n",
      "Step: 5772, Loss: 0.3728386163711548, Accuracy: 0.90625, Computation time: 0.928002119064331\n",
      "Step: 5773, Loss: 0.3846510350704193, Accuracy: 0.875, Computation time: 0.8114900588989258\n",
      "Step: 5774, Loss: 0.3019733726978302, Accuracy: 0.90625, Computation time: 0.9858412742614746\n",
      "Step: 5775, Loss: 0.581426203250885, Accuracy: 0.8125, Computation time: 1.0430221557617188\n",
      "Step: 5776, Loss: 0.33600011467933655, Accuracy: 0.9375, Computation time: 1.1119260787963867\n",
      "Step: 5777, Loss: 0.3019172251224518, Accuracy: 0.9375, Computation time: 0.8098371028900146\n",
      "Step: 5778, Loss: 0.18746675550937653, Accuracy: 0.96875, Computation time: 0.9138691425323486\n",
      "Step: 5779, Loss: 0.27645692229270935, Accuracy: 0.9375, Computation time: 0.9820461273193359\n",
      "Step: 5780, Loss: 0.8547564744949341, Accuracy: 0.78125, Computation time: 0.7789549827575684\n",
      "Step: 5781, Loss: 0.4319915473461151, Accuracy: 0.875, Computation time: 0.8014748096466064\n",
      "Step: 5782, Loss: 0.3251919150352478, Accuracy: 0.9375, Computation time: 0.6902551651000977\n",
      "Step: 5783, Loss: 0.7324214577674866, Accuracy: 0.75, Computation time: 0.7706470489501953\n",
      "Step: 5784, Loss: 0.16331662237644196, Accuracy: 0.96875, Computation time: 0.8594539165496826\n",
      "Step: 5785, Loss: 0.6301184892654419, Accuracy: 0.875, Computation time: 0.9105770587921143\n",
      "Step: 5786, Loss: 0.2940959334373474, Accuracy: 0.90625, Computation time: 0.800307035446167\n",
      "Step: 5787, Loss: 0.3511991798877716, Accuracy: 0.90625, Computation time: 0.6550159454345703\n",
      "Step: 5788, Loss: 0.6216660141944885, Accuracy: 0.78125, Computation time: 0.8448488712310791\n",
      "Step: 5789, Loss: 0.5567924380302429, Accuracy: 0.8125, Computation time: 0.9265258312225342\n",
      "Step: 5790, Loss: 0.5388160943984985, Accuracy: 0.875, Computation time: 0.751643180847168\n",
      "Step: 5791, Loss: 0.4757455885410309, Accuracy: 0.875, Computation time: 0.9339580535888672\n",
      "Step: 5792, Loss: 0.20688743889331818, Accuracy: 0.9375, Computation time: 1.0504188537597656\n",
      "Step: 5793, Loss: 0.3570581078529358, Accuracy: 0.9375, Computation time: 0.7974998950958252\n",
      "Step: 5794, Loss: 0.3428240716457367, Accuracy: 0.875, Computation time: 0.7579526901245117\n",
      "Step: 5795, Loss: 0.8872168064117432, Accuracy: 0.78125, Computation time: 0.6573731899261475\n",
      "Step: 5796, Loss: 0.3502469062805176, Accuracy: 0.90625, Computation time: 0.9003100395202637\n",
      "Step: 5797, Loss: 0.3706183433532715, Accuracy: 0.90625, Computation time: 0.926537275314331\n",
      "Step: 5798, Loss: 0.3848585784435272, Accuracy: 0.78125, Computation time: 0.8457789421081543\n",
      "Step: 5799, Loss: 0.2376873642206192, Accuracy: 0.90625, Computation time: 0.8414020538330078\n",
      "Step: 5800, Loss: 0.7156868577003479, Accuracy: 0.75, Computation time: 0.8321897983551025\n",
      "Step: 5801, Loss: 0.17468923330307007, Accuracy: 0.9375, Computation time: 1.4838531017303467\n",
      "Step: 5802, Loss: 0.15590041875839233, Accuracy: 0.9375, Computation time: 0.8190269470214844\n",
      "Step: 5803, Loss: 0.326614111661911, Accuracy: 0.875, Computation time: 1.0749921798706055\n",
      "Step: 5804, Loss: 0.12330545485019684, Accuracy: 0.9375, Computation time: 0.8127779960632324\n",
      "Step: 5805, Loss: 0.3171898126602173, Accuracy: 0.90625, Computation time: 0.8833389282226562\n",
      "Step: 5806, Loss: 0.24543066322803497, Accuracy: 0.90625, Computation time: 0.7745361328125\n",
      "Step: 5807, Loss: 0.636942982673645, Accuracy: 0.8125, Computation time: 0.917151927947998\n",
      "Step: 5808, Loss: 0.39812448620796204, Accuracy: 0.9375, Computation time: 0.8198988437652588\n",
      "Step: 5809, Loss: 0.472828209400177, Accuracy: 0.8125, Computation time: 0.9166951179504395\n",
      "Step: 5810, Loss: 0.9002179503440857, Accuracy: 0.71875, Computation time: 0.9376161098480225\n",
      "Step: 5811, Loss: 0.5388197898864746, Accuracy: 0.84375, Computation time: 0.8702068328857422\n",
      "Step: 5812, Loss: 0.52296382188797, Accuracy: 0.84375, Computation time: 0.9050729274749756\n",
      "Step: 5813, Loss: 0.5612800121307373, Accuracy: 0.8125, Computation time: 0.9048769474029541\n",
      "Step: 5814, Loss: 0.22884705662727356, Accuracy: 0.90625, Computation time: 0.9567291736602783\n",
      "Step: 5815, Loss: 0.44948819279670715, Accuracy: 0.90625, Computation time: 1.045661211013794\n",
      "Step: 5816, Loss: 0.40774065256118774, Accuracy: 0.96875, Computation time: 2.0512449741363525\n",
      "Step: 5817, Loss: 0.4266805350780487, Accuracy: 0.8125, Computation time: 0.920935869216919\n",
      "Step: 5818, Loss: 0.495849072933197, Accuracy: 0.84375, Computation time: 0.9845907688140869\n",
      "Step: 5819, Loss: 0.7667350769042969, Accuracy: 0.8125, Computation time: 0.8977000713348389\n",
      "Step: 5820, Loss: 0.4626297950744629, Accuracy: 0.875, Computation time: 0.91693115234375\n",
      "Step: 5821, Loss: 0.19402538239955902, Accuracy: 0.96875, Computation time: 0.7114050388336182\n",
      "Step: 5822, Loss: 0.28288909792900085, Accuracy: 0.9375, Computation time: 0.8000860214233398\n",
      "Step: 5823, Loss: 0.4870232939720154, Accuracy: 0.8125, Computation time: 0.7728900909423828\n",
      "Step: 5824, Loss: 0.3037473261356354, Accuracy: 0.90625, Computation time: 0.7050013542175293\n",
      "Step: 5825, Loss: 0.49715182185173035, Accuracy: 0.875, Computation time: 0.9254839420318604\n",
      "Step: 5826, Loss: 0.1613888442516327, Accuracy: 0.9375, Computation time: 0.7341408729553223\n",
      "Step: 5827, Loss: 0.26518526673316956, Accuracy: 0.875, Computation time: 1.0034723281860352\n",
      "Step: 5828, Loss: 0.8064215779304504, Accuracy: 0.75, Computation time: 0.9541499614715576\n",
      "Step: 5829, Loss: 0.5045008063316345, Accuracy: 0.8125, Computation time: 1.0987341403961182\n",
      "Step: 5830, Loss: 1.2074005603790283, Accuracy: 0.6875, Computation time: 1.656170129776001\n",
      "Step: 5831, Loss: 0.2673773765563965, Accuracy: 0.90625, Computation time: 0.8750479221343994\n",
      "Step: 5832, Loss: 0.8230002522468567, Accuracy: 0.75, Computation time: 0.9336822032928467\n",
      "Step: 5833, Loss: 0.23079633712768555, Accuracy: 0.90625, Computation time: 0.8479113578796387\n",
      "Step: 5834, Loss: 0.6124087572097778, Accuracy: 0.875, Computation time: 0.8675329685211182\n",
      "Step: 5835, Loss: 0.25994133949279785, Accuracy: 0.9375, Computation time: 0.8518152236938477\n",
      "Step: 5836, Loss: 0.1441241055727005, Accuracy: 0.96875, Computation time: 0.9001929759979248\n",
      "Step: 5837, Loss: 0.3118450939655304, Accuracy: 0.90625, Computation time: 0.8345582485198975\n",
      "Step: 5838, Loss: 0.3369489014148712, Accuracy: 0.875, Computation time: 0.8520402908325195\n",
      "Step: 5839, Loss: 0.3557451069355011, Accuracy: 0.875, Computation time: 0.9546480178833008\n",
      "Step: 5840, Loss: 0.442893922328949, Accuracy: 0.78125, Computation time: 0.8478589057922363\n",
      "Step: 5841, Loss: 0.5050944685935974, Accuracy: 0.90625, Computation time: 0.8825509548187256\n",
      "Step: 5842, Loss: 0.5709233283996582, Accuracy: 0.78125, Computation time: 0.9665861129760742\n",
      "Step: 5843, Loss: 0.47454720735549927, Accuracy: 0.78125, Computation time: 0.8142898082733154\n",
      "Step: 5844, Loss: 0.3134799003601074, Accuracy: 0.875, Computation time: 1.039417028427124\n",
      "Step: 5845, Loss: 0.5788453221321106, Accuracy: 0.875, Computation time: 0.7927100658416748\n",
      "Step: 5846, Loss: 0.49230900406837463, Accuracy: 0.84375, Computation time: 1.0704889297485352\n",
      "Step: 5847, Loss: 0.818727433681488, Accuracy: 0.75, Computation time: 1.0397191047668457\n",
      "Step: 5848, Loss: 0.2421751767396927, Accuracy: 0.9375, Computation time: 0.8787839412689209\n",
      "Step: 5849, Loss: 0.4350135326385498, Accuracy: 0.84375, Computation time: 0.8337688446044922\n",
      "Step: 5850, Loss: 0.5348053574562073, Accuracy: 0.8125, Computation time: 0.9190280437469482\n",
      "Step: 5851, Loss: 0.6636910438537598, Accuracy: 0.8125, Computation time: 1.0862038135528564\n",
      "Step: 5852, Loss: 0.6704299449920654, Accuracy: 0.71875, Computation time: 0.8827700614929199\n",
      "Step: 5853, Loss: 0.5872970819473267, Accuracy: 0.84375, Computation time: 1.0119929313659668\n",
      "Step: 5854, Loss: 0.4052637219429016, Accuracy: 0.8125, Computation time: 1.005620002746582\n",
      "Step: 5855, Loss: 0.5039929151535034, Accuracy: 0.84375, Computation time: 0.8281290531158447\n",
      "Step: 5856, Loss: 0.23983611166477203, Accuracy: 0.9375, Computation time: 0.849768877029419\n",
      "Step: 5857, Loss: 0.1557053029537201, Accuracy: 0.96875, Computation time: 0.9799890518188477\n",
      "Step: 5858, Loss: 0.25644904375076294, Accuracy: 0.9375, Computation time: 0.7390232086181641\n",
      "Step: 5859, Loss: 0.46651533246040344, Accuracy: 0.84375, Computation time: 1.614151954650879\n",
      "Step: 5860, Loss: 0.2945825159549713, Accuracy: 0.90625, Computation time: 0.7042908668518066\n",
      "Step: 5861, Loss: 0.6296277046203613, Accuracy: 0.75, Computation time: 0.9060437679290771\n",
      "Step: 5862, Loss: 0.20745812356472015, Accuracy: 0.96875, Computation time: 0.8353509902954102\n",
      "Step: 5863, Loss: 0.27076515555381775, Accuracy: 0.90625, Computation time: 0.9673902988433838\n",
      "Step: 5864, Loss: 0.32645323872566223, Accuracy: 0.84375, Computation time: 0.8257379531860352\n",
      "Step: 5865, Loss: 0.31180307269096375, Accuracy: 0.90625, Computation time: 0.7069859504699707\n",
      "Step: 5866, Loss: 0.591193437576294, Accuracy: 0.875, Computation time: 0.9035708904266357\n",
      "Step: 5867, Loss: 0.3746635913848877, Accuracy: 0.78125, Computation time: 0.8750941753387451\n",
      "Step: 5868, Loss: 0.22559143602848053, Accuracy: 0.9375, Computation time: 0.7218639850616455\n",
      "Step: 5869, Loss: 0.4599706530570984, Accuracy: 0.875, Computation time: 0.9281101226806641\n",
      "Step: 5870, Loss: 1.6573338508605957, Accuracy: 0.75, Computation time: 1.0150961875915527\n",
      "Step: 5871, Loss: 0.60137540102005, Accuracy: 0.78125, Computation time: 0.7496590614318848\n",
      "Step: 5872, Loss: 0.6423532366752625, Accuracy: 0.78125, Computation time: 0.8741610050201416\n",
      "Step: 5873, Loss: 0.4422440230846405, Accuracy: 0.875, Computation time: 0.7991390228271484\n",
      "Step: 5874, Loss: 0.7802883982658386, Accuracy: 0.75, Computation time: 0.8148488998413086\n",
      "Step: 5875, Loss: 0.45804548263549805, Accuracy: 0.875, Computation time: 0.8816781044006348\n",
      "Step: 5876, Loss: 0.7348790764808655, Accuracy: 0.84375, Computation time: 0.9646327495574951\n",
      "Step: 5877, Loss: 0.3745441734790802, Accuracy: 0.9375, Computation time: 0.7856230735778809\n",
      "Step: 5878, Loss: 0.40429893136024475, Accuracy: 0.90625, Computation time: 0.8948159217834473\n",
      "Step: 5879, Loss: 0.5608260631561279, Accuracy: 0.84375, Computation time: 0.7768571376800537\n",
      "Step: 5880, Loss: 0.7303948402404785, Accuracy: 0.875, Computation time: 0.9307219982147217\n",
      "Step: 5881, Loss: 0.397675484418869, Accuracy: 0.90625, Computation time: 0.7444798946380615\n",
      "Step: 5882, Loss: 0.4748527407646179, Accuracy: 0.90625, Computation time: 0.9495360851287842\n",
      "Step: 5883, Loss: 0.2806410491466522, Accuracy: 0.96875, Computation time: 0.7028501033782959\n",
      "Step: 5884, Loss: 0.505499005317688, Accuracy: 0.875, Computation time: 0.8415060043334961\n",
      "Step: 5885, Loss: 1.0094677209854126, Accuracy: 0.78125, Computation time: 0.8605189323425293\n",
      "Step: 5886, Loss: 0.8323166370391846, Accuracy: 0.75, Computation time: 0.8401520252227783\n",
      "Step: 5887, Loss: 0.46128419041633606, Accuracy: 0.84375, Computation time: 1.0912270545959473\n",
      "Step: 5888, Loss: 0.32762411236763, Accuracy: 0.90625, Computation time: 0.8515331745147705\n",
      "Step: 5889, Loss: 0.4866550862789154, Accuracy: 0.875, Computation time: 0.9076569080352783\n",
      "Step: 5890, Loss: 0.6802663207054138, Accuracy: 0.84375, Computation time: 1.5769259929656982\n",
      "Step: 5891, Loss: 0.5270940661430359, Accuracy: 0.78125, Computation time: 0.7814960479736328\n",
      "Step: 5892, Loss: 0.4189891219139099, Accuracy: 0.90625, Computation time: 0.869605302810669\n",
      "Step: 5893, Loss: 0.37070709466934204, Accuracy: 0.90625, Computation time: 0.8744072914123535\n",
      "Step: 5894, Loss: 0.34982001781463623, Accuracy: 0.90625, Computation time: 0.833500862121582\n",
      "Step: 5895, Loss: 0.2467828243970871, Accuracy: 0.9375, Computation time: 0.8139829635620117\n",
      "Step: 5896, Loss: 0.5457782745361328, Accuracy: 0.875, Computation time: 1.5408530235290527\n",
      "Step: 5897, Loss: 0.43147045373916626, Accuracy: 0.78125, Computation time: 1.4037208557128906\n",
      "Step: 5898, Loss: 0.938097357749939, Accuracy: 0.8125, Computation time: 0.7742159366607666\n",
      "Step: 5899, Loss: 0.3071887195110321, Accuracy: 0.90625, Computation time: 0.8121242523193359\n",
      "Step: 5900, Loss: 0.49483880400657654, Accuracy: 0.8125, Computation time: 0.8630878925323486\n",
      "Step: 5901, Loss: 0.6574501991271973, Accuracy: 0.90625, Computation time: 0.8411331176757812\n",
      "Step: 5902, Loss: 0.3911474943161011, Accuracy: 0.84375, Computation time: 0.9994471073150635\n",
      "Step: 5903, Loss: 0.27578410506248474, Accuracy: 0.90625, Computation time: 0.8951740264892578\n",
      "Step: 5904, Loss: 0.2001204490661621, Accuracy: 0.90625, Computation time: 0.775691032409668\n",
      "Step: 5905, Loss: 0.6317471265792847, Accuracy: 0.875, Computation time: 0.8325340747833252\n",
      "Step: 5906, Loss: 0.46965911984443665, Accuracy: 0.875, Computation time: 0.9788041114807129\n",
      "Step: 5907, Loss: 0.25598904490470886, Accuracy: 0.90625, Computation time: 0.9006049633026123\n",
      "Step: 5908, Loss: 0.37808552384376526, Accuracy: 0.9375, Computation time: 0.7848026752471924\n",
      "Step: 5909, Loss: 0.3076082170009613, Accuracy: 0.90625, Computation time: 0.8661561012268066\n",
      "Step: 5910, Loss: 0.181594118475914, Accuracy: 0.9375, Computation time: 0.8684217929840088\n",
      "Step: 5911, Loss: 0.4411871135234833, Accuracy: 0.84375, Computation time: 0.8794271945953369\n",
      "Step: 5912, Loss: 0.3449040949344635, Accuracy: 0.90625, Computation time: 0.7644298076629639\n",
      "Step: 5913, Loss: 0.41484060883522034, Accuracy: 0.84375, Computation time: 0.7851259708404541\n",
      "Step: 5914, Loss: 0.6878287196159363, Accuracy: 0.78125, Computation time: 0.8803269863128662\n",
      "Step: 5915, Loss: 0.3058125972747803, Accuracy: 0.90625, Computation time: 0.6921007633209229\n",
      "Step: 5916, Loss: 0.6273678541183472, Accuracy: 0.84375, Computation time: 0.8773770332336426\n",
      "Step: 5917, Loss: 0.6651215553283691, Accuracy: 0.875, Computation time: 0.7456550598144531\n",
      "Step: 5918, Loss: 0.5434507727622986, Accuracy: 0.875, Computation time: 0.7350270748138428\n",
      "Step: 5919, Loss: 0.2802446186542511, Accuracy: 0.9375, Computation time: 0.8093452453613281\n",
      "Step: 5920, Loss: 0.4706733226776123, Accuracy: 0.875, Computation time: 1.5557289123535156\n",
      "Step: 5921, Loss: 0.0968521386384964, Accuracy: 0.96875, Computation time: 0.8466579914093018\n",
      "Step: 5922, Loss: 0.9106691479682922, Accuracy: 0.8125, Computation time: 0.7508199214935303\n",
      "Step: 5923, Loss: 0.206370547413826, Accuracy: 0.9375, Computation time: 0.7249491214752197\n",
      "Step: 5924, Loss: 0.5358380675315857, Accuracy: 0.875, Computation time: 0.7548637390136719\n",
      "Step: 5925, Loss: 0.712718665599823, Accuracy: 0.78125, Computation time: 0.9048540592193604\n",
      "Step: 5926, Loss: 0.4271251857280731, Accuracy: 0.84375, Computation time: 0.965723991394043\n",
      "Step: 5927, Loss: 0.49988502264022827, Accuracy: 0.875, Computation time: 0.923900842666626\n",
      "Step: 5928, Loss: 0.20986828207969666, Accuracy: 0.9375, Computation time: 0.6809289455413818\n",
      "Step: 5929, Loss: 0.6518911719322205, Accuracy: 0.8125, Computation time: 1.3568651676177979\n",
      "Step: 5930, Loss: 0.14494095742702484, Accuracy: 0.96875, Computation time: 0.9345932006835938\n",
      "Step: 5931, Loss: 0.3404667377471924, Accuracy: 0.9375, Computation time: 0.9280240535736084\n",
      "Step: 5932, Loss: 0.39950332045555115, Accuracy: 0.90625, Computation time: 0.8885529041290283\n",
      "Step: 5933, Loss: 0.14432433247566223, Accuracy: 0.9375, Computation time: 0.8560769557952881\n",
      "Step: 5934, Loss: 0.4599497318267822, Accuracy: 0.875, Computation time: 0.6924998760223389\n",
      "Step: 5935, Loss: 0.31749120354652405, Accuracy: 0.9375, Computation time: 0.955970048904419\n",
      "Step: 5936, Loss: 0.4203110635280609, Accuracy: 0.875, Computation time: 0.9993290901184082\n",
      "Step: 5937, Loss: 0.2550687789916992, Accuracy: 0.96875, Computation time: 1.0031189918518066\n",
      "Step: 5938, Loss: 0.46804240345954895, Accuracy: 0.875, Computation time: 0.7784140110015869\n",
      "Step: 5939, Loss: 0.6368020176887512, Accuracy: 0.8125, Computation time: 0.9736337661743164\n",
      "Step: 5940, Loss: 0.7142475247383118, Accuracy: 0.8125, Computation time: 0.9502410888671875\n",
      "Step: 5941, Loss: 0.47584763169288635, Accuracy: 0.84375, Computation time: 0.8126192092895508\n",
      "Step: 5942, Loss: 0.30262649059295654, Accuracy: 0.84375, Computation time: 0.953671932220459\n",
      "Step: 5943, Loss: 0.5115476846694946, Accuracy: 0.875, Computation time: 0.826793909072876\n",
      "Step: 5944, Loss: 0.20870761573314667, Accuracy: 0.9375, Computation time: 1.241936206817627\n",
      "Step: 5945, Loss: 0.870320200920105, Accuracy: 0.71875, Computation time: 0.9183852672576904\n",
      "Step: 5946, Loss: 0.4212395250797272, Accuracy: 0.875, Computation time: 0.9836258888244629\n",
      "Step: 5947, Loss: 0.78184574842453, Accuracy: 0.75, Computation time: 0.8059027194976807\n",
      "Step: 5948, Loss: 0.7717322111129761, Accuracy: 0.8125, Computation time: 0.7637639045715332\n",
      "Step: 5949, Loss: 0.5605323314666748, Accuracy: 0.8125, Computation time: 0.8751280307769775\n",
      "Step: 5950, Loss: 0.3093496561050415, Accuracy: 0.875, Computation time: 1.499720811843872\n",
      "Step: 5951, Loss: 0.2162303924560547, Accuracy: 0.9375, Computation time: 0.854182243347168\n",
      "Step: 5952, Loss: 0.7963863611221313, Accuracy: 0.875, Computation time: 0.9762182235717773\n",
      "Step: 5953, Loss: 0.5746412873268127, Accuracy: 0.84375, Computation time: 0.8400349617004395\n",
      "Step: 5954, Loss: 0.18053553998470306, Accuracy: 0.9375, Computation time: 0.9370710849761963\n",
      "Step: 5955, Loss: 0.6811661720275879, Accuracy: 0.78125, Computation time: 0.8887553215026855\n",
      "Step: 5956, Loss: 0.2906821668148041, Accuracy: 0.9375, Computation time: 1.0171852111816406\n",
      "Step: 5957, Loss: 0.4152580201625824, Accuracy: 0.84375, Computation time: 0.7130799293518066\n",
      "Step: 5958, Loss: 0.6471881866455078, Accuracy: 0.8125, Computation time: 0.8399090766906738\n",
      "Step: 5959, Loss: 0.4657347798347473, Accuracy: 0.875, Computation time: 0.8922569751739502\n",
      "Step: 5960, Loss: 0.35408562421798706, Accuracy: 0.90625, Computation time: 1.0335209369659424\n",
      "Step: 5961, Loss: 0.1693578064441681, Accuracy: 0.96875, Computation time: 0.9096870422363281\n",
      "Step: 5962, Loss: 0.6952451467514038, Accuracy: 0.78125, Computation time: 0.7145447731018066\n",
      "Step: 5963, Loss: 0.5619854927062988, Accuracy: 0.84375, Computation time: 1.0396862030029297\n",
      "Step: 5964, Loss: 0.6519502401351929, Accuracy: 0.84375, Computation time: 0.8591759204864502\n",
      "Step: 5965, Loss: 0.538729727268219, Accuracy: 0.84375, Computation time: 0.9509098529815674\n",
      "Step: 5966, Loss: 0.1360655128955841, Accuracy: 0.96875, Computation time: 0.8308041095733643\n",
      "Step: 5967, Loss: 0.19402112066745758, Accuracy: 0.9375, Computation time: 0.964918851852417\n",
      "Step: 5968, Loss: 0.2124045491218567, Accuracy: 0.96875, Computation time: 0.9767313003540039\n",
      "Step: 5969, Loss: 0.5980601906776428, Accuracy: 0.84375, Computation time: 0.9417438507080078\n",
      "Step: 5970, Loss: 0.8030615448951721, Accuracy: 0.71875, Computation time: 0.9930307865142822\n",
      "Step: 5971, Loss: 0.5894920229911804, Accuracy: 0.84375, Computation time: 0.837338924407959\n",
      "Step: 5972, Loss: 0.23463411629199982, Accuracy: 0.96875, Computation time: 0.8335559368133545\n",
      "Step: 5973, Loss: 0.4236704111099243, Accuracy: 0.90625, Computation time: 0.8295631408691406\n",
      "Step: 5974, Loss: 0.8202781677246094, Accuracy: 0.75, Computation time: 0.907789945602417\n",
      "Step: 5975, Loss: 0.3584347665309906, Accuracy: 0.8125, Computation time: 0.8803527355194092\n",
      "Step: 5976, Loss: 0.40514683723449707, Accuracy: 0.8125, Computation time: 0.67684006690979\n",
      "Step: 5977, Loss: 0.6010705232620239, Accuracy: 0.78125, Computation time: 0.9515976905822754\n",
      "Step: 5978, Loss: 0.45705053210258484, Accuracy: 0.8125, Computation time: 0.7022931575775146\n",
      "Step: 5979, Loss: 0.20238542556762695, Accuracy: 0.90625, Computation time: 1.1297941207885742\n",
      "Step: 5980, Loss: 0.38572967052459717, Accuracy: 0.875, Computation time: 1.5981090068817139\n",
      "Step: 5981, Loss: 0.33591872453689575, Accuracy: 0.90625, Computation time: 0.7852029800415039\n",
      "Step: 5982, Loss: 0.5589569211006165, Accuracy: 0.8125, Computation time: 0.8868381977081299\n",
      "Step: 5983, Loss: 0.2017897367477417, Accuracy: 0.90625, Computation time: 0.6816730499267578\n",
      "Step: 5984, Loss: 0.26340463757514954, Accuracy: 0.90625, Computation time: 0.7731788158416748\n",
      "Step: 5985, Loss: 0.18400150537490845, Accuracy: 0.9375, Computation time: 0.7577078342437744\n",
      "Step: 5986, Loss: 0.5603240132331848, Accuracy: 0.84375, Computation time: 0.9240889549255371\n",
      "Step: 5987, Loss: 0.9864711761474609, Accuracy: 0.75, Computation time: 0.7935290336608887\n",
      "Step: 5988, Loss: 0.47586414217948914, Accuracy: 0.875, Computation time: 0.932178258895874\n",
      "Step: 5989, Loss: 0.44473254680633545, Accuracy: 0.8125, Computation time: 0.821110725402832\n",
      "Step: 5990, Loss: 0.3593808710575104, Accuracy: 0.90625, Computation time: 0.8914108276367188\n",
      "Step: 5991, Loss: 0.450111985206604, Accuracy: 0.84375, Computation time: 0.7881820201873779\n",
      "Step: 5992, Loss: 0.22915208339691162, Accuracy: 0.90625, Computation time: 0.7951681613922119\n",
      "Step: 5993, Loss: 0.18409982323646545, Accuracy: 0.96875, Computation time: 1.029547929763794\n",
      "Step: 5994, Loss: 0.21913041174411774, Accuracy: 0.9375, Computation time: 0.9936237335205078\n",
      "Step: 5995, Loss: 0.1953032910823822, Accuracy: 0.96875, Computation time: 0.8268029689788818\n",
      "Step: 5996, Loss: 0.39955392479896545, Accuracy: 0.90625, Computation time: 0.8396177291870117\n",
      "Step: 5997, Loss: 0.6235918402671814, Accuracy: 0.84375, Computation time: 0.8005099296569824\n",
      "Step: 5998, Loss: 0.5188865661621094, Accuracy: 0.78125, Computation time: 0.9252150058746338\n",
      "Step: 5999, Loss: 0.38810038566589355, Accuracy: 0.9375, Computation time: 1.2094411849975586\n",
      "Step: 6000, Loss: 0.7141443490982056, Accuracy: 0.875, Computation time: 1.0688879489898682\n",
      "Step: 6001, Loss: 0.6843708157539368, Accuracy: 0.75, Computation time: 0.998507022857666\n",
      "Step: 6002, Loss: 0.9320752620697021, Accuracy: 0.8125, Computation time: 0.9084060192108154\n",
      "Step: 6003, Loss: 0.737603485584259, Accuracy: 0.84375, Computation time: 0.9370708465576172\n",
      "Step: 6004, Loss: 0.5846799612045288, Accuracy: 0.84375, Computation time: 0.8967218399047852\n",
      "Step: 6005, Loss: 0.6671392321586609, Accuracy: 0.78125, Computation time: 0.7771308422088623\n",
      "Step: 6006, Loss: 0.35547199845314026, Accuracy: 0.84375, Computation time: 0.9150981903076172\n",
      "Step: 6007, Loss: 0.3013908267021179, Accuracy: 0.875, Computation time: 0.8024430274963379\n",
      "Step: 6008, Loss: 0.2415749430656433, Accuracy: 0.90625, Computation time: 0.8720262050628662\n",
      "Step: 6009, Loss: 0.40127241611480713, Accuracy: 0.875, Computation time: 2.0509769916534424\n",
      "Step: 6010, Loss: 0.7198083400726318, Accuracy: 0.78125, Computation time: 1.1423311233520508\n",
      "Step: 6011, Loss: 0.49519890546798706, Accuracy: 0.90625, Computation time: 1.4689888954162598\n",
      "Step: 6012, Loss: 0.6190006136894226, Accuracy: 0.84375, Computation time: 0.8034448623657227\n",
      "Step: 6013, Loss: 0.16534459590911865, Accuracy: 0.96875, Computation time: 0.9691650867462158\n",
      "Step: 6014, Loss: 0.6232949495315552, Accuracy: 0.84375, Computation time: 1.4901618957519531\n",
      "Step: 6015, Loss: 0.5625003576278687, Accuracy: 0.84375, Computation time: 0.895327091217041\n",
      "Step: 6016, Loss: 0.3019443154335022, Accuracy: 0.90625, Computation time: 0.7662129402160645\n",
      "Step: 6017, Loss: 0.6660045385360718, Accuracy: 0.8125, Computation time: 0.7446858882904053\n",
      "Step: 6018, Loss: 0.3447631001472473, Accuracy: 0.875, Computation time: 0.7950608730316162\n",
      "Step: 6019, Loss: 0.5101559162139893, Accuracy: 0.84375, Computation time: 0.8974330425262451\n",
      "Step: 6020, Loss: 0.30916523933410645, Accuracy: 0.90625, Computation time: 0.7612318992614746\n",
      "Step: 6021, Loss: 0.2811867892742157, Accuracy: 0.90625, Computation time: 0.8276889324188232\n",
      "Step: 6022, Loss: 0.251766175031662, Accuracy: 0.90625, Computation time: 0.8681871891021729\n",
      "Step: 6023, Loss: 0.6237846612930298, Accuracy: 0.75, Computation time: 0.8298611640930176\n",
      "Step: 6024, Loss: 0.4967324435710907, Accuracy: 0.875, Computation time: 0.8165011405944824\n",
      "Step: 6025, Loss: 0.1532527357339859, Accuracy: 1.0, Computation time: 0.9061288833618164\n",
      "Step: 6026, Loss: 0.23131176829338074, Accuracy: 0.90625, Computation time: 0.742142915725708\n",
      "Step: 6027, Loss: 0.23783034086227417, Accuracy: 0.90625, Computation time: 1.040459156036377\n",
      "Step: 6028, Loss: 0.32544684410095215, Accuracy: 0.875, Computation time: 0.8178434371948242\n",
      "Step: 6029, Loss: 0.41112020611763, Accuracy: 0.84375, Computation time: 1.1805047988891602\n",
      "Step: 6030, Loss: 0.38565361499786377, Accuracy: 0.875, Computation time: 0.9260151386260986\n",
      "Step: 6031, Loss: 0.2504241466522217, Accuracy: 0.90625, Computation time: 0.9758989810943604\n",
      "Step: 6032, Loss: 0.14031611382961273, Accuracy: 0.96875, Computation time: 1.0211410522460938\n",
      "Step: 6033, Loss: 0.1345236450433731, Accuracy: 0.9375, Computation time: 0.8449280261993408\n",
      "Step: 6034, Loss: 0.4241750240325928, Accuracy: 0.875, Computation time: 0.7902200222015381\n",
      "Step: 6035, Loss: 0.4212212860584259, Accuracy: 0.78125, Computation time: 0.7951910495758057\n",
      "Step: 6036, Loss: 0.7131640315055847, Accuracy: 0.84375, Computation time: 0.9576020240783691\n",
      "Step: 6037, Loss: 1.1400666236877441, Accuracy: 0.65625, Computation time: 0.9269452095031738\n",
      "Step: 6038, Loss: 0.3538220524787903, Accuracy: 0.90625, Computation time: 1.3338749408721924\n",
      "Step: 6039, Loss: 0.392014741897583, Accuracy: 0.90625, Computation time: 1.1564230918884277\n",
      "Step: 6040, Loss: 0.9518356919288635, Accuracy: 0.8125, Computation time: 0.7946829795837402\n",
      "Step: 6041, Loss: 0.5383837223052979, Accuracy: 0.8125, Computation time: 0.9035091400146484\n",
      "Step: 6042, Loss: 0.7841589450836182, Accuracy: 0.8125, Computation time: 0.8219780921936035\n",
      "Step: 6043, Loss: 0.3668574094772339, Accuracy: 0.8125, Computation time: 0.8323779106140137\n",
      "Step: 6044, Loss: 0.3735906779766083, Accuracy: 0.875, Computation time: 0.9313228130340576\n",
      "Step: 6045, Loss: 0.21099066734313965, Accuracy: 0.875, Computation time: 0.9727609157562256\n",
      "Step: 6046, Loss: 0.24815954267978668, Accuracy: 0.9375, Computation time: 0.8043928146362305\n",
      "Step: 6047, Loss: 0.5468844771385193, Accuracy: 0.78125, Computation time: 0.7709488868713379\n",
      "Step: 6048, Loss: 0.2829611301422119, Accuracy: 0.90625, Computation time: 0.9675967693328857\n",
      "Step: 6049, Loss: 0.3158281147480011, Accuracy: 0.90625, Computation time: 0.85699462890625\n",
      "Step: 6050, Loss: 0.5154324173927307, Accuracy: 0.84375, Computation time: 0.962069034576416\n",
      "Step: 6051, Loss: 0.5029251575469971, Accuracy: 0.8125, Computation time: 0.8494760990142822\n",
      "Step: 6052, Loss: 0.2898109555244446, Accuracy: 0.90625, Computation time: 0.8845610618591309\n",
      "Step: 6053, Loss: 0.5256947875022888, Accuracy: 0.84375, Computation time: 0.795353889465332\n",
      "Step: 6054, Loss: 0.4668295085430145, Accuracy: 0.8125, Computation time: 1.107872724533081\n",
      "Step: 6055, Loss: 0.5830941796302795, Accuracy: 0.875, Computation time: 1.1578419208526611\n",
      "Step: 6056, Loss: 0.41263726353645325, Accuracy: 0.90625, Computation time: 0.9254910945892334\n",
      "Step: 6057, Loss: 0.3304242789745331, Accuracy: 0.84375, Computation time: 0.7808308601379395\n",
      "Step: 6058, Loss: 0.34414851665496826, Accuracy: 0.875, Computation time: 0.9271159172058105\n",
      "Step: 6059, Loss: 0.5303255915641785, Accuracy: 0.84375, Computation time: 0.8423159122467041\n",
      "Step: 6060, Loss: 0.5339184403419495, Accuracy: 0.8125, Computation time: 0.8805580139160156\n",
      "Step: 6061, Loss: 0.3738665282726288, Accuracy: 0.875, Computation time: 0.8499491214752197\n",
      "Step: 6062, Loss: 0.5658918619155884, Accuracy: 0.84375, Computation time: 0.7225768566131592\n",
      "Step: 6063, Loss: 0.1823296844959259, Accuracy: 0.9375, Computation time: 0.8299360275268555\n",
      "Step: 6064, Loss: 0.3519521653652191, Accuracy: 0.90625, Computation time: 0.695486307144165\n",
      "Step: 6065, Loss: 0.8930699229240417, Accuracy: 0.71875, Computation time: 0.9280819892883301\n",
      "Step: 6066, Loss: 0.5988348722457886, Accuracy: 0.8125, Computation time: 0.9265921115875244\n",
      "Step: 6067, Loss: 0.34289470314979553, Accuracy: 0.90625, Computation time: 0.9244682788848877\n",
      "Step: 6068, Loss: 0.4547000527381897, Accuracy: 0.84375, Computation time: 1.350423812866211\n",
      "Step: 6069, Loss: 0.22645717859268188, Accuracy: 0.9375, Computation time: 1.0790085792541504\n",
      "Step: 6070, Loss: 0.5024489760398865, Accuracy: 0.90625, Computation time: 1.0002219676971436\n",
      "Step: 6071, Loss: 0.2456108033657074, Accuracy: 0.90625, Computation time: 0.872046947479248\n",
      "Step: 6072, Loss: 0.417521595954895, Accuracy: 0.84375, Computation time: 0.6755959987640381\n",
      "Step: 6073, Loss: 0.49040600657463074, Accuracy: 0.875, Computation time: 0.9149479866027832\n",
      "Step: 6074, Loss: 0.4491228461265564, Accuracy: 0.8125, Computation time: 0.8199889659881592\n",
      "Step: 6075, Loss: 0.4618196189403534, Accuracy: 0.78125, Computation time: 0.8934381008148193\n",
      "Step: 6076, Loss: 0.5581607222557068, Accuracy: 0.78125, Computation time: 0.9217891693115234\n",
      "Step: 6077, Loss: 0.3334428071975708, Accuracy: 0.875, Computation time: 0.8105220794677734\n",
      "Step: 6078, Loss: 0.29563990235328674, Accuracy: 0.875, Computation time: 1.0704309940338135\n",
      "Step: 6079, Loss: 0.12356118857860565, Accuracy: 1.0, Computation time: 0.9132888317108154\n",
      "Step: 6080, Loss: 0.7968539595603943, Accuracy: 0.8125, Computation time: 1.0887980461120605\n",
      "Step: 6081, Loss: 0.4280317425727844, Accuracy: 0.84375, Computation time: 0.8227300643920898\n",
      "Step: 6082, Loss: 0.5382635593414307, Accuracy: 0.84375, Computation time: 0.8512201309204102\n",
      "Step: 6083, Loss: 0.48345717787742615, Accuracy: 0.78125, Computation time: 0.8530659675598145\n",
      "Step: 6084, Loss: 0.9324254393577576, Accuracy: 0.6875, Computation time: 0.7270188331604004\n",
      "Step: 6085, Loss: 0.6894869804382324, Accuracy: 0.78125, Computation time: 0.7730691432952881\n",
      "Step: 6086, Loss: 0.562649130821228, Accuracy: 0.875, Computation time: 0.7362360954284668\n",
      "Step: 6087, Loss: 0.741701066493988, Accuracy: 0.8125, Computation time: 0.9894218444824219\n",
      "Step: 6088, Loss: 0.31052666902542114, Accuracy: 0.9375, Computation time: 0.9700899124145508\n",
      "Step: 6089, Loss: 0.33485162258148193, Accuracy: 0.90625, Computation time: 0.8451452255249023\n",
      "Step: 6090, Loss: 0.9325197339057922, Accuracy: 0.75, Computation time: 0.8682310581207275\n",
      "Step: 6091, Loss: 0.46078184247016907, Accuracy: 0.84375, Computation time: 0.7045400142669678\n",
      "Step: 6092, Loss: 0.6224735379219055, Accuracy: 0.78125, Computation time: 0.731997013092041\n",
      "Step: 6093, Loss: 0.6116543412208557, Accuracy: 0.90625, Computation time: 0.9086480140686035\n",
      "Step: 6094, Loss: 0.2807616889476776, Accuracy: 0.96875, Computation time: 1.1476192474365234\n",
      "Step: 6095, Loss: 0.5883790254592896, Accuracy: 0.8125, Computation time: 0.8499958515167236\n",
      "Step: 6096, Loss: 0.20339059829711914, Accuracy: 0.96875, Computation time: 0.8667972087860107\n",
      "Step: 6097, Loss: 0.5613596439361572, Accuracy: 0.84375, Computation time: 0.7501199245452881\n",
      "Step: 6098, Loss: 0.4300070106983185, Accuracy: 0.8125, Computation time: 0.8787648677825928\n",
      "Step: 6099, Loss: 0.37313878536224365, Accuracy: 0.90625, Computation time: 1.6995418071746826\n",
      "Step: 6100, Loss: 0.7944900393486023, Accuracy: 0.75, Computation time: 0.7822530269622803\n",
      "Step: 6101, Loss: 0.3174170255661011, Accuracy: 0.90625, Computation time: 0.7499268054962158\n",
      "Step: 6102, Loss: 0.5696538686752319, Accuracy: 0.8125, Computation time: 0.7967269420623779\n",
      "Step: 6103, Loss: 0.29659679532051086, Accuracy: 0.875, Computation time: 0.7514059543609619\n",
      "Step: 6104, Loss: 0.2936418652534485, Accuracy: 0.875, Computation time: 0.7551798820495605\n",
      "Step: 6105, Loss: 0.3500499427318573, Accuracy: 0.875, Computation time: 1.01841402053833\n",
      "Step: 6106, Loss: 0.7108464241027832, Accuracy: 0.84375, Computation time: 0.9834821224212646\n",
      "Step: 6107, Loss: 0.4414321780204773, Accuracy: 0.9375, Computation time: 0.729295015335083\n",
      "Step: 6108, Loss: 0.21459580957889557, Accuracy: 0.9375, Computation time: 1.6770472526550293\n",
      "Step: 6109, Loss: 0.29399213194847107, Accuracy: 0.9375, Computation time: 0.9084551334381104\n",
      "Step: 6110, Loss: 0.46796026825904846, Accuracy: 0.90625, Computation time: 0.7617683410644531\n",
      "Step: 6111, Loss: 0.5833462476730347, Accuracy: 0.84375, Computation time: 0.9008889198303223\n",
      "Step: 6112, Loss: 0.34631213545799255, Accuracy: 0.84375, Computation time: 1.4863581657409668\n",
      "Step: 6113, Loss: 0.5940113663673401, Accuracy: 0.84375, Computation time: 1.102924108505249\n",
      "Step: 6114, Loss: 0.5161202549934387, Accuracy: 0.8125, Computation time: 1.0199816226959229\n",
      "Step: 6115, Loss: 0.5999550223350525, Accuracy: 0.84375, Computation time: 0.980224609375\n",
      "Step: 6116, Loss: 0.4347858130931854, Accuracy: 0.90625, Computation time: 0.7791600227355957\n",
      "Step: 6117, Loss: 0.1329958289861679, Accuracy: 0.96875, Computation time: 0.8637590408325195\n",
      "Step: 6118, Loss: 0.44360312819480896, Accuracy: 0.875, Computation time: 0.8237459659576416\n",
      "Step: 6119, Loss: 0.5734329223632812, Accuracy: 0.8125, Computation time: 1.065290927886963\n",
      "Step: 6120, Loss: 0.6094719171524048, Accuracy: 0.8125, Computation time: 0.8411121368408203\n",
      "Step: 6121, Loss: 0.35120251774787903, Accuracy: 0.84375, Computation time: 0.8536241054534912\n",
      "Step: 6122, Loss: 0.2351546436548233, Accuracy: 0.96875, Computation time: 0.7747609615325928\n",
      "Step: 6123, Loss: 0.37335437536239624, Accuracy: 0.875, Computation time: 0.7789549827575684\n",
      "Step: 6124, Loss: 0.09932250529527664, Accuracy: 1.0, Computation time: 0.8076579570770264\n",
      "Step: 6125, Loss: 0.8768976926803589, Accuracy: 0.75, Computation time: 0.79669189453125\n",
      "Step: 6126, Loss: 0.14501981437206268, Accuracy: 0.96875, Computation time: 0.7674069404602051\n",
      "Step: 6127, Loss: 0.7155482769012451, Accuracy: 0.8125, Computation time: 0.9093518257141113\n",
      "Step: 6128, Loss: 0.8468815088272095, Accuracy: 0.6875, Computation time: 1.5008070468902588\n",
      "Step: 6129, Loss: 0.8347188234329224, Accuracy: 0.75, Computation time: 0.8639907836914062\n",
      "Step: 6130, Loss: 0.13896717131137848, Accuracy: 0.9375, Computation time: 0.942474365234375\n",
      "Step: 6131, Loss: 0.321900874376297, Accuracy: 0.9375, Computation time: 0.975297212600708\n",
      "Step: 6132, Loss: 0.36566564440727234, Accuracy: 0.875, Computation time: 0.8381252288818359\n",
      "Step: 6133, Loss: 0.6175017952919006, Accuracy: 0.84375, Computation time: 0.8803830146789551\n",
      "Step: 6134, Loss: 0.5544945597648621, Accuracy: 0.8125, Computation time: 0.8323588371276855\n",
      "Step: 6135, Loss: 0.6971724629402161, Accuracy: 0.78125, Computation time: 0.7328951358795166\n",
      "Step: 6136, Loss: 0.3905474841594696, Accuracy: 0.875, Computation time: 0.7232582569122314\n",
      "Step: 6137, Loss: 0.25938212871551514, Accuracy: 0.90625, Computation time: 0.8371589183807373\n",
      "Step: 6138, Loss: 0.60337895154953, Accuracy: 0.875, Computation time: 0.7403750419616699\n",
      "Step: 6139, Loss: 0.5882978439331055, Accuracy: 0.84375, Computation time: 0.7838730812072754\n",
      "Step: 6140, Loss: 0.46390077471733093, Accuracy: 0.84375, Computation time: 1.2093570232391357\n",
      "Step: 6141, Loss: 0.8736911416053772, Accuracy: 0.78125, Computation time: 0.9458239078521729\n",
      "Step: 6142, Loss: 0.6028257012367249, Accuracy: 0.78125, Computation time: 0.9786303043365479\n",
      "Step: 6143, Loss: 0.4359358847141266, Accuracy: 0.84375, Computation time: 0.8600180149078369\n",
      "Step: 6144, Loss: 0.5641621351242065, Accuracy: 0.84375, Computation time: 0.9904611110687256\n",
      "Step: 6145, Loss: 0.30733028054237366, Accuracy: 0.90625, Computation time: 0.9143109321594238\n",
      "Step: 6146, Loss: 0.7977952361106873, Accuracy: 0.78125, Computation time: 0.8276491165161133\n",
      "Step: 6147, Loss: 0.26032912731170654, Accuracy: 0.9375, Computation time: 0.7647988796234131\n",
      "Step: 6148, Loss: 0.6428062915802002, Accuracy: 0.78125, Computation time: 0.8436596393585205\n",
      "Step: 6149, Loss: 0.5390351414680481, Accuracy: 0.78125, Computation time: 0.846855878829956\n",
      "Step: 6150, Loss: 0.37731480598449707, Accuracy: 0.9375, Computation time: 0.9434030055999756\n",
      "Step: 6151, Loss: 0.3243882656097412, Accuracy: 0.90625, Computation time: 0.7697761058807373\n",
      "Step: 6152, Loss: 0.3101845681667328, Accuracy: 0.9375, Computation time: 0.7867169380187988\n",
      "Step: 6153, Loss: 0.4519832134246826, Accuracy: 0.90625, Computation time: 0.8759801387786865\n",
      "Step: 6154, Loss: 0.7485761046409607, Accuracy: 0.75, Computation time: 0.8110661506652832\n",
      "Step: 6155, Loss: 0.22697685658931732, Accuracy: 0.96875, Computation time: 0.7724440097808838\n",
      "Step: 6156, Loss: 0.46780964732170105, Accuracy: 0.90625, Computation time: 0.7334160804748535\n",
      "Step: 6157, Loss: 0.6388859748840332, Accuracy: 0.875, Computation time: 0.848639965057373\n",
      "Step: 6158, Loss: 0.33604535460472107, Accuracy: 0.90625, Computation time: 0.7908868789672852\n",
      "Step: 6159, Loss: 0.6316332221031189, Accuracy: 0.8125, Computation time: 1.841277837753296\n",
      "Step: 6160, Loss: 0.7766847610473633, Accuracy: 0.84375, Computation time: 0.9208335876464844\n",
      "Step: 6161, Loss: 0.2630853056907654, Accuracy: 0.875, Computation time: 0.7878079414367676\n",
      "Step: 6162, Loss: 0.3338325619697571, Accuracy: 0.90625, Computation time: 1.2421140670776367\n",
      "Step: 6163, Loss: 0.18399013578891754, Accuracy: 0.96875, Computation time: 0.7410709857940674\n",
      "Step: 6164, Loss: 0.275078147649765, Accuracy: 0.9375, Computation time: 1.0060698986053467\n",
      "Step: 6165, Loss: 0.6632871031761169, Accuracy: 0.78125, Computation time: 2.3713841438293457\n",
      "Step: 6166, Loss: 0.3101199269294739, Accuracy: 0.90625, Computation time: 0.8691489696502686\n",
      "Step: 6167, Loss: 0.312213659286499, Accuracy: 0.875, Computation time: 1.0672729015350342\n",
      "Step: 6168, Loss: 0.49767830967903137, Accuracy: 0.8125, Computation time: 0.889009952545166\n",
      "Step: 6169, Loss: 0.22155754268169403, Accuracy: 0.90625, Computation time: 0.8962459564208984\n",
      "Step: 6170, Loss: 0.32323700189590454, Accuracy: 0.9375, Computation time: 0.9013080596923828\n",
      "Step: 6171, Loss: 0.3410700559616089, Accuracy: 0.875, Computation time: 0.9113118648529053\n",
      "Step: 6172, Loss: 0.1926187127828598, Accuracy: 0.96875, Computation time: 0.802666187286377\n",
      "Step: 6173, Loss: 0.24041657149791718, Accuracy: 0.90625, Computation time: 0.6685581207275391\n",
      "Step: 6174, Loss: 0.9140315651893616, Accuracy: 0.71875, Computation time: 0.9170269966125488\n",
      "Step: 6175, Loss: 0.6113578677177429, Accuracy: 0.8125, Computation time: 0.8699939250946045\n",
      "Step: 6176, Loss: 0.2704088091850281, Accuracy: 0.9375, Computation time: 0.7389798164367676\n",
      "Step: 6177, Loss: 0.4776337742805481, Accuracy: 0.875, Computation time: 0.8652710914611816\n",
      "Step: 6178, Loss: 0.6516158580780029, Accuracy: 0.8125, Computation time: 0.8039159774780273\n",
      "Step: 6179, Loss: 1.0507045984268188, Accuracy: 0.65625, Computation time: 1.0406138896942139\n",
      "Step: 6180, Loss: 0.7865614891052246, Accuracy: 0.84375, Computation time: 0.7603669166564941\n",
      "Step: 6181, Loss: 0.4545224606990814, Accuracy: 0.8125, Computation time: 0.9004807472229004\n",
      "Step: 6182, Loss: 0.17079143226146698, Accuracy: 0.9375, Computation time: 0.8676400184631348\n",
      "Step: 6183, Loss: 0.6388776898384094, Accuracy: 0.78125, Computation time: 0.751349925994873\n",
      "Step: 6184, Loss: 0.6185674667358398, Accuracy: 0.8125, Computation time: 0.863318681716919\n",
      "Step: 6185, Loss: 0.07277233898639679, Accuracy: 1.0, Computation time: 0.9342222213745117\n",
      "Step: 6186, Loss: 0.5370137095451355, Accuracy: 0.78125, Computation time: 0.8920998573303223\n",
      "Step: 6187, Loss: 0.3567294776439667, Accuracy: 0.875, Computation time: 1.7088630199432373\n",
      "Step: 6188, Loss: 0.37388867139816284, Accuracy: 0.84375, Computation time: 0.8456640243530273\n",
      "Step: 6189, Loss: 0.49224305152893066, Accuracy: 0.8125, Computation time: 0.7377018928527832\n",
      "Step: 6190, Loss: 0.4181831479072571, Accuracy: 0.875, Computation time: 0.8416588306427002\n",
      "Step: 6191, Loss: 0.17163001000881195, Accuracy: 0.9375, Computation time: 0.7105560302734375\n",
      "Step: 6192, Loss: 0.6259905695915222, Accuracy: 0.8125, Computation time: 0.858834981918335\n",
      "Step: 6193, Loss: 0.37372609972953796, Accuracy: 0.875, Computation time: 0.811039924621582\n",
      "Step: 6194, Loss: 0.7587100267410278, Accuracy: 0.84375, Computation time: 0.7499260902404785\n",
      "Step: 6195, Loss: 0.3853234648704529, Accuracy: 0.9375, Computation time: 0.7396657466888428\n",
      "Step: 6196, Loss: 0.7968893051147461, Accuracy: 0.78125, Computation time: 0.827214241027832\n",
      "Step: 6197, Loss: 0.418113112449646, Accuracy: 0.875, Computation time: 0.8174211978912354\n",
      "Step: 6198, Loss: 0.3030346632003784, Accuracy: 0.9375, Computation time: 1.1840770244598389\n",
      "Step: 6199, Loss: 0.5945233106613159, Accuracy: 0.84375, Computation time: 0.7898669242858887\n",
      "Step: 6200, Loss: 0.4312766194343567, Accuracy: 0.90625, Computation time: 0.8547759056091309\n",
      "Step: 6201, Loss: 0.3409285247325897, Accuracy: 0.90625, Computation time: 0.8629059791564941\n",
      "Step: 6202, Loss: 0.39854440093040466, Accuracy: 0.90625, Computation time: 0.8293788433074951\n",
      "Step: 6203, Loss: 0.6027337908744812, Accuracy: 0.8125, Computation time: 0.8124148845672607\n",
      "Step: 6204, Loss: 0.21110261976718903, Accuracy: 0.9375, Computation time: 0.8676159381866455\n",
      "Step: 6205, Loss: 0.6318529844284058, Accuracy: 0.84375, Computation time: 0.8034608364105225\n",
      "Step: 6206, Loss: 0.35435473918914795, Accuracy: 0.90625, Computation time: 0.7569839954376221\n",
      "Step: 6207, Loss: 0.40480536222457886, Accuracy: 0.90625, Computation time: 0.7925271987915039\n",
      "Step: 6208, Loss: 0.4893578290939331, Accuracy: 0.84375, Computation time: 0.7978439331054688\n",
      "Step: 6209, Loss: 0.5013914108276367, Accuracy: 0.8125, Computation time: 0.836965799331665\n",
      "Step: 6210, Loss: 0.4640141725540161, Accuracy: 0.84375, Computation time: 0.8002650737762451\n",
      "Step: 6211, Loss: 1.0198777914047241, Accuracy: 0.75, Computation time: 0.9419388771057129\n",
      "Step: 6212, Loss: 0.6024951934814453, Accuracy: 0.8125, Computation time: 0.8777821063995361\n",
      "Step: 6213, Loss: 0.21053850650787354, Accuracy: 0.9375, Computation time: 0.9749188423156738\n",
      "Step: 6214, Loss: 0.5350993871688843, Accuracy: 0.8125, Computation time: 0.7449049949645996\n",
      "Step: 6215, Loss: 0.26046472787857056, Accuracy: 0.875, Computation time: 0.714379072189331\n",
      "Step: 6216, Loss: 0.761152982711792, Accuracy: 0.78125, Computation time: 0.9117388725280762\n",
      "Step: 6217, Loss: 0.6984047293663025, Accuracy: 0.75, Computation time: 0.8362970352172852\n",
      "Step: 6218, Loss: 0.48772484064102173, Accuracy: 0.875, Computation time: 0.8100128173828125\n",
      "Step: 6219, Loss: 0.5025354623794556, Accuracy: 0.875, Computation time: 1.5521149635314941\n",
      "Step: 6220, Loss: 0.2437702715396881, Accuracy: 0.90625, Computation time: 0.7387118339538574\n",
      "Step: 6221, Loss: 0.5137198567390442, Accuracy: 0.875, Computation time: 0.805649995803833\n",
      "Step: 6222, Loss: 0.2755941152572632, Accuracy: 0.9375, Computation time: 0.6944379806518555\n",
      "Step: 6223, Loss: 0.43411073088645935, Accuracy: 0.84375, Computation time: 0.7724850177764893\n",
      "Step: 6224, Loss: 0.3458241820335388, Accuracy: 0.875, Computation time: 0.8541169166564941\n",
      "Step: 6225, Loss: 0.3929854929447174, Accuracy: 0.90625, Computation time: 0.8641970157623291\n",
      "Step: 6226, Loss: 0.28377068042755127, Accuracy: 0.90625, Computation time: 0.8776991367340088\n",
      "Step: 6227, Loss: 0.19236698746681213, Accuracy: 0.96875, Computation time: 0.8751230239868164\n",
      "Step: 6228, Loss: 0.8608351349830627, Accuracy: 0.75, Computation time: 0.7401783466339111\n",
      "Step: 6229, Loss: 0.670536994934082, Accuracy: 0.84375, Computation time: 0.962151050567627\n",
      "Step: 6230, Loss: 0.5227468609809875, Accuracy: 0.875, Computation time: 0.8694260120391846\n",
      "Step: 6231, Loss: 0.43253618478775024, Accuracy: 0.8125, Computation time: 0.9532458782196045\n",
      "Step: 6232, Loss: 0.43153053522109985, Accuracy: 0.84375, Computation time: 0.7540991306304932\n",
      "Step: 6233, Loss: 0.4822120666503906, Accuracy: 0.84375, Computation time: 1.0202391147613525\n",
      "Step: 6234, Loss: 0.33297672867774963, Accuracy: 0.9375, Computation time: 0.922332763671875\n",
      "Step: 6235, Loss: 0.35647696256637573, Accuracy: 0.875, Computation time: 0.8161230087280273\n",
      "Step: 6236, Loss: 0.4644969403743744, Accuracy: 0.875, Computation time: 0.897183895111084\n",
      "Step: 6237, Loss: 0.2014414221048355, Accuracy: 0.9375, Computation time: 0.8408150672912598\n",
      "Step: 6238, Loss: 0.5423928499221802, Accuracy: 0.875, Computation time: 0.8534982204437256\n",
      "Step: 6239, Loss: 0.4546780586242676, Accuracy: 0.84375, Computation time: 0.7397007942199707\n",
      "Step: 6240, Loss: 0.917500913143158, Accuracy: 0.75, Computation time: 0.8853261470794678\n",
      "Step: 6241, Loss: 0.4845702350139618, Accuracy: 0.8125, Computation time: 0.8436567783355713\n",
      "Step: 6242, Loss: 0.6974312663078308, Accuracy: 0.8125, Computation time: 0.9344930648803711\n",
      "Step: 6243, Loss: 0.4631750285625458, Accuracy: 0.90625, Computation time: 0.8755269050598145\n",
      "Step: 6244, Loss: 0.44940537214279175, Accuracy: 0.90625, Computation time: 0.726578950881958\n",
      "Step: 6245, Loss: 0.3035699725151062, Accuracy: 0.9375, Computation time: 0.9573671817779541\n",
      "Step: 6246, Loss: 0.4928731322288513, Accuracy: 0.84375, Computation time: 0.8803772926330566\n",
      "Step: 6247, Loss: 0.6073541045188904, Accuracy: 0.8125, Computation time: 0.8745160102844238\n",
      "Step: 6248, Loss: 0.6698519587516785, Accuracy: 0.84375, Computation time: 0.7913708686828613\n",
      "Step: 6249, Loss: 0.5427250266075134, Accuracy: 0.84375, Computation time: 1.1767868995666504\n",
      "Step: 6250, Loss: 0.9908868670463562, Accuracy: 0.78125, Computation time: 1.110818862915039\n",
      "Step: 6251, Loss: 0.4135066568851471, Accuracy: 0.84375, Computation time: 0.9155514240264893\n",
      "Step: 6252, Loss: 0.30486974120140076, Accuracy: 0.9375, Computation time: 1.1228289604187012\n",
      "Step: 6253, Loss: 0.6947242021560669, Accuracy: 0.8125, Computation time: 0.9389059543609619\n",
      "Step: 6254, Loss: 0.5344513654708862, Accuracy: 0.8125, Computation time: 0.806708812713623\n",
      "Step: 6255, Loss: 0.5154908895492554, Accuracy: 0.84375, Computation time: 0.7747998237609863\n",
      "Step: 6256, Loss: 0.936020016670227, Accuracy: 0.75, Computation time: 0.9536161422729492\n",
      "Step: 6257, Loss: 0.43961861729621887, Accuracy: 0.84375, Computation time: 0.8179070949554443\n",
      "Step: 6258, Loss: 0.12423648685216904, Accuracy: 0.96875, Computation time: 0.859123945236206\n",
      "Step: 6259, Loss: 0.105683334171772, Accuracy: 1.0, Computation time: 0.7938632965087891\n",
      "Step: 6260, Loss: 0.5611398816108704, Accuracy: 0.84375, Computation time: 0.8602848052978516\n",
      "Step: 6261, Loss: 0.43055251240730286, Accuracy: 0.8125, Computation time: 1.0221359729766846\n",
      "Step: 6262, Loss: 0.6911565065383911, Accuracy: 0.8125, Computation time: 0.7676510810852051\n",
      "Step: 6263, Loss: 0.6864818930625916, Accuracy: 0.78125, Computation time: 0.7531960010528564\n",
      "Step: 6264, Loss: 0.4577765166759491, Accuracy: 0.8125, Computation time: 0.7917571067810059\n",
      "Step: 6265, Loss: 0.531521201133728, Accuracy: 0.84375, Computation time: 1.0133111476898193\n",
      "Step: 6266, Loss: 0.6346434354782104, Accuracy: 0.78125, Computation time: 0.9909710884094238\n",
      "Step: 6267, Loss: 0.3699794411659241, Accuracy: 0.84375, Computation time: 0.9579832553863525\n",
      "Step: 6268, Loss: 0.3358919024467468, Accuracy: 0.90625, Computation time: 0.808974027633667\n",
      "Step: 6269, Loss: 0.32564887404441833, Accuracy: 0.875, Computation time: 0.8403263092041016\n",
      "Step: 6270, Loss: 0.9542276859283447, Accuracy: 0.78125, Computation time: 1.0175819396972656\n",
      "Step: 6271, Loss: 0.644148051738739, Accuracy: 0.78125, Computation time: 0.8532509803771973\n",
      "Step: 6272, Loss: 0.24917441606521606, Accuracy: 0.90625, Computation time: 0.7812018394470215\n",
      "Step: 6273, Loss: 0.5514790415763855, Accuracy: 0.8125, Computation time: 0.9082682132720947\n",
      "Step: 6274, Loss: 0.37777581810951233, Accuracy: 0.84375, Computation time: 0.9352450370788574\n",
      "Step: 6275, Loss: 0.44042283296585083, Accuracy: 0.84375, Computation time: 0.7712559700012207\n",
      "Step: 6276, Loss: 0.42873501777648926, Accuracy: 0.90625, Computation time: 0.700300931930542\n",
      "Step: 6277, Loss: 0.5337519645690918, Accuracy: 0.84375, Computation time: 0.8173389434814453\n",
      "Step: 6278, Loss: 0.8254461288452148, Accuracy: 0.78125, Computation time: 0.8689887523651123\n",
      "Step: 6279, Loss: 0.28129372000694275, Accuracy: 0.875, Computation time: 0.897352933883667\n",
      "Step: 6280, Loss: 0.32422637939453125, Accuracy: 0.90625, Computation time: 0.8683960437774658\n",
      "Step: 6281, Loss: 0.581099808216095, Accuracy: 0.875, Computation time: 1.4011330604553223\n",
      "Step: 6282, Loss: 0.6473408341407776, Accuracy: 0.78125, Computation time: 0.773522138595581\n",
      "Step: 6283, Loss: 0.2494661808013916, Accuracy: 0.90625, Computation time: 0.911118745803833\n",
      "Step: 6284, Loss: 0.28433406352996826, Accuracy: 0.90625, Computation time: 0.899057149887085\n",
      "Step: 6285, Loss: 0.10387822985649109, Accuracy: 1.0, Computation time: 1.043064832687378\n",
      "Step: 6286, Loss: 0.6054348945617676, Accuracy: 0.84375, Computation time: 0.8536441326141357\n",
      "Step: 6287, Loss: 0.3783952593803406, Accuracy: 0.90625, Computation time: 1.4144172668457031\n",
      "Step: 6288, Loss: 0.28810712695121765, Accuracy: 0.875, Computation time: 0.8542959690093994\n",
      "Step: 6289, Loss: 0.7110922336578369, Accuracy: 0.75, Computation time: 1.456322193145752\n",
      "Step: 6290, Loss: 0.270119845867157, Accuracy: 0.875, Computation time: 0.806218147277832\n",
      "Step: 6291, Loss: 0.4411255419254303, Accuracy: 0.84375, Computation time: 0.8550567626953125\n",
      "Step: 6292, Loss: 0.5398308038711548, Accuracy: 0.84375, Computation time: 0.9812779426574707\n",
      "Step: 6293, Loss: 0.48469483852386475, Accuracy: 0.875, Computation time: 0.7790999412536621\n",
      "Step: 6294, Loss: 0.3590666651725769, Accuracy: 0.875, Computation time: 0.7971169948577881\n",
      "Step: 6295, Loss: 0.29055526852607727, Accuracy: 0.84375, Computation time: 1.0591611862182617\n",
      "Step: 6296, Loss: 0.49785467982292175, Accuracy: 0.84375, Computation time: 0.9083001613616943\n",
      "Step: 6297, Loss: 0.4699168801307678, Accuracy: 0.90625, Computation time: 0.9712257385253906\n",
      "Step: 6298, Loss: 0.8485815525054932, Accuracy: 0.71875, Computation time: 1.0487611293792725\n",
      "Step: 6299, Loss: 0.8827153444290161, Accuracy: 0.71875, Computation time: 0.7293200492858887\n",
      "Step: 6300, Loss: 0.34804967045783997, Accuracy: 0.84375, Computation time: 0.8725340366363525\n",
      "Step: 6301, Loss: 0.3024754822254181, Accuracy: 0.875, Computation time: 0.8206279277801514\n",
      "Step: 6302, Loss: 0.5638663172721863, Accuracy: 0.8125, Computation time: 0.8106591701507568\n",
      "Step: 6303, Loss: 0.427653044462204, Accuracy: 0.875, Computation time: 0.9535770416259766\n",
      "Step: 6304, Loss: 0.5405001640319824, Accuracy: 0.84375, Computation time: 0.8410606384277344\n",
      "Step: 6305, Loss: 0.3488980829715729, Accuracy: 0.84375, Computation time: 0.7937309741973877\n",
      "Step: 6306, Loss: 0.5730034708976746, Accuracy: 0.8125, Computation time: 0.8763678073883057\n",
      "Step: 6307, Loss: 0.29432010650634766, Accuracy: 0.90625, Computation time: 0.7344999313354492\n",
      "Step: 6308, Loss: 0.5026468634605408, Accuracy: 0.875, Computation time: 0.9465460777282715\n",
      "Step: 6309, Loss: 0.1283169835805893, Accuracy: 0.9375, Computation time: 0.8509318828582764\n",
      "Step: 6310, Loss: 0.600939929485321, Accuracy: 0.84375, Computation time: 1.5526719093322754\n",
      "Step: 6311, Loss: 0.3576188087463379, Accuracy: 0.875, Computation time: 0.8316831588745117\n",
      "Step: 6312, Loss: 0.5021034479141235, Accuracy: 0.875, Computation time: 0.8662641048431396\n",
      "Step: 6313, Loss: 0.32068154215812683, Accuracy: 0.875, Computation time: 0.8708291053771973\n",
      "Step: 6314, Loss: 0.6476618051528931, Accuracy: 0.8125, Computation time: 0.9266078472137451\n",
      "Step: 6315, Loss: 0.5094935894012451, Accuracy: 0.84375, Computation time: 1.1120941638946533\n",
      "Step: 6316, Loss: 0.4348909854888916, Accuracy: 0.90625, Computation time: 0.7704830169677734\n",
      "Step: 6317, Loss: 0.3878982663154602, Accuracy: 0.84375, Computation time: 0.9122011661529541\n",
      "Step: 6318, Loss: 0.7035983800888062, Accuracy: 0.8125, Computation time: 0.7446820735931396\n",
      "Step: 6319, Loss: 0.7160703539848328, Accuracy: 0.8125, Computation time: 0.7761788368225098\n",
      "Step: 6320, Loss: 0.6194741129875183, Accuracy: 0.84375, Computation time: 0.8017327785491943\n",
      "Step: 6321, Loss: 0.46393871307373047, Accuracy: 0.90625, Computation time: 0.9265279769897461\n",
      "Step: 6322, Loss: 0.22210918366909027, Accuracy: 0.9375, Computation time: 0.7986061573028564\n",
      "Step: 6323, Loss: 0.39891287684440613, Accuracy: 0.90625, Computation time: 0.8637111186981201\n",
      "Step: 6324, Loss: 0.37886372208595276, Accuracy: 0.84375, Computation time: 0.8968896865844727\n",
      "Step: 6325, Loss: 0.2629556357860565, Accuracy: 0.96875, Computation time: 0.9768421649932861\n",
      "Step: 6326, Loss: 0.47147706151008606, Accuracy: 0.90625, Computation time: 0.718724250793457\n",
      "Step: 6327, Loss: 0.3211694061756134, Accuracy: 0.875, Computation time: 1.0602760314941406\n",
      "Step: 6328, Loss: 0.27886977791786194, Accuracy: 0.9375, Computation time: 0.7943553924560547\n",
      "Step: 6329, Loss: 0.36488109827041626, Accuracy: 0.875, Computation time: 0.946904182434082\n",
      "Step: 6330, Loss: 0.20405852794647217, Accuracy: 0.9375, Computation time: 0.9369869232177734\n",
      "Step: 6331, Loss: 0.33661893010139465, Accuracy: 0.90625, Computation time: 1.080955982208252\n",
      "Step: 6332, Loss: 0.34724414348602295, Accuracy: 0.84375, Computation time: 1.1755399703979492\n",
      "Step: 6333, Loss: 0.7049306631088257, Accuracy: 0.8125, Computation time: 1.292637825012207\n",
      "Step: 6334, Loss: 0.6005309224128723, Accuracy: 0.8125, Computation time: 0.78879714012146\n",
      "Step: 6335, Loss: 0.27731889486312866, Accuracy: 0.90625, Computation time: 0.9354093074798584\n",
      "Step: 6336, Loss: 0.5045177936553955, Accuracy: 0.875, Computation time: 0.8623230457305908\n",
      "Step: 6337, Loss: 0.353986531496048, Accuracy: 0.90625, Computation time: 0.8533730506896973\n",
      "Step: 6338, Loss: 0.16528066992759705, Accuracy: 0.96875, Computation time: 0.8169817924499512\n",
      "Step: 6339, Loss: 0.46764910221099854, Accuracy: 0.875, Computation time: 0.8811190128326416\n",
      "Step: 6340, Loss: 0.329068660736084, Accuracy: 0.90625, Computation time: 1.3815150260925293\n",
      "Step: 6341, Loss: 0.3782581686973572, Accuracy: 0.84375, Computation time: 1.1510400772094727\n",
      "Step: 6342, Loss: 0.41374117136001587, Accuracy: 0.90625, Computation time: 0.831151008605957\n",
      "Step: 6343, Loss: 0.4847509562969208, Accuracy: 0.8125, Computation time: 0.8648252487182617\n",
      "Step: 6344, Loss: 0.5739940404891968, Accuracy: 0.8125, Computation time: 0.7386610507965088\n",
      "Step: 6345, Loss: 0.49595630168914795, Accuracy: 0.875, Computation time: 0.8287980556488037\n",
      "Step: 6346, Loss: 0.2757622301578522, Accuracy: 0.9375, Computation time: 0.7506520748138428\n",
      "Step: 6347, Loss: 0.3721098303794861, Accuracy: 0.84375, Computation time: 1.0217468738555908\n",
      "Step: 6348, Loss: 0.2220454216003418, Accuracy: 0.9375, Computation time: 0.8949699401855469\n",
      "Step: 6349, Loss: 0.24213090538978577, Accuracy: 0.9375, Computation time: 1.0059258937835693\n",
      "Step: 6350, Loss: 0.3817331790924072, Accuracy: 0.875, Computation time: 0.8197391033172607\n",
      "Step: 6351, Loss: 0.402545690536499, Accuracy: 0.875, Computation time: 0.7564620971679688\n",
      "Step: 6352, Loss: 0.49515870213508606, Accuracy: 0.75, Computation time: 0.9250640869140625\n",
      "Step: 6353, Loss: 0.19475099444389343, Accuracy: 0.96875, Computation time: 0.8315401077270508\n",
      "Step: 6354, Loss: 0.2284664511680603, Accuracy: 0.96875, Computation time: 0.8383729457855225\n",
      "Step: 6355, Loss: 0.46235746145248413, Accuracy: 0.875, Computation time: 0.9165160655975342\n",
      "Step: 6356, Loss: 0.18807943165302277, Accuracy: 0.96875, Computation time: 0.9973008632659912\n",
      "Step: 6357, Loss: 0.7252476811408997, Accuracy: 0.8125, Computation time: 0.6366572380065918\n",
      "Step: 6358, Loss: 0.6847290396690369, Accuracy: 0.875, Computation time: 0.9838621616363525\n",
      "Step: 6359, Loss: 0.10783272981643677, Accuracy: 0.96875, Computation time: 0.8078680038452148\n",
      "Step: 6360, Loss: 0.3968137204647064, Accuracy: 0.9375, Computation time: 0.8739099502563477\n",
      "Step: 6361, Loss: 0.29825013875961304, Accuracy: 0.9375, Computation time: 0.902554988861084\n",
      "Step: 6362, Loss: 0.5350752472877502, Accuracy: 0.84375, Computation time: 0.9517519474029541\n",
      "Step: 6363, Loss: 0.3696192800998688, Accuracy: 0.84375, Computation time: 0.7230520248413086\n",
      "Step: 6364, Loss: 0.4421776533126831, Accuracy: 0.90625, Computation time: 0.8163840770721436\n",
      "Step: 6365, Loss: 0.2614693343639374, Accuracy: 0.9375, Computation time: 0.745995044708252\n",
      "Step: 6366, Loss: 0.3995365798473358, Accuracy: 0.84375, Computation time: 1.0725009441375732\n",
      "Step: 6367, Loss: 0.5623831152915955, Accuracy: 0.875, Computation time: 0.7943379878997803\n",
      "Step: 6368, Loss: 0.4338776171207428, Accuracy: 0.875, Computation time: 1.152644157409668\n",
      "Step: 6369, Loss: 0.581230640411377, Accuracy: 0.84375, Computation time: 0.8882007598876953\n",
      "Step: 6370, Loss: 0.5387310981750488, Accuracy: 0.875, Computation time: 1.3884856700897217\n",
      "Step: 6371, Loss: 0.7532335519790649, Accuracy: 0.8125, Computation time: 0.890117883682251\n",
      "Step: 6372, Loss: 0.5288534760475159, Accuracy: 0.8125, Computation time: 0.8742918968200684\n",
      "Step: 6373, Loss: 0.2659883201122284, Accuracy: 0.90625, Computation time: 0.6850030422210693\n",
      "Step: 6374, Loss: 0.629932165145874, Accuracy: 0.78125, Computation time: 0.9097750186920166\n",
      "Step: 6375, Loss: 0.27074572443962097, Accuracy: 0.90625, Computation time: 1.028407096862793\n",
      "Step: 6376, Loss: 0.39628008008003235, Accuracy: 0.875, Computation time: 0.8055078983306885\n",
      "Step: 6377, Loss: 0.36566945910453796, Accuracy: 0.90625, Computation time: 0.955521821975708\n",
      "Step: 6378, Loss: 0.15659895539283752, Accuracy: 0.9375, Computation time: 0.8134059906005859\n",
      "Step: 6379, Loss: 0.17640919983386993, Accuracy: 0.96875, Computation time: 0.837878942489624\n",
      "Step: 6380, Loss: 0.3879293203353882, Accuracy: 0.90625, Computation time: 0.7691419124603271\n",
      "Step: 6381, Loss: 0.29524877667427063, Accuracy: 0.875, Computation time: 1.1666550636291504\n",
      "Step: 6382, Loss: 0.5071291327476501, Accuracy: 0.875, Computation time: 0.7343149185180664\n",
      "Step: 6383, Loss: 0.34534671902656555, Accuracy: 0.875, Computation time: 0.9748218059539795\n",
      "Step: 6384, Loss: 0.6105689406394958, Accuracy: 0.78125, Computation time: 0.9638710021972656\n",
      "Step: 6385, Loss: 0.39359065890312195, Accuracy: 0.9375, Computation time: 0.9045810699462891\n",
      "Step: 6386, Loss: 0.4127819538116455, Accuracy: 0.875, Computation time: 0.8329358100891113\n",
      "Step: 6387, Loss: 0.39753907918930054, Accuracy: 0.875, Computation time: 0.7719109058380127\n",
      "Step: 6388, Loss: 0.27728745341300964, Accuracy: 0.875, Computation time: 0.9973499774932861\n",
      "Step: 6389, Loss: 0.3387746214866638, Accuracy: 0.84375, Computation time: 0.7347469329833984\n",
      "Step: 6390, Loss: 0.3852299451828003, Accuracy: 0.90625, Computation time: 0.878101110458374\n",
      "Step: 6391, Loss: 0.6515717506408691, Accuracy: 0.84375, Computation time: 1.02128267288208\n",
      "Step: 6392, Loss: 0.7353380918502808, Accuracy: 0.75, Computation time: 0.7839488983154297\n",
      "Step: 6393, Loss: 0.19616226851940155, Accuracy: 0.96875, Computation time: 1.017545223236084\n",
      "Step: 6394, Loss: 0.3449009656906128, Accuracy: 0.875, Computation time: 0.8586869239807129\n",
      "Step: 6395, Loss: 0.6310566067695618, Accuracy: 0.8125, Computation time: 0.86289381980896\n",
      "Step: 6396, Loss: 0.34390050172805786, Accuracy: 0.90625, Computation time: 0.848289966583252\n",
      "Step: 6397, Loss: 0.37477877736091614, Accuracy: 0.875, Computation time: 0.7392418384552002\n",
      "Step: 6398, Loss: 0.5874576568603516, Accuracy: 0.84375, Computation time: 0.846743106842041\n",
      "Step: 6399, Loss: 0.2667927145957947, Accuracy: 0.9375, Computation time: 1.0067381858825684\n",
      "Step: 6400, Loss: 0.4395695924758911, Accuracy: 0.875, Computation time: 1.6582691669464111\n",
      "Step: 6401, Loss: 0.3921715319156647, Accuracy: 0.875, Computation time: 0.7695639133453369\n",
      "Step: 6402, Loss: 0.27523836493492126, Accuracy: 0.84375, Computation time: 0.804980993270874\n",
      "Step: 6403, Loss: 0.27035146951675415, Accuracy: 0.96875, Computation time: 0.7869460582733154\n",
      "Step: 6404, Loss: 0.24016712605953217, Accuracy: 0.90625, Computation time: 0.7713518142700195\n",
      "Step: 6405, Loss: 0.35267844796180725, Accuracy: 0.9375, Computation time: 0.827343225479126\n",
      "Step: 6406, Loss: 0.16147767007350922, Accuracy: 0.9375, Computation time: 0.787477970123291\n",
      "Step: 6407, Loss: 0.21881459653377533, Accuracy: 0.9375, Computation time: 0.8441429138183594\n",
      "Step: 6408, Loss: 0.46790555119514465, Accuracy: 0.84375, Computation time: 0.8711750507354736\n",
      "Step: 6409, Loss: 0.6139838099479675, Accuracy: 0.78125, Computation time: 0.9892899990081787\n",
      "Step: 6410, Loss: 0.34750428795814514, Accuracy: 0.90625, Computation time: 1.1505982875823975\n",
      "Step: 6411, Loss: 0.3687283396720886, Accuracy: 0.875, Computation time: 0.9131181240081787\n",
      "Step: 6412, Loss: 0.6469069123268127, Accuracy: 0.75, Computation time: 1.0213720798492432\n",
      "Step: 6413, Loss: 0.47286128997802734, Accuracy: 0.875, Computation time: 0.9156091213226318\n",
      "Step: 6414, Loss: 0.39488351345062256, Accuracy: 0.96875, Computation time: 0.9046807289123535\n",
      "Step: 6415, Loss: 0.5717342495918274, Accuracy: 0.8125, Computation time: 1.0073540210723877\n",
      "Step: 6416, Loss: 0.6163548231124878, Accuracy: 0.8125, Computation time: 0.8319528102874756\n",
      "Step: 6417, Loss: 0.3231010437011719, Accuracy: 0.90625, Computation time: 1.0003268718719482\n",
      "Step: 6418, Loss: 1.112230896949768, Accuracy: 0.78125, Computation time: 1.1254699230194092\n",
      "Step: 6419, Loss: 0.41455671191215515, Accuracy: 0.84375, Computation time: 0.8547470569610596\n",
      "Step: 6420, Loss: 0.31600221991539, Accuracy: 0.90625, Computation time: 0.8472189903259277\n",
      "Step: 6421, Loss: 0.26476234197616577, Accuracy: 0.875, Computation time: 0.8942828178405762\n",
      "Step: 6422, Loss: 0.4351053237915039, Accuracy: 0.84375, Computation time: 0.9673309326171875\n",
      "Step: 6423, Loss: 0.5639573931694031, Accuracy: 0.84375, Computation time: 0.8916900157928467\n",
      "Step: 6424, Loss: 0.6028586626052856, Accuracy: 0.78125, Computation time: 0.8162591457366943\n",
      "Step: 6425, Loss: 0.4297257661819458, Accuracy: 0.875, Computation time: 0.8058218955993652\n",
      "Step: 6426, Loss: 0.4186854660511017, Accuracy: 0.90625, Computation time: 1.0242269039154053\n",
      "Step: 6427, Loss: 0.39397764205932617, Accuracy: 0.875, Computation time: 0.7909979820251465\n",
      "Step: 6428, Loss: 0.39586129784584045, Accuracy: 0.90625, Computation time: 0.8301849365234375\n",
      "Step: 6429, Loss: 0.5111578106880188, Accuracy: 0.78125, Computation time: 0.8239929676055908\n",
      "Step: 6430, Loss: 0.569258451461792, Accuracy: 0.75, Computation time: 1.5677261352539062\n",
      "Step: 6431, Loss: 0.3919501304626465, Accuracy: 0.875, Computation time: 0.8739697933197021\n",
      "Step: 6432, Loss: 0.26266446709632874, Accuracy: 0.90625, Computation time: 1.0717570781707764\n",
      "Step: 6433, Loss: 0.41052860021591187, Accuracy: 0.84375, Computation time: 1.0304970741271973\n",
      "Step: 6434, Loss: 0.43097537755966187, Accuracy: 0.84375, Computation time: 0.8062567710876465\n",
      "Step: 6435, Loss: 0.30924156308174133, Accuracy: 0.9375, Computation time: 1.0518560409545898\n",
      "Step: 6436, Loss: 0.45496228337287903, Accuracy: 0.84375, Computation time: 1.178131103515625\n",
      "Step: 6437, Loss: 0.2773500978946686, Accuracy: 0.90625, Computation time: 0.8745391368865967\n",
      "Step: 6438, Loss: 0.5179804563522339, Accuracy: 0.875, Computation time: 1.0127849578857422\n",
      "Step: 6439, Loss: 0.5362238883972168, Accuracy: 0.78125, Computation time: 0.9724438190460205\n",
      "Step: 6440, Loss: 0.49024438858032227, Accuracy: 0.84375, Computation time: 0.8698618412017822\n",
      "Step: 6441, Loss: 0.9974563717842102, Accuracy: 0.78125, Computation time: 0.9015891551971436\n",
      "Step: 6442, Loss: 0.3328979015350342, Accuracy: 0.90625, Computation time: 0.7562899589538574\n",
      "Step: 6443, Loss: 0.15620553493499756, Accuracy: 0.96875, Computation time: 0.7359821796417236\n",
      "Step: 6444, Loss: 0.2274223268032074, Accuracy: 0.90625, Computation time: 0.8557040691375732\n",
      "Step: 6445, Loss: 0.6261877417564392, Accuracy: 0.78125, Computation time: 0.7541937828063965\n",
      "Step: 6446, Loss: 0.8314529061317444, Accuracy: 0.8125, Computation time: 0.8932716846466064\n",
      "Step: 6447, Loss: 0.2837587893009186, Accuracy: 0.90625, Computation time: 0.8064079284667969\n",
      "Step: 6448, Loss: 0.41635867953300476, Accuracy: 0.875, Computation time: 0.8124649524688721\n",
      "Step: 6449, Loss: 0.40135034918785095, Accuracy: 0.875, Computation time: 0.7562968730926514\n",
      "Step: 6450, Loss: 0.4418296217918396, Accuracy: 0.875, Computation time: 0.8357503414154053\n",
      "Step: 6451, Loss: 0.09129580110311508, Accuracy: 1.0, Computation time: 0.8399629592895508\n",
      "Step: 6452, Loss: 0.6010348796844482, Accuracy: 0.84375, Computation time: 0.7958190441131592\n",
      "Step: 6453, Loss: 0.4933554232120514, Accuracy: 0.90625, Computation time: 0.7777609825134277\n",
      "Step: 6454, Loss: 0.35754236578941345, Accuracy: 0.90625, Computation time: 0.749953031539917\n",
      "Step: 6455, Loss: 0.5174072980880737, Accuracy: 0.8125, Computation time: 0.9529759883880615\n",
      "Step: 6456, Loss: 0.7101367115974426, Accuracy: 0.84375, Computation time: 0.9419598579406738\n",
      "Step: 6457, Loss: 0.36259719729423523, Accuracy: 0.875, Computation time: 0.8493239879608154\n",
      "Step: 6458, Loss: 0.2380688190460205, Accuracy: 0.90625, Computation time: 0.9137392044067383\n",
      "Step: 6459, Loss: 0.27163615822792053, Accuracy: 0.96875, Computation time: 0.9676649570465088\n",
      "Step: 6460, Loss: 0.17796628177165985, Accuracy: 0.9375, Computation time: 0.725139856338501\n",
      "Step: 6461, Loss: 0.7560763359069824, Accuracy: 0.75, Computation time: 0.8571181297302246\n",
      "Step: 6462, Loss: 0.5336694717407227, Accuracy: 0.84375, Computation time: 0.8681111335754395\n",
      "Step: 6463, Loss: 0.39017394185066223, Accuracy: 0.875, Computation time: 0.927833080291748\n",
      "Step: 6464, Loss: 0.1515210121870041, Accuracy: 0.96875, Computation time: 0.8132460117340088\n",
      "Step: 6465, Loss: 0.2868495583534241, Accuracy: 0.90625, Computation time: 0.8791439533233643\n",
      "Step: 6466, Loss: 0.5962913632392883, Accuracy: 0.90625, Computation time: 0.8201649188995361\n",
      "Step: 6467, Loss: 0.5807507038116455, Accuracy: 0.8125, Computation time: 0.8574779033660889\n",
      "Step: 6468, Loss: 0.40458741784095764, Accuracy: 0.875, Computation time: 0.9675180912017822\n",
      "Step: 6469, Loss: 0.4918055832386017, Accuracy: 0.78125, Computation time: 0.7521111965179443\n",
      "Step: 6470, Loss: 0.28729286789894104, Accuracy: 0.96875, Computation time: 0.8201851844787598\n",
      "Step: 6471, Loss: 0.2378062605857849, Accuracy: 0.90625, Computation time: 0.8759288787841797\n",
      "Step: 6472, Loss: 0.117672860622406, Accuracy: 0.96875, Computation time: 1.055129051208496\n",
      "Step: 6473, Loss: 0.6543578505516052, Accuracy: 0.78125, Computation time: 0.8150639533996582\n",
      "Step: 6474, Loss: 0.17317035794258118, Accuracy: 0.96875, Computation time: 1.1377480030059814\n",
      "Step: 6475, Loss: 0.3834296762943268, Accuracy: 0.90625, Computation time: 0.8971378803253174\n",
      "Step: 6476, Loss: 0.35367581248283386, Accuracy: 0.875, Computation time: 1.0959420204162598\n",
      "Step: 6477, Loss: 0.8264269232749939, Accuracy: 0.8125, Computation time: 0.867542028427124\n",
      "Step: 6478, Loss: 0.706742525100708, Accuracy: 0.90625, Computation time: 0.8314769268035889\n",
      "Step: 6479, Loss: 0.608096718788147, Accuracy: 0.84375, Computation time: 0.8418958187103271\n",
      "Step: 6480, Loss: 0.29152119159698486, Accuracy: 0.9375, Computation time: 0.9461610317230225\n",
      "Step: 6481, Loss: 0.23997050523757935, Accuracy: 0.84375, Computation time: 0.931298017501831\n",
      "Step: 6482, Loss: 0.08427035808563232, Accuracy: 1.0, Computation time: 0.9056529998779297\n",
      "Step: 6483, Loss: 0.3752499520778656, Accuracy: 0.84375, Computation time: 0.7159528732299805\n",
      "Step: 6484, Loss: 0.29033878445625305, Accuracy: 0.90625, Computation time: 0.713752031326294\n",
      "Step: 6485, Loss: 0.2830908000469208, Accuracy: 0.875, Computation time: 0.8031411170959473\n",
      "Step: 6486, Loss: 0.6763542294502258, Accuracy: 0.84375, Computation time: 0.9070219993591309\n",
      "Step: 6487, Loss: 0.17359599471092224, Accuracy: 0.96875, Computation time: 0.8444371223449707\n",
      "Step: 6488, Loss: 0.7305454015731812, Accuracy: 0.78125, Computation time: 0.8211688995361328\n",
      "Step: 6489, Loss: 0.27653878927230835, Accuracy: 0.90625, Computation time: 0.8355159759521484\n",
      "Step: 6490, Loss: 0.18017169833183289, Accuracy: 0.96875, Computation time: 0.8452029228210449\n",
      "Step: 6491, Loss: 0.9907844662666321, Accuracy: 0.78125, Computation time: 1.7187738418579102\n",
      "Step: 6492, Loss: 0.3273002505302429, Accuracy: 0.90625, Computation time: 0.8138959407806396\n",
      "Step: 6493, Loss: 0.5373676419258118, Accuracy: 0.8125, Computation time: 0.8676259517669678\n",
      "Step: 6494, Loss: 0.6928336024284363, Accuracy: 0.8125, Computation time: 1.0431222915649414\n",
      "Step: 6495, Loss: 0.421736478805542, Accuracy: 0.875, Computation time: 0.9282412528991699\n",
      "Step: 6496, Loss: 0.46953797340393066, Accuracy: 0.84375, Computation time: 0.9517548084259033\n",
      "Step: 6497, Loss: 0.3780888319015503, Accuracy: 0.90625, Computation time: 0.8442318439483643\n",
      "Step: 6498, Loss: 0.355989009141922, Accuracy: 0.90625, Computation time: 0.8542881011962891\n",
      "Step: 6499, Loss: 0.42953500151634216, Accuracy: 0.875, Computation time: 1.0170800685882568\n",
      "Step: 6500, Loss: 0.43058866262435913, Accuracy: 0.90625, Computation time: 0.9117999076843262\n",
      "Step: 6501, Loss: 0.44253140687942505, Accuracy: 0.84375, Computation time: 0.7360398769378662\n",
      "Step: 6502, Loss: 0.2892872095108032, Accuracy: 0.90625, Computation time: 0.996164083480835\n",
      "Step: 6503, Loss: 0.39132535457611084, Accuracy: 0.84375, Computation time: 0.8143038749694824\n",
      "Step: 6504, Loss: 0.3469175398349762, Accuracy: 0.84375, Computation time: 0.8717529773712158\n",
      "Step: 6505, Loss: 0.8593086004257202, Accuracy: 0.75, Computation time: 0.8869607448577881\n",
      "Step: 6506, Loss: 0.169876366853714, Accuracy: 0.96875, Computation time: 0.7182812690734863\n",
      "Step: 6507, Loss: 0.5585275888442993, Accuracy: 0.78125, Computation time: 0.7765932083129883\n",
      "Step: 6508, Loss: 0.6217458248138428, Accuracy: 0.8125, Computation time: 0.9016680717468262\n",
      "Step: 6509, Loss: 0.35154804587364197, Accuracy: 0.875, Computation time: 0.7365789413452148\n",
      "Step: 6510, Loss: 0.9394035935401917, Accuracy: 0.8125, Computation time: 1.061920166015625\n",
      "Step: 6511, Loss: 0.34888216853141785, Accuracy: 0.875, Computation time: 1.0103378295898438\n",
      "Step: 6512, Loss: 0.4467606246471405, Accuracy: 0.84375, Computation time: 0.759329080581665\n",
      "Step: 6513, Loss: 0.4548710584640503, Accuracy: 0.875, Computation time: 0.9697761535644531\n",
      "Step: 6514, Loss: 0.20224326848983765, Accuracy: 0.9375, Computation time: 0.7598512172698975\n",
      "Step: 6515, Loss: 0.5721486210823059, Accuracy: 0.8125, Computation time: 0.7606868743896484\n",
      "Step: 6516, Loss: 0.9918462634086609, Accuracy: 0.75, Computation time: 0.8148386478424072\n",
      "Step: 6517, Loss: 0.4460223913192749, Accuracy: 0.90625, Computation time: 1.0642728805541992\n",
      "Step: 6518, Loss: 0.5858473777770996, Accuracy: 0.84375, Computation time: 0.865123987197876\n",
      "Step: 6519, Loss: 0.5854701399803162, Accuracy: 0.78125, Computation time: 0.9826829433441162\n",
      "Step: 6520, Loss: 0.29912886023521423, Accuracy: 0.9375, Computation time: 0.8721411228179932\n",
      "Step: 6521, Loss: 0.29726576805114746, Accuracy: 0.875, Computation time: 1.1991419792175293\n",
      "Step: 6522, Loss: 0.34853076934814453, Accuracy: 0.90625, Computation time: 0.7718300819396973\n",
      "Step: 6523, Loss: 0.7673341035842896, Accuracy: 0.78125, Computation time: 0.8442721366882324\n",
      "Step: 6524, Loss: 0.3149113953113556, Accuracy: 0.9375, Computation time: 0.8102259635925293\n",
      "Step: 6525, Loss: 0.6262795925140381, Accuracy: 0.78125, Computation time: 0.8942019939422607\n",
      "Step: 6526, Loss: 0.3560527265071869, Accuracy: 0.875, Computation time: 0.8305490016937256\n",
      "Step: 6527, Loss: 0.37809669971466064, Accuracy: 0.8125, Computation time: 0.8603489398956299\n",
      "Step: 6528, Loss: 0.2178918570280075, Accuracy: 0.9375, Computation time: 0.8524632453918457\n",
      "Step: 6529, Loss: 0.6012746691703796, Accuracy: 0.8125, Computation time: 0.8957722187042236\n",
      "Step: 6530, Loss: 0.34154418110847473, Accuracy: 0.90625, Computation time: 0.8897461891174316\n",
      "Step: 6531, Loss: 0.6227596998214722, Accuracy: 0.875, Computation time: 1.1581430435180664\n",
      "Step: 6532, Loss: 0.34866687655448914, Accuracy: 0.875, Computation time: 0.8477649688720703\n",
      "Step: 6533, Loss: 0.7955223321914673, Accuracy: 0.8125, Computation time: 0.9358670711517334\n",
      "Step: 6534, Loss: 0.6010463237762451, Accuracy: 0.75, Computation time: 0.7775790691375732\n",
      "Step: 6535, Loss: 0.49418553709983826, Accuracy: 0.78125, Computation time: 0.8095757961273193\n",
      "Step: 6536, Loss: 0.2545524835586548, Accuracy: 0.9375, Computation time: 0.9152877330780029\n",
      "Step: 6537, Loss: 0.5399053692817688, Accuracy: 0.8125, Computation time: 1.0621299743652344\n",
      "Step: 6538, Loss: 0.7193667888641357, Accuracy: 0.8125, Computation time: 0.8392491340637207\n",
      "Step: 6539, Loss: 0.5525789260864258, Accuracy: 0.78125, Computation time: 0.8757588863372803\n",
      "Step: 6540, Loss: 0.35583484172821045, Accuracy: 0.84375, Computation time: 0.9836070537567139\n",
      "Step: 6541, Loss: 0.3747018575668335, Accuracy: 0.875, Computation time: 0.8692231178283691\n",
      "Step: 6542, Loss: 0.3497332036495209, Accuracy: 0.84375, Computation time: 0.9448151588439941\n",
      "Step: 6543, Loss: 0.3151624798774719, Accuracy: 0.90625, Computation time: 0.6566598415374756\n",
      "Step: 6544, Loss: 0.6278244256973267, Accuracy: 0.78125, Computation time: 0.7898528575897217\n",
      "Step: 6545, Loss: 0.5302690267562866, Accuracy: 0.875, Computation time: 0.8450891971588135\n",
      "Step: 6546, Loss: 0.6032722592353821, Accuracy: 0.78125, Computation time: 0.981069803237915\n",
      "Step: 6547, Loss: 0.4038979709148407, Accuracy: 0.9375, Computation time: 0.8712530136108398\n",
      "Step: 6548, Loss: 0.7861495614051819, Accuracy: 0.78125, Computation time: 0.8565139770507812\n",
      "Step: 6549, Loss: 0.9668301939964294, Accuracy: 0.78125, Computation time: 0.7811579704284668\n",
      "Step: 6550, Loss: 0.7867674827575684, Accuracy: 0.75, Computation time: 1.0434558391571045\n",
      "Step: 6551, Loss: 0.7573551535606384, Accuracy: 0.8125, Computation time: 1.139869213104248\n",
      "Step: 6552, Loss: 0.22641149163246155, Accuracy: 0.96875, Computation time: 0.9243118762969971\n",
      "Step: 6553, Loss: 0.1799020767211914, Accuracy: 0.96875, Computation time: 1.0176520347595215\n",
      "Step: 6554, Loss: 0.5036315321922302, Accuracy: 0.84375, Computation time: 1.1196789741516113\n",
      "Step: 6555, Loss: 0.4137080907821655, Accuracy: 0.8125, Computation time: 0.784555196762085\n",
      "Step: 6556, Loss: 0.5067893862724304, Accuracy: 0.78125, Computation time: 0.7087688446044922\n",
      "Step: 6557, Loss: 0.4896896779537201, Accuracy: 0.875, Computation time: 0.9751288890838623\n",
      "Step: 6558, Loss: 0.8771184682846069, Accuracy: 0.84375, Computation time: 0.7298839092254639\n",
      "Step: 6559, Loss: 0.4497259557247162, Accuracy: 0.78125, Computation time: 0.8585481643676758\n",
      "Step: 6560, Loss: 0.41988039016723633, Accuracy: 0.90625, Computation time: 0.7527010440826416\n",
      "Step: 6561, Loss: 0.47737303376197815, Accuracy: 0.84375, Computation time: 0.7385857105255127\n",
      "Step: 6562, Loss: 0.4414577782154083, Accuracy: 0.84375, Computation time: 0.9168500900268555\n",
      "Step: 6563, Loss: 0.5885356068611145, Accuracy: 0.8125, Computation time: 0.8708310127258301\n",
      "Step: 6564, Loss: 0.6587597131729126, Accuracy: 0.78125, Computation time: 0.9852180480957031\n",
      "Step: 6565, Loss: 0.5770980715751648, Accuracy: 0.84375, Computation time: 0.8789219856262207\n",
      "Step: 6566, Loss: 0.6767941117286682, Accuracy: 0.84375, Computation time: 0.9731059074401855\n",
      "Step: 6567, Loss: 0.6776160001754761, Accuracy: 0.875, Computation time: 0.8627710342407227\n",
      "Step: 6568, Loss: 0.46934184432029724, Accuracy: 0.84375, Computation time: 1.149986982345581\n",
      "Step: 6569, Loss: 0.5828867554664612, Accuracy: 0.8125, Computation time: 0.751776933670044\n",
      "Step: 6570, Loss: 0.4273650646209717, Accuracy: 0.90625, Computation time: 0.8600411415100098\n",
      "Step: 6571, Loss: 0.25048667192459106, Accuracy: 0.9375, Computation time: 0.9150540828704834\n",
      "Step: 6572, Loss: 0.3138069808483124, Accuracy: 0.9375, Computation time: 0.8701608180999756\n",
      "Step: 6573, Loss: 0.6552868485450745, Accuracy: 0.75, Computation time: 0.7765228748321533\n",
      "Step: 6574, Loss: 0.21550744771957397, Accuracy: 0.9375, Computation time: 0.714259147644043\n",
      "Step: 6575, Loss: 0.176634281873703, Accuracy: 0.9375, Computation time: 0.8875448703765869\n",
      "Step: 6576, Loss: 0.46474695205688477, Accuracy: 0.84375, Computation time: 0.9369509220123291\n",
      "Step: 6577, Loss: 0.4846476912498474, Accuracy: 0.875, Computation time: 0.7699580192565918\n",
      "Step: 6578, Loss: 0.5352402925491333, Accuracy: 0.90625, Computation time: 0.7572479248046875\n",
      "Step: 6579, Loss: 0.34237903356552124, Accuracy: 0.84375, Computation time: 0.7569918632507324\n",
      "Step: 6580, Loss: 0.44390466809272766, Accuracy: 0.875, Computation time: 0.7299437522888184\n",
      "Step: 6581, Loss: 0.5499953627586365, Accuracy: 0.78125, Computation time: 0.6849157810211182\n",
      "Step: 6582, Loss: 0.3425852358341217, Accuracy: 0.96875, Computation time: 0.8581459522247314\n",
      "Step: 6583, Loss: 0.24139440059661865, Accuracy: 0.90625, Computation time: 1.3175280094146729\n",
      "Step: 6584, Loss: 0.23321563005447388, Accuracy: 0.96875, Computation time: 0.9042890071868896\n",
      "Step: 6585, Loss: 0.23606444895267487, Accuracy: 0.90625, Computation time: 0.7850477695465088\n",
      "Step: 6586, Loss: 0.1731334775686264, Accuracy: 0.96875, Computation time: 0.954988956451416\n",
      "Step: 6587, Loss: 0.11410050094127655, Accuracy: 0.96875, Computation time: 0.9157609939575195\n",
      "Step: 6588, Loss: 0.3886869251728058, Accuracy: 0.84375, Computation time: 0.8808910846710205\n",
      "Step: 6589, Loss: 0.31695523858070374, Accuracy: 0.875, Computation time: 0.8181450366973877\n",
      "Step: 6590, Loss: 0.4835113286972046, Accuracy: 0.8125, Computation time: 0.9682409763336182\n",
      "Step: 6591, Loss: 0.3492909073829651, Accuracy: 0.875, Computation time: 0.8045408725738525\n",
      "Step: 6592, Loss: 0.6458731293678284, Accuracy: 0.78125, Computation time: 0.8484008312225342\n",
      "Step: 6593, Loss: 0.286232054233551, Accuracy: 0.875, Computation time: 0.9212889671325684\n",
      "Step: 6594, Loss: 0.4914158284664154, Accuracy: 0.8125, Computation time: 0.9180440902709961\n",
      "Step: 6595, Loss: 0.5814395546913147, Accuracy: 0.71875, Computation time: 0.9107041358947754\n",
      "Step: 6596, Loss: 0.40299516916275024, Accuracy: 0.90625, Computation time: 1.2610070705413818\n",
      "Step: 6597, Loss: 0.688347339630127, Accuracy: 0.875, Computation time: 0.7795429229736328\n",
      "Step: 6598, Loss: 0.4350237250328064, Accuracy: 0.84375, Computation time: 0.7626252174377441\n",
      "Step: 6599, Loss: 0.37619122862815857, Accuracy: 0.90625, Computation time: 0.7747659683227539\n",
      "Step: 6600, Loss: 0.471505343914032, Accuracy: 0.84375, Computation time: 0.8121402263641357\n",
      "Step: 6601, Loss: 0.13323213160037994, Accuracy: 0.96875, Computation time: 0.9429309368133545\n",
      "Step: 6602, Loss: 0.49446621537208557, Accuracy: 0.84375, Computation time: 0.7510578632354736\n",
      "Step: 6603, Loss: 0.9359447956085205, Accuracy: 0.75, Computation time: 0.7882089614868164\n",
      "Step: 6604, Loss: 0.2863118052482605, Accuracy: 0.90625, Computation time: 0.7885818481445312\n",
      "Step: 6605, Loss: 0.5042957067489624, Accuracy: 0.78125, Computation time: 0.9301068782806396\n",
      "Step: 6606, Loss: 0.23895931243896484, Accuracy: 0.9375, Computation time: 0.9127097129821777\n",
      "Step: 6607, Loss: 0.45830270648002625, Accuracy: 0.8125, Computation time: 0.7605569362640381\n",
      "Step: 6608, Loss: 0.5860426425933838, Accuracy: 0.78125, Computation time: 0.6637592315673828\n",
      "Step: 6609, Loss: 0.35632452368736267, Accuracy: 0.90625, Computation time: 0.9347667694091797\n",
      "Step: 6610, Loss: 0.4566308259963989, Accuracy: 0.8125, Computation time: 0.9676196575164795\n",
      "Step: 6611, Loss: 0.36473017930984497, Accuracy: 0.84375, Computation time: 0.8751587867736816\n",
      "Step: 6612, Loss: 0.21549591422080994, Accuracy: 0.90625, Computation time: 0.6931169033050537\n",
      "Step: 6613, Loss: 0.1638582944869995, Accuracy: 0.96875, Computation time: 1.5924711227416992\n",
      "Step: 6614, Loss: 0.5228880643844604, Accuracy: 0.8125, Computation time: 0.9003572463989258\n",
      "Step: 6615, Loss: 0.39852669835090637, Accuracy: 0.875, Computation time: 1.008409023284912\n",
      "Step: 6616, Loss: 0.11700679361820221, Accuracy: 1.0, Computation time: 0.7037391662597656\n",
      "Step: 6617, Loss: 0.2441886067390442, Accuracy: 0.9375, Computation time: 0.9581906795501709\n",
      "Step: 6618, Loss: 0.5479332804679871, Accuracy: 0.84375, Computation time: 0.8004050254821777\n",
      "Step: 6619, Loss: 0.46714073419570923, Accuracy: 0.84375, Computation time: 0.9588003158569336\n",
      "Step: 6620, Loss: 0.2315981090068817, Accuracy: 0.90625, Computation time: 0.7446789741516113\n",
      "Step: 6621, Loss: 0.1531722992658615, Accuracy: 0.96875, Computation time: 0.9587299823760986\n",
      "Step: 6622, Loss: 0.5425305366516113, Accuracy: 0.84375, Computation time: 0.9667656421661377\n",
      "Step: 6623, Loss: 0.44930553436279297, Accuracy: 0.84375, Computation time: 0.8071341514587402\n",
      "Step: 6624, Loss: 0.35160255432128906, Accuracy: 0.9375, Computation time: 1.122147798538208\n",
      "Step: 6625, Loss: 0.6056984663009644, Accuracy: 0.78125, Computation time: 0.9918720722198486\n",
      "Step: 6626, Loss: 0.2653207778930664, Accuracy: 0.90625, Computation time: 0.806035041809082\n",
      "Step: 6627, Loss: 0.5986042022705078, Accuracy: 0.84375, Computation time: 0.7842631340026855\n",
      "Step: 6628, Loss: 0.2950926423072815, Accuracy: 0.90625, Computation time: 0.7861509323120117\n",
      "Step: 6629, Loss: 0.26945972442626953, Accuracy: 0.90625, Computation time: 1.1312460899353027\n",
      "Step: 6630, Loss: 0.2295973151922226, Accuracy: 0.9375, Computation time: 0.7920031547546387\n",
      "Step: 6631, Loss: 0.5486218929290771, Accuracy: 0.875, Computation time: 0.9930469989776611\n",
      "Step: 6632, Loss: 0.44494113326072693, Accuracy: 0.9375, Computation time: 0.8823049068450928\n",
      "Step: 6633, Loss: 1.1703637838363647, Accuracy: 0.75, Computation time: 1.0388109683990479\n",
      "Step: 6634, Loss: 0.792671263217926, Accuracy: 0.8125, Computation time: 1.2477948665618896\n",
      "Step: 6635, Loss: 0.32070600986480713, Accuracy: 0.9375, Computation time: 0.9052879810333252\n",
      "Step: 6636, Loss: 0.4586108922958374, Accuracy: 0.90625, Computation time: 0.8668889999389648\n",
      "Step: 6637, Loss: 0.675957202911377, Accuracy: 0.8125, Computation time: 1.0239880084991455\n",
      "Step: 6638, Loss: 0.921638548374176, Accuracy: 0.75, Computation time: 0.8973128795623779\n",
      "Step: 6639, Loss: 0.36706283688545227, Accuracy: 0.875, Computation time: 0.9079933166503906\n",
      "Step: 6640, Loss: 0.3658513128757477, Accuracy: 0.90625, Computation time: 0.9611220359802246\n",
      "Step: 6641, Loss: 0.5298789143562317, Accuracy: 0.8125, Computation time: 0.8761060237884521\n",
      "Step: 6642, Loss: 0.29637569189071655, Accuracy: 0.90625, Computation time: 1.0117299556732178\n",
      "Step: 6643, Loss: 0.43136364221572876, Accuracy: 0.875, Computation time: 0.8105149269104004\n",
      "Step: 6644, Loss: 1.0394588708877563, Accuracy: 0.71875, Computation time: 1.1270349025726318\n",
      "Step: 6645, Loss: 0.49983805418014526, Accuracy: 0.8125, Computation time: 0.7765700817108154\n",
      "Step: 6646, Loss: 0.42782336473464966, Accuracy: 0.84375, Computation time: 0.7924349308013916\n",
      "Step: 6647, Loss: 0.4253571331501007, Accuracy: 0.84375, Computation time: 0.7291648387908936\n",
      "Step: 6648, Loss: 0.41931092739105225, Accuracy: 0.8125, Computation time: 0.7595138549804688\n",
      "Step: 6649, Loss: 0.15116989612579346, Accuracy: 0.96875, Computation time: 1.036754846572876\n",
      "Step: 6650, Loss: 0.9147734642028809, Accuracy: 0.71875, Computation time: 0.9965610504150391\n",
      "Step: 6651, Loss: 0.7052067518234253, Accuracy: 0.71875, Computation time: 0.8066997528076172\n",
      "Step: 6652, Loss: 0.4853437542915344, Accuracy: 0.75, Computation time: 0.929448127746582\n",
      "Step: 6653, Loss: 0.25238606333732605, Accuracy: 0.9375, Computation time: 1.0096120834350586\n",
      "Step: 6654, Loss: 0.5488076210021973, Accuracy: 0.875, Computation time: 0.8064761161804199\n",
      "Step: 6655, Loss: 0.5203417539596558, Accuracy: 0.875, Computation time: 0.9477403163909912\n",
      "Step: 6656, Loss: 0.44416335225105286, Accuracy: 0.90625, Computation time: 0.7931408882141113\n",
      "Step: 6657, Loss: 0.5689734816551208, Accuracy: 0.8125, Computation time: 0.8346419334411621\n",
      "Step: 6658, Loss: 1.0935544967651367, Accuracy: 0.78125, Computation time: 0.8476128578186035\n",
      "Step: 6659, Loss: 0.5279262661933899, Accuracy: 0.84375, Computation time: 0.9286048412322998\n",
      "Step: 6660, Loss: 0.2783298194408417, Accuracy: 0.90625, Computation time: 0.9142992496490479\n",
      "Step: 6661, Loss: 0.37433546781539917, Accuracy: 0.875, Computation time: 0.7928719520568848\n",
      "Step: 6662, Loss: 0.24003253877162933, Accuracy: 0.9375, Computation time: 0.8617889881134033\n",
      "Step: 6663, Loss: 0.6059786677360535, Accuracy: 0.84375, Computation time: 0.8286299705505371\n",
      "Step: 6664, Loss: 0.41315746307373047, Accuracy: 0.90625, Computation time: 0.9716920852661133\n",
      "Step: 6665, Loss: 0.46582403779029846, Accuracy: 0.875, Computation time: 0.8977470397949219\n",
      "Step: 6666, Loss: 0.28491300344467163, Accuracy: 0.9375, Computation time: 0.7431049346923828\n",
      "Step: 6667, Loss: 0.3942488729953766, Accuracy: 0.90625, Computation time: 0.7293341159820557\n",
      "Step: 6668, Loss: 0.294377863407135, Accuracy: 0.90625, Computation time: 1.0448520183563232\n",
      "Step: 6669, Loss: 0.14884093403816223, Accuracy: 1.0, Computation time: 0.9481792449951172\n",
      "Step: 6670, Loss: 0.9361201524734497, Accuracy: 0.84375, Computation time: 0.8699502944946289\n",
      "Step: 6671, Loss: 0.43425452709198, Accuracy: 0.8125, Computation time: 0.9935958385467529\n",
      "Step: 6672, Loss: 0.8752238750457764, Accuracy: 0.75, Computation time: 0.8495337963104248\n",
      "Step: 6673, Loss: 0.5363773107528687, Accuracy: 0.8125, Computation time: 1.2074520587921143\n",
      "Step: 6674, Loss: 0.6524490714073181, Accuracy: 0.75, Computation time: 0.7758758068084717\n",
      "Step: 6675, Loss: 0.32498300075531006, Accuracy: 0.875, Computation time: 0.8869929313659668\n",
      "Step: 6676, Loss: 0.37890002131462097, Accuracy: 0.90625, Computation time: 0.8671550750732422\n",
      "Step: 6677, Loss: 0.3360151946544647, Accuracy: 0.90625, Computation time: 0.8404417037963867\n",
      "Step: 6678, Loss: 0.40692126750946045, Accuracy: 0.875, Computation time: 0.8363699913024902\n",
      "Step: 6679, Loss: 0.23823674023151398, Accuracy: 0.9375, Computation time: 0.986461877822876\n",
      "Step: 6680, Loss: 0.45317894220352173, Accuracy: 0.84375, Computation time: 0.9146652221679688\n",
      "Step: 6681, Loss: 0.30792781710624695, Accuracy: 0.96875, Computation time: 0.8635678291320801\n",
      "Step: 6682, Loss: 0.4344249963760376, Accuracy: 0.875, Computation time: 0.9086472988128662\n",
      "Step: 6683, Loss: 0.4150208532810211, Accuracy: 0.8125, Computation time: 1.305866003036499\n",
      "Step: 6684, Loss: 0.3229837417602539, Accuracy: 0.875, Computation time: 0.7202188968658447\n",
      "Step: 6685, Loss: 0.6890427470207214, Accuracy: 0.78125, Computation time: 0.927790641784668\n",
      "Step: 6686, Loss: 1.1945765018463135, Accuracy: 0.5625, Computation time: 1.136497974395752\n",
      "Step: 6687, Loss: 0.4508240520954132, Accuracy: 0.84375, Computation time: 0.8720777034759521\n",
      "Step: 6688, Loss: 0.42304226756095886, Accuracy: 0.875, Computation time: 0.8212289810180664\n",
      "Step: 6689, Loss: 0.4776585102081299, Accuracy: 0.875, Computation time: 0.7542929649353027\n",
      "Step: 6690, Loss: 0.31217509508132935, Accuracy: 0.875, Computation time: 0.9487371444702148\n",
      "Step: 6691, Loss: 0.35200005769729614, Accuracy: 0.9375, Computation time: 1.1777591705322266\n",
      "Step: 6692, Loss: 0.10029815882444382, Accuracy: 1.0, Computation time: 0.8400189876556396\n",
      "Step: 6693, Loss: 0.6445565819740295, Accuracy: 0.84375, Computation time: 0.8880119323730469\n",
      "Step: 6694, Loss: 0.3245033025741577, Accuracy: 0.90625, Computation time: 0.9713242053985596\n",
      "Step: 6695, Loss: 0.4692242741584778, Accuracy: 0.875, Computation time: 0.8827400207519531\n",
      "Step: 6696, Loss: 0.4827231168746948, Accuracy: 0.875, Computation time: 0.8572359085083008\n",
      "Step: 6697, Loss: 0.43625307083129883, Accuracy: 0.84375, Computation time: 1.1106722354888916\n",
      "Step: 6698, Loss: 0.42689335346221924, Accuracy: 0.875, Computation time: 0.7253158092498779\n",
      "Step: 6699, Loss: 0.8798961639404297, Accuracy: 0.8125, Computation time: 0.971527099609375\n",
      "Step: 6700, Loss: 0.3474045395851135, Accuracy: 0.8125, Computation time: 0.8751437664031982\n",
      "Step: 6701, Loss: 0.6702432632446289, Accuracy: 0.84375, Computation time: 0.769460916519165\n",
      "Step: 6702, Loss: 0.21028614044189453, Accuracy: 0.9375, Computation time: 0.8103060722351074\n",
      "Step: 6703, Loss: 0.7329252362251282, Accuracy: 0.78125, Computation time: 1.7021689414978027\n",
      "Step: 6704, Loss: 0.5989368557929993, Accuracy: 0.8125, Computation time: 1.008174180984497\n",
      "Step: 6705, Loss: 0.3171979784965515, Accuracy: 0.875, Computation time: 0.7918820381164551\n",
      "Step: 6706, Loss: 0.36342161893844604, Accuracy: 0.875, Computation time: 0.9443068504333496\n",
      "Step: 6707, Loss: 0.8215135335922241, Accuracy: 0.75, Computation time: 1.0785629749298096\n",
      "Step: 6708, Loss: 0.43688133358955383, Accuracy: 0.84375, Computation time: 0.812870979309082\n",
      "Step: 6709, Loss: 0.3798803985118866, Accuracy: 0.90625, Computation time: 1.0013718605041504\n",
      "Step: 6710, Loss: 0.5276275277137756, Accuracy: 0.8125, Computation time: 0.8412880897521973\n",
      "Step: 6711, Loss: 0.29615581035614014, Accuracy: 0.875, Computation time: 0.9251902103424072\n",
      "Step: 6712, Loss: 0.30507683753967285, Accuracy: 0.875, Computation time: 0.8424849510192871\n",
      "Step: 6713, Loss: 0.28323134779930115, Accuracy: 0.90625, Computation time: 0.793522834777832\n",
      "Step: 6714, Loss: 0.21733272075653076, Accuracy: 0.90625, Computation time: 0.9271759986877441\n",
      "Step: 6715, Loss: 0.4274190068244934, Accuracy: 0.90625, Computation time: 0.9362339973449707\n",
      "Step: 6716, Loss: 0.2054823935031891, Accuracy: 0.9375, Computation time: 0.7744519710540771\n",
      "Step: 6717, Loss: 0.6041104197502136, Accuracy: 0.84375, Computation time: 0.8486356735229492\n",
      "Step: 6718, Loss: 0.41695648431777954, Accuracy: 0.84375, Computation time: 0.7460122108459473\n",
      "Step: 6719, Loss: 0.994101881980896, Accuracy: 0.8125, Computation time: 0.8833978176116943\n",
      "Step: 6720, Loss: 0.24626800417900085, Accuracy: 0.90625, Computation time: 0.8442142009735107\n",
      "Step: 6721, Loss: 0.2250264436006546, Accuracy: 0.90625, Computation time: 0.8895502090454102\n",
      "Step: 6722, Loss: 0.3167622983455658, Accuracy: 0.9375, Computation time: 0.8563902378082275\n",
      "Step: 6723, Loss: 0.41290318965911865, Accuracy: 0.875, Computation time: 0.8986678123474121\n",
      "Step: 6724, Loss: 0.8378597497940063, Accuracy: 0.8125, Computation time: 0.8490700721740723\n",
      "Step: 6725, Loss: 0.6807398796081543, Accuracy: 0.8125, Computation time: 0.9027068614959717\n",
      "Step: 6726, Loss: 0.4511198401451111, Accuracy: 0.90625, Computation time: 0.8703269958496094\n",
      "Step: 6727, Loss: 0.6903539896011353, Accuracy: 0.75, Computation time: 0.9608938694000244\n",
      "Step: 6728, Loss: 0.305835098028183, Accuracy: 0.90625, Computation time: 0.8764522075653076\n",
      "Step: 6729, Loss: 0.6811323165893555, Accuracy: 0.8125, Computation time: 1.1829102039337158\n",
      "Step: 6730, Loss: 0.21943004429340363, Accuracy: 0.9375, Computation time: 0.9805970191955566\n",
      "Step: 6731, Loss: 0.5197504758834839, Accuracy: 0.84375, Computation time: 0.9774258136749268\n",
      "Step: 6732, Loss: 0.4765032231807709, Accuracy: 0.8125, Computation time: 1.9896249771118164\n",
      "Step: 6733, Loss: 0.37923261523246765, Accuracy: 0.875, Computation time: 0.8148822784423828\n",
      "Step: 6734, Loss: 0.564301073551178, Accuracy: 0.78125, Computation time: 0.8193771839141846\n",
      "Step: 6735, Loss: 0.23121973872184753, Accuracy: 0.9375, Computation time: 0.8771834373474121\n",
      "Step: 6736, Loss: 0.4908052980899811, Accuracy: 0.90625, Computation time: 1.174426794052124\n",
      "Step: 6737, Loss: 0.39241233468055725, Accuracy: 0.90625, Computation time: 0.8297410011291504\n",
      "Step: 6738, Loss: 0.5484597682952881, Accuracy: 0.8125, Computation time: 0.9047977924346924\n",
      "Step: 6739, Loss: 0.9827542304992676, Accuracy: 0.65625, Computation time: 0.9637928009033203\n",
      "Step: 6740, Loss: 0.4019582271575928, Accuracy: 0.90625, Computation time: 0.7311840057373047\n",
      "Step: 6741, Loss: 0.38066014647483826, Accuracy: 0.90625, Computation time: 0.8693270683288574\n",
      "Step: 6742, Loss: 0.5362194180488586, Accuracy: 0.8125, Computation time: 0.8788070678710938\n",
      "Step: 6743, Loss: 0.30905917286872864, Accuracy: 0.9375, Computation time: 0.9270660877227783\n",
      "Step: 6744, Loss: 0.36455127596855164, Accuracy: 0.8125, Computation time: 0.8434317111968994\n",
      "Step: 6745, Loss: 0.609682023525238, Accuracy: 0.84375, Computation time: 0.8269779682159424\n",
      "Step: 6746, Loss: 0.24094025790691376, Accuracy: 0.90625, Computation time: 0.8289589881896973\n",
      "Step: 6747, Loss: 0.24463285505771637, Accuracy: 0.96875, Computation time: 0.7935028076171875\n",
      "Step: 6748, Loss: 0.7719873785972595, Accuracy: 0.75, Computation time: 0.8567538261413574\n",
      "Step: 6749, Loss: 0.7001006007194519, Accuracy: 0.8125, Computation time: 0.9014790058135986\n",
      "Step: 6750, Loss: 0.44022125005722046, Accuracy: 0.8125, Computation time: 0.829477071762085\n",
      "Step: 6751, Loss: 0.658705472946167, Accuracy: 0.78125, Computation time: 0.841343879699707\n",
      "Step: 6752, Loss: 0.6816655993461609, Accuracy: 0.84375, Computation time: 0.8253889083862305\n",
      "Step: 6753, Loss: 0.48893463611602783, Accuracy: 0.78125, Computation time: 0.8317689895629883\n",
      "Step: 6754, Loss: 0.38983216881752014, Accuracy: 0.875, Computation time: 0.9796292781829834\n",
      "Step: 6755, Loss: 0.4209443926811218, Accuracy: 0.875, Computation time: 0.9747920036315918\n",
      "Step: 6756, Loss: 0.42128318548202515, Accuracy: 0.875, Computation time: 1.0625309944152832\n",
      "Step: 6757, Loss: 0.5024095773696899, Accuracy: 0.875, Computation time: 0.8068442344665527\n",
      "Step: 6758, Loss: 0.489472895860672, Accuracy: 0.90625, Computation time: 0.8813939094543457\n",
      "Step: 6759, Loss: 0.6828578114509583, Accuracy: 0.75, Computation time: 1.0693261623382568\n",
      "Step: 6760, Loss: 0.38307422399520874, Accuracy: 0.9375, Computation time: 0.7749578952789307\n",
      "Step: 6761, Loss: 0.5876981019973755, Accuracy: 0.8125, Computation time: 0.8851957321166992\n",
      "Step: 6762, Loss: 0.40899762511253357, Accuracy: 0.9375, Computation time: 1.614328145980835\n",
      "Step: 6763, Loss: 0.350187748670578, Accuracy: 0.875, Computation time: 0.8828880786895752\n",
      "Step: 6764, Loss: 0.42312875390052795, Accuracy: 0.84375, Computation time: 0.9091939926147461\n",
      "Step: 6765, Loss: 0.3739476203918457, Accuracy: 0.875, Computation time: 0.9480030536651611\n",
      "Step: 6766, Loss: 0.29105105996131897, Accuracy: 0.875, Computation time: 0.8417620658874512\n",
      "Step: 6767, Loss: 0.48807451128959656, Accuracy: 0.875, Computation time: 0.9917619228363037\n",
      "Step: 6768, Loss: 0.09493595361709595, Accuracy: 1.0, Computation time: 0.858253002166748\n",
      "Step: 6769, Loss: 0.4051664173603058, Accuracy: 0.90625, Computation time: 0.9125871658325195\n",
      "Step: 6770, Loss: 0.6823129653930664, Accuracy: 0.8125, Computation time: 0.8572671413421631\n",
      "Step: 6771, Loss: 0.5695692300796509, Accuracy: 0.8125, Computation time: 0.9507598876953125\n",
      "Step: 6772, Loss: 0.7024925351142883, Accuracy: 0.78125, Computation time: 0.8637712001800537\n",
      "Step: 6773, Loss: 0.6992691159248352, Accuracy: 0.78125, Computation time: 0.8719420433044434\n",
      "Step: 6774, Loss: 0.6680447459220886, Accuracy: 0.75, Computation time: 0.845585823059082\n",
      "Step: 6775, Loss: 0.5433939695358276, Accuracy: 0.84375, Computation time: 0.8057208061218262\n",
      "Step: 6776, Loss: 0.6216542720794678, Accuracy: 0.875, Computation time: 0.7529151439666748\n",
      "Step: 6777, Loss: 0.7296238541603088, Accuracy: 0.8125, Computation time: 0.7624809741973877\n",
      "Step: 6778, Loss: 0.6386552453041077, Accuracy: 0.8125, Computation time: 0.9550220966339111\n",
      "Step: 6779, Loss: 1.1692827939987183, Accuracy: 0.75, Computation time: 0.8111391067504883\n",
      "Step: 6780, Loss: 0.6874558925628662, Accuracy: 0.6875, Computation time: 0.8312349319458008\n",
      "Step: 6781, Loss: 0.615352988243103, Accuracy: 0.8125, Computation time: 0.8272881507873535\n",
      "Step: 6782, Loss: 0.32188230752944946, Accuracy: 0.875, Computation time: 1.1505908966064453\n",
      "Step: 6783, Loss: 0.36209359765052795, Accuracy: 0.90625, Computation time: 0.9339179992675781\n",
      "Step: 6784, Loss: 0.22518427670001984, Accuracy: 0.9375, Computation time: 0.8753159046173096\n",
      "Step: 6785, Loss: 0.5937372446060181, Accuracy: 0.8125, Computation time: 1.2367680072784424\n",
      "Step: 6786, Loss: 0.32024282217025757, Accuracy: 0.84375, Computation time: 0.8525490760803223\n",
      "Step: 6787, Loss: 0.5410564541816711, Accuracy: 0.84375, Computation time: 0.8565101623535156\n",
      "Step: 6788, Loss: 0.21236753463745117, Accuracy: 0.96875, Computation time: 0.8135221004486084\n",
      "Step: 6789, Loss: 0.5294727683067322, Accuracy: 0.78125, Computation time: 0.8620710372924805\n",
      "Step: 6790, Loss: 0.33374860882759094, Accuracy: 0.875, Computation time: 0.9541800022125244\n",
      "Step: 6791, Loss: 0.2820162773132324, Accuracy: 0.875, Computation time: 0.9127349853515625\n",
      "Step: 6792, Loss: 0.692518413066864, Accuracy: 0.78125, Computation time: 1.4961950778961182\n",
      "Step: 6793, Loss: 0.27290382981300354, Accuracy: 0.9375, Computation time: 0.9484407901763916\n",
      "Step: 6794, Loss: 0.46158450841903687, Accuracy: 0.8125, Computation time: 0.6916160583496094\n",
      "Step: 6795, Loss: 0.4521321952342987, Accuracy: 0.84375, Computation time: 0.883476972579956\n",
      "Step: 6796, Loss: 0.36378738284111023, Accuracy: 0.875, Computation time: 0.7741658687591553\n",
      "Step: 6797, Loss: 0.6523243188858032, Accuracy: 0.8125, Computation time: 0.9677438735961914\n",
      "Step: 6798, Loss: 0.2474871128797531, Accuracy: 0.9375, Computation time: 0.7370791435241699\n",
      "Step: 6799, Loss: 0.3448333442211151, Accuracy: 0.875, Computation time: 0.805311918258667\n",
      "Step: 6800, Loss: 0.6346727609634399, Accuracy: 0.84375, Computation time: 0.8361930847167969\n",
      "Step: 6801, Loss: 0.5475704073905945, Accuracy: 0.78125, Computation time: 0.8427047729492188\n",
      "Step: 6802, Loss: 0.47249406576156616, Accuracy: 0.875, Computation time: 0.7950851917266846\n",
      "Step: 6803, Loss: 0.47645485401153564, Accuracy: 0.84375, Computation time: 0.978405237197876\n",
      "Step: 6804, Loss: 0.2987438440322876, Accuracy: 0.96875, Computation time: 0.9201798439025879\n",
      "Step: 6805, Loss: 0.36009112000465393, Accuracy: 0.875, Computation time: 0.943688154220581\n",
      "Step: 6806, Loss: 0.65691739320755, Accuracy: 0.8125, Computation time: 0.7311718463897705\n",
      "Step: 6807, Loss: 1.1727937459945679, Accuracy: 0.65625, Computation time: 0.8011949062347412\n",
      "Step: 6808, Loss: 0.6273150444030762, Accuracy: 0.8125, Computation time: 0.8002622127532959\n",
      "Step: 6809, Loss: 0.4954622685909271, Accuracy: 0.84375, Computation time: 1.0561981201171875\n",
      "Step: 6810, Loss: 0.3812900185585022, Accuracy: 0.90625, Computation time: 1.1002559661865234\n",
      "Step: 6811, Loss: 0.6404812335968018, Accuracy: 0.84375, Computation time: 0.8403849601745605\n",
      "Step: 6812, Loss: 0.40462690591812134, Accuracy: 0.90625, Computation time: 0.8347949981689453\n",
      "Step: 6813, Loss: 0.37506794929504395, Accuracy: 0.875, Computation time: 0.824146032333374\n",
      "Step: 6814, Loss: 0.1979171186685562, Accuracy: 0.96875, Computation time: 0.9529869556427002\n",
      "Step: 6815, Loss: 0.4898596405982971, Accuracy: 0.875, Computation time: 0.9497458934783936\n",
      "Step: 6816, Loss: 0.49228766560554504, Accuracy: 0.84375, Computation time: 0.988867998123169\n",
      "Step: 6817, Loss: 0.34327805042266846, Accuracy: 0.90625, Computation time: 0.7764012813568115\n",
      "Step: 6818, Loss: 0.572895348072052, Accuracy: 0.84375, Computation time: 1.0368058681488037\n",
      "Step: 6819, Loss: 0.4393641948699951, Accuracy: 0.875, Computation time: 0.7604029178619385\n",
      "Step: 6820, Loss: 0.8681203722953796, Accuracy: 0.75, Computation time: 0.7673652172088623\n",
      "Step: 6821, Loss: 0.3883141875267029, Accuracy: 0.875, Computation time: 0.979423999786377\n",
      "Step: 6822, Loss: 0.5675094723701477, Accuracy: 0.75, Computation time: 2.098518133163452\n",
      "Step: 6823, Loss: 0.4787846505641937, Accuracy: 0.84375, Computation time: 0.8582248687744141\n",
      "Step: 6824, Loss: 0.35026073455810547, Accuracy: 0.90625, Computation time: 0.7726588249206543\n",
      "Step: 6825, Loss: 0.4977014660835266, Accuracy: 0.84375, Computation time: 0.7819252014160156\n",
      "Step: 6826, Loss: 0.2744903862476349, Accuracy: 0.875, Computation time: 0.7217180728912354\n",
      "Step: 6827, Loss: 0.14894619584083557, Accuracy: 0.96875, Computation time: 1.004060983657837\n",
      "Step: 6828, Loss: 0.9280341267585754, Accuracy: 0.75, Computation time: 0.9000098705291748\n",
      "Step: 6829, Loss: 0.5568721294403076, Accuracy: 0.8125, Computation time: 0.819256067276001\n",
      "Step: 6830, Loss: 0.6218388080596924, Accuracy: 0.875, Computation time: 0.7857909202575684\n",
      "Step: 6831, Loss: 0.612837016582489, Accuracy: 0.84375, Computation time: 1.657555103302002\n",
      "Step: 6832, Loss: 0.3066549003124237, Accuracy: 0.90625, Computation time: 0.7349979877471924\n",
      "Step: 6833, Loss: 0.27478522062301636, Accuracy: 0.9375, Computation time: 0.8330621719360352\n",
      "Step: 6834, Loss: 0.45133116841316223, Accuracy: 0.875, Computation time: 0.7872231006622314\n",
      "Step: 6835, Loss: 0.814396321773529, Accuracy: 0.8125, Computation time: 0.867455005645752\n",
      "Step: 6836, Loss: 0.2765433192253113, Accuracy: 0.90625, Computation time: 0.8208599090576172\n",
      "Step: 6837, Loss: 0.3796214163303375, Accuracy: 0.875, Computation time: 0.7662222385406494\n",
      "Step: 6838, Loss: 0.6000202298164368, Accuracy: 0.875, Computation time: 0.8220908641815186\n",
      "Step: 6839, Loss: 0.7659742832183838, Accuracy: 0.8125, Computation time: 0.9527232646942139\n",
      "Step: 6840, Loss: 0.2789815366268158, Accuracy: 0.90625, Computation time: 0.824678897857666\n",
      "Step: 6841, Loss: 0.2611023187637329, Accuracy: 0.90625, Computation time: 0.8732481002807617\n",
      "Step: 6842, Loss: 0.8857381939888, Accuracy: 0.78125, Computation time: 1.3783161640167236\n",
      "Step: 6843, Loss: 0.24659934639930725, Accuracy: 0.9375, Computation time: 0.9151887893676758\n",
      "Step: 6844, Loss: 0.4586627781391144, Accuracy: 0.84375, Computation time: 0.8976080417633057\n",
      "Step: 6845, Loss: 0.1795952320098877, Accuracy: 0.9375, Computation time: 0.990119218826294\n",
      "Step: 6846, Loss: 0.6028404831886292, Accuracy: 0.84375, Computation time: 0.8389570713043213\n",
      "Step: 6847, Loss: 0.3992170989513397, Accuracy: 0.875, Computation time: 0.9096128940582275\n",
      "Step: 6848, Loss: 0.5200248956680298, Accuracy: 0.8125, Computation time: 1.0726661682128906\n",
      "Step: 6849, Loss: 0.3546481132507324, Accuracy: 0.90625, Computation time: 0.8668270111083984\n",
      "Step: 6850, Loss: 0.33767154812812805, Accuracy: 0.8125, Computation time: 0.7859430313110352\n",
      "Step: 6851, Loss: 0.4106370210647583, Accuracy: 0.84375, Computation time: 1.4064610004425049\n",
      "Step: 6852, Loss: 0.7814340591430664, Accuracy: 0.78125, Computation time: 0.7772772312164307\n",
      "Step: 6853, Loss: 0.6285120844841003, Accuracy: 0.6875, Computation time: 0.9769442081451416\n",
      "Step: 6854, Loss: 0.7770549058914185, Accuracy: 0.78125, Computation time: 0.8184881210327148\n",
      "Step: 6855, Loss: 0.6387976408004761, Accuracy: 0.78125, Computation time: 0.8329780101776123\n",
      "Step: 6856, Loss: 0.2699791193008423, Accuracy: 0.84375, Computation time: 0.779932975769043\n",
      "Step: 6857, Loss: 0.2480107545852661, Accuracy: 0.90625, Computation time: 0.6722853183746338\n",
      "Step: 6858, Loss: 0.2022639662027359, Accuracy: 0.9375, Computation time: 1.0003888607025146\n",
      "Step: 6859, Loss: 0.6330267190933228, Accuracy: 0.84375, Computation time: 0.7976479530334473\n",
      "Step: 6860, Loss: 0.553057074546814, Accuracy: 0.84375, Computation time: 0.7548058032989502\n",
      "Step: 6861, Loss: 0.32704123854637146, Accuracy: 0.90625, Computation time: 0.8516871929168701\n",
      "Step: 6862, Loss: 0.23637616634368896, Accuracy: 0.9375, Computation time: 0.995344877243042\n",
      "Step: 6863, Loss: 0.7871339917182922, Accuracy: 0.71875, Computation time: 0.8928120136260986\n",
      "Step: 6864, Loss: 0.6765800714492798, Accuracy: 0.75, Computation time: 0.7611649036407471\n",
      "Step: 6865, Loss: 0.26843032240867615, Accuracy: 0.9375, Computation time: 0.9319460391998291\n",
      "Step: 6866, Loss: 0.38332003355026245, Accuracy: 0.84375, Computation time: 0.761631965637207\n",
      "Step: 6867, Loss: 0.15870033204555511, Accuracy: 0.9375, Computation time: 0.8085899353027344\n",
      "Step: 6868, Loss: 0.44915416836738586, Accuracy: 0.875, Computation time: 0.799163818359375\n",
      "Step: 6869, Loss: 0.4642602205276489, Accuracy: 0.90625, Computation time: 0.961400032043457\n",
      "Step: 6870, Loss: 0.42965832352638245, Accuracy: 0.875, Computation time: 0.8673999309539795\n",
      "Step: 6871, Loss: 0.2901093065738678, Accuracy: 0.90625, Computation time: 0.7064402103424072\n",
      "Step: 6872, Loss: 0.2684452533721924, Accuracy: 0.9375, Computation time: 0.7409830093383789\n",
      "Step: 6873, Loss: 0.679135799407959, Accuracy: 0.78125, Computation time: 0.8928780555725098\n",
      "Step: 6874, Loss: 0.2200484424829483, Accuracy: 0.9375, Computation time: 0.7888498306274414\n",
      "Step: 6875, Loss: 0.19910484552383423, Accuracy: 0.96875, Computation time: 0.8997890949249268\n",
      "Step: 6876, Loss: 0.19037781655788422, Accuracy: 0.9375, Computation time: 1.0412359237670898\n",
      "Step: 6877, Loss: 0.1988592892885208, Accuracy: 0.96875, Computation time: 0.873725175857544\n",
      "Step: 6878, Loss: 0.39641231298446655, Accuracy: 0.875, Computation time: 0.8582417964935303\n",
      "Step: 6879, Loss: 0.34565749764442444, Accuracy: 0.90625, Computation time: 0.7781839370727539\n",
      "Step: 6880, Loss: 0.570476770401001, Accuracy: 0.8125, Computation time: 0.8203859329223633\n",
      "Step: 6881, Loss: 0.29443806409835815, Accuracy: 0.875, Computation time: 0.9225239753723145\n",
      "Step: 6882, Loss: 0.7373462915420532, Accuracy: 0.875, Computation time: 1.7224559783935547\n",
      "Step: 6883, Loss: 0.47204455733299255, Accuracy: 0.8125, Computation time: 0.8340108394622803\n",
      "Step: 6884, Loss: 0.6020992398262024, Accuracy: 0.8125, Computation time: 0.916301965713501\n",
      "Step: 6885, Loss: 0.4868195950984955, Accuracy: 0.875, Computation time: 0.8961117267608643\n",
      "Step: 6886, Loss: 0.39709386229515076, Accuracy: 0.84375, Computation time: 1.1814289093017578\n",
      "Step: 6887, Loss: 0.20077648758888245, Accuracy: 0.9375, Computation time: 0.8406212329864502\n",
      "Step: 6888, Loss: 0.28914764523506165, Accuracy: 0.90625, Computation time: 0.9034669399261475\n",
      "Step: 6889, Loss: 0.4932251572608948, Accuracy: 0.875, Computation time: 1.1150450706481934\n",
      "Step: 6890, Loss: 0.31931018829345703, Accuracy: 0.875, Computation time: 0.8464951515197754\n",
      "Step: 6891, Loss: 0.4574420154094696, Accuracy: 0.875, Computation time: 0.8112728595733643\n",
      "Step: 6892, Loss: 0.2731218636035919, Accuracy: 0.9375, Computation time: 0.8410649299621582\n",
      "Step: 6893, Loss: 0.6021909117698669, Accuracy: 0.78125, Computation time: 0.7836501598358154\n",
      "Step: 6894, Loss: 0.3289412260055542, Accuracy: 0.90625, Computation time: 1.890498161315918\n",
      "Step: 6895, Loss: 0.9328962564468384, Accuracy: 0.6875, Computation time: 0.887253999710083\n",
      "Step: 6896, Loss: 0.6528131365776062, Accuracy: 0.75, Computation time: 0.8972647190093994\n",
      "Step: 6897, Loss: 0.5028468370437622, Accuracy: 0.8125, Computation time: 0.9093658924102783\n",
      "Step: 6898, Loss: 0.48018455505371094, Accuracy: 0.8125, Computation time: 0.808978796005249\n",
      "Step: 6899, Loss: 0.3437019884586334, Accuracy: 0.84375, Computation time: 0.7987101078033447\n",
      "Step: 6900, Loss: 0.5365667939186096, Accuracy: 0.84375, Computation time: 0.8717010021209717\n",
      "Step: 6901, Loss: 0.46327245235443115, Accuracy: 0.84375, Computation time: 0.8824210166931152\n",
      "Step: 6902, Loss: 0.546858549118042, Accuracy: 0.78125, Computation time: 0.7914671897888184\n",
      "Step: 6903, Loss: 0.5944890379905701, Accuracy: 0.8125, Computation time: 0.8174300193786621\n",
      "Step: 6904, Loss: 0.23853079974651337, Accuracy: 0.9375, Computation time: 0.9388301372528076\n",
      "Step: 6905, Loss: 0.8765310049057007, Accuracy: 0.84375, Computation time: 0.7914621829986572\n",
      "Step: 6906, Loss: 0.5192976593971252, Accuracy: 0.84375, Computation time: 0.9713451862335205\n",
      "Step: 6907, Loss: 1.07285737991333, Accuracy: 0.65625, Computation time: 0.8891048431396484\n",
      "Step: 6908, Loss: 0.44171157479286194, Accuracy: 0.90625, Computation time: 1.0187139511108398\n",
      "Step: 6909, Loss: 0.720658004283905, Accuracy: 0.78125, Computation time: 1.348379135131836\n",
      "Step: 6910, Loss: 0.4051431119441986, Accuracy: 0.90625, Computation time: 0.7047348022460938\n",
      "Step: 6911, Loss: 0.6913382411003113, Accuracy: 0.84375, Computation time: 1.4156107902526855\n",
      "Step: 6912, Loss: 0.5965926051139832, Accuracy: 0.78125, Computation time: 1.0918431282043457\n",
      "Step: 6913, Loss: 0.3925556540489197, Accuracy: 0.875, Computation time: 0.8784399032592773\n",
      "Step: 6914, Loss: 0.3845325708389282, Accuracy: 0.90625, Computation time: 1.0423498153686523\n",
      "Step: 6915, Loss: 0.8704489469528198, Accuracy: 0.8125, Computation time: 0.7510011196136475\n",
      "Step: 6916, Loss: 0.5665529370307922, Accuracy: 0.8125, Computation time: 0.9065062999725342\n",
      "Step: 6917, Loss: 0.12155209481716156, Accuracy: 1.0, Computation time: 0.8451111316680908\n",
      "Step: 6918, Loss: 0.23241613805294037, Accuracy: 0.90625, Computation time: 0.8666961193084717\n",
      "Step: 6919, Loss: 0.5691840648651123, Accuracy: 0.84375, Computation time: 0.7277050018310547\n",
      "Step: 6920, Loss: 0.3864523768424988, Accuracy: 0.9375, Computation time: 0.8099539279937744\n",
      "Step: 6921, Loss: 0.23201806843280792, Accuracy: 0.90625, Computation time: 0.888390064239502\n",
      "Step: 6922, Loss: 0.5295069813728333, Accuracy: 0.875, Computation time: 0.8186430931091309\n",
      "Step: 6923, Loss: 0.346052885055542, Accuracy: 0.875, Computation time: 0.9769878387451172\n",
      "Step: 6924, Loss: 0.2850673496723175, Accuracy: 0.9375, Computation time: 0.9466338157653809\n",
      "Step: 6925, Loss: 0.256716787815094, Accuracy: 0.9375, Computation time: 0.978039026260376\n",
      "Step: 6926, Loss: 0.6870095133781433, Accuracy: 0.75, Computation time: 0.7219369411468506\n",
      "Step: 6927, Loss: 0.5138050317764282, Accuracy: 0.8125, Computation time: 0.9227261543273926\n",
      "Step: 6928, Loss: 0.5733989477157593, Accuracy: 0.8125, Computation time: 0.9254357814788818\n",
      "Step: 6929, Loss: 0.2605946362018585, Accuracy: 0.9375, Computation time: 0.9973876476287842\n",
      "Step: 6930, Loss: 0.42545440793037415, Accuracy: 0.90625, Computation time: 1.074342966079712\n",
      "Step: 6931, Loss: 0.12035026401281357, Accuracy: 0.96875, Computation time: 0.8314080238342285\n",
      "Step: 6932, Loss: 0.6116021275520325, Accuracy: 0.78125, Computation time: 0.9069759845733643\n",
      "Step: 6933, Loss: 0.5258207321166992, Accuracy: 0.84375, Computation time: 0.7854568958282471\n",
      "Step: 6934, Loss: 0.36282432079315186, Accuracy: 0.90625, Computation time: 0.997410774230957\n",
      "Step: 6935, Loss: 0.4064987003803253, Accuracy: 0.8125, Computation time: 0.763991117477417\n",
      "Step: 6936, Loss: 0.4964158535003662, Accuracy: 0.875, Computation time: 0.7453088760375977\n",
      "Step: 6937, Loss: 0.7372217178344727, Accuracy: 0.78125, Computation time: 0.9761919975280762\n",
      "Step: 6938, Loss: 0.27834752202033997, Accuracy: 0.9375, Computation time: 1.1097850799560547\n",
      "Step: 6939, Loss: 0.9237433075904846, Accuracy: 0.84375, Computation time: 0.8889939785003662\n",
      "Step: 6940, Loss: 0.2861423194408417, Accuracy: 0.875, Computation time: 0.8956611156463623\n",
      "Step: 6941, Loss: 0.2699395418167114, Accuracy: 0.9375, Computation time: 1.195685863494873\n",
      "Step: 6942, Loss: 0.7612922787666321, Accuracy: 0.8125, Computation time: 0.8258159160614014\n",
      "Step: 6943, Loss: 0.2560783922672272, Accuracy: 0.9375, Computation time: 0.7878241539001465\n",
      "Step: 6944, Loss: 0.49103111028671265, Accuracy: 0.8125, Computation time: 0.9748530387878418\n",
      "Step: 6945, Loss: 0.2445237934589386, Accuracy: 0.90625, Computation time: 0.7482109069824219\n",
      "Step: 6946, Loss: 0.2669256925582886, Accuracy: 0.875, Computation time: 0.9128360748291016\n",
      "Step: 6947, Loss: 0.9925886988639832, Accuracy: 0.75, Computation time: 0.9369099140167236\n",
      "Step: 6948, Loss: 0.23136121034622192, Accuracy: 0.9375, Computation time: 0.9798998832702637\n",
      "Step: 6949, Loss: 0.5208514928817749, Accuracy: 0.90625, Computation time: 0.9294970035552979\n",
      "Step: 6950, Loss: 0.46751868724823, Accuracy: 0.875, Computation time: 0.8662240505218506\n",
      "Step: 6951, Loss: 0.4264132082462311, Accuracy: 0.8125, Computation time: 0.8214068412780762\n",
      "Step: 6952, Loss: 0.6490015983581543, Accuracy: 0.75, Computation time: 0.8753111362457275\n",
      "Step: 6953, Loss: 0.3039551377296448, Accuracy: 0.90625, Computation time: 0.8527770042419434\n",
      "Step: 6954, Loss: 0.5608499050140381, Accuracy: 0.84375, Computation time: 0.752640962600708\n",
      "Step: 6955, Loss: 0.2710723280906677, Accuracy: 0.90625, Computation time: 0.9889593124389648\n",
      "Step: 6956, Loss: 0.15448446571826935, Accuracy: 1.0, Computation time: 0.7361960411071777\n",
      "Step: 6957, Loss: 0.49287813901901245, Accuracy: 0.8125, Computation time: 0.9537389278411865\n",
      "Step: 6958, Loss: 0.4285805821418762, Accuracy: 0.875, Computation time: 0.8041641712188721\n",
      "Step: 6959, Loss: 0.8218780159950256, Accuracy: 0.84375, Computation time: 0.7741870880126953\n",
      "Step: 6960, Loss: 0.45527973771095276, Accuracy: 0.875, Computation time: 0.9637100696563721\n",
      "Step: 6961, Loss: 0.8824771046638489, Accuracy: 0.6875, Computation time: 0.8928167819976807\n",
      "Step: 6962, Loss: 0.42003801465034485, Accuracy: 0.90625, Computation time: 0.8010749816894531\n",
      "Step: 6963, Loss: 0.5968001484870911, Accuracy: 0.84375, Computation time: 0.8033220767974854\n",
      "Step: 6964, Loss: 0.3969084322452545, Accuracy: 0.90625, Computation time: 0.923490047454834\n",
      "Step: 6965, Loss: 0.44434213638305664, Accuracy: 0.875, Computation time: 0.6784577369689941\n",
      "Step: 6966, Loss: 0.29032477736473083, Accuracy: 0.90625, Computation time: 0.7407050132751465\n",
      "Step: 6967, Loss: 0.665116548538208, Accuracy: 0.75, Computation time: 0.8921070098876953\n",
      "Step: 6968, Loss: 0.32375118136405945, Accuracy: 0.875, Computation time: 0.9101638793945312\n",
      "Step: 6969, Loss: 0.8714547157287598, Accuracy: 0.71875, Computation time: 0.7899470329284668\n",
      "Step: 6970, Loss: 0.33819815516471863, Accuracy: 0.875, Computation time: 0.7243137359619141\n",
      "Step: 6971, Loss: 0.727732241153717, Accuracy: 0.75, Computation time: 0.8639950752258301\n",
      "Step: 6972, Loss: 0.49971845746040344, Accuracy: 0.8125, Computation time: 1.231921911239624\n",
      "Step: 6973, Loss: 0.7057382464408875, Accuracy: 0.875, Computation time: 0.788743257522583\n",
      "Step: 6974, Loss: 0.7312734723091125, Accuracy: 0.71875, Computation time: 0.9183108806610107\n",
      "Step: 6975, Loss: 0.43266168236732483, Accuracy: 0.84375, Computation time: 0.9170489311218262\n",
      "Step: 6976, Loss: 0.44242197275161743, Accuracy: 0.875, Computation time: 0.8143339157104492\n",
      "Step: 6977, Loss: 0.5284735560417175, Accuracy: 0.78125, Computation time: 0.8243198394775391\n",
      "Step: 6978, Loss: 0.636721670627594, Accuracy: 0.875, Computation time: 0.6323511600494385\n",
      "Step: 6979, Loss: 0.4685942530632019, Accuracy: 0.90625, Computation time: 0.76078200340271\n",
      "Step: 6980, Loss: 0.5116574764251709, Accuracy: 0.8125, Computation time: 0.7191739082336426\n",
      "Step: 6981, Loss: 0.3485110104084015, Accuracy: 0.875, Computation time: 0.868847131729126\n",
      "Step: 6982, Loss: 0.4416861832141876, Accuracy: 0.875, Computation time: 0.8263659477233887\n",
      "Step: 6983, Loss: 0.4327683746814728, Accuracy: 0.90625, Computation time: 0.9685487747192383\n",
      "Step: 6984, Loss: 0.3015245497226715, Accuracy: 0.875, Computation time: 0.8523960113525391\n",
      "Step: 6985, Loss: 0.6270041465759277, Accuracy: 0.78125, Computation time: 0.8373732566833496\n",
      "Step: 6986, Loss: 0.4133332669734955, Accuracy: 0.90625, Computation time: 0.8600819110870361\n",
      "Step: 6987, Loss: 0.5794575810432434, Accuracy: 0.78125, Computation time: 0.8275249004364014\n",
      "Step: 6988, Loss: 0.7639201283454895, Accuracy: 0.78125, Computation time: 1.9715640544891357\n",
      "Step: 6989, Loss: 0.45602545142173767, Accuracy: 0.875, Computation time: 0.8059799671173096\n",
      "Step: 6990, Loss: 0.3015371263027191, Accuracy: 0.90625, Computation time: 0.7972121238708496\n",
      "Step: 6991, Loss: 0.5395883321762085, Accuracy: 0.8125, Computation time: 0.9550809860229492\n",
      "Step: 6992, Loss: 0.6439491510391235, Accuracy: 0.84375, Computation time: 0.7666549682617188\n",
      "Step: 6993, Loss: 0.342552125453949, Accuracy: 0.90625, Computation time: 0.8217978477478027\n",
      "Step: 6994, Loss: 0.3248823583126068, Accuracy: 0.875, Computation time: 0.7460870742797852\n",
      "Step: 6995, Loss: 0.5116139054298401, Accuracy: 0.8125, Computation time: 0.7830462455749512\n",
      "Step: 6996, Loss: 0.5402196049690247, Accuracy: 0.875, Computation time: 0.9309890270233154\n",
      "Step: 6997, Loss: 0.6242709755897522, Accuracy: 0.875, Computation time: 0.8998138904571533\n",
      "Step: 6998, Loss: 0.5296860933303833, Accuracy: 0.9375, Computation time: 0.8494851589202881\n",
      "Step: 6999, Loss: 0.6617022752761841, Accuracy: 0.8125, Computation time: 0.7871520519256592\n",
      "Step: 7000, Loss: 0.6639947295188904, Accuracy: 0.84375, Computation time: 0.8182830810546875\n",
      "Step: 7001, Loss: 0.9395570158958435, Accuracy: 0.78125, Computation time: 1.052366018295288\n",
      "Step: 7002, Loss: 0.14395368099212646, Accuracy: 0.96875, Computation time: 1.1019330024719238\n",
      "Step: 7003, Loss: 0.3714435398578644, Accuracy: 0.875, Computation time: 1.7585699558258057\n",
      "Step: 7004, Loss: 0.7227094173431396, Accuracy: 0.78125, Computation time: 0.7276811599731445\n",
      "Step: 7005, Loss: 0.7111433744430542, Accuracy: 0.8125, Computation time: 0.966149091720581\n",
      "Step: 7006, Loss: 0.41587305068969727, Accuracy: 0.875, Computation time: 0.8250963687896729\n",
      "Step: 7007, Loss: 0.7053059935569763, Accuracy: 0.78125, Computation time: 0.9505138397216797\n",
      "Step: 7008, Loss: 0.567960798740387, Accuracy: 0.875, Computation time: 1.1248791217803955\n",
      "Step: 7009, Loss: 0.6400233507156372, Accuracy: 0.875, Computation time: 1.3935728073120117\n",
      "Step: 7010, Loss: 0.489542692899704, Accuracy: 0.8125, Computation time: 0.9383659362792969\n",
      "Step: 7011, Loss: 0.23311454057693481, Accuracy: 0.9375, Computation time: 0.862666130065918\n",
      "Step: 7012, Loss: 0.38282546401023865, Accuracy: 0.9375, Computation time: 0.917119026184082\n",
      "Step: 7013, Loss: 0.44457682967185974, Accuracy: 0.84375, Computation time: 0.8653337955474854\n",
      "Step: 7014, Loss: 0.5391814708709717, Accuracy: 0.84375, Computation time: 0.8918609619140625\n",
      "Step: 7015, Loss: 0.3907732665538788, Accuracy: 0.9375, Computation time: 0.7771480083465576\n",
      "Step: 7016, Loss: 0.6332653760910034, Accuracy: 0.78125, Computation time: 0.9216880798339844\n",
      "Step: 7017, Loss: 0.8799245953559875, Accuracy: 0.75, Computation time: 0.8431589603424072\n",
      "Step: 7018, Loss: 0.6025975942611694, Accuracy: 0.78125, Computation time: 0.8297460079193115\n",
      "Step: 7019, Loss: 0.6010098457336426, Accuracy: 0.875, Computation time: 0.8698809146881104\n",
      "Step: 7020, Loss: 0.18848344683647156, Accuracy: 0.96875, Computation time: 0.7650232315063477\n",
      "Step: 7021, Loss: 0.6315023899078369, Accuracy: 0.90625, Computation time: 0.7706208229064941\n",
      "Step: 7022, Loss: 0.8808072805404663, Accuracy: 0.78125, Computation time: 0.8358631134033203\n",
      "Step: 7023, Loss: 0.255455881357193, Accuracy: 0.875, Computation time: 0.7176342010498047\n",
      "Step: 7024, Loss: 0.15862321853637695, Accuracy: 0.96875, Computation time: 0.8140816688537598\n",
      "Step: 7025, Loss: 0.5673245191574097, Accuracy: 0.78125, Computation time: 0.8992030620574951\n",
      "Step: 7026, Loss: 0.3551582396030426, Accuracy: 0.875, Computation time: 0.7121937274932861\n",
      "Step: 7027, Loss: 0.2752929627895355, Accuracy: 0.9375, Computation time: 1.0880591869354248\n",
      "Step: 7028, Loss: 0.5406753420829773, Accuracy: 0.78125, Computation time: 0.7172541618347168\n",
      "Step: 7029, Loss: 0.5492256283760071, Accuracy: 0.84375, Computation time: 0.6987719535827637\n",
      "Step: 7030, Loss: 0.4161106050014496, Accuracy: 0.90625, Computation time: 1.0056629180908203\n",
      "Step: 7031, Loss: 0.5124808549880981, Accuracy: 0.84375, Computation time: 0.9123659133911133\n",
      "Step: 7032, Loss: 0.8342359662055969, Accuracy: 0.78125, Computation time: 0.9037530422210693\n",
      "Step: 7033, Loss: 0.4460263252258301, Accuracy: 0.78125, Computation time: 1.5192408561706543\n",
      "Step: 7034, Loss: 0.2589232623577118, Accuracy: 0.9375, Computation time: 0.9390418529510498\n",
      "Step: 7035, Loss: 0.3286476135253906, Accuracy: 0.875, Computation time: 0.8742520809173584\n",
      "Step: 7036, Loss: 0.47749435901641846, Accuracy: 0.84375, Computation time: 1.028562068939209\n",
      "Step: 7037, Loss: 0.38865146040916443, Accuracy: 0.8125, Computation time: 0.8053619861602783\n",
      "Step: 7038, Loss: 0.9614109992980957, Accuracy: 0.78125, Computation time: 0.7881529331207275\n",
      "Step: 7039, Loss: 0.4939751625061035, Accuracy: 0.84375, Computation time: 0.8080120086669922\n",
      "Step: 7040, Loss: 0.9866781830787659, Accuracy: 0.78125, Computation time: 0.9449789524078369\n",
      "Step: 7041, Loss: 0.4073193371295929, Accuracy: 0.875, Computation time: 0.7136189937591553\n",
      "Step: 7042, Loss: 0.39252978563308716, Accuracy: 0.9375, Computation time: 0.8555448055267334\n",
      "Step: 7043, Loss: 0.5037140846252441, Accuracy: 0.875, Computation time: 0.80277419090271\n",
      "Step: 7044, Loss: 0.7285543084144592, Accuracy: 0.78125, Computation time: 0.9432587623596191\n",
      "Step: 7045, Loss: 0.2833128869533539, Accuracy: 0.90625, Computation time: 0.7568767070770264\n",
      "Step: 7046, Loss: 0.3748783767223358, Accuracy: 0.90625, Computation time: 0.9906597137451172\n",
      "Step: 7047, Loss: 0.5745000243186951, Accuracy: 0.875, Computation time: 0.7660129070281982\n",
      "Step: 7048, Loss: 0.19905926287174225, Accuracy: 0.96875, Computation time: 0.898859977722168\n",
      "Step: 7049, Loss: 0.3764604330062866, Accuracy: 0.875, Computation time: 0.8771741390228271\n",
      "Step: 7050, Loss: 0.2717309296131134, Accuracy: 0.90625, Computation time: 1.026033878326416\n",
      "Step: 7051, Loss: 0.4542789161205292, Accuracy: 0.8125, Computation time: 0.8947122097015381\n",
      "Step: 7052, Loss: 0.6842472553253174, Accuracy: 0.875, Computation time: 0.8407480716705322\n",
      "Step: 7053, Loss: 0.28066328167915344, Accuracy: 0.9375, Computation time: 0.7600009441375732\n",
      "Step: 7054, Loss: 0.6574437618255615, Accuracy: 0.78125, Computation time: 0.8492691516876221\n",
      "Step: 7055, Loss: 0.6429337859153748, Accuracy: 0.8125, Computation time: 0.827584981918335\n",
      "Step: 7056, Loss: 0.11963163316249847, Accuracy: 0.96875, Computation time: 0.8251791000366211\n",
      "Step: 7057, Loss: 0.4457774758338928, Accuracy: 0.84375, Computation time: 0.8108787536621094\n",
      "Step: 7058, Loss: 0.3054482340812683, Accuracy: 0.90625, Computation time: 0.910834789276123\n",
      "Step: 7059, Loss: 0.47487056255340576, Accuracy: 0.84375, Computation time: 0.7440688610076904\n",
      "Step: 7060, Loss: 0.17073026299476624, Accuracy: 0.96875, Computation time: 0.896909236907959\n",
      "Step: 7061, Loss: 0.33891281485557556, Accuracy: 0.9375, Computation time: 0.8841729164123535\n",
      "Step: 7062, Loss: 0.9694051146507263, Accuracy: 0.6875, Computation time: 0.7177369594573975\n",
      "Step: 7063, Loss: 0.27620261907577515, Accuracy: 0.90625, Computation time: 0.7641291618347168\n",
      "Step: 7064, Loss: 0.1761254519224167, Accuracy: 0.96875, Computation time: 1.771134853363037\n",
      "Step: 7065, Loss: 0.5964843034744263, Accuracy: 0.875, Computation time: 0.8449862003326416\n",
      "Step: 7066, Loss: 0.547335147857666, Accuracy: 0.8125, Computation time: 0.9115078449249268\n",
      "Step: 7067, Loss: 0.473649263381958, Accuracy: 0.78125, Computation time: 1.075005054473877\n",
      "Step: 7068, Loss: 0.1420348584651947, Accuracy: 0.96875, Computation time: 1.0752902030944824\n",
      "Step: 7069, Loss: 0.432663232088089, Accuracy: 0.875, Computation time: 0.8266041278839111\n",
      "Step: 7070, Loss: 0.9951829314231873, Accuracy: 0.78125, Computation time: 0.9813032150268555\n",
      "Step: 7071, Loss: 0.6810892224311829, Accuracy: 0.84375, Computation time: 1.0044090747833252\n",
      "Step: 7072, Loss: 0.32727697491645813, Accuracy: 0.9375, Computation time: 0.9082319736480713\n",
      "Step: 7073, Loss: 0.33911052346229553, Accuracy: 0.84375, Computation time: 0.9111659526824951\n",
      "Step: 7074, Loss: 0.1893405020236969, Accuracy: 0.9375, Computation time: 0.7778818607330322\n",
      "Step: 7075, Loss: 0.29479390382766724, Accuracy: 0.84375, Computation time: 0.7798478603363037\n",
      "Step: 7076, Loss: 0.2445286512374878, Accuracy: 0.90625, Computation time: 0.7356810569763184\n",
      "Step: 7077, Loss: 0.25941967964172363, Accuracy: 0.9375, Computation time: 0.9816451072692871\n",
      "Step: 7078, Loss: 0.2250632643699646, Accuracy: 0.875, Computation time: 0.8116049766540527\n",
      "Step: 7079, Loss: 0.40305474400520325, Accuracy: 0.90625, Computation time: 0.9227640628814697\n",
      "Step: 7080, Loss: 0.4960620105266571, Accuracy: 0.84375, Computation time: 0.8447072505950928\n",
      "Step: 7081, Loss: 0.39330387115478516, Accuracy: 0.875, Computation time: 0.8934869766235352\n",
      "Step: 7082, Loss: 0.48793625831604004, Accuracy: 0.84375, Computation time: 0.8013858795166016\n",
      "Step: 7083, Loss: 0.3973890542984009, Accuracy: 0.875, Computation time: 0.8731040954589844\n",
      "Step: 7084, Loss: 0.3154238760471344, Accuracy: 0.90625, Computation time: 0.8244688510894775\n",
      "Step: 7085, Loss: 0.7754107713699341, Accuracy: 0.75, Computation time: 1.1230990886688232\n",
      "Step: 7086, Loss: 0.2117326408624649, Accuracy: 0.96875, Computation time: 0.7250752449035645\n",
      "Step: 7087, Loss: 0.24104949831962585, Accuracy: 0.9375, Computation time: 0.7622027397155762\n",
      "Step: 7088, Loss: 0.26253193616867065, Accuracy: 0.90625, Computation time: 0.8692770004272461\n",
      "Step: 7089, Loss: 0.2963014245033264, Accuracy: 0.9375, Computation time: 0.8030471801757812\n",
      "Step: 7090, Loss: 0.43281036615371704, Accuracy: 0.875, Computation time: 0.7713460922241211\n",
      "Step: 7091, Loss: 0.3058905601501465, Accuracy: 0.90625, Computation time: 1.059926986694336\n",
      "Step: 7092, Loss: 0.6151790022850037, Accuracy: 0.84375, Computation time: 1.0557708740234375\n",
      "Step: 7093, Loss: 0.48427483439445496, Accuracy: 0.84375, Computation time: 0.7033748626708984\n",
      "Step: 7094, Loss: 0.3348236680030823, Accuracy: 0.9375, Computation time: 1.9095532894134521\n",
      "Step: 7095, Loss: 0.4421217441558838, Accuracy: 0.78125, Computation time: 0.7784581184387207\n",
      "Step: 7096, Loss: 0.3344515562057495, Accuracy: 0.90625, Computation time: 0.8894917964935303\n",
      "Step: 7097, Loss: 0.16071976721286774, Accuracy: 0.9375, Computation time: 0.9023809432983398\n",
      "Step: 7098, Loss: 0.44106972217559814, Accuracy: 0.84375, Computation time: 0.9040341377258301\n",
      "Step: 7099, Loss: 0.7874482870101929, Accuracy: 0.6875, Computation time: 0.8591160774230957\n",
      "Step: 7100, Loss: 0.491103857755661, Accuracy: 0.8125, Computation time: 0.917356014251709\n",
      "Step: 7101, Loss: 0.24496851861476898, Accuracy: 0.90625, Computation time: 0.9202430248260498\n",
      "Step: 7102, Loss: 0.6471893191337585, Accuracy: 0.8125, Computation time: 0.7700858116149902\n",
      "Step: 7103, Loss: 0.6219775676727295, Accuracy: 0.84375, Computation time: 1.1573760509490967\n",
      "Step: 7104, Loss: 0.3304469585418701, Accuracy: 0.875, Computation time: 0.9795730113983154\n",
      "Step: 7105, Loss: 0.45566606521606445, Accuracy: 0.90625, Computation time: 0.9583139419555664\n",
      "Step: 7106, Loss: 0.4128565192222595, Accuracy: 0.875, Computation time: 0.8162789344787598\n",
      "Step: 7107, Loss: 0.6335712671279907, Accuracy: 0.84375, Computation time: 0.8250479698181152\n",
      "Step: 7108, Loss: 0.47570130228996277, Accuracy: 0.84375, Computation time: 0.8487401008605957\n",
      "Step: 7109, Loss: 0.41254371404647827, Accuracy: 0.90625, Computation time: 15.175100088119507\n",
      "Step: 7110, Loss: 0.7130411267280579, Accuracy: 0.78125, Computation time: 0.9756252765655518\n",
      "Step: 7111, Loss: 0.29964277148246765, Accuracy: 0.9375, Computation time: 0.7990589141845703\n",
      "Step: 7112, Loss: 0.19789372384548187, Accuracy: 0.90625, Computation time: 1.0017249584197998\n",
      "Step: 7113, Loss: 0.2948299050331116, Accuracy: 0.84375, Computation time: 0.8206660747528076\n",
      "Step: 7114, Loss: 0.33763962984085083, Accuracy: 0.9375, Computation time: 0.7553229331970215\n",
      "Step: 7115, Loss: 0.3680134117603302, Accuracy: 0.90625, Computation time: 0.8953690528869629\n",
      "Step: 7116, Loss: 0.39735332131385803, Accuracy: 0.84375, Computation time: 0.8467409610748291\n",
      "Step: 7117, Loss: 0.42833980917930603, Accuracy: 0.875, Computation time: 0.8018701076507568\n",
      "Step: 7118, Loss: 0.3459416925907135, Accuracy: 0.90625, Computation time: 1.376905918121338\n",
      "Step: 7119, Loss: 0.5350874662399292, Accuracy: 0.8125, Computation time: 0.8797099590301514\n",
      "Step: 7120, Loss: 0.2806166708469391, Accuracy: 0.90625, Computation time: 1.0915629863739014\n",
      "Step: 7121, Loss: 0.3755178153514862, Accuracy: 0.875, Computation time: 0.7767601013183594\n",
      "Step: 7122, Loss: 0.21711046993732452, Accuracy: 0.9375, Computation time: 1.5706419944763184\n",
      "Step: 7123, Loss: 0.3500842750072479, Accuracy: 0.90625, Computation time: 0.9318101406097412\n",
      "Step: 7124, Loss: 0.32548901438713074, Accuracy: 0.875, Computation time: 0.8500139713287354\n",
      "Step: 7125, Loss: 0.5726822018623352, Accuracy: 0.90625, Computation time: 0.8371028900146484\n",
      "Step: 7126, Loss: 0.5553918480873108, Accuracy: 0.84375, Computation time: 0.7732532024383545\n",
      "Step: 7127, Loss: 0.5320289731025696, Accuracy: 0.84375, Computation time: 0.9132018089294434\n",
      "Step: 7128, Loss: 0.5335982441902161, Accuracy: 0.875, Computation time: 0.9283230304718018\n",
      "Step: 7129, Loss: 0.2603606879711151, Accuracy: 0.875, Computation time: 0.8142096996307373\n",
      "Step: 7130, Loss: 0.27008381485939026, Accuracy: 0.96875, Computation time: 0.754115104675293\n",
      "Step: 7131, Loss: 0.6126669645309448, Accuracy: 0.8125, Computation time: 1.0262110233306885\n",
      "Step: 7132, Loss: 0.5129995942115784, Accuracy: 0.84375, Computation time: 0.8292570114135742\n",
      "Step: 7133, Loss: 0.2621474266052246, Accuracy: 0.90625, Computation time: 0.9188451766967773\n",
      "Step: 7134, Loss: 0.44155439734458923, Accuracy: 0.8125, Computation time: 0.8249280452728271\n",
      "Step: 7135, Loss: 0.5193926095962524, Accuracy: 0.78125, Computation time: 0.88344407081604\n",
      "Step: 7136, Loss: 0.4343605041503906, Accuracy: 0.875, Computation time: 0.9399669170379639\n",
      "Step: 7137, Loss: 0.23999035358428955, Accuracy: 0.96875, Computation time: 0.7206668853759766\n",
      "Step: 7138, Loss: 0.49086064100265503, Accuracy: 0.96875, Computation time: 0.9408471584320068\n",
      "Step: 7139, Loss: 0.3934606909751892, Accuracy: 0.8125, Computation time: 0.877108097076416\n",
      "Step: 7140, Loss: 0.4466797709465027, Accuracy: 0.875, Computation time: 0.8276278972625732\n",
      "Step: 7141, Loss: 0.37864741683006287, Accuracy: 0.8125, Computation time: 0.9359920024871826\n",
      "Step: 7142, Loss: 0.3750781714916229, Accuracy: 0.84375, Computation time: 0.9872539043426514\n",
      "Step: 7143, Loss: 0.3723224103450775, Accuracy: 0.875, Computation time: 0.8118629455566406\n",
      "Step: 7144, Loss: 0.24263794720172882, Accuracy: 0.875, Computation time: 0.9553482532501221\n",
      "Step: 7145, Loss: 0.6946218609809875, Accuracy: 0.6875, Computation time: 0.8417508602142334\n",
      "Step: 7146, Loss: 0.12028475850820541, Accuracy: 0.96875, Computation time: 0.6626911163330078\n",
      "Step: 7147, Loss: 0.5989010334014893, Accuracy: 0.84375, Computation time: 0.8297469615936279\n",
      "Step: 7148, Loss: 0.47779157757759094, Accuracy: 0.84375, Computation time: 0.8024420738220215\n",
      "Step: 7149, Loss: 0.5382230281829834, Accuracy: 0.84375, Computation time: 0.7262668609619141\n",
      "Step: 7150, Loss: 0.24018095433712006, Accuracy: 0.9375, Computation time: 0.8606069087982178\n",
      "Step: 7151, Loss: 0.30249670147895813, Accuracy: 0.9375, Computation time: 0.7173089981079102\n",
      "Step: 7152, Loss: 0.11529622226953506, Accuracy: 0.96875, Computation time: 0.7866840362548828\n",
      "Step: 7153, Loss: 0.21065464615821838, Accuracy: 0.9375, Computation time: 1.4929630756378174\n",
      "Step: 7154, Loss: 0.4862561523914337, Accuracy: 0.84375, Computation time: 0.8784439563751221\n",
      "Step: 7155, Loss: 0.6021872162818909, Accuracy: 0.75, Computation time: 1.0092780590057373\n",
      "Step: 7156, Loss: 0.5515194535255432, Accuracy: 0.84375, Computation time: 0.7875099182128906\n",
      "Step: 7157, Loss: 0.17436939477920532, Accuracy: 0.9375, Computation time: 0.8510558605194092\n",
      "Step: 7158, Loss: 0.3594333231449127, Accuracy: 0.9375, Computation time: 1.066174030303955\n",
      "Step: 7159, Loss: 0.4228285849094391, Accuracy: 0.875, Computation time: 0.8971409797668457\n",
      "Step: 7160, Loss: 0.4717528223991394, Accuracy: 0.84375, Computation time: 0.9127249717712402\n",
      "Step: 7161, Loss: 0.4500676691532135, Accuracy: 0.84375, Computation time: 0.8151030540466309\n",
      "Step: 7162, Loss: 0.43511903285980225, Accuracy: 0.875, Computation time: 0.8596999645233154\n",
      "Step: 7163, Loss: 0.4323000907897949, Accuracy: 0.90625, Computation time: 0.8583390712738037\n",
      "Step: 7164, Loss: 0.36303386092185974, Accuracy: 0.875, Computation time: 0.9665992259979248\n",
      "Step: 7165, Loss: 0.18581195175647736, Accuracy: 0.96875, Computation time: 0.9934039115905762\n",
      "Step: 7166, Loss: 0.6964259743690491, Accuracy: 0.90625, Computation time: 1.5836138725280762\n",
      "Step: 7167, Loss: 0.20410628616809845, Accuracy: 0.96875, Computation time: 0.8790531158447266\n",
      "Step: 7168, Loss: 0.16159527003765106, Accuracy: 0.9375, Computation time: 0.8389508724212646\n",
      "Step: 7169, Loss: 0.4340004026889801, Accuracy: 0.84375, Computation time: 0.959622859954834\n",
      "Step: 7170, Loss: 0.421802282333374, Accuracy: 0.90625, Computation time: 0.9662089347839355\n",
      "Step: 7171, Loss: 0.31543034315109253, Accuracy: 0.90625, Computation time: 1.2537450790405273\n",
      "Step: 7172, Loss: 0.1981545388698578, Accuracy: 0.9375, Computation time: 0.9926488399505615\n",
      "Step: 7173, Loss: 0.5723835825920105, Accuracy: 0.78125, Computation time: 0.8031148910522461\n",
      "Step: 7174, Loss: 0.35894957184791565, Accuracy: 0.90625, Computation time: 0.9696493148803711\n",
      "Step: 7175, Loss: 0.2945719063282013, Accuracy: 0.9375, Computation time: 1.053189992904663\n",
      "Step: 7176, Loss: 0.4349678158760071, Accuracy: 0.84375, Computation time: 0.9109592437744141\n",
      "Step: 7177, Loss: 0.40244928002357483, Accuracy: 0.84375, Computation time: 0.8508181571960449\n",
      "Step: 7178, Loss: 0.3972747325897217, Accuracy: 0.84375, Computation time: 1.032057762145996\n",
      "Step: 7179, Loss: 0.3937065303325653, Accuracy: 0.875, Computation time: 0.8730411529541016\n",
      "Step: 7180, Loss: 0.19438087940216064, Accuracy: 0.96875, Computation time: 0.9517600536346436\n",
      "Step: 7181, Loss: 0.40487876534461975, Accuracy: 0.875, Computation time: 0.7729887962341309\n",
      "Step: 7182, Loss: 0.9226877689361572, Accuracy: 0.6875, Computation time: 0.8018739223480225\n",
      "Step: 7183, Loss: 0.4319251477718353, Accuracy: 0.90625, Computation time: 0.8423678874969482\n",
      "Step: 7184, Loss: 0.3703364431858063, Accuracy: 0.875, Computation time: 0.7526741027832031\n",
      "Step: 7185, Loss: 0.439810186624527, Accuracy: 0.8125, Computation time: 0.8198997974395752\n",
      "Step: 7186, Loss: 0.3741873502731323, Accuracy: 0.90625, Computation time: 0.9700078964233398\n",
      "Step: 7187, Loss: 0.25745344161987305, Accuracy: 0.9375, Computation time: 0.8005728721618652\n",
      "Step: 7188, Loss: 0.42467889189720154, Accuracy: 0.8125, Computation time: 1.0195231437683105\n",
      "Step: 7189, Loss: 0.5228092074394226, Accuracy: 0.84375, Computation time: 0.7869479656219482\n",
      "Step: 7190, Loss: 0.8718970417976379, Accuracy: 0.75, Computation time: 0.8436620235443115\n",
      "Step: 7191, Loss: 0.3391340672969818, Accuracy: 0.875, Computation time: 0.9704740047454834\n",
      "Step: 7192, Loss: 0.6922261714935303, Accuracy: 0.84375, Computation time: 0.9130780696868896\n",
      "Step: 7193, Loss: 0.3624889850616455, Accuracy: 0.875, Computation time: 0.720984935760498\n",
      "Step: 7194, Loss: 0.35390493273735046, Accuracy: 0.84375, Computation time: 0.8225741386413574\n",
      "Step: 7195, Loss: 0.45700380206108093, Accuracy: 0.78125, Computation time: 0.8594467639923096\n",
      "Step: 7196, Loss: 0.25970035791397095, Accuracy: 0.875, Computation time: 1.120408058166504\n",
      "Step: 7197, Loss: 0.4518703818321228, Accuracy: 0.875, Computation time: 0.9677567481994629\n",
      "Step: 7198, Loss: 0.529467761516571, Accuracy: 0.75, Computation time: 0.7856769561767578\n",
      "Step: 7199, Loss: 0.8116398453712463, Accuracy: 0.75, Computation time: 0.8813519477844238\n",
      "Step: 7200, Loss: 0.3185258209705353, Accuracy: 0.875, Computation time: 0.928962230682373\n",
      "Step: 7201, Loss: 0.4021761119365692, Accuracy: 0.875, Computation time: 0.8616917133331299\n",
      "Step: 7202, Loss: 0.6068203449249268, Accuracy: 0.84375, Computation time: 0.9861230850219727\n",
      "Step: 7203, Loss: 0.41925734281539917, Accuracy: 0.875, Computation time: 0.8739321231842041\n",
      "Step: 7204, Loss: 0.4956105351448059, Accuracy: 0.90625, Computation time: 0.8237531185150146\n",
      "Step: 7205, Loss: 0.5889253616333008, Accuracy: 0.875, Computation time: 0.75901198387146\n",
      "Step: 7206, Loss: 0.798916757106781, Accuracy: 0.71875, Computation time: 0.9276919364929199\n",
      "Step: 7207, Loss: 0.21509060263633728, Accuracy: 0.9375, Computation time: 0.9428272247314453\n",
      "Step: 7208, Loss: 0.47543081641197205, Accuracy: 0.8125, Computation time: 1.2770390510559082\n",
      "Step: 7209, Loss: 0.4772490859031677, Accuracy: 0.84375, Computation time: 0.705531120300293\n",
      "Step: 7210, Loss: 0.4091688096523285, Accuracy: 0.875, Computation time: 0.7972249984741211\n",
      "Step: 7211, Loss: 0.9794946312904358, Accuracy: 0.71875, Computation time: 0.8056919574737549\n",
      "Step: 7212, Loss: 0.3191503584384918, Accuracy: 0.9375, Computation time: 1.436018943786621\n",
      "Step: 7213, Loss: 0.2733815908432007, Accuracy: 0.9375, Computation time: 0.8415839672088623\n",
      "Step: 7214, Loss: 0.47093650698661804, Accuracy: 0.8125, Computation time: 0.9653201103210449\n",
      "Step: 7215, Loss: 0.4169212877750397, Accuracy: 0.90625, Computation time: 0.9501781463623047\n",
      "Step: 7216, Loss: 0.640480101108551, Accuracy: 0.84375, Computation time: 0.7687971591949463\n",
      "Step: 7217, Loss: 0.5366727113723755, Accuracy: 0.84375, Computation time: 1.060027837753296\n",
      "Step: 7218, Loss: 0.9058039784431458, Accuracy: 0.8125, Computation time: 1.0150668621063232\n",
      "Step: 7219, Loss: 0.7474578619003296, Accuracy: 0.8125, Computation time: 0.9581501483917236\n",
      "Step: 7220, Loss: 0.7114055156707764, Accuracy: 0.75, Computation time: 0.868887186050415\n",
      "Step: 7221, Loss: 0.7514212727546692, Accuracy: 0.84375, Computation time: 1.0363781452178955\n",
      "Step: 7222, Loss: 0.3398683965206146, Accuracy: 0.84375, Computation time: 0.8860440254211426\n",
      "Step: 7223, Loss: 0.6258472204208374, Accuracy: 0.78125, Computation time: 0.9285681247711182\n",
      "Step: 7224, Loss: 0.5539207458496094, Accuracy: 0.84375, Computation time: 0.7802503108978271\n",
      "Step: 7225, Loss: 0.2571084797382355, Accuracy: 0.875, Computation time: 0.8627722263336182\n",
      "Step: 7226, Loss: 0.34637027978897095, Accuracy: 0.9375, Computation time: 0.8605771064758301\n",
      "Step: 7227, Loss: 0.37926480174064636, Accuracy: 0.8125, Computation time: 0.7758693695068359\n",
      "Step: 7228, Loss: 0.2014595866203308, Accuracy: 0.90625, Computation time: 0.7831737995147705\n",
      "Step: 7229, Loss: 0.3850812017917633, Accuracy: 0.875, Computation time: 0.8198730945587158\n",
      "Step: 7230, Loss: 0.47352278232574463, Accuracy: 0.875, Computation time: 0.9756453037261963\n",
      "Step: 7231, Loss: 0.3706628978252411, Accuracy: 0.90625, Computation time: 0.8442471027374268\n",
      "Step: 7232, Loss: 0.3018980920314789, Accuracy: 0.90625, Computation time: 0.9808647632598877\n",
      "Step: 7233, Loss: 0.4483984708786011, Accuracy: 0.84375, Computation time: 0.9096393585205078\n",
      "Step: 7234, Loss: 0.517988383769989, Accuracy: 0.8125, Computation time: 0.8054158687591553\n",
      "Step: 7235, Loss: 0.7028077244758606, Accuracy: 0.78125, Computation time: 0.7706818580627441\n",
      "Step: 7236, Loss: 0.5591912865638733, Accuracy: 0.8125, Computation time: 0.8669593334197998\n",
      "Step: 7237, Loss: 0.39678332209587097, Accuracy: 0.875, Computation time: 0.8803951740264893\n",
      "Step: 7238, Loss: 0.5333418846130371, Accuracy: 0.84375, Computation time: 0.9318850040435791\n",
      "Step: 7239, Loss: 0.3574666380882263, Accuracy: 0.9375, Computation time: 0.9368109703063965\n",
      "Step: 7240, Loss: 0.7102148532867432, Accuracy: 0.84375, Computation time: 1.0444459915161133\n",
      "Step: 7241, Loss: 0.5325800180435181, Accuracy: 0.8125, Computation time: 0.8381199836730957\n",
      "Step: 7242, Loss: 0.3286619484424591, Accuracy: 0.90625, Computation time: 0.9792060852050781\n",
      "Step: 7243, Loss: 0.443408340215683, Accuracy: 0.875, Computation time: 0.782214879989624\n",
      "Step: 7244, Loss: 0.4350571036338806, Accuracy: 0.875, Computation time: 0.8262829780578613\n",
      "Step: 7245, Loss: 0.565727710723877, Accuracy: 0.8125, Computation time: 0.7430939674377441\n",
      "Step: 7246, Loss: 0.3245660960674286, Accuracy: 0.875, Computation time: 0.9591679573059082\n",
      "Step: 7247, Loss: 0.2604455351829529, Accuracy: 0.90625, Computation time: 0.99996018409729\n",
      "Step: 7248, Loss: 0.4883084297180176, Accuracy: 0.875, Computation time: 0.722435712814331\n",
      "Step: 7249, Loss: 0.4707343876361847, Accuracy: 0.8125, Computation time: 1.267076015472412\n",
      "Step: 7250, Loss: 0.7447769641876221, Accuracy: 0.8125, Computation time: 0.9111330509185791\n",
      "Step: 7251, Loss: 0.24736088514328003, Accuracy: 0.9375, Computation time: 0.7761857509613037\n",
      "Step: 7252, Loss: 0.5260778665542603, Accuracy: 0.84375, Computation time: 0.8845241069793701\n",
      "Step: 7253, Loss: 0.1919810026884079, Accuracy: 0.96875, Computation time: 0.7867832183837891\n",
      "Step: 7254, Loss: 0.1677667647600174, Accuracy: 0.96875, Computation time: 0.7754747867584229\n",
      "Step: 7255, Loss: 0.5601935982704163, Accuracy: 0.8125, Computation time: 0.8960540294647217\n",
      "Step: 7256, Loss: 0.2747737765312195, Accuracy: 0.875, Computation time: 1.0702130794525146\n",
      "Step: 7257, Loss: 0.619764506816864, Accuracy: 0.84375, Computation time: 0.9108688831329346\n",
      "Step: 7258, Loss: 0.23120637238025665, Accuracy: 0.90625, Computation time: 0.8136298656463623\n",
      "Step: 7259, Loss: 0.5313538312911987, Accuracy: 0.78125, Computation time: 1.0807998180389404\n",
      "Step: 7260, Loss: 0.39582744240760803, Accuracy: 0.84375, Computation time: 0.9008388519287109\n",
      "Step: 7261, Loss: 0.21462444961071014, Accuracy: 0.9375, Computation time: 0.805556058883667\n",
      "Step: 7262, Loss: 0.4779696464538574, Accuracy: 0.8125, Computation time: 1.0988678932189941\n",
      "Step: 7263, Loss: 0.15966016054153442, Accuracy: 0.96875, Computation time: 0.778867244720459\n",
      "Step: 7264, Loss: 0.4171396493911743, Accuracy: 0.875, Computation time: 0.8491477966308594\n",
      "Step: 7265, Loss: 0.5032169222831726, Accuracy: 0.90625, Computation time: 1.1284329891204834\n",
      "Step: 7266, Loss: 0.34401148557662964, Accuracy: 0.90625, Computation time: 0.8378109931945801\n",
      "Step: 7267, Loss: 0.7690609693527222, Accuracy: 0.8125, Computation time: 1.117976188659668\n",
      "Step: 7268, Loss: 0.3675589859485626, Accuracy: 0.84375, Computation time: 0.8772249221801758\n",
      "Step: 7269, Loss: 0.601674497127533, Accuracy: 0.75, Computation time: 0.8618240356445312\n",
      "Step: 7270, Loss: 0.566866397857666, Accuracy: 0.875, Computation time: 1.0568978786468506\n",
      "Step: 7271, Loss: 0.7821090817451477, Accuracy: 0.71875, Computation time: 1.147312879562378\n",
      "Step: 7272, Loss: 0.3400377333164215, Accuracy: 0.90625, Computation time: 0.8434512615203857\n",
      "Step: 7273, Loss: 0.3881627023220062, Accuracy: 0.875, Computation time: 0.8918251991271973\n",
      "Step: 7274, Loss: 0.3774496614933014, Accuracy: 0.90625, Computation time: 0.7701592445373535\n",
      "Step: 7275, Loss: 0.16959460079669952, Accuracy: 0.9375, Computation time: 0.7636520862579346\n",
      "Step: 7276, Loss: 0.23462723195552826, Accuracy: 0.9375, Computation time: 0.7530031204223633\n",
      "Step: 7277, Loss: 0.471515029668808, Accuracy: 0.90625, Computation time: 0.8694460391998291\n",
      "Step: 7278, Loss: 0.5204327702522278, Accuracy: 0.84375, Computation time: 1.1883487701416016\n",
      "Step: 7279, Loss: 0.2799762189388275, Accuracy: 0.9375, Computation time: 0.8399543762207031\n",
      "Step: 7280, Loss: 0.4143899083137512, Accuracy: 0.875, Computation time: 0.9496068954467773\n",
      "Step: 7281, Loss: 0.4353536367416382, Accuracy: 0.875, Computation time: 0.7157940864562988\n",
      "Step: 7282, Loss: 0.19572967290878296, Accuracy: 0.9375, Computation time: 1.0677402019500732\n",
      "Step: 7283, Loss: 0.4971659779548645, Accuracy: 0.8125, Computation time: 0.9302630424499512\n",
      "Step: 7284, Loss: 0.403760701417923, Accuracy: 0.84375, Computation time: 0.8584690093994141\n",
      "Step: 7285, Loss: 0.3165844976902008, Accuracy: 0.875, Computation time: 0.7234981060028076\n",
      "Step: 7286, Loss: 0.7794199585914612, Accuracy: 0.71875, Computation time: 0.8381350040435791\n",
      "Step: 7287, Loss: 0.6665124297142029, Accuracy: 0.84375, Computation time: 0.9423012733459473\n",
      "Step: 7288, Loss: 0.3386439085006714, Accuracy: 0.84375, Computation time: 0.8735408782958984\n",
      "Step: 7289, Loss: 0.5372315645217896, Accuracy: 0.8125, Computation time: 0.7105560302734375\n",
      "Step: 7290, Loss: 0.4829455614089966, Accuracy: 0.875, Computation time: 0.8945598602294922\n",
      "Step: 7291, Loss: 0.266257107257843, Accuracy: 0.875, Computation time: 0.9685981273651123\n",
      "Step: 7292, Loss: 0.4449043869972229, Accuracy: 0.84375, Computation time: 0.6803040504455566\n",
      "Step: 7293, Loss: 0.5965694189071655, Accuracy: 0.84375, Computation time: 0.7485461235046387\n",
      "Step: 7294, Loss: 0.3391976058483124, Accuracy: 0.9375, Computation time: 0.9265737533569336\n",
      "Step: 7295, Loss: 0.6368513107299805, Accuracy: 0.78125, Computation time: 1.0046820640563965\n",
      "Step: 7296, Loss: 0.4073368310928345, Accuracy: 0.875, Computation time: 0.933718204498291\n",
      "Step: 7297, Loss: 0.47534656524658203, Accuracy: 0.84375, Computation time: 0.9790451526641846\n",
      "Step: 7298, Loss: 0.8267377018928528, Accuracy: 0.65625, Computation time: 0.8703508377075195\n",
      "Step: 7299, Loss: 0.2521268129348755, Accuracy: 0.875, Computation time: 0.9492819309234619\n",
      "Step: 7300, Loss: 0.29188933968544006, Accuracy: 0.8125, Computation time: 0.8473138809204102\n",
      "Step: 7301, Loss: 0.32221707701683044, Accuracy: 0.90625, Computation time: 0.8840639591217041\n",
      "Step: 7302, Loss: 0.8504145741462708, Accuracy: 0.78125, Computation time: 0.833730936050415\n",
      "Step: 7303, Loss: 0.3148171603679657, Accuracy: 0.90625, Computation time: 0.8348491191864014\n",
      "Step: 7304, Loss: 0.38092368841171265, Accuracy: 0.875, Computation time: 1.1145308017730713\n",
      "Step: 7305, Loss: 0.563511073589325, Accuracy: 0.84375, Computation time: 0.8231487274169922\n",
      "Step: 7306, Loss: 0.42545461654663086, Accuracy: 0.875, Computation time: 1.1026082038879395\n",
      "Step: 7307, Loss: 0.417946457862854, Accuracy: 0.84375, Computation time: 0.8716390132904053\n",
      "Step: 7308, Loss: 0.4495321810245514, Accuracy: 0.78125, Computation time: 0.8162457942962646\n",
      "Step: 7309, Loss: 0.31847083568573, Accuracy: 0.9375, Computation time: 0.7497909069061279\n",
      "Step: 7310, Loss: 0.20337912440299988, Accuracy: 0.9375, Computation time: 1.0565969944000244\n",
      "Step: 7311, Loss: 0.37336015701293945, Accuracy: 0.96875, Computation time: 0.9485549926757812\n",
      "Step: 7312, Loss: 0.3850542902946472, Accuracy: 0.875, Computation time: 1.0904872417449951\n",
      "Step: 7313, Loss: 0.12080632150173187, Accuracy: 1.0, Computation time: 0.8402152061462402\n",
      "Step: 7314, Loss: 0.4323684573173523, Accuracy: 0.875, Computation time: 0.9652800559997559\n",
      "Step: 7315, Loss: 0.45318734645843506, Accuracy: 0.84375, Computation time: 0.8605830669403076\n",
      "Step: 7316, Loss: 0.39963987469673157, Accuracy: 0.875, Computation time: 0.9687991142272949\n",
      "Step: 7317, Loss: 1.1205343008041382, Accuracy: 0.8125, Computation time: 0.788679838180542\n",
      "Step: 7318, Loss: 0.6141383647918701, Accuracy: 0.84375, Computation time: 0.9623889923095703\n",
      "Step: 7319, Loss: 0.5204963684082031, Accuracy: 0.90625, Computation time: 0.963763952255249\n",
      "Step: 7320, Loss: 0.5333086252212524, Accuracy: 0.90625, Computation time: 1.0143351554870605\n",
      "Step: 7321, Loss: 0.47932276129722595, Accuracy: 0.78125, Computation time: 0.8480489253997803\n",
      "Step: 7322, Loss: 0.5012221932411194, Accuracy: 0.90625, Computation time: 0.991117000579834\n",
      "Step: 7323, Loss: 0.383862167596817, Accuracy: 0.84375, Computation time: 0.9406349658966064\n",
      "Step: 7324, Loss: 0.25955358147621155, Accuracy: 0.90625, Computation time: 0.7777650356292725\n",
      "Step: 7325, Loss: 0.4631580412387848, Accuracy: 0.90625, Computation time: 0.930222749710083\n",
      "Step: 7326, Loss: 0.2862703800201416, Accuracy: 0.9375, Computation time: 0.7916450500488281\n",
      "Step: 7327, Loss: 0.509141206741333, Accuracy: 0.84375, Computation time: 0.9637410640716553\n",
      "Step: 7328, Loss: 0.6872701048851013, Accuracy: 0.78125, Computation time: 0.9761831760406494\n",
      "Step: 7329, Loss: 0.1905093938112259, Accuracy: 0.96875, Computation time: 0.9286508560180664\n",
      "Step: 7330, Loss: 0.7346256971359253, Accuracy: 0.75, Computation time: 0.7949059009552002\n",
      "Step: 7331, Loss: 0.5773864388465881, Accuracy: 0.875, Computation time: 1.6637749671936035\n",
      "Step: 7332, Loss: 0.5555118918418884, Accuracy: 0.84375, Computation time: 0.9934220314025879\n",
      "Step: 7333, Loss: 0.1357686072587967, Accuracy: 1.0, Computation time: 0.9675989151000977\n",
      "Step: 7334, Loss: 0.36856937408447266, Accuracy: 0.875, Computation time: 0.7042098045349121\n",
      "Step: 7335, Loss: 0.40532127022743225, Accuracy: 0.84375, Computation time: 0.9683060646057129\n",
      "Step: 7336, Loss: 0.22401946783065796, Accuracy: 0.9375, Computation time: 0.926663875579834\n",
      "Step: 7337, Loss: 0.2310590296983719, Accuracy: 0.9375, Computation time: 0.9715471267700195\n",
      "Step: 7338, Loss: 0.2370574176311493, Accuracy: 0.96875, Computation time: 0.8405001163482666\n",
      "Step: 7339, Loss: 0.706366240978241, Accuracy: 0.78125, Computation time: 0.7449429035186768\n",
      "Step: 7340, Loss: 0.640350878238678, Accuracy: 0.8125, Computation time: 0.9491381645202637\n",
      "Step: 7341, Loss: 0.11038976162672043, Accuracy: 0.96875, Computation time: 0.818518877029419\n",
      "Step: 7342, Loss: 0.15952709317207336, Accuracy: 0.96875, Computation time: 0.9958150386810303\n",
      "Step: 7343, Loss: 0.46612548828125, Accuracy: 0.84375, Computation time: 0.8783581256866455\n",
      "Step: 7344, Loss: 0.26007282733917236, Accuracy: 0.9375, Computation time: 0.8782069683074951\n",
      "Step: 7345, Loss: 0.30189260840415955, Accuracy: 0.875, Computation time: 0.8595521450042725\n",
      "Step: 7346, Loss: 0.3196451663970947, Accuracy: 0.90625, Computation time: 1.0750017166137695\n",
      "Step: 7347, Loss: 0.4398227035999298, Accuracy: 0.84375, Computation time: 0.7765250205993652\n",
      "Step: 7348, Loss: 0.2475583702325821, Accuracy: 0.9375, Computation time: 0.8366649150848389\n",
      "Step: 7349, Loss: 0.5458360910415649, Accuracy: 0.84375, Computation time: 0.9297399520874023\n",
      "Step: 7350, Loss: 0.6273223161697388, Accuracy: 0.8125, Computation time: 0.8906190395355225\n",
      "Step: 7351, Loss: 0.3312346041202545, Accuracy: 0.875, Computation time: 0.8107059001922607\n",
      "Step: 7352, Loss: 0.4978846311569214, Accuracy: 0.78125, Computation time: 0.7737140655517578\n",
      "Step: 7353, Loss: 0.3799284100532532, Accuracy: 0.875, Computation time: 0.8997890949249268\n",
      "Step: 7354, Loss: 0.300690233707428, Accuracy: 0.875, Computation time: 0.8368520736694336\n",
      "Step: 7355, Loss: 0.45564258098602295, Accuracy: 0.875, Computation time: 0.7583260536193848\n",
      "Step: 7356, Loss: 0.44837403297424316, Accuracy: 0.84375, Computation time: 0.8630108833312988\n",
      "Step: 7357, Loss: 0.4712371528148651, Accuracy: 0.875, Computation time: 0.8796029090881348\n",
      "Step: 7358, Loss: 0.3093748688697815, Accuracy: 0.9375, Computation time: 0.9371180534362793\n",
      "Step: 7359, Loss: 0.5940160155296326, Accuracy: 0.8125, Computation time: 0.9187710285186768\n",
      "Step: 7360, Loss: 0.29586806893348694, Accuracy: 0.90625, Computation time: 0.8706908226013184\n",
      "Step: 7361, Loss: 0.7585802674293518, Accuracy: 0.65625, Computation time: 1.6621980667114258\n",
      "Step: 7362, Loss: 0.6431294083595276, Accuracy: 0.8125, Computation time: 0.8683180809020996\n",
      "Step: 7363, Loss: 0.6663928031921387, Accuracy: 0.78125, Computation time: 0.9020349979400635\n",
      "Step: 7364, Loss: 0.6458129286766052, Accuracy: 0.78125, Computation time: 0.8420732021331787\n",
      "Step: 7365, Loss: 0.3050687313079834, Accuracy: 0.96875, Computation time: 0.9029059410095215\n",
      "Step: 7366, Loss: 0.38252392411231995, Accuracy: 0.84375, Computation time: 0.8751249313354492\n",
      "Step: 7367, Loss: 0.9030583500862122, Accuracy: 0.6875, Computation time: 0.9381301403045654\n",
      "Step: 7368, Loss: 0.3830798864364624, Accuracy: 0.875, Computation time: 1.0493109226226807\n",
      "Step: 7369, Loss: 0.7327591180801392, Accuracy: 0.78125, Computation time: 0.7897152900695801\n",
      "Step: 7370, Loss: 0.2946373224258423, Accuracy: 0.90625, Computation time: 0.7971079349517822\n",
      "Step: 7371, Loss: 0.18745850026607513, Accuracy: 0.9375, Computation time: 0.7827389240264893\n",
      "Step: 7372, Loss: 0.5026354193687439, Accuracy: 0.84375, Computation time: 0.8708400726318359\n",
      "Step: 7373, Loss: 0.47696787118911743, Accuracy: 0.84375, Computation time: 1.008427619934082\n",
      "Step: 7374, Loss: 0.410691499710083, Accuracy: 0.875, Computation time: 0.9318592548370361\n",
      "Step: 7375, Loss: 0.7940138578414917, Accuracy: 0.75, Computation time: 0.9374768733978271\n",
      "Step: 7376, Loss: 0.28444021940231323, Accuracy: 0.84375, Computation time: 0.8682539463043213\n",
      "Step: 7377, Loss: 0.31890368461608887, Accuracy: 0.90625, Computation time: 0.944091796875\n",
      "Step: 7378, Loss: 0.502801775932312, Accuracy: 0.90625, Computation time: 0.7731950283050537\n",
      "Step: 7379, Loss: 0.20012064278125763, Accuracy: 0.9375, Computation time: 0.8524947166442871\n",
      "Step: 7380, Loss: 0.8172807097434998, Accuracy: 0.84375, Computation time: 0.8273820877075195\n",
      "Step: 7381, Loss: 0.4357224404811859, Accuracy: 0.90625, Computation time: 0.8249757289886475\n",
      "Step: 7382, Loss: 0.2653527855873108, Accuracy: 0.9375, Computation time: 0.9367361068725586\n",
      "Step: 7383, Loss: 0.4505294859409332, Accuracy: 0.875, Computation time: 0.8657522201538086\n",
      "Step: 7384, Loss: 0.5608506798744202, Accuracy: 0.84375, Computation time: 0.8716762065887451\n",
      "Step: 7385, Loss: 0.5186673998832703, Accuracy: 0.875, Computation time: 0.9650952816009521\n",
      "Step: 7386, Loss: 0.19828402996063232, Accuracy: 0.96875, Computation time: 1.0138037204742432\n",
      "Step: 7387, Loss: 0.5636502504348755, Accuracy: 0.78125, Computation time: 0.8267269134521484\n",
      "Step: 7388, Loss: 0.7014271020889282, Accuracy: 0.75, Computation time: 0.9597060680389404\n",
      "Step: 7389, Loss: 0.2010364681482315, Accuracy: 0.96875, Computation time: 0.8615982532501221\n",
      "Step: 7390, Loss: 0.3399621248245239, Accuracy: 0.875, Computation time: 0.8817861080169678\n",
      "Step: 7391, Loss: 0.5127364993095398, Accuracy: 0.90625, Computation time: 1.727139949798584\n",
      "Step: 7392, Loss: 0.364260196685791, Accuracy: 0.9375, Computation time: 0.7743890285491943\n",
      "Step: 7393, Loss: 0.3326963186264038, Accuracy: 0.90625, Computation time: 0.7861747741699219\n",
      "Step: 7394, Loss: 0.47208794951438904, Accuracy: 0.875, Computation time: 0.9964900016784668\n",
      "Step: 7395, Loss: 0.17159153521060944, Accuracy: 0.96875, Computation time: 0.8926472663879395\n",
      "Step: 7396, Loss: 0.6701838374137878, Accuracy: 0.84375, Computation time: 0.8766322135925293\n",
      "Step: 7397, Loss: 0.38114404678344727, Accuracy: 0.84375, Computation time: 0.820641040802002\n",
      "Step: 7398, Loss: 0.41845372319221497, Accuracy: 0.875, Computation time: 0.8853518962860107\n",
      "Step: 7399, Loss: 0.31976234912872314, Accuracy: 0.875, Computation time: 0.7379977703094482\n",
      "Step: 7400, Loss: 0.6237191557884216, Accuracy: 0.71875, Computation time: 0.833125114440918\n",
      "Step: 7401, Loss: 0.22766131162643433, Accuracy: 0.90625, Computation time: 0.8129100799560547\n",
      "Step: 7402, Loss: 0.38201022148132324, Accuracy: 0.84375, Computation time: 0.8427839279174805\n",
      "Step: 7403, Loss: 0.5324175357818604, Accuracy: 0.78125, Computation time: 0.9421432018280029\n",
      "Step: 7404, Loss: 0.32709842920303345, Accuracy: 0.875, Computation time: 0.8703188896179199\n",
      "Step: 7405, Loss: 0.25603869557380676, Accuracy: 0.9375, Computation time: 0.755734920501709\n",
      "Step: 7406, Loss: 0.1303766369819641, Accuracy: 1.0, Computation time: 0.7521500587463379\n",
      "Step: 7407, Loss: 0.5298437476158142, Accuracy: 0.8125, Computation time: 1.1395010948181152\n",
      "Step: 7408, Loss: 0.42714184522628784, Accuracy: 0.84375, Computation time: 0.9619147777557373\n",
      "Step: 7409, Loss: 0.21788440644741058, Accuracy: 0.90625, Computation time: 0.736051082611084\n",
      "Step: 7410, Loss: 0.524756133556366, Accuracy: 0.875, Computation time: 0.7397778034210205\n",
      "Step: 7411, Loss: 0.18634606897830963, Accuracy: 0.96875, Computation time: 0.8364987373352051\n",
      "Step: 7412, Loss: 0.23736585676670074, Accuracy: 0.9375, Computation time: 0.6928448677062988\n",
      "Step: 7413, Loss: 0.3332664370536804, Accuracy: 0.9375, Computation time: 0.888422966003418\n",
      "Step: 7414, Loss: 0.5490158200263977, Accuracy: 0.875, Computation time: 0.9136061668395996\n",
      "Step: 7415, Loss: 0.2975669801235199, Accuracy: 0.9375, Computation time: 1.3702137470245361\n",
      "Step: 7416, Loss: 0.3377261459827423, Accuracy: 0.90625, Computation time: 0.7625422477722168\n",
      "Step: 7417, Loss: 0.22490592300891876, Accuracy: 0.90625, Computation time: 0.7479150295257568\n",
      "Step: 7418, Loss: 0.380920946598053, Accuracy: 0.875, Computation time: 0.7567620277404785\n",
      "Step: 7419, Loss: 0.1424292027950287, Accuracy: 0.9375, Computation time: 0.8945257663726807\n",
      "Step: 7420, Loss: 0.5461643934249878, Accuracy: 0.75, Computation time: 0.8034398555755615\n",
      "Step: 7421, Loss: 0.298007071018219, Accuracy: 0.9375, Computation time: 1.6458971500396729\n",
      "Step: 7422, Loss: 0.31444501876831055, Accuracy: 0.875, Computation time: 0.8808400630950928\n",
      "Step: 7423, Loss: 0.5567317008972168, Accuracy: 0.78125, Computation time: 0.8831360340118408\n",
      "Step: 7424, Loss: 0.3897782266139984, Accuracy: 0.90625, Computation time: 0.838813066482544\n",
      "Step: 7425, Loss: 0.22856847941875458, Accuracy: 0.96875, Computation time: 0.9066548347473145\n",
      "Step: 7426, Loss: 0.7049750685691833, Accuracy: 0.78125, Computation time: 1.4252347946166992\n",
      "Step: 7427, Loss: 0.32498985528945923, Accuracy: 0.90625, Computation time: 0.8589780330657959\n",
      "Step: 7428, Loss: 0.5061689615249634, Accuracy: 0.8125, Computation time: 0.8307099342346191\n",
      "Step: 7429, Loss: 0.3898194134235382, Accuracy: 0.875, Computation time: 0.7723748683929443\n",
      "Step: 7430, Loss: 0.36936330795288086, Accuracy: 0.90625, Computation time: 0.9222991466522217\n",
      "Step: 7431, Loss: 0.3310317099094391, Accuracy: 0.9375, Computation time: 0.9033718109130859\n",
      "Step: 7432, Loss: 0.19938087463378906, Accuracy: 0.9375, Computation time: 0.9673440456390381\n",
      "Step: 7433, Loss: 0.30472496151924133, Accuracy: 0.90625, Computation time: 0.847017765045166\n",
      "Step: 7434, Loss: 0.4007352292537689, Accuracy: 0.84375, Computation time: 0.8733160495758057\n",
      "Step: 7435, Loss: 0.49241775274276733, Accuracy: 0.875, Computation time: 0.6567339897155762\n",
      "Step: 7436, Loss: 0.8201801776885986, Accuracy: 0.8125, Computation time: 1.0042550563812256\n",
      "Step: 7437, Loss: 0.5577648282051086, Accuracy: 0.84375, Computation time: 0.8569810390472412\n",
      "Step: 7438, Loss: 0.6681768894195557, Accuracy: 0.8125, Computation time: 0.8195509910583496\n",
      "Step: 7439, Loss: 0.589924156665802, Accuracy: 0.84375, Computation time: 0.9211668968200684\n",
      "Step: 7440, Loss: 0.590903639793396, Accuracy: 0.84375, Computation time: 1.020906925201416\n",
      "Step: 7441, Loss: 0.6512989401817322, Accuracy: 0.8125, Computation time: 0.7730298042297363\n",
      "Step: 7442, Loss: 0.47288501262664795, Accuracy: 0.84375, Computation time: 0.9573919773101807\n",
      "Step: 7443, Loss: 0.2940213978290558, Accuracy: 0.9375, Computation time: 0.976599931716919\n",
      "Step: 7444, Loss: 0.2181113362312317, Accuracy: 0.9375, Computation time: 0.8897910118103027\n",
      "Step: 7445, Loss: 0.37035098671913147, Accuracy: 0.84375, Computation time: 0.8246269226074219\n",
      "Step: 7446, Loss: 0.7664613127708435, Accuracy: 0.71875, Computation time: 0.8138020038604736\n",
      "Step: 7447, Loss: 0.12273789197206497, Accuracy: 0.96875, Computation time: 0.7260808944702148\n",
      "Step: 7448, Loss: 0.5732558369636536, Accuracy: 0.84375, Computation time: 0.7698299884796143\n",
      "Step: 7449, Loss: 0.4408923089504242, Accuracy: 0.84375, Computation time: 0.8748490810394287\n",
      "Step: 7450, Loss: 0.5265809297561646, Accuracy: 0.8125, Computation time: 0.799281120300293\n",
      "Step: 7451, Loss: 0.303745836019516, Accuracy: 0.90625, Computation time: 0.7749402523040771\n",
      "Step: 7452, Loss: 0.5530896186828613, Accuracy: 0.78125, Computation time: 1.798393964767456\n",
      "Step: 7453, Loss: 0.4662827253341675, Accuracy: 0.84375, Computation time: 1.190981149673462\n",
      "Step: 7454, Loss: 0.7381173968315125, Accuracy: 0.8125, Computation time: 0.954477071762085\n",
      "Step: 7455, Loss: 0.7136979699134827, Accuracy: 0.78125, Computation time: 0.9189281463623047\n",
      "Step: 7456, Loss: 0.4969903826713562, Accuracy: 0.90625, Computation time: 0.8341948986053467\n",
      "Step: 7457, Loss: 0.6504660248756409, Accuracy: 0.8125, Computation time: 0.953834056854248\n",
      "Step: 7458, Loss: 0.27187663316726685, Accuracy: 0.875, Computation time: 0.74853515625\n",
      "Step: 7459, Loss: 0.4533707797527313, Accuracy: 0.84375, Computation time: 0.9949162006378174\n",
      "Step: 7460, Loss: 0.3835691213607788, Accuracy: 0.8125, Computation time: 0.8716890811920166\n",
      "Step: 7461, Loss: 0.49217477440834045, Accuracy: 0.84375, Computation time: 0.7837629318237305\n",
      "Step: 7462, Loss: 0.38949066400527954, Accuracy: 0.90625, Computation time: 0.7671413421630859\n",
      "Step: 7463, Loss: 0.4045814573764801, Accuracy: 0.875, Computation time: 0.8668568134307861\n",
      "Step: 7464, Loss: 0.2572499215602875, Accuracy: 0.90625, Computation time: 0.8447637557983398\n",
      "Step: 7465, Loss: 0.3381391167640686, Accuracy: 0.875, Computation time: 1.0730979442596436\n",
      "Step: 7466, Loss: 0.5864077806472778, Accuracy: 0.8125, Computation time: 0.808912992477417\n",
      "Step: 7467, Loss: 0.4144362211227417, Accuracy: 0.8125, Computation time: 1.0316059589385986\n",
      "Step: 7468, Loss: 0.37202316522598267, Accuracy: 0.90625, Computation time: 1.1449170112609863\n",
      "Step: 7469, Loss: 0.5167046785354614, Accuracy: 0.8125, Computation time: 0.8333008289337158\n",
      "Step: 7470, Loss: 0.5658829808235168, Accuracy: 0.84375, Computation time: 0.7448291778564453\n",
      "Step: 7471, Loss: 0.14365147054195404, Accuracy: 0.9375, Computation time: 0.8560090065002441\n",
      "Step: 7472, Loss: 0.6320382952690125, Accuracy: 0.8125, Computation time: 1.0727360248565674\n",
      "Step: 7473, Loss: 0.2048891931772232, Accuracy: 0.90625, Computation time: 1.0015521049499512\n",
      "Step: 7474, Loss: 0.32931628823280334, Accuracy: 0.90625, Computation time: 1.0108318328857422\n",
      "Step: 7475, Loss: 0.6198007464408875, Accuracy: 0.71875, Computation time: 1.0262870788574219\n",
      "Step: 7476, Loss: 0.8119567632675171, Accuracy: 0.75, Computation time: 1.0962257385253906\n",
      "Step: 7477, Loss: 0.3990618586540222, Accuracy: 0.96875, Computation time: 0.8280308246612549\n",
      "Step: 7478, Loss: 0.7659052610397339, Accuracy: 0.8125, Computation time: 0.8695409297943115\n",
      "Step: 7479, Loss: 0.43870875239372253, Accuracy: 0.84375, Computation time: 1.2162020206451416\n",
      "Step: 7480, Loss: 0.542217493057251, Accuracy: 0.8125, Computation time: 1.7574989795684814\n",
      "Step: 7481, Loss: 0.525169849395752, Accuracy: 0.8125, Computation time: 0.8457300662994385\n",
      "Step: 7482, Loss: 0.4375481903553009, Accuracy: 0.875, Computation time: 0.8326859474182129\n",
      "Step: 7483, Loss: 0.6551926136016846, Accuracy: 0.8125, Computation time: 0.871880292892456\n",
      "Step: 7484, Loss: 0.7660461664199829, Accuracy: 0.78125, Computation time: 0.943505048751831\n",
      "Step: 7485, Loss: 0.42458733916282654, Accuracy: 0.875, Computation time: 1.099147081375122\n",
      "Step: 7486, Loss: 0.18801692128181458, Accuracy: 0.90625, Computation time: 0.8917901515960693\n",
      "Step: 7487, Loss: 0.29437142610549927, Accuracy: 0.90625, Computation time: 0.7499091625213623\n",
      "Step: 7488, Loss: 0.17161494493484497, Accuracy: 0.9375, Computation time: 0.8513631820678711\n",
      "Step: 7489, Loss: 0.4161564111709595, Accuracy: 0.875, Computation time: 0.7709052562713623\n",
      "Step: 7490, Loss: 0.7570194602012634, Accuracy: 0.78125, Computation time: 0.9451010227203369\n",
      "Step: 7491, Loss: 0.6108116507530212, Accuracy: 0.8125, Computation time: 0.7800259590148926\n",
      "Step: 7492, Loss: 0.8158540725708008, Accuracy: 0.75, Computation time: 0.9478180408477783\n",
      "Step: 7493, Loss: 0.2659207582473755, Accuracy: 0.9375, Computation time: 0.7221329212188721\n",
      "Step: 7494, Loss: 0.34523987770080566, Accuracy: 0.8125, Computation time: 0.7636549472808838\n",
      "Step: 7495, Loss: 0.6420053839683533, Accuracy: 0.84375, Computation time: 0.7393810749053955\n",
      "Step: 7496, Loss: 0.37657690048217773, Accuracy: 0.8125, Computation time: 0.9335699081420898\n",
      "Step: 7497, Loss: 0.5235862731933594, Accuracy: 0.90625, Computation time: 0.9185309410095215\n",
      "Step: 7498, Loss: 0.3129272758960724, Accuracy: 0.9375, Computation time: 0.8940329551696777\n",
      "Step: 7499, Loss: 0.5157584547996521, Accuracy: 0.8125, Computation time: 0.8468358516693115\n",
      "Step: 7500, Loss: 0.5207917094230652, Accuracy: 0.84375, Computation time: 1.0361969470977783\n",
      "Step: 7501, Loss: 0.5933628678321838, Accuracy: 0.8125, Computation time: 0.8385891914367676\n",
      "Step: 7502, Loss: 0.1904483586549759, Accuracy: 0.9375, Computation time: 0.7985730171203613\n",
      "Step: 7503, Loss: 0.4440481960773468, Accuracy: 0.8125, Computation time: 0.8460311889648438\n",
      "Step: 7504, Loss: 0.3997277617454529, Accuracy: 0.84375, Computation time: 0.7894039154052734\n",
      "Step: 7505, Loss: 0.411154568195343, Accuracy: 0.90625, Computation time: 0.826801061630249\n",
      "Step: 7506, Loss: 0.34677204489707947, Accuracy: 0.875, Computation time: 0.9752640724182129\n",
      "Step: 7507, Loss: 0.16924352943897247, Accuracy: 0.9375, Computation time: 0.8729889392852783\n",
      "Step: 7508, Loss: 0.5582631230354309, Accuracy: 0.8125, Computation time: 0.8997938632965088\n",
      "Step: 7509, Loss: 0.4680478572845459, Accuracy: 0.84375, Computation time: 0.7323389053344727\n",
      "Step: 7510, Loss: 0.07925213873386383, Accuracy: 1.0, Computation time: 1.554750919342041\n",
      "Step: 7511, Loss: 0.663384199142456, Accuracy: 0.84375, Computation time: 0.8698890209197998\n",
      "Step: 7512, Loss: 0.5069094896316528, Accuracy: 0.75, Computation time: 0.9788820743560791\n",
      "Step: 7513, Loss: 0.48068320751190186, Accuracy: 0.875, Computation time: 0.9556131362915039\n",
      "Step: 7514, Loss: 0.3174971640110016, Accuracy: 0.84375, Computation time: 0.9997057914733887\n",
      "Step: 7515, Loss: 0.3296816647052765, Accuracy: 0.90625, Computation time: 0.7807102203369141\n",
      "Step: 7516, Loss: 0.26479288935661316, Accuracy: 0.9375, Computation time: 0.8556962013244629\n",
      "Step: 7517, Loss: 0.5191441774368286, Accuracy: 0.84375, Computation time: 0.9376182556152344\n",
      "Step: 7518, Loss: 0.35529667139053345, Accuracy: 0.9375, Computation time: 1.2468218803405762\n",
      "Step: 7519, Loss: 0.852469801902771, Accuracy: 0.78125, Computation time: 0.9301967620849609\n",
      "Step: 7520, Loss: 0.36936047673225403, Accuracy: 0.9375, Computation time: 0.7646007537841797\n",
      "Step: 7521, Loss: 0.2793165147304535, Accuracy: 0.875, Computation time: 0.9189250469207764\n",
      "Step: 7522, Loss: 0.3411467373371124, Accuracy: 0.90625, Computation time: 0.7755618095397949\n",
      "Step: 7523, Loss: 0.23514071106910706, Accuracy: 0.9375, Computation time: 0.9609310626983643\n",
      "Step: 7524, Loss: 0.3180248439311981, Accuracy: 0.875, Computation time: 0.7661778926849365\n",
      "Step: 7525, Loss: 0.4132680296897888, Accuracy: 0.8125, Computation time: 0.9272336959838867\n",
      "Step: 7526, Loss: 0.3053770363330841, Accuracy: 0.875, Computation time: 0.8904900550842285\n",
      "Step: 7527, Loss: 0.4309611916542053, Accuracy: 0.875, Computation time: 0.9675819873809814\n",
      "Step: 7528, Loss: 0.5536870360374451, Accuracy: 0.78125, Computation time: 0.9041042327880859\n",
      "Step: 7529, Loss: 0.21795813739299774, Accuracy: 0.90625, Computation time: 0.8766131401062012\n",
      "Step: 7530, Loss: 0.35388752818107605, Accuracy: 0.9375, Computation time: 0.9110710620880127\n",
      "Step: 7531, Loss: 0.2856209874153137, Accuracy: 0.90625, Computation time: 0.8112728595733643\n",
      "Step: 7532, Loss: 0.15166355669498444, Accuracy: 0.96875, Computation time: 0.7221870422363281\n",
      "Step: 7533, Loss: 0.25089237093925476, Accuracy: 0.90625, Computation time: 1.0591280460357666\n",
      "Step: 7534, Loss: 0.3425751030445099, Accuracy: 0.84375, Computation time: 0.7967250347137451\n",
      "Step: 7535, Loss: 0.7441734075546265, Accuracy: 0.71875, Computation time: 1.4833781719207764\n",
      "Step: 7536, Loss: 0.336735337972641, Accuracy: 0.875, Computation time: 0.8092479705810547\n",
      "Step: 7537, Loss: 0.18976567685604095, Accuracy: 0.9375, Computation time: 1.070115089416504\n",
      "Step: 7538, Loss: 0.20148466527462006, Accuracy: 0.96875, Computation time: 0.7714769840240479\n",
      "Step: 7539, Loss: 0.09114246815443039, Accuracy: 0.96875, Computation time: 0.8749628067016602\n",
      "Step: 7540, Loss: 0.44373783469200134, Accuracy: 0.90625, Computation time: 0.995060920715332\n",
      "Step: 7541, Loss: 0.0962713286280632, Accuracy: 1.0, Computation time: 1.0049419403076172\n",
      "Step: 7542, Loss: 0.5473939776420593, Accuracy: 0.8125, Computation time: 0.8259329795837402\n",
      "Step: 7543, Loss: 0.3319728374481201, Accuracy: 0.875, Computation time: 0.7954690456390381\n",
      "Step: 7544, Loss: 0.2794220447540283, Accuracy: 0.90625, Computation time: 1.0066771507263184\n",
      "Step: 7545, Loss: 0.6794032454490662, Accuracy: 0.84375, Computation time: 0.8785829544067383\n",
      "Step: 7546, Loss: 0.2737811505794525, Accuracy: 0.90625, Computation time: 0.9584848880767822\n",
      "Step: 7547, Loss: 0.16742965579032898, Accuracy: 0.90625, Computation time: 0.8919250965118408\n",
      "Step: 7548, Loss: 0.42507171630859375, Accuracy: 0.90625, Computation time: 0.8521888256072998\n",
      "Step: 7549, Loss: 0.20153436064720154, Accuracy: 0.9375, Computation time: 0.7759809494018555\n",
      "Step: 7550, Loss: 0.43085095286369324, Accuracy: 0.90625, Computation time: 0.7655198574066162\n",
      "Step: 7551, Loss: 0.5793152451515198, Accuracy: 0.84375, Computation time: 0.857208251953125\n",
      "Step: 7552, Loss: 0.16310498118400574, Accuracy: 0.96875, Computation time: 0.7992458343505859\n",
      "Step: 7553, Loss: 0.6950905323028564, Accuracy: 0.8125, Computation time: 0.9398410320281982\n",
      "Step: 7554, Loss: 0.8761960864067078, Accuracy: 0.78125, Computation time: 0.8804910182952881\n",
      "Step: 7555, Loss: 0.5918928980827332, Accuracy: 0.84375, Computation time: 2.287364959716797\n",
      "Step: 7556, Loss: 0.5460866093635559, Accuracy: 0.8125, Computation time: 0.8179531097412109\n",
      "Step: 7557, Loss: 0.5985342860221863, Accuracy: 0.90625, Computation time: 0.8149120807647705\n",
      "Step: 7558, Loss: 0.45172056555747986, Accuracy: 0.84375, Computation time: 0.7443068027496338\n",
      "Step: 7559, Loss: 0.28866487741470337, Accuracy: 0.875, Computation time: 0.8004932403564453\n",
      "Step: 7560, Loss: 0.5757128000259399, Accuracy: 0.78125, Computation time: 0.8965601921081543\n",
      "Step: 7561, Loss: 0.5553886294364929, Accuracy: 0.84375, Computation time: 0.8122310638427734\n",
      "Step: 7562, Loss: 0.37014681100845337, Accuracy: 0.8125, Computation time: 0.7165827751159668\n",
      "Step: 7563, Loss: 0.17548973858356476, Accuracy: 0.9375, Computation time: 0.7774860858917236\n",
      "Step: 7564, Loss: 0.4427438974380493, Accuracy: 0.90625, Computation time: 0.9296190738677979\n",
      "Step: 7565, Loss: 0.24986042082309723, Accuracy: 0.9375, Computation time: 0.9051961898803711\n",
      "Step: 7566, Loss: 0.5310424566268921, Accuracy: 0.90625, Computation time: 0.8486261367797852\n",
      "Step: 7567, Loss: 0.5564989447593689, Accuracy: 0.8125, Computation time: 0.7253577709197998\n",
      "Step: 7568, Loss: 0.2530961036682129, Accuracy: 0.9375, Computation time: 1.0322160720825195\n",
      "Step: 7569, Loss: 0.6238377094268799, Accuracy: 0.84375, Computation time: 1.5391669273376465\n",
      "Step: 7570, Loss: 0.5570866465568542, Accuracy: 0.875, Computation time: 0.8164041042327881\n",
      "Step: 7571, Loss: 0.4002925157546997, Accuracy: 0.84375, Computation time: 0.8925728797912598\n",
      "Step: 7572, Loss: 0.39386042952537537, Accuracy: 0.90625, Computation time: 0.8089940547943115\n",
      "Step: 7573, Loss: 0.46219250559806824, Accuracy: 0.78125, Computation time: 1.030000925064087\n",
      "Step: 7574, Loss: 0.6450732350349426, Accuracy: 0.8125, Computation time: 0.9108600616455078\n",
      "Step: 7575, Loss: 0.3595770597457886, Accuracy: 0.90625, Computation time: 1.0484099388122559\n",
      "Step: 7576, Loss: 0.5962351560592651, Accuracy: 0.875, Computation time: 0.7936289310455322\n",
      "Step: 7577, Loss: 0.46545952558517456, Accuracy: 0.84375, Computation time: 1.4067027568817139\n",
      "Step: 7578, Loss: 0.5502290725708008, Accuracy: 0.78125, Computation time: 0.7802650928497314\n",
      "Step: 7579, Loss: 0.5158358812332153, Accuracy: 0.84375, Computation time: 0.9930768013000488\n",
      "Step: 7580, Loss: 0.5414826273918152, Accuracy: 0.84375, Computation time: 0.7637889385223389\n",
      "Step: 7581, Loss: 0.44620251655578613, Accuracy: 0.875, Computation time: 0.8457419872283936\n",
      "Step: 7582, Loss: 0.47115275263786316, Accuracy: 0.8125, Computation time: 0.766160249710083\n",
      "Step: 7583, Loss: 0.28311479091644287, Accuracy: 0.8125, Computation time: 0.8950810432434082\n",
      "Step: 7584, Loss: 0.27497225999832153, Accuracy: 0.90625, Computation time: 0.8469028472900391\n",
      "Step: 7585, Loss: 0.5192312002182007, Accuracy: 0.75, Computation time: 0.926353931427002\n",
      "Step: 7586, Loss: 0.29730868339538574, Accuracy: 0.875, Computation time: 0.8089437484741211\n",
      "Step: 7587, Loss: 0.6368143558502197, Accuracy: 0.8125, Computation time: 0.8321361541748047\n",
      "Step: 7588, Loss: 0.5671252608299255, Accuracy: 0.78125, Computation time: 1.4162800312042236\n",
      "Step: 7589, Loss: 0.36039769649505615, Accuracy: 0.875, Computation time: 0.9023420810699463\n",
      "Step: 7590, Loss: 0.4233246445655823, Accuracy: 0.90625, Computation time: 1.8509349822998047\n",
      "Step: 7591, Loss: 0.5129363536834717, Accuracy: 0.8125, Computation time: 0.9364609718322754\n",
      "Step: 7592, Loss: 0.45758888125419617, Accuracy: 0.875, Computation time: 0.8671691417694092\n",
      "Step: 7593, Loss: 0.5367941856384277, Accuracy: 0.8125, Computation time: 1.3542118072509766\n",
      "Step: 7594, Loss: 0.4003882110118866, Accuracy: 0.875, Computation time: 0.835028886795044\n",
      "Step: 7595, Loss: 0.38318535685539246, Accuracy: 0.90625, Computation time: 0.9207170009613037\n",
      "Step: 7596, Loss: 0.2025769203901291, Accuracy: 0.9375, Computation time: 0.6855149269104004\n",
      "Step: 7597, Loss: 0.12351075559854507, Accuracy: 0.96875, Computation time: 1.2967541217803955\n",
      "Step: 7598, Loss: 0.600040853023529, Accuracy: 0.84375, Computation time: 0.7435588836669922\n",
      "Step: 7599, Loss: 0.6951097249984741, Accuracy: 0.84375, Computation time: 0.7023782730102539\n",
      "Step: 7600, Loss: 0.3576083481311798, Accuracy: 0.875, Computation time: 0.8498501777648926\n",
      "Step: 7601, Loss: 0.58477383852005, Accuracy: 0.78125, Computation time: 1.1372878551483154\n",
      "Step: 7602, Loss: 0.24506114423274994, Accuracy: 0.9375, Computation time: 0.9372060298919678\n",
      "Step: 7603, Loss: 0.6625458598136902, Accuracy: 0.78125, Computation time: 0.9078099727630615\n",
      "Step: 7604, Loss: 0.3105156421661377, Accuracy: 0.90625, Computation time: 0.8330841064453125\n",
      "Step: 7605, Loss: 0.261587530374527, Accuracy: 0.90625, Computation time: 0.9166550636291504\n",
      "Step: 7606, Loss: 0.30250898003578186, Accuracy: 0.875, Computation time: 0.8445210456848145\n",
      "Step: 7607, Loss: 0.27385857701301575, Accuracy: 0.875, Computation time: 0.867255687713623\n",
      "Step: 7608, Loss: 0.2960991859436035, Accuracy: 0.90625, Computation time: 0.7837121486663818\n",
      "Step: 7609, Loss: 0.7014620900154114, Accuracy: 0.8125, Computation time: 0.9934799671173096\n",
      "Step: 7610, Loss: 0.29032960534095764, Accuracy: 0.90625, Computation time: 0.8220751285552979\n",
      "Step: 7611, Loss: 0.36638638377189636, Accuracy: 0.90625, Computation time: 0.8601851463317871\n",
      "Step: 7612, Loss: 0.19964320957660675, Accuracy: 0.9375, Computation time: 0.7910621166229248\n",
      "Step: 7613, Loss: 0.682694137096405, Accuracy: 0.8125, Computation time: 0.932244062423706\n",
      "Step: 7614, Loss: 0.23592694103717804, Accuracy: 0.90625, Computation time: 0.9247119426727295\n",
      "Step: 7615, Loss: 0.30535224080085754, Accuracy: 0.9375, Computation time: 0.8982670307159424\n",
      "Step: 7616, Loss: 0.42476749420166016, Accuracy: 0.875, Computation time: 0.7929682731628418\n",
      "Step: 7617, Loss: 0.3691065013408661, Accuracy: 0.90625, Computation time: 0.6681349277496338\n",
      "Step: 7618, Loss: 0.28519782423973083, Accuracy: 0.90625, Computation time: 1.6774039268493652\n",
      "Step: 7619, Loss: 0.12859252095222473, Accuracy: 0.96875, Computation time: 0.8879458904266357\n",
      "Step: 7620, Loss: 0.47935163974761963, Accuracy: 0.875, Computation time: 0.9424030780792236\n",
      "Step: 7621, Loss: 0.16987384855747223, Accuracy: 0.9375, Computation time: 0.7849409580230713\n",
      "Step: 7622, Loss: 0.3397582769393921, Accuracy: 0.90625, Computation time: 0.9827320575714111\n",
      "Step: 7623, Loss: 0.6875903010368347, Accuracy: 0.875, Computation time: 0.9392833709716797\n",
      "Step: 7624, Loss: 0.4315204322338104, Accuracy: 0.84375, Computation time: 0.8858010768890381\n",
      "Step: 7625, Loss: 0.16266386210918427, Accuracy: 0.96875, Computation time: 0.910383939743042\n",
      "Step: 7626, Loss: 0.39635342359542847, Accuracy: 0.875, Computation time: 0.8453998565673828\n",
      "Step: 7627, Loss: 0.29928526282310486, Accuracy: 0.90625, Computation time: 1.3933181762695312\n",
      "Step: 7628, Loss: 0.35966944694519043, Accuracy: 0.875, Computation time: 0.9110898971557617\n",
      "Step: 7629, Loss: 0.24630478024482727, Accuracy: 0.90625, Computation time: 0.9644269943237305\n",
      "Step: 7630, Loss: 0.3687329590320587, Accuracy: 0.90625, Computation time: 0.9484028816223145\n",
      "Step: 7631, Loss: 0.6101261377334595, Accuracy: 0.8125, Computation time: 0.9646267890930176\n",
      "Step: 7632, Loss: 0.33921924233436584, Accuracy: 0.84375, Computation time: 0.9153048992156982\n",
      "Step: 7633, Loss: 0.5357016921043396, Accuracy: 0.8125, Computation time: 1.0033071041107178\n",
      "Step: 7634, Loss: 0.422465443611145, Accuracy: 0.84375, Computation time: 0.9412209987640381\n",
      "Step: 7635, Loss: 0.26101911067962646, Accuracy: 0.90625, Computation time: 0.7226099967956543\n",
      "Step: 7636, Loss: 0.5907444953918457, Accuracy: 0.84375, Computation time: 0.9048311710357666\n",
      "Step: 7637, Loss: 0.2642456591129303, Accuracy: 0.9375, Computation time: 0.934891939163208\n",
      "Step: 7638, Loss: 0.35190582275390625, Accuracy: 0.90625, Computation time: 0.8523728847503662\n",
      "Step: 7639, Loss: 0.2634192109107971, Accuracy: 0.96875, Computation time: 0.8315210342407227\n",
      "Step: 7640, Loss: 0.7749463319778442, Accuracy: 0.75, Computation time: 1.0953419208526611\n",
      "Step: 7641, Loss: 0.4339786171913147, Accuracy: 0.84375, Computation time: 0.8922748565673828\n",
      "Step: 7642, Loss: 0.18025195598602295, Accuracy: 0.9375, Computation time: 0.8575539588928223\n",
      "Step: 7643, Loss: 0.6505609154701233, Accuracy: 0.8125, Computation time: 0.9819009304046631\n",
      "Step: 7644, Loss: 0.22527599334716797, Accuracy: 0.9375, Computation time: 1.0731799602508545\n",
      "Step: 7645, Loss: 0.2242620587348938, Accuracy: 0.9375, Computation time: 0.7783818244934082\n",
      "Step: 7646, Loss: 0.2316545695066452, Accuracy: 0.9375, Computation time: 0.7075502872467041\n",
      "Step: 7647, Loss: 0.22770032286643982, Accuracy: 0.96875, Computation time: 0.7664828300476074\n",
      "Step: 7648, Loss: 0.28579360246658325, Accuracy: 0.90625, Computation time: 0.7902858257293701\n",
      "Step: 7649, Loss: 0.73128342628479, Accuracy: 0.8125, Computation time: 0.9053630828857422\n",
      "Step: 7650, Loss: 0.35461315512657166, Accuracy: 0.875, Computation time: 1.0332300662994385\n",
      "Step: 7651, Loss: 0.5263758301734924, Accuracy: 0.875, Computation time: 0.8349571228027344\n",
      "Step: 7652, Loss: 0.3559880256652832, Accuracy: 0.875, Computation time: 0.9574728012084961\n",
      "Step: 7653, Loss: 0.3641481101512909, Accuracy: 0.9375, Computation time: 0.8487529754638672\n",
      "Step: 7654, Loss: 0.1350065916776657, Accuracy: 0.96875, Computation time: 0.732440710067749\n",
      "Step: 7655, Loss: 0.2146529108285904, Accuracy: 0.9375, Computation time: 1.0453169345855713\n",
      "Step: 7656, Loss: 0.9903369545936584, Accuracy: 0.8125, Computation time: 0.8237090110778809\n",
      "Step: 7657, Loss: 0.6495362520217896, Accuracy: 0.84375, Computation time: 1.2113661766052246\n",
      "Step: 7658, Loss: 0.6124446392059326, Accuracy: 0.8125, Computation time: 0.8656060695648193\n",
      "Step: 7659, Loss: 0.10942871868610382, Accuracy: 0.96875, Computation time: 0.967454195022583\n",
      "Step: 7660, Loss: 0.6691555976867676, Accuracy: 0.8125, Computation time: 0.9253780841827393\n",
      "Step: 7661, Loss: 0.29661789536476135, Accuracy: 0.90625, Computation time: 0.7793569564819336\n",
      "Step: 7662, Loss: 0.21905529499053955, Accuracy: 0.875, Computation time: 0.8453929424285889\n",
      "Step: 7663, Loss: 0.425660640001297, Accuracy: 0.8125, Computation time: 0.7484972476959229\n",
      "Step: 7664, Loss: 0.3325316607952118, Accuracy: 0.875, Computation time: 0.8389837741851807\n",
      "Step: 7665, Loss: 0.43519675731658936, Accuracy: 0.90625, Computation time: 0.8826282024383545\n",
      "Step: 7666, Loss: 0.23926913738250732, Accuracy: 0.90625, Computation time: 0.8767189979553223\n",
      "Step: 7667, Loss: 0.39711713790893555, Accuracy: 0.875, Computation time: 0.8509540557861328\n",
      "Step: 7668, Loss: 0.6223958134651184, Accuracy: 0.84375, Computation time: 0.7953841686248779\n",
      "Step: 7669, Loss: 0.2640130817890167, Accuracy: 0.9375, Computation time: 0.9281289577484131\n",
      "Step: 7670, Loss: 0.35866010189056396, Accuracy: 0.90625, Computation time: 0.8438351154327393\n",
      "Step: 7671, Loss: 0.508297324180603, Accuracy: 0.84375, Computation time: 0.8284447193145752\n",
      "Step: 7672, Loss: 0.9282088875770569, Accuracy: 0.8125, Computation time: 0.8650548458099365\n",
      "Step: 7673, Loss: 0.3230186998844147, Accuracy: 0.9375, Computation time: 0.8854589462280273\n",
      "Step: 7674, Loss: 0.4829309582710266, Accuracy: 0.90625, Computation time: 0.8846938610076904\n",
      "Step: 7675, Loss: 0.4715602993965149, Accuracy: 0.875, Computation time: 1.0076031684875488\n",
      "Step: 7676, Loss: 0.3189466595649719, Accuracy: 0.90625, Computation time: 0.8571183681488037\n",
      "Step: 7677, Loss: 0.44806766510009766, Accuracy: 0.8125, Computation time: 0.796278715133667\n",
      "Step: 7678, Loss: 0.22232620418071747, Accuracy: 0.90625, Computation time: 0.8000710010528564\n",
      "Step: 7679, Loss: 0.27609097957611084, Accuracy: 0.90625, Computation time: 1.062777042388916\n",
      "Step: 7680, Loss: 0.2521818280220032, Accuracy: 0.9375, Computation time: 0.9820427894592285\n",
      "Step: 7681, Loss: 0.18804426491260529, Accuracy: 0.96875, Computation time: 0.8439297676086426\n",
      "Step: 7682, Loss: 0.7947303652763367, Accuracy: 0.84375, Computation time: 0.8306708335876465\n",
      "Step: 7683, Loss: 0.6325497031211853, Accuracy: 0.84375, Computation time: 0.8823368549346924\n",
      "Step: 7684, Loss: 0.41506704688072205, Accuracy: 0.875, Computation time: 0.9978020191192627\n",
      "Step: 7685, Loss: 0.814498782157898, Accuracy: 0.6875, Computation time: 0.8626587390899658\n",
      "Step: 7686, Loss: 0.45964816212654114, Accuracy: 0.875, Computation time: 1.9080779552459717\n",
      "Step: 7687, Loss: 0.4816902279853821, Accuracy: 0.90625, Computation time: 0.7867319583892822\n",
      "Step: 7688, Loss: 0.38361552357673645, Accuracy: 0.90625, Computation time: 0.863914966583252\n",
      "Step: 7689, Loss: 0.7041437029838562, Accuracy: 0.75, Computation time: 0.800745964050293\n",
      "Step: 7690, Loss: 0.6196587681770325, Accuracy: 0.8125, Computation time: 0.8643417358398438\n",
      "Step: 7691, Loss: 0.5403249263763428, Accuracy: 0.78125, Computation time: 0.7692101001739502\n",
      "Step: 7692, Loss: 0.67701256275177, Accuracy: 0.78125, Computation time: 0.792039155960083\n",
      "Step: 7693, Loss: 0.27013328671455383, Accuracy: 0.9375, Computation time: 0.9755349159240723\n",
      "Step: 7694, Loss: 0.5020206570625305, Accuracy: 0.84375, Computation time: 0.9187750816345215\n",
      "Step: 7695, Loss: 0.2682386040687561, Accuracy: 0.875, Computation time: 1.0308740139007568\n",
      "Step: 7696, Loss: 0.311013787984848, Accuracy: 0.90625, Computation time: 1.0862410068511963\n",
      "Step: 7697, Loss: 0.49891263246536255, Accuracy: 0.78125, Computation time: 1.0703978538513184\n",
      "Step: 7698, Loss: 0.39053875207901, Accuracy: 0.84375, Computation time: 1.0051641464233398\n",
      "Step: 7699, Loss: 0.6869259476661682, Accuracy: 0.84375, Computation time: 0.9145631790161133\n",
      "Step: 7700, Loss: 2.154435873031616, Accuracy: 0.90625, Computation time: 0.7359700202941895\n",
      "Step: 7701, Loss: 0.82301926612854, Accuracy: 0.78125, Computation time: 0.8121790885925293\n",
      "Step: 7702, Loss: 0.4268413782119751, Accuracy: 0.84375, Computation time: 0.8099138736724854\n",
      "Step: 7703, Loss: 0.32288843393325806, Accuracy: 0.875, Computation time: 1.0091049671173096\n",
      "Step: 7704, Loss: 0.6187756061553955, Accuracy: 0.8125, Computation time: 0.9083750247955322\n",
      "Step: 7705, Loss: 0.3952859342098236, Accuracy: 0.875, Computation time: 0.7957370281219482\n",
      "Step: 7706, Loss: 0.3320217430591583, Accuracy: 0.84375, Computation time: 0.887744665145874\n",
      "Step: 7707, Loss: 0.39166316390037537, Accuracy: 0.875, Computation time: 0.8593170642852783\n",
      "Step: 7708, Loss: 0.5656662583351135, Accuracy: 0.8125, Computation time: 0.8970372676849365\n",
      "Step: 7709, Loss: 0.38994044065475464, Accuracy: 0.875, Computation time: 0.8978590965270996\n",
      "Step: 7710, Loss: 0.45668503642082214, Accuracy: 0.8125, Computation time: 0.9674808979034424\n",
      "Step: 7711, Loss: 0.8152039647102356, Accuracy: 0.78125, Computation time: 0.8746178150177002\n",
      "Step: 7712, Loss: 0.304008424282074, Accuracy: 0.9375, Computation time: 0.8174059391021729\n",
      "Step: 7713, Loss: 0.35731402039527893, Accuracy: 0.90625, Computation time: 1.0611600875854492\n",
      "Step: 7714, Loss: 0.3793146312236786, Accuracy: 0.84375, Computation time: 0.8480849266052246\n",
      "Step: 7715, Loss: 0.4635091722011566, Accuracy: 0.84375, Computation time: 0.9010250568389893\n",
      "Step: 7716, Loss: 0.4894411265850067, Accuracy: 0.84375, Computation time: 1.812582015991211\n",
      "Step: 7717, Loss: 0.14662493765354156, Accuracy: 1.0, Computation time: 0.8309359550476074\n",
      "Step: 7718, Loss: 0.4894528090953827, Accuracy: 0.90625, Computation time: 0.8313202857971191\n",
      "Step: 7719, Loss: 0.38139182329177856, Accuracy: 0.90625, Computation time: 0.9347882270812988\n",
      "Step: 7720, Loss: 0.48626914620399475, Accuracy: 0.96875, Computation time: 0.8752357959747314\n",
      "Step: 7721, Loss: 0.1998443305492401, Accuracy: 0.96875, Computation time: 0.9384207725524902\n",
      "Step: 7722, Loss: 0.33369389176368713, Accuracy: 0.90625, Computation time: 0.9704587459564209\n",
      "Step: 7723, Loss: 0.45991432666778564, Accuracy: 0.90625, Computation time: 1.1026930809020996\n",
      "Step: 7724, Loss: 0.6619675159454346, Accuracy: 0.84375, Computation time: 0.9872128963470459\n",
      "Step: 7725, Loss: 0.354013055562973, Accuracy: 0.9375, Computation time: 0.8759350776672363\n",
      "Step: 7726, Loss: 0.4467449486255646, Accuracy: 0.84375, Computation time: 0.9084501266479492\n",
      "Step: 7727, Loss: 0.558020830154419, Accuracy: 0.78125, Computation time: 0.90824294090271\n",
      "Step: 7728, Loss: 0.39329099655151367, Accuracy: 0.875, Computation time: 0.8721320629119873\n",
      "Step: 7729, Loss: 0.37084296345710754, Accuracy: 0.8125, Computation time: 0.9986870288848877\n",
      "Step: 7730, Loss: 0.5060674548149109, Accuracy: 0.84375, Computation time: 1.0098776817321777\n",
      "Step: 7731, Loss: 0.295111745595932, Accuracy: 0.9375, Computation time: 1.125533103942871\n",
      "Step: 7732, Loss: 0.3056516647338867, Accuracy: 0.84375, Computation time: 0.905677080154419\n",
      "Step: 7733, Loss: 0.4568970203399658, Accuracy: 0.78125, Computation time: 0.9137222766876221\n",
      "Step: 7734, Loss: 0.15084074437618256, Accuracy: 0.9375, Computation time: 0.8537061214447021\n",
      "Step: 7735, Loss: 0.329580694437027, Accuracy: 0.9375, Computation time: 0.8843767642974854\n",
      "Step: 7736, Loss: 0.325077623128891, Accuracy: 0.90625, Computation time: 0.8267412185668945\n",
      "Step: 7737, Loss: 0.21396031975746155, Accuracy: 0.9375, Computation time: 0.8268730640411377\n",
      "Step: 7738, Loss: 0.19528894126415253, Accuracy: 0.96875, Computation time: 0.758601188659668\n",
      "Step: 7739, Loss: 0.4272458851337433, Accuracy: 0.84375, Computation time: 0.8415279388427734\n",
      "Step: 7740, Loss: 0.5567793846130371, Accuracy: 0.8125, Computation time: 0.9892840385437012\n",
      "Step: 7741, Loss: 0.49907687306404114, Accuracy: 0.84375, Computation time: 0.8046708106994629\n",
      "Step: 7742, Loss: 0.5528505444526672, Accuracy: 0.78125, Computation time: 1.153221845626831\n",
      "Step: 7743, Loss: 0.168474480509758, Accuracy: 0.96875, Computation time: 0.9325268268585205\n",
      "Step: 7744, Loss: 0.3772207796573639, Accuracy: 0.8125, Computation time: 0.945854902267456\n",
      "Step: 7745, Loss: 0.4343273937702179, Accuracy: 0.8125, Computation time: 0.999920129776001\n",
      "Step: 7746, Loss: 0.2152128964662552, Accuracy: 0.90625, Computation time: 0.9824960231781006\n",
      "Step: 7747, Loss: 0.36953556537628174, Accuracy: 0.875, Computation time: 0.8313889503479004\n",
      "Step: 7748, Loss: 0.17641857266426086, Accuracy: 0.96875, Computation time: 1.0281522274017334\n",
      "Step: 7749, Loss: 0.46969279646873474, Accuracy: 0.84375, Computation time: 0.9782121181488037\n",
      "Step: 7750, Loss: 0.29443904757499695, Accuracy: 0.90625, Computation time: 0.8812339305877686\n",
      "Step: 7751, Loss: 0.20516881346702576, Accuracy: 0.9375, Computation time: 1.033275842666626\n",
      "Step: 7752, Loss: 0.10604812949895859, Accuracy: 0.96875, Computation time: 0.7928290367126465\n",
      "Step: 7753, Loss: 0.22708772122859955, Accuracy: 0.90625, Computation time: 0.8498101234436035\n",
      "Step: 7754, Loss: 0.13075001537799835, Accuracy: 0.9375, Computation time: 1.0454630851745605\n",
      "Step: 7755, Loss: 0.3052203357219696, Accuracy: 0.90625, Computation time: 0.7811970710754395\n",
      "Step: 7756, Loss: 0.6817409992218018, Accuracy: 0.78125, Computation time: 0.9310269355773926\n",
      "Step: 7757, Loss: 0.2683713734149933, Accuracy: 0.9375, Computation time: 1.0592851638793945\n",
      "Step: 7758, Loss: 0.3550556004047394, Accuracy: 0.875, Computation time: 1.0720980167388916\n",
      "Step: 7759, Loss: 0.6568241119384766, Accuracy: 0.875, Computation time: 1.074368953704834\n",
      "Step: 7760, Loss: 0.5082108974456787, Accuracy: 0.84375, Computation time: 0.787041187286377\n",
      "Step: 7761, Loss: 0.4672681987285614, Accuracy: 0.875, Computation time: 1.125661849975586\n",
      "Step: 7762, Loss: 0.7414687275886536, Accuracy: 0.8125, Computation time: 1.3109312057495117\n",
      "Step: 7763, Loss: 0.33854490518569946, Accuracy: 0.875, Computation time: 0.9201898574829102\n",
      "Step: 7764, Loss: 0.49415796995162964, Accuracy: 0.875, Computation time: 1.0357310771942139\n",
      "Step: 7765, Loss: 0.2892935574054718, Accuracy: 0.90625, Computation time: 1.177137851715088\n",
      "Step: 7766, Loss: 0.7088609933853149, Accuracy: 0.78125, Computation time: 0.9835600852966309\n",
      "Step: 7767, Loss: 0.3050745129585266, Accuracy: 0.90625, Computation time: 0.8915550708770752\n",
      "Step: 7768, Loss: 0.11653797328472137, Accuracy: 0.96875, Computation time: 0.8979370594024658\n",
      "Step: 7769, Loss: 0.4832130968570709, Accuracy: 0.84375, Computation time: 1.0020849704742432\n",
      "Step: 7770, Loss: 0.25873076915740967, Accuracy: 0.90625, Computation time: 0.8396286964416504\n",
      "Step: 7771, Loss: 0.3309400677680969, Accuracy: 0.875, Computation time: 0.7831459045410156\n",
      "Step: 7772, Loss: 0.2698991596698761, Accuracy: 0.9375, Computation time: 1.4505970478057861\n",
      "Step: 7773, Loss: 0.5656282305717468, Accuracy: 0.875, Computation time: 0.9315059185028076\n",
      "Step: 7774, Loss: 0.5289269685745239, Accuracy: 0.84375, Computation time: 0.8895320892333984\n",
      "Step: 7775, Loss: 0.3623430132865906, Accuracy: 0.84375, Computation time: 0.9134469032287598\n",
      "Step: 7776, Loss: 0.5960394740104675, Accuracy: 0.78125, Computation time: 0.8580672740936279\n",
      "Step: 7777, Loss: 0.5194328427314758, Accuracy: 0.84375, Computation time: 0.8406970500946045\n",
      "Step: 7778, Loss: 0.31434494256973267, Accuracy: 0.9375, Computation time: 0.827782154083252\n",
      "Step: 7779, Loss: 0.2203061580657959, Accuracy: 0.96875, Computation time: 0.8876891136169434\n",
      "Step: 7780, Loss: 0.22828447818756104, Accuracy: 0.9375, Computation time: 1.0442078113555908\n",
      "Step: 7781, Loss: 0.15373486280441284, Accuracy: 0.96875, Computation time: 0.9382810592651367\n",
      "Step: 7782, Loss: 0.2536907494068146, Accuracy: 0.90625, Computation time: 0.8718945980072021\n",
      "Step: 7783, Loss: 0.7210014462471008, Accuracy: 0.75, Computation time: 0.9546658992767334\n",
      "Step: 7784, Loss: 0.3659118413925171, Accuracy: 0.875, Computation time: 0.7497730255126953\n",
      "Step: 7785, Loss: 0.2675645351409912, Accuracy: 0.90625, Computation time: 0.8230547904968262\n",
      "Step: 7786, Loss: 0.6384856104850769, Accuracy: 0.84375, Computation time: 1.0636029243469238\n",
      "Step: 7787, Loss: 0.41248631477355957, Accuracy: 0.8125, Computation time: 0.9434199333190918\n",
      "Step: 7788, Loss: 0.4302835464477539, Accuracy: 0.90625, Computation time: 0.990919828414917\n",
      "Step: 7789, Loss: 0.5033364295959473, Accuracy: 0.875, Computation time: 1.061668872833252\n",
      "Step: 7790, Loss: 0.25393882393836975, Accuracy: 0.9375, Computation time: 0.9023332595825195\n",
      "Step: 7791, Loss: 0.2663981318473816, Accuracy: 0.90625, Computation time: 1.2233400344848633\n",
      "Step: 7792, Loss: 0.21265541017055511, Accuracy: 0.9375, Computation time: 0.7746067047119141\n",
      "Step: 7793, Loss: 0.35122907161712646, Accuracy: 0.90625, Computation time: 0.9703679084777832\n",
      "Step: 7794, Loss: 0.4160262942314148, Accuracy: 0.90625, Computation time: 0.8796889781951904\n",
      "Step: 7795, Loss: 0.15547169744968414, Accuracy: 0.9375, Computation time: 0.8359701633453369\n",
      "Step: 7796, Loss: 0.4094247817993164, Accuracy: 0.90625, Computation time: 0.8367869853973389\n",
      "Step: 7797, Loss: 0.2768590748310089, Accuracy: 0.90625, Computation time: 0.72005295753479\n",
      "Step: 7798, Loss: 0.9925695657730103, Accuracy: 0.8125, Computation time: 0.8210339546203613\n",
      "Step: 7799, Loss: 0.511114776134491, Accuracy: 0.90625, Computation time: 0.811920166015625\n",
      "Step: 7800, Loss: 0.3162192404270172, Accuracy: 0.90625, Computation time: 0.8984212875366211\n",
      "Step: 7801, Loss: 0.11094152182340622, Accuracy: 0.96875, Computation time: 0.9987180233001709\n",
      "Step: 7802, Loss: 0.3627921938896179, Accuracy: 0.875, Computation time: 0.9378960132598877\n",
      "Step: 7803, Loss: 0.5249338746070862, Accuracy: 0.90625, Computation time: 0.977121114730835\n",
      "Step: 7804, Loss: 0.4718530476093292, Accuracy: 0.90625, Computation time: 1.0021288394927979\n",
      "Step: 7805, Loss: 0.5619157552719116, Accuracy: 0.84375, Computation time: 0.7927839756011963\n",
      "Step: 7806, Loss: 0.5197718739509583, Accuracy: 0.84375, Computation time: 0.9832959175109863\n",
      "Step: 7807, Loss: 0.38723504543304443, Accuracy: 0.90625, Computation time: 0.9573287963867188\n",
      "Step: 7808, Loss: 0.409544438123703, Accuracy: 0.84375, Computation time: 0.7978920936584473\n",
      "Step: 7809, Loss: 0.5601615905761719, Accuracy: 0.90625, Computation time: 0.9449841976165771\n",
      "Step: 7810, Loss: 0.5070748925209045, Accuracy: 0.84375, Computation time: 1.051069974899292\n",
      "Step: 7811, Loss: 0.6814079880714417, Accuracy: 0.84375, Computation time: 1.0966029167175293\n",
      "Step: 7812, Loss: 0.1860051304101944, Accuracy: 0.9375, Computation time: 1.0452079772949219\n",
      "Step: 7813, Loss: 0.3371545672416687, Accuracy: 0.90625, Computation time: 1.3506498336791992\n",
      "Step: 7814, Loss: 0.3830474019050598, Accuracy: 0.8125, Computation time: 0.8487002849578857\n",
      "Step: 7815, Loss: 0.7230726480484009, Accuracy: 0.84375, Computation time: 1.032963752746582\n",
      "Step: 7816, Loss: 0.4746820628643036, Accuracy: 0.875, Computation time: 0.939068078994751\n",
      "Step: 7817, Loss: 0.41204947233200073, Accuracy: 0.8125, Computation time: 0.8136649131774902\n",
      "Step: 7818, Loss: 0.15210649371147156, Accuracy: 0.96875, Computation time: 1.059293270111084\n",
      "Step: 7819, Loss: 0.19659850001335144, Accuracy: 0.9375, Computation time: 0.869149923324585\n",
      "Step: 7820, Loss: 0.15275277197360992, Accuracy: 0.9375, Computation time: 0.9156520366668701\n",
      "Step: 7821, Loss: 0.6687089800834656, Accuracy: 0.8125, Computation time: 1.0324289798736572\n",
      "Step: 7822, Loss: 0.6650582551956177, Accuracy: 0.8125, Computation time: 0.8353309631347656\n",
      "Step: 7823, Loss: 0.6051084995269775, Accuracy: 0.78125, Computation time: 0.7662980556488037\n",
      "Step: 7824, Loss: 0.34427642822265625, Accuracy: 0.90625, Computation time: 0.9844379425048828\n",
      "Step: 7825, Loss: 0.5342398285865784, Accuracy: 0.78125, Computation time: 0.9515559673309326\n",
      "Step: 7826, Loss: 0.10487084090709686, Accuracy: 1.0, Computation time: 0.8888359069824219\n",
      "Step: 7827, Loss: 0.5342089533805847, Accuracy: 0.8125, Computation time: 0.8955328464508057\n",
      "Step: 7828, Loss: 0.42321738600730896, Accuracy: 0.84375, Computation time: 0.8812520503997803\n",
      "Step: 7829, Loss: 0.25428545475006104, Accuracy: 0.90625, Computation time: 0.7345609664916992\n",
      "Step: 7830, Loss: 0.6433139443397522, Accuracy: 0.8125, Computation time: 0.9135668277740479\n",
      "Step: 7831, Loss: 0.32273590564727783, Accuracy: 0.875, Computation time: 0.8018810749053955\n",
      "Step: 7832, Loss: 0.32877328991889954, Accuracy: 0.875, Computation time: 0.9811227321624756\n",
      "Step: 7833, Loss: 0.3683468997478485, Accuracy: 0.875, Computation time: 0.8327090740203857\n",
      "Step: 7834, Loss: 0.7996259927749634, Accuracy: 0.8125, Computation time: 0.7819771766662598\n",
      "Step: 7835, Loss: 0.5081828236579895, Accuracy: 0.875, Computation time: 0.8779692649841309\n",
      "Step: 7836, Loss: 0.43324923515319824, Accuracy: 0.78125, Computation time: 0.8212690353393555\n",
      "Step: 7837, Loss: 0.2770995497703552, Accuracy: 0.9375, Computation time: 0.9205586910247803\n",
      "Step: 7838, Loss: 0.511814296245575, Accuracy: 0.875, Computation time: 0.8373708724975586\n",
      "Step: 7839, Loss: 0.3815781772136688, Accuracy: 0.9375, Computation time: 0.877661943435669\n",
      "Step: 7840, Loss: 0.8245866298675537, Accuracy: 0.8125, Computation time: 0.9704811573028564\n",
      "Step: 7841, Loss: 0.33219194412231445, Accuracy: 0.90625, Computation time: 0.9469952583312988\n",
      "Step: 7842, Loss: 0.47777020931243896, Accuracy: 0.78125, Computation time: 1.022416114807129\n",
      "Step: 7843, Loss: 0.5928941965103149, Accuracy: 0.78125, Computation time: 0.9290127754211426\n",
      "Step: 7844, Loss: 0.35380950570106506, Accuracy: 0.875, Computation time: 1.0329177379608154\n",
      "Step: 7845, Loss: 0.22547627985477448, Accuracy: 0.9375, Computation time: 0.9579379558563232\n",
      "Step: 7846, Loss: 0.38111168146133423, Accuracy: 0.90625, Computation time: 0.8566961288452148\n",
      "Step: 7847, Loss: 0.3991977870464325, Accuracy: 0.90625, Computation time: 0.8953218460083008\n",
      "Step: 7848, Loss: 0.4991605877876282, Accuracy: 0.84375, Computation time: 1.028048038482666\n",
      "Step: 7849, Loss: 0.6624681949615479, Accuracy: 0.75, Computation time: 0.8054678440093994\n",
      "Step: 7850, Loss: 0.2554411292076111, Accuracy: 0.90625, Computation time: 0.8702452182769775\n",
      "Step: 7851, Loss: 0.3528268039226532, Accuracy: 0.90625, Computation time: 0.7659571170806885\n",
      "Step: 7852, Loss: 0.40758833289146423, Accuracy: 0.875, Computation time: 0.9609689712524414\n",
      "Step: 7853, Loss: 0.5386571884155273, Accuracy: 0.875, Computation time: 0.9245550632476807\n",
      "Step: 7854, Loss: 0.533921480178833, Accuracy: 0.84375, Computation time: 0.7664880752563477\n",
      "Step: 7855, Loss: 0.1684918850660324, Accuracy: 0.96875, Computation time: 0.9513561725616455\n",
      "Step: 7856, Loss: 0.38506320118904114, Accuracy: 0.875, Computation time: 0.8008801937103271\n",
      "Step: 7857, Loss: 0.1449233442544937, Accuracy: 0.9375, Computation time: 0.9668850898742676\n",
      "Step: 7858, Loss: 0.24614255130290985, Accuracy: 0.90625, Computation time: 0.7318131923675537\n",
      "Step: 7859, Loss: 0.761522114276886, Accuracy: 0.8125, Computation time: 0.7540578842163086\n",
      "Step: 7860, Loss: 0.5325747728347778, Accuracy: 0.8125, Computation time: 1.4442219734191895\n",
      "Step: 7861, Loss: 0.46444910764694214, Accuracy: 0.84375, Computation time: 0.9723110198974609\n",
      "Step: 7862, Loss: 0.5278594493865967, Accuracy: 0.875, Computation time: 0.8485100269317627\n",
      "Step: 7863, Loss: 0.33427894115448, Accuracy: 0.875, Computation time: 0.8866710662841797\n",
      "Step: 7864, Loss: 0.3350047767162323, Accuracy: 0.875, Computation time: 0.8019149303436279\n",
      "Step: 7865, Loss: 0.4762958288192749, Accuracy: 0.8125, Computation time: 0.7728519439697266\n",
      "Step: 7866, Loss: 0.11123784631490707, Accuracy: 1.0, Computation time: 0.7731351852416992\n",
      "Step: 7867, Loss: 0.46455127000808716, Accuracy: 0.84375, Computation time: 0.8788819313049316\n",
      "Step: 7868, Loss: 0.8100438117980957, Accuracy: 0.75, Computation time: 0.9645156860351562\n",
      "Step: 7869, Loss: 0.3044832646846771, Accuracy: 0.90625, Computation time: 0.9316301345825195\n",
      "Step: 7870, Loss: 0.6406302452087402, Accuracy: 0.875, Computation time: 0.8461649417877197\n",
      "Step: 7871, Loss: 0.34560316801071167, Accuracy: 0.90625, Computation time: 0.9964940547943115\n",
      "Step: 7872, Loss: 0.4882814586162567, Accuracy: 0.90625, Computation time: 0.8443918228149414\n",
      "Step: 7873, Loss: 0.6374425292015076, Accuracy: 0.8125, Computation time: 0.9391610622406006\n",
      "Step: 7874, Loss: 0.43333491683006287, Accuracy: 0.90625, Computation time: 1.0256171226501465\n",
      "Step: 7875, Loss: 0.3452463448047638, Accuracy: 0.84375, Computation time: 0.8189899921417236\n",
      "Step: 7876, Loss: 0.22271117568016052, Accuracy: 0.96875, Computation time: 0.7240719795227051\n",
      "Step: 7877, Loss: 0.3488851487636566, Accuracy: 0.90625, Computation time: 0.9436588287353516\n",
      "Step: 7878, Loss: 0.5780831575393677, Accuracy: 0.78125, Computation time: 0.9911410808563232\n",
      "Step: 7879, Loss: 0.30331066250801086, Accuracy: 0.90625, Computation time: 0.8907101154327393\n",
      "Step: 7880, Loss: 0.28577208518981934, Accuracy: 0.9375, Computation time: 0.7788281440734863\n",
      "Step: 7881, Loss: 0.5217065811157227, Accuracy: 0.78125, Computation time: 0.8622498512268066\n",
      "Step: 7882, Loss: 0.38007625937461853, Accuracy: 0.84375, Computation time: 1.0300102233886719\n",
      "Step: 7883, Loss: 0.23016589879989624, Accuracy: 0.9375, Computation time: 0.7384068965911865\n",
      "Step: 7884, Loss: 0.9298062920570374, Accuracy: 0.78125, Computation time: 0.9921820163726807\n",
      "Step: 7885, Loss: 0.400858998298645, Accuracy: 0.875, Computation time: 0.9463381767272949\n",
      "Step: 7886, Loss: 0.3536931574344635, Accuracy: 0.875, Computation time: 1.1025121212005615\n",
      "Step: 7887, Loss: 0.4684160351753235, Accuracy: 0.84375, Computation time: 0.8956928253173828\n",
      "Step: 7888, Loss: 0.37364062666893005, Accuracy: 0.84375, Computation time: 0.8821620941162109\n",
      "Step: 7889, Loss: 0.24503538012504578, Accuracy: 0.9375, Computation time: 0.9578118324279785\n",
      "Step: 7890, Loss: 0.43220168352127075, Accuracy: 0.875, Computation time: 1.5563700199127197\n",
      "Step: 7891, Loss: 0.4137846529483795, Accuracy: 0.875, Computation time: 0.769970178604126\n",
      "Step: 7892, Loss: 0.3223881423473358, Accuracy: 0.9375, Computation time: 0.9537858963012695\n",
      "Step: 7893, Loss: 0.34866851568222046, Accuracy: 0.90625, Computation time: 1.0373330116271973\n",
      "Step: 7894, Loss: 0.3463038206100464, Accuracy: 0.90625, Computation time: 0.8690030574798584\n",
      "Step: 7895, Loss: 0.1748412400484085, Accuracy: 0.96875, Computation time: 0.9885711669921875\n",
      "Step: 7896, Loss: 0.28662800788879395, Accuracy: 0.90625, Computation time: 0.9075560569763184\n",
      "Step: 7897, Loss: 0.4260232448577881, Accuracy: 0.875, Computation time: 0.9073789119720459\n",
      "Step: 7898, Loss: 0.33129042387008667, Accuracy: 0.875, Computation time: 0.9997527599334717\n",
      "Step: 7899, Loss: 0.2879371643066406, Accuracy: 0.90625, Computation time: 0.9007973670959473\n",
      "Step: 7900, Loss: 0.7064334750175476, Accuracy: 0.84375, Computation time: 0.917827844619751\n",
      "Step: 7901, Loss: 0.5069319009780884, Accuracy: 0.875, Computation time: 1.0804078578948975\n",
      "Step: 7902, Loss: 0.2606211006641388, Accuracy: 0.9375, Computation time: 0.8006091117858887\n",
      "Step: 7903, Loss: 0.37922152876853943, Accuracy: 0.9375, Computation time: 1.1448729038238525\n",
      "Step: 7904, Loss: 0.7284744381904602, Accuracy: 0.78125, Computation time: 0.9726133346557617\n",
      "Step: 7905, Loss: 0.5961868762969971, Accuracy: 0.84375, Computation time: 0.9227571487426758\n",
      "Step: 7906, Loss: 0.4088275730609894, Accuracy: 0.875, Computation time: 0.9310102462768555\n",
      "Step: 7907, Loss: 0.365370512008667, Accuracy: 0.84375, Computation time: 0.9324197769165039\n",
      "Step: 7908, Loss: 0.46928274631500244, Accuracy: 0.875, Computation time: 0.9079420566558838\n",
      "Step: 7909, Loss: 0.45490020513534546, Accuracy: 0.9375, Computation time: 0.870459794998169\n",
      "Step: 7910, Loss: 0.26256459951400757, Accuracy: 0.90625, Computation time: 1.009066104888916\n",
      "Step: 7911, Loss: 0.5369157791137695, Accuracy: 0.75, Computation time: 0.8822479248046875\n",
      "Step: 7912, Loss: 0.4011514186859131, Accuracy: 0.90625, Computation time: 0.8644740581512451\n",
      "Step: 7913, Loss: 0.5409206748008728, Accuracy: 0.8125, Computation time: 1.1489551067352295\n",
      "Step: 7914, Loss: 0.5184873938560486, Accuracy: 0.875, Computation time: 0.8785719871520996\n",
      "Step: 7915, Loss: 0.10209964215755463, Accuracy: 1.0, Computation time: 0.8656210899353027\n",
      "Step: 7916, Loss: 0.9770835638046265, Accuracy: 0.78125, Computation time: 0.9993898868560791\n",
      "Step: 7917, Loss: 0.42467406392097473, Accuracy: 0.875, Computation time: 0.9026679992675781\n",
      "Step: 7918, Loss: 0.3690524101257324, Accuracy: 0.875, Computation time: 0.8514013290405273\n",
      "Step: 7919, Loss: 0.34960636496543884, Accuracy: 0.90625, Computation time: 1.3608078956604004\n",
      "Step: 7920, Loss: 0.28775879740715027, Accuracy: 0.9375, Computation time: 0.8152048587799072\n",
      "Step: 7921, Loss: 0.6678152680397034, Accuracy: 0.78125, Computation time: 0.919511079788208\n",
      "Step: 7922, Loss: 0.27180808782577515, Accuracy: 0.90625, Computation time: 0.8408041000366211\n",
      "Step: 7923, Loss: 0.3488699197769165, Accuracy: 0.90625, Computation time: 0.8306219577789307\n",
      "Step: 7924, Loss: 0.33303695917129517, Accuracy: 0.90625, Computation time: 0.7792000770568848\n",
      "Step: 7925, Loss: 0.7099161148071289, Accuracy: 0.75, Computation time: 0.8051469326019287\n",
      "Step: 7926, Loss: 0.32253116369247437, Accuracy: 0.90625, Computation time: 0.8123800754547119\n",
      "Step: 7927, Loss: 0.45698195695877075, Accuracy: 0.84375, Computation time: 0.9480721950531006\n",
      "Step: 7928, Loss: 0.454986035823822, Accuracy: 0.84375, Computation time: 0.8922600746154785\n",
      "Step: 7929, Loss: 0.3352499008178711, Accuracy: 0.90625, Computation time: 0.7742400169372559\n",
      "Step: 7930, Loss: 0.2989160716533661, Accuracy: 0.90625, Computation time: 0.7953109741210938\n",
      "Step: 7931, Loss: 0.4689178764820099, Accuracy: 0.84375, Computation time: 0.9823422431945801\n",
      "Step: 7932, Loss: 0.1846865564584732, Accuracy: 0.96875, Computation time: 1.0253610610961914\n",
      "Step: 7933, Loss: 0.4580629765987396, Accuracy: 0.96875, Computation time: 0.7923071384429932\n",
      "Step: 7934, Loss: 0.3147627115249634, Accuracy: 0.875, Computation time: 0.912017822265625\n",
      "Step: 7935, Loss: 0.27099254727363586, Accuracy: 0.875, Computation time: 0.7445130348205566\n",
      "Step: 7936, Loss: 0.26940101385116577, Accuracy: 0.9375, Computation time: 0.8666191101074219\n",
      "Step: 7937, Loss: 0.17502841353416443, Accuracy: 0.96875, Computation time: 0.8727321624755859\n",
      "Step: 7938, Loss: 0.3436812162399292, Accuracy: 0.9375, Computation time: 0.8556821346282959\n",
      "Step: 7939, Loss: 0.4504912197589874, Accuracy: 0.84375, Computation time: 0.9409191608428955\n",
      "Step: 7940, Loss: 0.4520600736141205, Accuracy: 0.875, Computation time: 0.9163861274719238\n",
      "Step: 7941, Loss: 0.28379878401756287, Accuracy: 0.90625, Computation time: 0.827329158782959\n",
      "Step: 7942, Loss: 0.7560268640518188, Accuracy: 0.75, Computation time: 0.9089829921722412\n",
      "Step: 7943, Loss: 0.3686794936656952, Accuracy: 0.84375, Computation time: 1.0011940002441406\n",
      "Step: 7944, Loss: 0.38069474697113037, Accuracy: 0.9375, Computation time: 0.8149752616882324\n",
      "Step: 7945, Loss: 0.45799243450164795, Accuracy: 0.84375, Computation time: 0.8628637790679932\n",
      "Step: 7946, Loss: 0.3036107122898102, Accuracy: 0.9375, Computation time: 0.7300710678100586\n",
      "Step: 7947, Loss: 0.13205574452877045, Accuracy: 1.0, Computation time: 0.8948280811309814\n",
      "Step: 7948, Loss: 0.6313033699989319, Accuracy: 0.875, Computation time: 1.0407490730285645\n",
      "Step: 7949, Loss: 0.28021112084388733, Accuracy: 0.90625, Computation time: 1.5523099899291992\n",
      "Step: 7950, Loss: 0.8066791296005249, Accuracy: 0.75, Computation time: 0.885796070098877\n",
      "Step: 7951, Loss: 0.5321410894393921, Accuracy: 0.8125, Computation time: 0.8753840923309326\n",
      "Step: 7952, Loss: 0.4356518089771271, Accuracy: 0.875, Computation time: 0.7672760486602783\n",
      "Step: 7953, Loss: 0.22500477731227875, Accuracy: 0.90625, Computation time: 1.0148098468780518\n",
      "Step: 7954, Loss: 0.48713764548301697, Accuracy: 0.875, Computation time: 0.849240779876709\n",
      "Step: 7955, Loss: 0.43597644567489624, Accuracy: 0.875, Computation time: 0.9526119232177734\n",
      "Step: 7956, Loss: 0.4308009743690491, Accuracy: 0.78125, Computation time: 0.8796648979187012\n",
      "Step: 7957, Loss: 0.5495696663856506, Accuracy: 0.84375, Computation time: 0.8159999847412109\n",
      "Step: 7958, Loss: 0.43255874514579773, Accuracy: 0.875, Computation time: 0.9003527164459229\n",
      "Step: 7959, Loss: 0.8540372252464294, Accuracy: 0.78125, Computation time: 0.7797009944915771\n",
      "Step: 7960, Loss: 0.454223096370697, Accuracy: 0.84375, Computation time: 0.9236268997192383\n",
      "Step: 7961, Loss: 0.23616161942481995, Accuracy: 0.90625, Computation time: 0.7976138591766357\n",
      "Step: 7962, Loss: 0.4736021161079407, Accuracy: 0.875, Computation time: 0.9134230613708496\n",
      "Step: 7963, Loss: 0.08993671834468842, Accuracy: 1.0, Computation time: 0.8138167858123779\n",
      "Step: 7964, Loss: 0.5577220916748047, Accuracy: 0.75, Computation time: 0.9795680046081543\n",
      "Step: 7965, Loss: 0.36384427547454834, Accuracy: 0.90625, Computation time: 0.9202790260314941\n",
      "Step: 7966, Loss: 0.39305010437965393, Accuracy: 0.875, Computation time: 0.8689088821411133\n",
      "Step: 7967, Loss: 0.4362773299217224, Accuracy: 0.84375, Computation time: 0.942922830581665\n",
      "Step: 7968, Loss: 0.7894220352172852, Accuracy: 0.71875, Computation time: 0.9251298904418945\n",
      "Step: 7969, Loss: 0.7265950441360474, Accuracy: 0.78125, Computation time: 1.2212259769439697\n",
      "Step: 7970, Loss: 0.7251476645469666, Accuracy: 0.84375, Computation time: 0.891160249710083\n",
      "Step: 7971, Loss: 0.9639196395874023, Accuracy: 0.8125, Computation time: 0.8265199661254883\n",
      "Step: 7972, Loss: 0.43081021308898926, Accuracy: 0.875, Computation time: 0.9170219898223877\n",
      "Step: 7973, Loss: 0.913229763507843, Accuracy: 0.78125, Computation time: 1.0502119064331055\n",
      "Step: 7974, Loss: 0.5804129838943481, Accuracy: 0.78125, Computation time: 1.0070312023162842\n",
      "Step: 7975, Loss: 0.23283730447292328, Accuracy: 0.90625, Computation time: 1.0281531810760498\n",
      "Step: 7976, Loss: 0.3096849024295807, Accuracy: 0.90625, Computation time: 0.8277628421783447\n",
      "Step: 7977, Loss: 0.9449625015258789, Accuracy: 0.78125, Computation time: 0.9902770519256592\n",
      "Step: 7978, Loss: 0.5746958255767822, Accuracy: 0.84375, Computation time: 0.9831972122192383\n",
      "Step: 7979, Loss: 0.8188997507095337, Accuracy: 0.75, Computation time: 1.5188732147216797\n",
      "Step: 7980, Loss: 0.49063947796821594, Accuracy: 0.84375, Computation time: 0.9641342163085938\n",
      "Step: 7981, Loss: 0.22890782356262207, Accuracy: 0.9375, Computation time: 0.9459278583526611\n",
      "Step: 7982, Loss: 0.2846829295158386, Accuracy: 0.90625, Computation time: 0.959129810333252\n",
      "Step: 7983, Loss: 0.901358962059021, Accuracy: 0.71875, Computation time: 0.933480978012085\n",
      "Step: 7984, Loss: 0.33007025718688965, Accuracy: 0.90625, Computation time: 0.9069139957427979\n",
      "Step: 7985, Loss: 0.34491387009620667, Accuracy: 0.875, Computation time: 0.8673489093780518\n",
      "Step: 7986, Loss: 0.5345011353492737, Accuracy: 0.8125, Computation time: 0.8831667900085449\n",
      "Step: 7987, Loss: 0.4353248178958893, Accuracy: 0.875, Computation time: 0.8866610527038574\n",
      "Step: 7988, Loss: 0.4552411437034607, Accuracy: 0.84375, Computation time: 1.0253658294677734\n",
      "Step: 7989, Loss: 0.7146066427230835, Accuracy: 0.75, Computation time: 1.029128074645996\n",
      "Step: 7990, Loss: 0.4623839259147644, Accuracy: 0.875, Computation time: 0.8512928485870361\n",
      "Step: 7991, Loss: 0.5146573781967163, Accuracy: 0.875, Computation time: 0.7831051349639893\n",
      "Step: 7992, Loss: 0.8232854008674622, Accuracy: 0.71875, Computation time: 0.8152010440826416\n",
      "Step: 7993, Loss: 0.3160855770111084, Accuracy: 0.875, Computation time: 0.9362711906433105\n",
      "Step: 7994, Loss: 0.3361574411392212, Accuracy: 0.875, Computation time: 0.8618621826171875\n",
      "Step: 7995, Loss: 0.26640382409095764, Accuracy: 0.90625, Computation time: 0.8462607860565186\n",
      "Step: 7996, Loss: 0.6967164278030396, Accuracy: 0.8125, Computation time: 0.844304084777832\n",
      "Step: 7997, Loss: 0.3726290166378021, Accuracy: 0.84375, Computation time: 0.8349587917327881\n",
      "Step: 7998, Loss: 0.6013445258140564, Accuracy: 0.8125, Computation time: 0.8495690822601318\n",
      "Step: 7999, Loss: 0.6235494613647461, Accuracy: 0.8125, Computation time: 1.1440377235412598\n",
      "Step: 8000, Loss: 0.523318350315094, Accuracy: 0.875, Computation time: 1.1607160568237305\n",
      "Step: 8001, Loss: 0.21030853688716888, Accuracy: 0.9375, Computation time: 0.8391621112823486\n",
      "Step: 8002, Loss: 0.5854396224021912, Accuracy: 0.84375, Computation time: 0.9723830223083496\n",
      "Step: 8003, Loss: 0.4069441556930542, Accuracy: 0.875, Computation time: 0.9477150440216064\n",
      "Step: 8004, Loss: 0.431708425283432, Accuracy: 0.875, Computation time: 0.7925591468811035\n",
      "Step: 8005, Loss: 0.2051651030778885, Accuracy: 0.9375, Computation time: 1.159057855606079\n",
      "Step: 8006, Loss: 0.6649227142333984, Accuracy: 0.8125, Computation time: 0.823063850402832\n",
      "Step: 8007, Loss: 0.3022530674934387, Accuracy: 0.90625, Computation time: 0.8783581256866455\n",
      "Step: 8008, Loss: 0.32601621747016907, Accuracy: 0.875, Computation time: 1.066720962524414\n",
      "Step: 8009, Loss: 0.46036967635154724, Accuracy: 0.84375, Computation time: 0.8454740047454834\n",
      "Step: 8010, Loss: 0.4584842026233673, Accuracy: 0.875, Computation time: 0.9805240631103516\n",
      "Step: 8011, Loss: 0.48342210054397583, Accuracy: 0.875, Computation time: 1.1862001419067383\n",
      "Step: 8012, Loss: 0.4714207351207733, Accuracy: 0.84375, Computation time: 0.8638129234313965\n",
      "Step: 8013, Loss: 0.48514461517333984, Accuracy: 0.84375, Computation time: 0.8264560699462891\n",
      "Step: 8014, Loss: 0.5267968773841858, Accuracy: 0.90625, Computation time: 0.9546198844909668\n",
      "Step: 8015, Loss: 0.5285544395446777, Accuracy: 0.90625, Computation time: 1.0069031715393066\n",
      "Step: 8016, Loss: 0.38381344079971313, Accuracy: 0.875, Computation time: 1.1554980278015137\n",
      "Step: 8017, Loss: 0.40349850058555603, Accuracy: 0.875, Computation time: 1.001081943511963\n",
      "Step: 8018, Loss: 0.6095356941223145, Accuracy: 0.84375, Computation time: 0.8003661632537842\n",
      "Step: 8019, Loss: 0.290613055229187, Accuracy: 0.875, Computation time: 0.7384240627288818\n",
      "Step: 8020, Loss: 0.43356552720069885, Accuracy: 0.78125, Computation time: 0.918147087097168\n",
      "Step: 8021, Loss: 0.3835175037384033, Accuracy: 0.84375, Computation time: 0.7920069694519043\n",
      "Step: 8022, Loss: 0.505872368812561, Accuracy: 0.875, Computation time: 1.1037259101867676\n",
      "Step: 8023, Loss: 0.32841458916664124, Accuracy: 0.90625, Computation time: 1.0171678066253662\n",
      "Step: 8024, Loss: 0.6261315941810608, Accuracy: 0.84375, Computation time: 0.8015937805175781\n",
      "Step: 8025, Loss: 0.261666476726532, Accuracy: 0.9375, Computation time: 1.1883611679077148\n",
      "Step: 8026, Loss: 0.44793465733528137, Accuracy: 0.78125, Computation time: 1.0027058124542236\n",
      "Step: 8027, Loss: 0.3227440118789673, Accuracy: 0.84375, Computation time: 0.8995227813720703\n",
      "Step: 8028, Loss: 0.35303831100463867, Accuracy: 0.875, Computation time: 1.049708604812622\n",
      "Step: 8029, Loss: 0.35048696398735046, Accuracy: 0.90625, Computation time: 0.9234559535980225\n",
      "Step: 8030, Loss: 0.45194944739341736, Accuracy: 0.84375, Computation time: 0.7774918079376221\n",
      "Step: 8031, Loss: 0.08945012837648392, Accuracy: 1.0, Computation time: 0.8460888862609863\n",
      "Step: 8032, Loss: 0.251755028963089, Accuracy: 0.96875, Computation time: 0.7398719787597656\n",
      "Step: 8033, Loss: 0.46598052978515625, Accuracy: 0.90625, Computation time: 0.9885289669036865\n",
      "Step: 8034, Loss: 0.3846333622932434, Accuracy: 0.875, Computation time: 0.8977327346801758\n",
      "Step: 8035, Loss: 0.3589319884777069, Accuracy: 0.90625, Computation time: 0.9133248329162598\n",
      "Step: 8036, Loss: 0.39617374539375305, Accuracy: 0.90625, Computation time: 1.8035812377929688\n",
      "Step: 8037, Loss: 0.5352362990379333, Accuracy: 0.75, Computation time: 0.8331599235534668\n",
      "Step: 8038, Loss: 0.5615918040275574, Accuracy: 0.84375, Computation time: 0.8806209564208984\n",
      "Step: 8039, Loss: 0.21342134475708008, Accuracy: 0.9375, Computation time: 0.9240808486938477\n",
      "Step: 8040, Loss: 0.7380203604698181, Accuracy: 0.8125, Computation time: 0.8353397846221924\n",
      "Step: 8041, Loss: 0.3756316006183624, Accuracy: 0.84375, Computation time: 0.8711118698120117\n",
      "Step: 8042, Loss: 0.4700421392917633, Accuracy: 0.84375, Computation time: 0.8632509708404541\n",
      "Step: 8043, Loss: 0.401236355304718, Accuracy: 0.875, Computation time: 0.853693962097168\n",
      "Step: 8044, Loss: 0.8304353952407837, Accuracy: 0.78125, Computation time: 1.0378749370574951\n",
      "Step: 8045, Loss: 0.49713295698165894, Accuracy: 0.875, Computation time: 1.0412800312042236\n",
      "Step: 8046, Loss: 0.21972984075546265, Accuracy: 0.90625, Computation time: 1.0251920223236084\n",
      "Step: 8047, Loss: 0.6091047525405884, Accuracy: 0.78125, Computation time: 0.7796061038970947\n",
      "Step: 8048, Loss: 0.3012446165084839, Accuracy: 0.90625, Computation time: 0.8219408988952637\n",
      "Step: 8049, Loss: 0.09552174806594849, Accuracy: 1.0, Computation time: 0.8099648952484131\n",
      "Step: 8050, Loss: 0.502041220664978, Accuracy: 0.84375, Computation time: 0.9281439781188965\n",
      "Step: 8051, Loss: 0.3616017699241638, Accuracy: 0.90625, Computation time: 0.9205522537231445\n",
      "Step: 8052, Loss: 0.2761857211589813, Accuracy: 0.9375, Computation time: 0.9041500091552734\n",
      "Step: 8053, Loss: 0.26029008626937866, Accuracy: 0.875, Computation time: 0.8946897983551025\n",
      "Step: 8054, Loss: 0.5147398114204407, Accuracy: 0.875, Computation time: 0.9117639064788818\n",
      "Step: 8055, Loss: 0.46827006340026855, Accuracy: 0.8125, Computation time: 0.9386649131774902\n",
      "Step: 8056, Loss: 0.20946073532104492, Accuracy: 0.96875, Computation time: 0.9197230339050293\n",
      "Step: 8057, Loss: 0.16417476534843445, Accuracy: 0.9375, Computation time: 0.9215869903564453\n",
      "Step: 8058, Loss: 0.36208710074424744, Accuracy: 0.875, Computation time: 0.9357712268829346\n",
      "Step: 8059, Loss: 0.4524743854999542, Accuracy: 0.875, Computation time: 0.8368709087371826\n",
      "Step: 8060, Loss: 0.3212869465351105, Accuracy: 0.875, Computation time: 0.9291160106658936\n",
      "Step: 8061, Loss: 0.34080731868743896, Accuracy: 0.875, Computation time: 0.8776140213012695\n",
      "Step: 8062, Loss: 0.3706316351890564, Accuracy: 0.875, Computation time: 0.7866387367248535\n",
      "Step: 8063, Loss: 0.3840290904045105, Accuracy: 0.84375, Computation time: 0.9127330780029297\n",
      "Step: 8064, Loss: 0.3249610364437103, Accuracy: 0.90625, Computation time: 1.096130132675171\n",
      "Step: 8065, Loss: 0.7787137031555176, Accuracy: 0.75, Computation time: 0.9556448459625244\n",
      "Step: 8066, Loss: 0.31886208057403564, Accuracy: 0.875, Computation time: 1.660644769668579\n",
      "Step: 8067, Loss: 0.30461716651916504, Accuracy: 0.875, Computation time: 1.0261690616607666\n",
      "Step: 8068, Loss: 0.40454208850860596, Accuracy: 0.9375, Computation time: 0.9086651802062988\n",
      "Step: 8069, Loss: 0.5312362909317017, Accuracy: 0.875, Computation time: 1.037477970123291\n",
      "Step: 8070, Loss: 0.4070500135421753, Accuracy: 0.84375, Computation time: 0.8003940582275391\n",
      "Step: 8071, Loss: 0.44786691665649414, Accuracy: 0.90625, Computation time: 0.718052864074707\n",
      "Step: 8072, Loss: 0.09651167690753937, Accuracy: 0.96875, Computation time: 0.8711011409759521\n",
      "Step: 8073, Loss: 0.3503653109073639, Accuracy: 0.875, Computation time: 0.8942089080810547\n",
      "Step: 8074, Loss: 1.0198811292648315, Accuracy: 0.8125, Computation time: 0.8508951663970947\n",
      "Step: 8075, Loss: 0.18576888740062714, Accuracy: 0.9375, Computation time: 0.8530731201171875\n",
      "Step: 8076, Loss: 0.2990526258945465, Accuracy: 0.9375, Computation time: 0.9484553337097168\n",
      "Step: 8077, Loss: 0.4157646894454956, Accuracy: 0.84375, Computation time: 0.9527397155761719\n",
      "Step: 8078, Loss: 0.5093657374382019, Accuracy: 0.875, Computation time: 0.9498293399810791\n",
      "Step: 8079, Loss: 0.4507732093334198, Accuracy: 0.84375, Computation time: 1.1928372383117676\n",
      "Step: 8080, Loss: 0.5863646864891052, Accuracy: 0.78125, Computation time: 0.8045358657836914\n",
      "Step: 8081, Loss: 0.2290186583995819, Accuracy: 0.90625, Computation time: 0.8820581436157227\n",
      "Step: 8082, Loss: 0.7495177388191223, Accuracy: 0.6875, Computation time: 0.8459510803222656\n",
      "Step: 8083, Loss: 0.6135842800140381, Accuracy: 0.8125, Computation time: 0.9917020797729492\n",
      "Step: 8084, Loss: 0.37631887197494507, Accuracy: 0.84375, Computation time: 0.8454749584197998\n",
      "Step: 8085, Loss: 0.17644424736499786, Accuracy: 0.96875, Computation time: 0.8291339874267578\n",
      "Step: 8086, Loss: 0.3380521833896637, Accuracy: 0.875, Computation time: 0.8461639881134033\n",
      "Step: 8087, Loss: 0.4394080638885498, Accuracy: 0.875, Computation time: 1.0198450088500977\n",
      "Step: 8088, Loss: 0.4021000266075134, Accuracy: 0.875, Computation time: 0.8458712100982666\n",
      "Step: 8089, Loss: 0.5708558559417725, Accuracy: 0.75, Computation time: 0.9218146800994873\n",
      "Step: 8090, Loss: 0.28123489022254944, Accuracy: 0.875, Computation time: 0.825861930847168\n",
      "Step: 8091, Loss: 0.36046144366264343, Accuracy: 0.90625, Computation time: 0.9648580551147461\n",
      "Step: 8092, Loss: 0.3528267443180084, Accuracy: 0.9375, Computation time: 0.8515939712524414\n",
      "Step: 8093, Loss: 0.34008726477622986, Accuracy: 0.9375, Computation time: 0.9994378089904785\n",
      "Step: 8094, Loss: 0.3818489611148834, Accuracy: 0.84375, Computation time: 0.8356451988220215\n",
      "Step: 8095, Loss: 0.13302655518054962, Accuracy: 1.0, Computation time: 0.7951209545135498\n",
      "Step: 8096, Loss: 0.5203992128372192, Accuracy: 0.8125, Computation time: 1.6189100742340088\n",
      "Step: 8097, Loss: 0.2856752872467041, Accuracy: 0.90625, Computation time: 1.0489349365234375\n",
      "Step: 8098, Loss: 0.563772976398468, Accuracy: 0.8125, Computation time: 0.8989119529724121\n",
      "Step: 8099, Loss: 0.3807440996170044, Accuracy: 0.8125, Computation time: 0.7798941135406494\n",
      "Step: 8100, Loss: 0.15269295871257782, Accuracy: 1.0, Computation time: 0.7792580127716064\n",
      "Step: 8101, Loss: 0.16932086646556854, Accuracy: 0.96875, Computation time: 0.8861980438232422\n",
      "Step: 8102, Loss: 0.3466712236404419, Accuracy: 0.875, Computation time: 0.7489089965820312\n",
      "Step: 8103, Loss: 0.40881091356277466, Accuracy: 0.90625, Computation time: 1.0720949172973633\n",
      "Step: 8104, Loss: 0.11100820451974869, Accuracy: 1.0, Computation time: 0.8691191673278809\n",
      "Step: 8105, Loss: 0.3912833631038666, Accuracy: 0.875, Computation time: 0.9811477661132812\n",
      "Step: 8106, Loss: 0.6154074668884277, Accuracy: 0.90625, Computation time: 1.1337940692901611\n",
      "Step: 8107, Loss: 0.32868385314941406, Accuracy: 0.90625, Computation time: 0.848160982131958\n",
      "Step: 8108, Loss: 0.6664224863052368, Accuracy: 0.8125, Computation time: 0.9262828826904297\n",
      "Step: 8109, Loss: 0.32448458671569824, Accuracy: 0.875, Computation time: 0.9449660778045654\n",
      "Step: 8110, Loss: 0.3564562499523163, Accuracy: 0.90625, Computation time: 1.0221362113952637\n",
      "Step: 8111, Loss: 0.3838130235671997, Accuracy: 0.8125, Computation time: 1.4799890518188477\n",
      "Step: 8112, Loss: 0.6522586345672607, Accuracy: 0.84375, Computation time: 0.940108060836792\n",
      "Step: 8113, Loss: 0.49639463424682617, Accuracy: 0.90625, Computation time: 0.9251680374145508\n",
      "Step: 8114, Loss: 0.37413373589515686, Accuracy: 0.875, Computation time: 0.9564058780670166\n",
      "Step: 8115, Loss: 0.9847760200500488, Accuracy: 0.84375, Computation time: 1.0920090675354004\n",
      "Step: 8116, Loss: 1.0655375719070435, Accuracy: 0.71875, Computation time: 0.8235781192779541\n",
      "Step: 8117, Loss: 0.5618681311607361, Accuracy: 0.8125, Computation time: 0.944843053817749\n",
      "Step: 8118, Loss: 0.5175045728683472, Accuracy: 0.8125, Computation time: 0.9044589996337891\n",
      "Step: 8119, Loss: 0.435010701417923, Accuracy: 0.875, Computation time: 0.882188081741333\n",
      "Step: 8120, Loss: 0.5548456311225891, Accuracy: 0.84375, Computation time: 0.8471050262451172\n",
      "Step: 8121, Loss: 0.591528058052063, Accuracy: 0.8125, Computation time: 0.8178648948669434\n",
      "Step: 8122, Loss: 0.6004838943481445, Accuracy: 0.84375, Computation time: 1.1623008251190186\n",
      "Step: 8123, Loss: 1.2693912982940674, Accuracy: 0.71875, Computation time: 1.071239948272705\n",
      "Step: 8124, Loss: 1.1046369075775146, Accuracy: 0.6875, Computation time: 1.4783291816711426\n",
      "Step: 8125, Loss: 0.720565676689148, Accuracy: 0.8125, Computation time: 0.788377046585083\n",
      "Step: 8126, Loss: 0.5701454281806946, Accuracy: 0.8125, Computation time: 0.9162380695343018\n",
      "Step: 8127, Loss: 0.9081081748008728, Accuracy: 0.75, Computation time: 0.8115291595458984\n",
      "Step: 8128, Loss: 0.5808696746826172, Accuracy: 0.84375, Computation time: 0.8116521835327148\n",
      "Step: 8129, Loss: 0.7014245986938477, Accuracy: 0.78125, Computation time: 0.9916889667510986\n",
      "Step: 8130, Loss: 0.3533332645893097, Accuracy: 0.84375, Computation time: 0.7722377777099609\n",
      "Step: 8131, Loss: 0.44617706537246704, Accuracy: 0.8125, Computation time: 0.9151270389556885\n",
      "Step: 8132, Loss: 0.3215271234512329, Accuracy: 0.96875, Computation time: 0.873866081237793\n",
      "Step: 8133, Loss: 0.4937151372432709, Accuracy: 0.875, Computation time: 0.837803840637207\n",
      "Step: 8134, Loss: 0.8168495297431946, Accuracy: 0.8125, Computation time: 0.9029707908630371\n",
      "Step: 8135, Loss: 0.4188912510871887, Accuracy: 0.84375, Computation time: 0.8616278171539307\n",
      "Step: 8136, Loss: 0.39961665868759155, Accuracy: 0.8125, Computation time: 0.8169407844543457\n",
      "Step: 8137, Loss: 0.3827109932899475, Accuracy: 0.84375, Computation time: 0.7765779495239258\n",
      "Step: 8138, Loss: 0.3582751154899597, Accuracy: 0.84375, Computation time: 1.1343941688537598\n",
      "Step: 8139, Loss: 0.5301992297172546, Accuracy: 0.8125, Computation time: 0.8158941268920898\n",
      "Step: 8140, Loss: 0.4380621314048767, Accuracy: 0.8125, Computation time: 0.7748680114746094\n",
      "Step: 8141, Loss: 0.45538437366485596, Accuracy: 0.8125, Computation time: 0.8912529945373535\n",
      "Step: 8142, Loss: 0.7496728897094727, Accuracy: 0.75, Computation time: 1.210448980331421\n",
      "Step: 8143, Loss: 0.3894712030887604, Accuracy: 0.875, Computation time: 0.8036308288574219\n",
      "Step: 8144, Loss: 0.5920430421829224, Accuracy: 0.8125, Computation time: 0.9694209098815918\n",
      "Step: 8145, Loss: 0.506911039352417, Accuracy: 0.8125, Computation time: 0.8335850238800049\n",
      "Step: 8146, Loss: 0.3948042094707489, Accuracy: 0.90625, Computation time: 1.076097011566162\n",
      "Step: 8147, Loss: 0.42962223291397095, Accuracy: 0.84375, Computation time: 1.0269100666046143\n",
      "Step: 8148, Loss: 0.4227287769317627, Accuracy: 0.84375, Computation time: 0.8772530555725098\n",
      "Step: 8149, Loss: 0.2582642138004303, Accuracy: 0.90625, Computation time: 0.8797910213470459\n",
      "Step: 8150, Loss: 0.6937928199768066, Accuracy: 0.78125, Computation time: 0.8441958427429199\n",
      "Step: 8151, Loss: 0.5786721110343933, Accuracy: 0.875, Computation time: 0.8861591815948486\n",
      "Step: 8152, Loss: 0.5507040023803711, Accuracy: 0.84375, Computation time: 0.7713758945465088\n",
      "Step: 8153, Loss: 0.3785775303840637, Accuracy: 0.84375, Computation time: 0.9365670680999756\n",
      "Step: 8154, Loss: 0.3439161777496338, Accuracy: 0.875, Computation time: 1.4752607345581055\n",
      "Step: 8155, Loss: 0.7376664280891418, Accuracy: 0.75, Computation time: 0.9095730781555176\n",
      "Step: 8156, Loss: 0.6967582702636719, Accuracy: 0.78125, Computation time: 0.9716320037841797\n",
      "Step: 8157, Loss: 0.5054562091827393, Accuracy: 0.875, Computation time: 1.0341219902038574\n",
      "Step: 8158, Loss: 0.6169204115867615, Accuracy: 0.78125, Computation time: 0.8478400707244873\n",
      "Step: 8159, Loss: 0.32248613238334656, Accuracy: 0.90625, Computation time: 0.9863510131835938\n",
      "Step: 8160, Loss: 0.15707530081272125, Accuracy: 0.96875, Computation time: 0.8923909664154053\n",
      "Step: 8161, Loss: 0.6893102526664734, Accuracy: 0.8125, Computation time: 1.2517540454864502\n",
      "Step: 8162, Loss: 0.12147071212530136, Accuracy: 1.0, Computation time: 0.9313960075378418\n",
      "Step: 8163, Loss: 0.2660404145717621, Accuracy: 0.90625, Computation time: 0.8168990612030029\n",
      "Step: 8164, Loss: 0.5111554861068726, Accuracy: 0.84375, Computation time: 0.6972949504852295\n",
      "Step: 8165, Loss: 0.18239052593708038, Accuracy: 0.90625, Computation time: 0.8959622383117676\n",
      "Step: 8166, Loss: 0.9146807789802551, Accuracy: 0.875, Computation time: 0.8470678329467773\n",
      "Step: 8167, Loss: 0.28934183716773987, Accuracy: 0.875, Computation time: 0.8075230121612549\n",
      "Step: 8168, Loss: 0.8721092939376831, Accuracy: 0.65625, Computation time: 0.7444489002227783\n",
      "Step: 8169, Loss: 0.2893911898136139, Accuracy: 0.9375, Computation time: 0.8625121116638184\n",
      "Step: 8170, Loss: 0.8945611715316772, Accuracy: 0.78125, Computation time: 0.8753793239593506\n",
      "Step: 8171, Loss: 0.24879734218120575, Accuracy: 0.9375, Computation time: 0.9131660461425781\n",
      "Step: 8172, Loss: 0.22299377620220184, Accuracy: 0.9375, Computation time: 0.8396799564361572\n",
      "Step: 8173, Loss: 0.8349720239639282, Accuracy: 0.71875, Computation time: 0.983267068862915\n",
      "Step: 8174, Loss: 0.26953962445259094, Accuracy: 0.90625, Computation time: 0.8077120780944824\n",
      "Step: 8175, Loss: 0.35324764251708984, Accuracy: 0.90625, Computation time: 1.125103235244751\n",
      "Step: 8176, Loss: 0.8449770212173462, Accuracy: 0.78125, Computation time: 0.7841527462005615\n",
      "Step: 8177, Loss: 0.5589545965194702, Accuracy: 0.8125, Computation time: 0.7892920970916748\n",
      "Step: 8178, Loss: 0.3748721778392792, Accuracy: 0.875, Computation time: 0.8673160076141357\n",
      "Step: 8179, Loss: 0.4391917288303375, Accuracy: 0.875, Computation time: 0.8735120296478271\n",
      "Step: 8180, Loss: 0.7498710751533508, Accuracy: 0.8125, Computation time: 1.247941255569458\n",
      "Step: 8181, Loss: 0.7649731636047363, Accuracy: 0.78125, Computation time: 0.7982962131500244\n",
      "Step: 8182, Loss: 0.2982772886753082, Accuracy: 0.90625, Computation time: 0.86419677734375\n",
      "Step: 8183, Loss: 0.31820574402809143, Accuracy: 0.90625, Computation time: 1.6990139484405518\n",
      "Step: 8184, Loss: 0.3009198307991028, Accuracy: 0.9375, Computation time: 0.9038982391357422\n",
      "Step: 8185, Loss: 0.3276808559894562, Accuracy: 0.9375, Computation time: 0.9285891056060791\n",
      "Step: 8186, Loss: 0.5250899791717529, Accuracy: 0.84375, Computation time: 0.8494420051574707\n",
      "Step: 8187, Loss: 0.5964287519454956, Accuracy: 0.84375, Computation time: 0.8918130397796631\n",
      "Step: 8188, Loss: 0.566946268081665, Accuracy: 0.84375, Computation time: 0.8584940433502197\n",
      "Step: 8189, Loss: 0.41110652685165405, Accuracy: 0.84375, Computation time: 0.9115428924560547\n",
      "Step: 8190, Loss: 0.32889899611473083, Accuracy: 0.90625, Computation time: 0.8834869861602783\n",
      "Step: 8191, Loss: 0.5747532844543457, Accuracy: 0.84375, Computation time: 0.9614222049713135\n",
      "Step: 8192, Loss: 0.6941373348236084, Accuracy: 0.78125, Computation time: 0.8880178928375244\n",
      "Step: 8193, Loss: 0.42612358927726746, Accuracy: 0.875, Computation time: 0.8241150379180908\n",
      "Step: 8194, Loss: 0.34380707144737244, Accuracy: 0.875, Computation time: 0.8049318790435791\n",
      "Step: 8195, Loss: 0.7893643975257874, Accuracy: 0.8125, Computation time: 0.9442288875579834\n",
      "Step: 8196, Loss: 0.7316585183143616, Accuracy: 0.8125, Computation time: 0.8754050731658936\n",
      "Step: 8197, Loss: 0.2215830385684967, Accuracy: 0.9375, Computation time: 0.8991658687591553\n",
      "Step: 8198, Loss: 0.1377466470003128, Accuracy: 0.96875, Computation time: 0.7415339946746826\n",
      "Step: 8199, Loss: 0.34980565309524536, Accuracy: 0.90625, Computation time: 0.9505703449249268\n",
      "Step: 8200, Loss: 0.5349339246749878, Accuracy: 0.8125, Computation time: 1.0148789882659912\n",
      "Step: 8201, Loss: 0.6340053081512451, Accuracy: 0.875, Computation time: 0.9647669792175293\n",
      "Step: 8202, Loss: 0.47288742661476135, Accuracy: 0.875, Computation time: 0.8746738433837891\n",
      "Step: 8203, Loss: 0.27956491708755493, Accuracy: 0.90625, Computation time: 0.9122610092163086\n",
      "Step: 8204, Loss: 0.4147394895553589, Accuracy: 0.875, Computation time: 1.0463440418243408\n",
      "Step: 8205, Loss: 0.5771663188934326, Accuracy: 0.8125, Computation time: 0.8266329765319824\n",
      "Step: 8206, Loss: 0.3740002512931824, Accuracy: 0.90625, Computation time: 1.0139551162719727\n",
      "Step: 8207, Loss: 0.50545734167099, Accuracy: 0.875, Computation time: 1.012956142425537\n",
      "Step: 8208, Loss: 0.4583512842655182, Accuracy: 0.90625, Computation time: 1.1452960968017578\n",
      "Step: 8209, Loss: 0.2747466266155243, Accuracy: 0.90625, Computation time: 0.7435698509216309\n",
      "Step: 8210, Loss: 0.503077507019043, Accuracy: 0.84375, Computation time: 0.8269000053405762\n",
      "Step: 8211, Loss: 0.41089361906051636, Accuracy: 0.84375, Computation time: 0.9701457023620605\n",
      "Step: 8212, Loss: 0.3925130069255829, Accuracy: 0.875, Computation time: 1.2547781467437744\n",
      "Step: 8213, Loss: 0.3404395878314972, Accuracy: 0.90625, Computation time: 0.856503963470459\n",
      "Step: 8214, Loss: 0.5231848359107971, Accuracy: 0.84375, Computation time: 0.9498069286346436\n",
      "Step: 8215, Loss: 0.49291467666625977, Accuracy: 0.875, Computation time: 0.9938561916351318\n",
      "Step: 8216, Loss: 0.3075113892555237, Accuracy: 0.875, Computation time: 0.762470006942749\n",
      "Step: 8217, Loss: 0.6005368828773499, Accuracy: 0.78125, Computation time: 0.9504051208496094\n",
      "Step: 8218, Loss: 0.45993533730506897, Accuracy: 0.84375, Computation time: 0.9432079792022705\n",
      "Step: 8219, Loss: 0.7921757102012634, Accuracy: 0.78125, Computation time: 0.9747910499572754\n",
      "Step: 8220, Loss: 0.3411344885826111, Accuracy: 0.90625, Computation time: 0.8812069892883301\n",
      "Step: 8221, Loss: 0.6034344434738159, Accuracy: 0.8125, Computation time: 0.7260439395904541\n",
      "Step: 8222, Loss: 0.2480398416519165, Accuracy: 0.875, Computation time: 1.0043866634368896\n",
      "Step: 8223, Loss: 0.34339389204978943, Accuracy: 0.90625, Computation time: 0.8682889938354492\n",
      "Step: 8224, Loss: 0.6537801027297974, Accuracy: 0.875, Computation time: 0.8384220600128174\n",
      "Step: 8225, Loss: 0.31669116020202637, Accuracy: 0.96875, Computation time: 1.1111798286437988\n",
      "Step: 8226, Loss: 0.3944065272808075, Accuracy: 0.90625, Computation time: 0.8314869403839111\n",
      "Step: 8227, Loss: 0.06335864961147308, Accuracy: 1.0, Computation time: 0.7890582084655762\n",
      "Step: 8228, Loss: 0.7269708514213562, Accuracy: 0.8125, Computation time: 0.967249870300293\n",
      "Step: 8229, Loss: 0.9880553483963013, Accuracy: 0.78125, Computation time: 0.8012611865997314\n",
      "Step: 8230, Loss: 0.7065145969390869, Accuracy: 0.78125, Computation time: 1.1205928325653076\n",
      "Step: 8231, Loss: 0.3294505476951599, Accuracy: 0.84375, Computation time: 0.8226711750030518\n",
      "Step: 8232, Loss: 0.4780369699001312, Accuracy: 0.90625, Computation time: 1.1963152885437012\n",
      "Step: 8233, Loss: 0.37688302993774414, Accuracy: 0.90625, Computation time: 1.0647799968719482\n",
      "Step: 8234, Loss: 0.4265848398208618, Accuracy: 0.84375, Computation time: 0.9157419204711914\n",
      "Step: 8235, Loss: 0.24457058310508728, Accuracy: 0.90625, Computation time: 0.9457941055297852\n",
      "Step: 8236, Loss: 0.33450767397880554, Accuracy: 0.90625, Computation time: 1.012624740600586\n",
      "Step: 8237, Loss: 0.12687598168849945, Accuracy: 0.96875, Computation time: 0.9179058074951172\n",
      "Step: 8238, Loss: 0.7524162530899048, Accuracy: 0.75, Computation time: 0.8610107898712158\n",
      "Step: 8239, Loss: 0.3595774471759796, Accuracy: 0.9375, Computation time: 0.8968448638916016\n",
      "Step: 8240, Loss: 0.44936737418174744, Accuracy: 0.84375, Computation time: 0.9548897743225098\n",
      "Step: 8241, Loss: 0.41025617718696594, Accuracy: 0.875, Computation time: 1.5046641826629639\n",
      "Step: 8242, Loss: 0.4120415449142456, Accuracy: 0.84375, Computation time: 0.946753978729248\n",
      "Step: 8243, Loss: 0.2962602376937866, Accuracy: 0.875, Computation time: 0.9205019474029541\n",
      "Step: 8244, Loss: 0.48394647240638733, Accuracy: 0.8125, Computation time: 0.9456419944763184\n",
      "Step: 8245, Loss: 0.36432206630706787, Accuracy: 0.875, Computation time: 1.1260719299316406\n",
      "Step: 8246, Loss: 0.250843346118927, Accuracy: 0.96875, Computation time: 1.0519461631774902\n",
      "Step: 8247, Loss: 0.3813653886318207, Accuracy: 0.8125, Computation time: 1.1550018787384033\n",
      "Step: 8248, Loss: 0.3098447620868683, Accuracy: 0.96875, Computation time: 0.792517900466919\n",
      "Step: 8249, Loss: 0.5663924813270569, Accuracy: 0.875, Computation time: 0.9291749000549316\n",
      "Step: 8250, Loss: 0.3339850902557373, Accuracy: 0.9375, Computation time: 1.039933204650879\n",
      "Step: 8251, Loss: 0.2087472677230835, Accuracy: 0.96875, Computation time: 0.9250941276550293\n",
      "Step: 8252, Loss: 0.2550449073314667, Accuracy: 0.90625, Computation time: 0.8944840431213379\n",
      "Step: 8253, Loss: 0.5736111402511597, Accuracy: 0.8125, Computation time: 0.8572092056274414\n",
      "Step: 8254, Loss: 0.3480962812900543, Accuracy: 0.90625, Computation time: 0.7530701160430908\n",
      "Step: 8255, Loss: 0.32048526406288147, Accuracy: 0.90625, Computation time: 0.7953269481658936\n",
      "Step: 8256, Loss: 0.4062683582305908, Accuracy: 0.875, Computation time: 0.847797155380249\n",
      "Step: 8257, Loss: 0.23700544238090515, Accuracy: 0.90625, Computation time: 0.9072589874267578\n",
      "Step: 8258, Loss: 0.3763391673564911, Accuracy: 0.84375, Computation time: 1.0841951370239258\n",
      "Step: 8259, Loss: 0.9607409834861755, Accuracy: 0.71875, Computation time: 0.8917760848999023\n",
      "Step: 8260, Loss: 0.5228837728500366, Accuracy: 0.84375, Computation time: 1.4639592170715332\n",
      "Step: 8261, Loss: 0.353193074464798, Accuracy: 0.84375, Computation time: 0.8454580307006836\n",
      "Step: 8262, Loss: 0.3260636627674103, Accuracy: 0.9375, Computation time: 1.0587749481201172\n",
      "Step: 8263, Loss: 0.580199658870697, Accuracy: 0.9375, Computation time: 0.812993049621582\n",
      "Step: 8264, Loss: 0.6365986466407776, Accuracy: 0.78125, Computation time: 0.8773508071899414\n",
      "Step: 8265, Loss: 0.32034221291542053, Accuracy: 0.90625, Computation time: 0.9474010467529297\n",
      "Step: 8266, Loss: 0.38456496596336365, Accuracy: 0.90625, Computation time: 0.9346530437469482\n",
      "Step: 8267, Loss: 0.4507562518119812, Accuracy: 0.90625, Computation time: 1.0623259544372559\n",
      "Step: 8268, Loss: 0.18030893802642822, Accuracy: 0.9375, Computation time: 0.844890832901001\n",
      "Step: 8269, Loss: 0.2603267729282379, Accuracy: 0.90625, Computation time: 0.8509421348571777\n",
      "Step: 8270, Loss: 0.4683132767677307, Accuracy: 0.90625, Computation time: 1.563176155090332\n",
      "Step: 8271, Loss: 0.3052685558795929, Accuracy: 0.875, Computation time: 0.9789392948150635\n",
      "Step: 8272, Loss: 0.6272399425506592, Accuracy: 0.71875, Computation time: 0.9323749542236328\n",
      "Step: 8273, Loss: 0.26283061504364014, Accuracy: 0.875, Computation time: 0.812147855758667\n",
      "Step: 8274, Loss: 0.302174836397171, Accuracy: 0.90625, Computation time: 0.889359712600708\n",
      "Step: 8275, Loss: 0.2615700960159302, Accuracy: 0.90625, Computation time: 0.8033897876739502\n",
      "Step: 8276, Loss: 0.36236247420310974, Accuracy: 0.875, Computation time: 0.898015022277832\n",
      "Step: 8277, Loss: 0.8381876349449158, Accuracy: 0.78125, Computation time: 1.137787103652954\n",
      "Step: 8278, Loss: 0.7242259383201599, Accuracy: 0.75, Computation time: 0.7799129486083984\n",
      "Step: 8279, Loss: 0.4516603648662567, Accuracy: 0.78125, Computation time: 0.7932140827178955\n",
      "Step: 8280, Loss: 0.3305407464504242, Accuracy: 0.84375, Computation time: 1.0218160152435303\n",
      "Step: 8281, Loss: 0.2223612666130066, Accuracy: 0.9375, Computation time: 0.8443260192871094\n",
      "Step: 8282, Loss: 0.3355962932109833, Accuracy: 0.875, Computation time: 0.8089179992675781\n",
      "Step: 8283, Loss: 0.3832813501358032, Accuracy: 0.875, Computation time: 1.2957069873809814\n",
      "Step: 8284, Loss: 0.8165074586868286, Accuracy: 0.84375, Computation time: 0.9861018657684326\n",
      "Step: 8285, Loss: 0.26996976137161255, Accuracy: 0.84375, Computation time: 1.0882878303527832\n",
      "Step: 8286, Loss: 0.34433993697166443, Accuracy: 0.90625, Computation time: 1.0316710472106934\n",
      "Step: 8287, Loss: 0.07401391118764877, Accuracy: 1.0, Computation time: 0.7949790954589844\n",
      "Step: 8288, Loss: 0.5608990788459778, Accuracy: 0.875, Computation time: 0.809453010559082\n",
      "Step: 8289, Loss: 0.39761587977409363, Accuracy: 0.9375, Computation time: 0.8598651885986328\n",
      "Step: 8290, Loss: 0.23239766061306, Accuracy: 0.9375, Computation time: 0.9720146656036377\n",
      "Step: 8291, Loss: 0.28563597798347473, Accuracy: 0.875, Computation time: 0.9669618606567383\n",
      "Step: 8292, Loss: 0.23738838732242584, Accuracy: 0.90625, Computation time: 1.028935194015503\n",
      "Step: 8293, Loss: 1.1277090311050415, Accuracy: 0.8125, Computation time: 0.7254068851470947\n",
      "Step: 8294, Loss: 0.48364898562431335, Accuracy: 0.84375, Computation time: 0.7677021026611328\n",
      "Step: 8295, Loss: 0.6815007925033569, Accuracy: 0.78125, Computation time: 0.8811101913452148\n",
      "Step: 8296, Loss: 0.32260003685951233, Accuracy: 0.875, Computation time: 1.0532870292663574\n",
      "Step: 8297, Loss: 0.6436994075775146, Accuracy: 0.84375, Computation time: 0.7266030311584473\n",
      "Step: 8298, Loss: 0.4932979941368103, Accuracy: 0.875, Computation time: 0.8424220085144043\n",
      "Step: 8299, Loss: 0.9662140011787415, Accuracy: 0.625, Computation time: 1.8768410682678223\n",
      "Step: 8300, Loss: 0.4515553414821625, Accuracy: 0.875, Computation time: 0.8633718490600586\n",
      "Step: 8301, Loss: 0.5169169902801514, Accuracy: 0.8125, Computation time: 1.1474559307098389\n",
      "Step: 8302, Loss: 0.5907377004623413, Accuracy: 0.84375, Computation time: 0.8473069667816162\n",
      "Step: 8303, Loss: 0.23454326391220093, Accuracy: 0.875, Computation time: 1.07973313331604\n",
      "Step: 8304, Loss: 0.3296900689601898, Accuracy: 0.875, Computation time: 1.0562269687652588\n",
      "Step: 8305, Loss: 0.40403518080711365, Accuracy: 0.84375, Computation time: 0.9085686206817627\n",
      "Step: 8306, Loss: 1.1203179359436035, Accuracy: 0.6875, Computation time: 0.8884012699127197\n",
      "Step: 8307, Loss: 0.1433025300502777, Accuracy: 0.96875, Computation time: 0.9378879070281982\n",
      "Step: 8308, Loss: 0.7455833554267883, Accuracy: 0.75, Computation time: 1.0452561378479004\n",
      "Step: 8309, Loss: 0.3416783809661865, Accuracy: 0.90625, Computation time: 1.1463239192962646\n",
      "Step: 8310, Loss: 0.7606250643730164, Accuracy: 0.875, Computation time: 1.0693209171295166\n",
      "Step: 8311, Loss: 0.3391008973121643, Accuracy: 0.875, Computation time: 0.9918689727783203\n",
      "Step: 8312, Loss: 0.4249296188354492, Accuracy: 0.875, Computation time: 0.9124197959899902\n",
      "Step: 8313, Loss: 0.5971093773841858, Accuracy: 0.84375, Computation time: 0.9698128700256348\n",
      "Step: 8314, Loss: 0.2962622344493866, Accuracy: 0.90625, Computation time: 0.9221110343933105\n",
      "Step: 8315, Loss: 0.42438897490501404, Accuracy: 0.90625, Computation time: 1.117563009262085\n",
      "Step: 8316, Loss: 0.39561620354652405, Accuracy: 0.875, Computation time: 0.9339189529418945\n",
      "Step: 8317, Loss: 0.2742709815502167, Accuracy: 0.9375, Computation time: 0.9127299785614014\n",
      "Step: 8318, Loss: 0.3488650321960449, Accuracy: 0.875, Computation time: 1.6982910633087158\n",
      "Step: 8319, Loss: 0.7865238785743713, Accuracy: 0.84375, Computation time: 0.9749507904052734\n",
      "Step: 8320, Loss: 0.5395680665969849, Accuracy: 0.75, Computation time: 1.0963120460510254\n",
      "Step: 8321, Loss: 0.5696535706520081, Accuracy: 0.84375, Computation time: 0.9453623294830322\n",
      "Step: 8322, Loss: 0.4178657531738281, Accuracy: 0.875, Computation time: 1.0347890853881836\n",
      "Step: 8323, Loss: 0.29491758346557617, Accuracy: 0.875, Computation time: 0.75248122215271\n",
      "Step: 8324, Loss: 0.4835771918296814, Accuracy: 0.78125, Computation time: 0.9533648490905762\n",
      "Step: 8325, Loss: 0.4017513394355774, Accuracy: 0.90625, Computation time: 1.4913451671600342\n",
      "Step: 8326, Loss: 0.35541069507598877, Accuracy: 0.875, Computation time: 0.8507487773895264\n",
      "Step: 8327, Loss: 0.716234028339386, Accuracy: 0.8125, Computation time: 1.0504801273345947\n",
      "Step: 8328, Loss: 0.7065234184265137, Accuracy: 0.78125, Computation time: 1.1270859241485596\n",
      "Step: 8329, Loss: 0.23279574513435364, Accuracy: 0.9375, Computation time: 0.7626850605010986\n",
      "Step: 8330, Loss: 0.41824623942375183, Accuracy: 0.84375, Computation time: 0.8043880462646484\n",
      "Step: 8331, Loss: 0.7335802912712097, Accuracy: 0.875, Computation time: 1.1310608386993408\n",
      "Step: 8332, Loss: 0.5788614153862, Accuracy: 0.8125, Computation time: 1.0501010417938232\n",
      "Step: 8333, Loss: 0.4192075729370117, Accuracy: 0.90625, Computation time: 0.8391170501708984\n",
      "Step: 8334, Loss: 0.41942307353019714, Accuracy: 0.84375, Computation time: 0.9001431465148926\n",
      "Step: 8335, Loss: 0.4008893370628357, Accuracy: 0.84375, Computation time: 1.0319240093231201\n",
      "Step: 8336, Loss: 0.5834404826164246, Accuracy: 0.84375, Computation time: 0.8936009407043457\n",
      "Step: 8337, Loss: 0.6803597211837769, Accuracy: 0.8125, Computation time: 0.9439980983734131\n",
      "Step: 8338, Loss: 0.45095303654670715, Accuracy: 0.875, Computation time: 0.8292109966278076\n",
      "Step: 8339, Loss: 0.6553657054901123, Accuracy: 0.78125, Computation time: 0.7508530616760254\n",
      "Step: 8340, Loss: 0.4447541832923889, Accuracy: 0.875, Computation time: 1.048140048980713\n",
      "Step: 8341, Loss: 0.17926958203315735, Accuracy: 1.0, Computation time: 0.852590799331665\n",
      "Step: 8342, Loss: 0.4958750903606415, Accuracy: 0.78125, Computation time: 0.8093690872192383\n",
      "Step: 8343, Loss: 0.33716830611228943, Accuracy: 0.90625, Computation time: 0.8325538635253906\n",
      "Step: 8344, Loss: 0.27568918466567993, Accuracy: 0.96875, Computation time: 0.9770560264587402\n",
      "Step: 8345, Loss: 0.34169167280197144, Accuracy: 0.84375, Computation time: 0.9206750392913818\n",
      "Step: 8346, Loss: 0.25226280093193054, Accuracy: 0.9375, Computation time: 0.8161699771881104\n",
      "Step: 8347, Loss: 0.40557244420051575, Accuracy: 0.90625, Computation time: 0.8389279842376709\n",
      "Step: 8348, Loss: 0.6220753192901611, Accuracy: 0.84375, Computation time: 0.7640690803527832\n",
      "Step: 8349, Loss: 0.37550756335258484, Accuracy: 0.875, Computation time: 0.9691917896270752\n",
      "Step: 8350, Loss: 0.3669509291648865, Accuracy: 0.90625, Computation time: 0.8541841506958008\n",
      "Step: 8351, Loss: 0.3949929475784302, Accuracy: 0.875, Computation time: 0.8501119613647461\n",
      "Step: 8352, Loss: 0.7692581415176392, Accuracy: 0.84375, Computation time: 1.2770519256591797\n",
      "Step: 8353, Loss: 0.5303400754928589, Accuracy: 0.84375, Computation time: 0.8943119049072266\n",
      "Step: 8354, Loss: 0.46508359909057617, Accuracy: 0.875, Computation time: 0.897183895111084\n",
      "Step: 8355, Loss: 0.7827668190002441, Accuracy: 0.78125, Computation time: 1.282278060913086\n",
      "Step: 8356, Loss: 0.35143694281578064, Accuracy: 0.875, Computation time: 0.9566600322723389\n",
      "Step: 8357, Loss: 0.48766788840293884, Accuracy: 0.8125, Computation time: 0.9126601219177246\n",
      "Step: 8358, Loss: 0.4029620885848999, Accuracy: 0.875, Computation time: 1.0198967456817627\n",
      "Step: 8359, Loss: 0.44943132996559143, Accuracy: 0.875, Computation time: 0.8133456707000732\n",
      "Step: 8360, Loss: 0.4546549916267395, Accuracy: 0.875, Computation time: 0.8259329795837402\n",
      "Step: 8361, Loss: 0.4522126019001007, Accuracy: 0.84375, Computation time: 1.048011064529419\n",
      "Step: 8362, Loss: 0.5891577005386353, Accuracy: 0.71875, Computation time: 0.8682370185852051\n",
      "Step: 8363, Loss: 0.40488922595977783, Accuracy: 0.90625, Computation time: 1.0546939373016357\n",
      "Step: 8364, Loss: 0.25290098786354065, Accuracy: 0.9375, Computation time: 0.8958139419555664\n",
      "Step: 8365, Loss: 0.48872655630111694, Accuracy: 0.8125, Computation time: 1.050567865371704\n",
      "Step: 8366, Loss: 0.6641241312026978, Accuracy: 0.78125, Computation time: 0.7687678337097168\n",
      "Step: 8367, Loss: 0.3391285538673401, Accuracy: 0.875, Computation time: 1.0488617420196533\n",
      "Step: 8368, Loss: 0.28745460510253906, Accuracy: 0.875, Computation time: 0.8490829467773438\n",
      "Step: 8369, Loss: 0.2897500991821289, Accuracy: 0.90625, Computation time: 0.8425719738006592\n",
      "Step: 8370, Loss: 0.2748901844024658, Accuracy: 0.9375, Computation time: 0.8398151397705078\n",
      "Step: 8371, Loss: 0.43393486738204956, Accuracy: 0.96875, Computation time: 0.8640413284301758\n",
      "Step: 8372, Loss: 0.31759220361709595, Accuracy: 0.90625, Computation time: 0.9655971527099609\n",
      "Step: 8373, Loss: 0.2420663684606552, Accuracy: 0.96875, Computation time: 1.323800802230835\n",
      "Step: 8374, Loss: 0.37645870447158813, Accuracy: 0.875, Computation time: 0.8771090507507324\n",
      "Step: 8375, Loss: 0.20994585752487183, Accuracy: 0.9375, Computation time: 0.8239240646362305\n",
      "Step: 8376, Loss: 0.39932262897491455, Accuracy: 0.84375, Computation time: 0.7348310947418213\n",
      "Step: 8377, Loss: 0.1251743584871292, Accuracy: 1.0, Computation time: 0.9158852100372314\n",
      "Step: 8378, Loss: 0.6249828338623047, Accuracy: 0.78125, Computation time: 0.882612943649292\n",
      "Step: 8379, Loss: 0.3544315993785858, Accuracy: 0.9375, Computation time: 0.805311918258667\n",
      "Step: 8380, Loss: 0.7402815222740173, Accuracy: 0.75, Computation time: 1.0403411388397217\n",
      "Step: 8381, Loss: 0.37511971592903137, Accuracy: 0.9375, Computation time: 1.0037832260131836\n",
      "Step: 8382, Loss: 0.4640764594078064, Accuracy: 0.875, Computation time: 0.774055004119873\n",
      "Step: 8383, Loss: 0.37271976470947266, Accuracy: 0.78125, Computation time: 1.4796888828277588\n",
      "Step: 8384, Loss: 0.48334282636642456, Accuracy: 0.8125, Computation time: 0.9263949394226074\n",
      "Step: 8385, Loss: 0.21696437895298004, Accuracy: 0.90625, Computation time: 0.7847602367401123\n",
      "Step: 8386, Loss: 0.26678773760795593, Accuracy: 0.96875, Computation time: 1.0970418453216553\n",
      "Step: 8387, Loss: 0.3250480592250824, Accuracy: 0.84375, Computation time: 0.8113667964935303\n",
      "Step: 8388, Loss: 0.14056937396526337, Accuracy: 1.0, Computation time: 0.9239201545715332\n",
      "Step: 8389, Loss: 0.2499934434890747, Accuracy: 0.875, Computation time: 0.8135850429534912\n",
      "Step: 8390, Loss: 0.9869354367256165, Accuracy: 0.625, Computation time: 0.8941619396209717\n",
      "Step: 8391, Loss: 0.368328332901001, Accuracy: 0.90625, Computation time: 0.9804332256317139\n",
      "Step: 8392, Loss: 0.3095250427722931, Accuracy: 0.875, Computation time: 0.9194843769073486\n",
      "Step: 8393, Loss: 0.5443578958511353, Accuracy: 0.84375, Computation time: 0.9633820056915283\n",
      "Step: 8394, Loss: 0.439554363489151, Accuracy: 0.84375, Computation time: 1.0858039855957031\n",
      "Step: 8395, Loss: 0.34893742203712463, Accuracy: 0.96875, Computation time: 0.8108022212982178\n",
      "Step: 8396, Loss: 0.581206202507019, Accuracy: 0.8125, Computation time: 0.7791292667388916\n",
      "Step: 8397, Loss: 0.24779589474201202, Accuracy: 0.90625, Computation time: 0.9432361125946045\n",
      "Step: 8398, Loss: 1.2458916902542114, Accuracy: 0.75, Computation time: 1.013416051864624\n",
      "Step: 8399, Loss: 0.21126581728458405, Accuracy: 0.9375, Computation time: 0.9011666774749756\n",
      "Step: 8400, Loss: 0.8016921281814575, Accuracy: 0.78125, Computation time: 0.843113899230957\n",
      "Step: 8401, Loss: 0.6463347673416138, Accuracy: 0.84375, Computation time: 0.8548688888549805\n",
      "Step: 8402, Loss: 0.37530288100242615, Accuracy: 0.84375, Computation time: 1.0469460487365723\n",
      "Step: 8403, Loss: 0.4144483208656311, Accuracy: 0.84375, Computation time: 0.8064291477203369\n",
      "Step: 8404, Loss: 0.4943486154079437, Accuracy: 0.875, Computation time: 1.165747880935669\n",
      "Step: 8405, Loss: 0.45644456148147583, Accuracy: 0.8125, Computation time: 0.8385441303253174\n",
      "Step: 8406, Loss: 0.24723802506923676, Accuracy: 0.9375, Computation time: 0.7714810371398926\n",
      "Step: 8407, Loss: 0.48557180166244507, Accuracy: 0.84375, Computation time: 0.9026031494140625\n",
      "Step: 8408, Loss: 1.0726567506790161, Accuracy: 0.71875, Computation time: 1.0266189575195312\n",
      "Step: 8409, Loss: 0.514375627040863, Accuracy: 0.84375, Computation time: 0.8919579982757568\n",
      "Step: 8410, Loss: 0.2575908303260803, Accuracy: 0.96875, Computation time: 0.805945873260498\n",
      "Step: 8411, Loss: 1.1470540761947632, Accuracy: 0.75, Computation time: 1.1072959899902344\n",
      "Step: 8412, Loss: 0.24265915155410767, Accuracy: 0.90625, Computation time: 1.7756502628326416\n",
      "Step: 8413, Loss: 0.44008782505989075, Accuracy: 0.84375, Computation time: 0.9752700328826904\n",
      "Step: 8414, Loss: 0.16586101055145264, Accuracy: 0.96875, Computation time: 0.8207716941833496\n",
      "Step: 8415, Loss: 0.47360432147979736, Accuracy: 0.84375, Computation time: 0.8104090690612793\n",
      "Step: 8416, Loss: 0.2425750195980072, Accuracy: 0.90625, Computation time: 0.8948690891265869\n",
      "Step: 8417, Loss: 0.33927688002586365, Accuracy: 0.875, Computation time: 0.8440899848937988\n",
      "Step: 8418, Loss: 0.48620715737342834, Accuracy: 0.90625, Computation time: 0.8044371604919434\n",
      "Step: 8419, Loss: 0.5379400253295898, Accuracy: 0.84375, Computation time: 0.9524819850921631\n",
      "Step: 8420, Loss: 0.1226557269692421, Accuracy: 0.96875, Computation time: 0.7740027904510498\n",
      "Step: 8421, Loss: 0.5361635684967041, Accuracy: 0.8125, Computation time: 0.8480288982391357\n",
      "Step: 8422, Loss: 0.6470845341682434, Accuracy: 0.90625, Computation time: 0.9745378494262695\n",
      "Step: 8423, Loss: 0.8785943388938904, Accuracy: 0.78125, Computation time: 0.8122498989105225\n",
      "Step: 8424, Loss: 0.34384483098983765, Accuracy: 0.90625, Computation time: 1.0594518184661865\n",
      "Step: 8425, Loss: 0.5859172940254211, Accuracy: 0.84375, Computation time: 0.9444143772125244\n",
      "Step: 8426, Loss: 0.540049135684967, Accuracy: 0.875, Computation time: 1.1511690616607666\n",
      "Step: 8427, Loss: 0.29581499099731445, Accuracy: 0.9375, Computation time: 0.9284591674804688\n",
      "Step: 8428, Loss: 0.6073459982872009, Accuracy: 0.8125, Computation time: 0.8879129886627197\n",
      "Step: 8429, Loss: 0.34534958004951477, Accuracy: 0.875, Computation time: 0.7066929340362549\n",
      "Step: 8430, Loss: 0.45646223425865173, Accuracy: 0.84375, Computation time: 0.9376649856567383\n",
      "Step: 8431, Loss: 0.5302833318710327, Accuracy: 0.84375, Computation time: 1.0650577545166016\n",
      "Step: 8432, Loss: 0.3662881851196289, Accuracy: 0.8125, Computation time: 0.8524448871612549\n",
      "Step: 8433, Loss: 0.730337917804718, Accuracy: 0.8125, Computation time: 0.9151320457458496\n",
      "Step: 8434, Loss: 0.5613757967948914, Accuracy: 0.84375, Computation time: 1.4310898780822754\n",
      "Step: 8435, Loss: 0.3250410258769989, Accuracy: 0.875, Computation time: 1.2813470363616943\n",
      "Step: 8436, Loss: 0.7032705545425415, Accuracy: 0.6875, Computation time: 1.0049400329589844\n",
      "Step: 8437, Loss: 0.10590021312236786, Accuracy: 0.96875, Computation time: 0.917647123336792\n",
      "Step: 8438, Loss: 0.23230071365833282, Accuracy: 0.90625, Computation time: 0.792853832244873\n",
      "Step: 8439, Loss: 0.3829995095729828, Accuracy: 0.875, Computation time: 0.8771030902862549\n",
      "Step: 8440, Loss: 0.36770135164260864, Accuracy: 0.9375, Computation time: 0.836076021194458\n",
      "Step: 8441, Loss: 0.7478234171867371, Accuracy: 0.8125, Computation time: 1.2780237197875977\n",
      "Step: 8442, Loss: 0.38671204447746277, Accuracy: 0.875, Computation time: 1.0650417804718018\n",
      "Step: 8443, Loss: 0.4898570775985718, Accuracy: 0.875, Computation time: 0.833136796951294\n",
      "Step: 8444, Loss: 0.3371019661426544, Accuracy: 0.84375, Computation time: 1.051306962966919\n",
      "Step: 8445, Loss: 0.21205691993236542, Accuracy: 0.9375, Computation time: 1.103363037109375\n",
      "Step: 8446, Loss: 0.5644930601119995, Accuracy: 0.84375, Computation time: 0.9087989330291748\n",
      "Step: 8447, Loss: 0.3479490578174591, Accuracy: 0.8125, Computation time: 0.9248230457305908\n",
      "Step: 8448, Loss: 0.26739227771759033, Accuracy: 0.9375, Computation time: 0.8390672206878662\n",
      "Step: 8449, Loss: 0.6012513637542725, Accuracy: 0.84375, Computation time: 0.855571985244751\n",
      "Step: 8450, Loss: 0.2854240834712982, Accuracy: 0.9375, Computation time: 0.7525339126586914\n",
      "Step: 8451, Loss: 0.18250669538974762, Accuracy: 0.96875, Computation time: 1.0168330669403076\n",
      "Step: 8452, Loss: 0.8130600452423096, Accuracy: 0.75, Computation time: 0.9204909801483154\n",
      "Step: 8453, Loss: 0.22533880174160004, Accuracy: 0.96875, Computation time: 1.0646400451660156\n",
      "Step: 8454, Loss: 0.35037076473236084, Accuracy: 0.9375, Computation time: 0.8972322940826416\n",
      "Step: 8455, Loss: 0.1750509887933731, Accuracy: 1.0, Computation time: 0.8881411552429199\n",
      "Step: 8456, Loss: 0.4376865327358246, Accuracy: 0.84375, Computation time: 0.9114871025085449\n",
      "Step: 8457, Loss: 0.366661936044693, Accuracy: 0.90625, Computation time: 0.8993000984191895\n",
      "Step: 8458, Loss: 0.39231085777282715, Accuracy: 0.875, Computation time: 0.877709150314331\n",
      "Step: 8459, Loss: 0.4743858575820923, Accuracy: 0.84375, Computation time: 0.8949220180511475\n",
      "Step: 8460, Loss: 0.3250408172607422, Accuracy: 0.90625, Computation time: 1.0286309719085693\n",
      "Step: 8461, Loss: 0.14273060858249664, Accuracy: 0.96875, Computation time: 0.9545400142669678\n",
      "Step: 8462, Loss: 0.6706684827804565, Accuracy: 0.78125, Computation time: 0.8603620529174805\n",
      "Step: 8463, Loss: 0.27088797092437744, Accuracy: 0.9375, Computation time: 0.9089782238006592\n",
      "Step: 8464, Loss: 0.4114569425582886, Accuracy: 0.90625, Computation time: 0.9426860809326172\n",
      "Step: 8465, Loss: 0.20512261986732483, Accuracy: 0.96875, Computation time: 1.0249719619750977\n",
      "Step: 8466, Loss: 0.25876927375793457, Accuracy: 0.9375, Computation time: 0.9491548538208008\n",
      "Step: 8467, Loss: 0.42656710743904114, Accuracy: 0.90625, Computation time: 0.8966689109802246\n",
      "Step: 8468, Loss: 0.3243248760700226, Accuracy: 0.90625, Computation time: 1.1953887939453125\n",
      "Step: 8469, Loss: 0.2594718933105469, Accuracy: 0.90625, Computation time: 1.3810639381408691\n",
      "Step: 8470, Loss: 0.2756707966327667, Accuracy: 0.90625, Computation time: 0.9716639518737793\n",
      "Step: 8471, Loss: 0.2924621105194092, Accuracy: 0.90625, Computation time: 0.9870650768280029\n",
      "Step: 8472, Loss: 0.5706444978713989, Accuracy: 0.78125, Computation time: 0.9734852313995361\n",
      "Step: 8473, Loss: 0.4151233732700348, Accuracy: 0.8125, Computation time: 0.8997759819030762\n",
      "Step: 8474, Loss: 0.3605788052082062, Accuracy: 0.90625, Computation time: 1.012977123260498\n",
      "Step: 8475, Loss: 0.35338321328163147, Accuracy: 0.875, Computation time: 0.7856500148773193\n",
      "Step: 8476, Loss: 0.6571725010871887, Accuracy: 0.84375, Computation time: 0.9722731113433838\n",
      "Step: 8477, Loss: 0.5836611390113831, Accuracy: 0.75, Computation time: 0.8893649578094482\n",
      "Step: 8478, Loss: 0.4386426508426666, Accuracy: 0.84375, Computation time: 0.9924502372741699\n",
      "Step: 8479, Loss: 0.11297861486673355, Accuracy: 0.96875, Computation time: 0.9553079605102539\n",
      "Step: 8480, Loss: 0.29436084628105164, Accuracy: 0.90625, Computation time: 0.8877549171447754\n",
      "Step: 8481, Loss: 0.4677160680294037, Accuracy: 0.84375, Computation time: 0.9151408672332764\n",
      "Step: 8482, Loss: 0.21745362877845764, Accuracy: 0.9375, Computation time: 0.8032670021057129\n",
      "Step: 8483, Loss: 0.3007768392562866, Accuracy: 0.875, Computation time: 0.8384370803833008\n",
      "Step: 8484, Loss: 0.3189316391944885, Accuracy: 0.9375, Computation time: 1.0744457244873047\n",
      "Step: 8485, Loss: 0.41479724645614624, Accuracy: 0.875, Computation time: 1.0844531059265137\n",
      "Step: 8486, Loss: 0.19838567078113556, Accuracy: 0.9375, Computation time: 1.133430004119873\n",
      "Step: 8487, Loss: 0.17710907757282257, Accuracy: 0.9375, Computation time: 0.8121311664581299\n",
      "Step: 8488, Loss: 0.5296450853347778, Accuracy: 0.90625, Computation time: 1.024838924407959\n",
      "Step: 8489, Loss: 0.5093284845352173, Accuracy: 0.875, Computation time: 0.8626470565795898\n",
      "Step: 8490, Loss: 0.23349222540855408, Accuracy: 0.96875, Computation time: 0.8767609596252441\n",
      "Step: 8491, Loss: 0.11286752671003342, Accuracy: 0.96875, Computation time: 0.8708090782165527\n",
      "Step: 8492, Loss: 0.21762901544570923, Accuracy: 0.96875, Computation time: 0.8415522575378418\n",
      "Step: 8493, Loss: 0.2984561622142792, Accuracy: 0.9375, Computation time: 0.8191070556640625\n",
      "Step: 8494, Loss: 0.2754761576652527, Accuracy: 0.90625, Computation time: 0.9557890892028809\n",
      "Step: 8495, Loss: 0.0681953951716423, Accuracy: 0.96875, Computation time: 0.8867921829223633\n",
      "Step: 8496, Loss: 0.34542301297187805, Accuracy: 0.875, Computation time: 0.9846971035003662\n",
      "Step: 8497, Loss: 0.6962300539016724, Accuracy: 0.84375, Computation time: 2.7566299438476562\n",
      "Step: 8498, Loss: 0.5697673559188843, Accuracy: 0.8125, Computation time: 0.9305751323699951\n",
      "Step: 8499, Loss: 0.07329075783491135, Accuracy: 1.0, Computation time: 0.8118348121643066\n",
      "Step: 8500, Loss: 0.22763536870479584, Accuracy: 0.90625, Computation time: 0.8552629947662354\n",
      "Step: 8501, Loss: 0.3673727214336395, Accuracy: 0.9375, Computation time: 0.8684060573577881\n",
      "Step: 8502, Loss: 0.4126371741294861, Accuracy: 0.875, Computation time: 0.9810690879821777\n",
      "Step: 8503, Loss: 0.18227414786815643, Accuracy: 0.96875, Computation time: 0.758228063583374\n",
      "Step: 8504, Loss: 0.25462785363197327, Accuracy: 0.90625, Computation time: 1.13979172706604\n",
      "Step: 8505, Loss: 0.5833072662353516, Accuracy: 0.84375, Computation time: 0.8991940021514893\n",
      "Step: 8506, Loss: 0.5307198166847229, Accuracy: 0.875, Computation time: 1.211435079574585\n",
      "Step: 8507, Loss: 0.5743433237075806, Accuracy: 0.875, Computation time: 0.8332352638244629\n",
      "Step: 8508, Loss: 0.3756489157676697, Accuracy: 0.84375, Computation time: 1.0339231491088867\n",
      "Step: 8509, Loss: 0.34487348794937134, Accuracy: 0.875, Computation time: 0.8326718807220459\n",
      "Step: 8510, Loss: 0.9721360802650452, Accuracy: 0.75, Computation time: 1.6211597919464111\n",
      "Step: 8511, Loss: 0.1442105770111084, Accuracy: 0.96875, Computation time: 0.8647730350494385\n",
      "Step: 8512, Loss: 0.3493364155292511, Accuracy: 0.90625, Computation time: 0.8608791828155518\n",
      "Step: 8513, Loss: 0.3328370749950409, Accuracy: 0.90625, Computation time: 0.85996413230896\n",
      "Step: 8514, Loss: 0.2847576439380646, Accuracy: 0.9375, Computation time: 0.8892049789428711\n",
      "Step: 8515, Loss: 0.3721773326396942, Accuracy: 0.9375, Computation time: 1.0332629680633545\n",
      "Step: 8516, Loss: 0.2065119594335556, Accuracy: 0.9375, Computation time: 0.9221429824829102\n",
      "Step: 8517, Loss: 0.24216648936271667, Accuracy: 0.9375, Computation time: 0.8599810600280762\n",
      "Step: 8518, Loss: 0.47662219405174255, Accuracy: 0.9375, Computation time: 0.9159669876098633\n",
      "Step: 8519, Loss: 0.2616463303565979, Accuracy: 0.9375, Computation time: 1.004957914352417\n",
      "Step: 8520, Loss: 0.35621193051338196, Accuracy: 0.875, Computation time: 0.8894579410552979\n",
      "Step: 8521, Loss: 0.24280594289302826, Accuracy: 0.90625, Computation time: 0.848463773727417\n",
      "Step: 8522, Loss: 0.358862042427063, Accuracy: 0.875, Computation time: 0.9787187576293945\n",
      "Step: 8523, Loss: 0.44024476408958435, Accuracy: 0.8125, Computation time: 0.8808550834655762\n",
      "Step: 8524, Loss: 0.3925419747829437, Accuracy: 0.875, Computation time: 0.9486329555511475\n",
      "Step: 8525, Loss: 0.29574981331825256, Accuracy: 0.875, Computation time: 1.3540308475494385\n",
      "Step: 8526, Loss: 0.2452239990234375, Accuracy: 0.9375, Computation time: 0.9101870059967041\n",
      "Step: 8527, Loss: 0.25384950637817383, Accuracy: 0.90625, Computation time: 0.9412281513214111\n",
      "Step: 8528, Loss: 0.4276266098022461, Accuracy: 0.875, Computation time: 0.9485211372375488\n",
      "Step: 8529, Loss: 0.8462469577789307, Accuracy: 0.75, Computation time: 1.088487148284912\n",
      "Step: 8530, Loss: 0.26849275827407837, Accuracy: 0.84375, Computation time: 0.9095139503479004\n",
      "Step: 8531, Loss: 0.40084928274154663, Accuracy: 0.84375, Computation time: 0.8507452011108398\n",
      "Step: 8532, Loss: 0.323386549949646, Accuracy: 0.90625, Computation time: 1.359234094619751\n",
      "Step: 8533, Loss: 0.5095279812812805, Accuracy: 0.875, Computation time: 0.9041600227355957\n",
      "Step: 8534, Loss: 0.14806552231311798, Accuracy: 1.0, Computation time: 0.8604402542114258\n",
      "Step: 8535, Loss: 0.21798354387283325, Accuracy: 0.96875, Computation time: 0.910567045211792\n",
      "Step: 8536, Loss: 0.3948272168636322, Accuracy: 0.875, Computation time: 1.027266025543213\n",
      "Step: 8537, Loss: 0.2682344615459442, Accuracy: 0.84375, Computation time: 1.0792067050933838\n",
      "Step: 8538, Loss: 0.22617104649543762, Accuracy: 0.9375, Computation time: 0.8836688995361328\n",
      "Step: 8539, Loss: 0.3569999933242798, Accuracy: 0.875, Computation time: 1.0385210514068604\n",
      "Step: 8540, Loss: 0.5465747714042664, Accuracy: 0.8125, Computation time: 0.8603408336639404\n",
      "Step: 8541, Loss: 0.27550777792930603, Accuracy: 0.90625, Computation time: 0.9558749198913574\n",
      "Step: 8542, Loss: 0.327633798122406, Accuracy: 0.90625, Computation time: 0.9771289825439453\n",
      "Step: 8543, Loss: 0.4780367910861969, Accuracy: 0.875, Computation time: 1.0664992332458496\n",
      "Step: 8544, Loss: 0.27688807249069214, Accuracy: 0.875, Computation time: 0.8904592990875244\n",
      "Step: 8545, Loss: 0.5513460636138916, Accuracy: 0.84375, Computation time: 0.9204399585723877\n",
      "Step: 8546, Loss: 0.20109030604362488, Accuracy: 0.9375, Computation time: 0.9902987480163574\n",
      "Step: 8547, Loss: 0.3481297791004181, Accuracy: 0.90625, Computation time: 0.8578979969024658\n",
      "Step: 8548, Loss: 0.7174361944198608, Accuracy: 0.78125, Computation time: 0.9464902877807617\n",
      "Step: 8549, Loss: 0.23980814218521118, Accuracy: 0.90625, Computation time: 1.0469768047332764\n",
      "Step: 8550, Loss: 0.26215213537216187, Accuracy: 0.875, Computation time: 0.8873422145843506\n",
      "Step: 8551, Loss: 0.43512481451034546, Accuracy: 0.8125, Computation time: 0.9482581615447998\n",
      "Step: 8552, Loss: 0.28636258840560913, Accuracy: 0.875, Computation time: 0.8355269432067871\n",
      "Step: 8553, Loss: 0.46919411420822144, Accuracy: 0.875, Computation time: 0.7745389938354492\n",
      "Step: 8554, Loss: 0.32693713903427124, Accuracy: 0.84375, Computation time: 1.420912742614746\n",
      "Step: 8555, Loss: 0.8224189877510071, Accuracy: 0.8125, Computation time: 0.8705599308013916\n",
      "Step: 8556, Loss: 0.6044859886169434, Accuracy: 0.8125, Computation time: 1.5117676258087158\n",
      "Step: 8557, Loss: 0.41977307200431824, Accuracy: 0.84375, Computation time: 0.788567066192627\n",
      "Step: 8558, Loss: 0.39723536372184753, Accuracy: 0.875, Computation time: 0.881209135055542\n",
      "Step: 8559, Loss: 0.3993566036224365, Accuracy: 0.90625, Computation time: 0.83980393409729\n",
      "Step: 8560, Loss: 0.5344918370246887, Accuracy: 0.90625, Computation time: 0.987675666809082\n",
      "Step: 8561, Loss: 0.5806451439857483, Accuracy: 0.8125, Computation time: 0.932499885559082\n",
      "Step: 8562, Loss: 0.47718676924705505, Accuracy: 0.90625, Computation time: 1.0692689418792725\n",
      "Step: 8563, Loss: 1.124767541885376, Accuracy: 0.8125, Computation time: 1.2967610359191895\n",
      "Step: 8564, Loss: 0.428069531917572, Accuracy: 0.90625, Computation time: 1.040781021118164\n",
      "Step: 8565, Loss: 0.4558922350406647, Accuracy: 0.90625, Computation time: 0.7587602138519287\n",
      "Step: 8566, Loss: 0.25708332657814026, Accuracy: 0.9375, Computation time: 1.265671968460083\n",
      "Step: 8567, Loss: 0.418094664812088, Accuracy: 0.8125, Computation time: 0.8916149139404297\n",
      "Step: 8568, Loss: 0.2825153172016144, Accuracy: 0.90625, Computation time: 0.9504120349884033\n",
      "Step: 8569, Loss: 0.24421446025371552, Accuracy: 0.875, Computation time: 0.7887060642242432\n",
      "Step: 8570, Loss: 0.2952064573764801, Accuracy: 0.84375, Computation time: 0.838982105255127\n",
      "Step: 8571, Loss: 0.6223379969596863, Accuracy: 0.8125, Computation time: 0.7914042472839355\n",
      "Step: 8572, Loss: 0.3344542384147644, Accuracy: 0.90625, Computation time: 0.8387861251831055\n",
      "Step: 8573, Loss: 0.18552452325820923, Accuracy: 0.9375, Computation time: 0.84490966796875\n",
      "Step: 8574, Loss: 0.299978107213974, Accuracy: 0.90625, Computation time: 1.0752739906311035\n",
      "Step: 8575, Loss: 0.5862475633621216, Accuracy: 0.84375, Computation time: 0.9123492240905762\n",
      "Step: 8576, Loss: 0.7205265164375305, Accuracy: 0.875, Computation time: 1.053929090499878\n",
      "Step: 8577, Loss: 0.5292220711708069, Accuracy: 0.84375, Computation time: 0.9007248878479004\n",
      "Step: 8578, Loss: 0.3680536448955536, Accuracy: 0.90625, Computation time: 0.9072511196136475\n",
      "Step: 8579, Loss: 0.9497302770614624, Accuracy: 0.6875, Computation time: 1.3759901523590088\n",
      "Step: 8580, Loss: 1.3019497394561768, Accuracy: 0.65625, Computation time: 0.834475040435791\n",
      "Step: 8581, Loss: 1.577085256576538, Accuracy: 0.5, Computation time: 0.8424727916717529\n",
      "Step: 8582, Loss: 1.088590383529663, Accuracy: 0.71875, Computation time: 1.4955027103424072\n",
      "Step: 8583, Loss: 0.5845217108726501, Accuracy: 0.84375, Computation time: 0.8554389476776123\n",
      "Step: 8584, Loss: 0.9262175559997559, Accuracy: 0.71875, Computation time: 1.1355440616607666\n",
      "Step: 8585, Loss: 0.6447437405586243, Accuracy: 0.78125, Computation time: 1.0646262168884277\n",
      "Step: 8586, Loss: 0.3787892758846283, Accuracy: 0.84375, Computation time: 0.8902769088745117\n",
      "Step: 8587, Loss: 0.6598187685012817, Accuracy: 0.75, Computation time: 0.7781691551208496\n",
      "Step: 8588, Loss: 0.8372283577919006, Accuracy: 0.8125, Computation time: 0.9190719127655029\n",
      "Step: 8589, Loss: 1.4904725551605225, Accuracy: 0.59375, Computation time: 1.2092170715332031\n",
      "Step: 8590, Loss: 1.0528888702392578, Accuracy: 0.6875, Computation time: 1.084261178970337\n",
      "Step: 8591, Loss: 0.6615825891494751, Accuracy: 0.75, Computation time: 0.9062800407409668\n",
      "Step: 8592, Loss: 0.572328507900238, Accuracy: 0.75, Computation time: 0.8042340278625488\n",
      "Step: 8593, Loss: 0.2632317543029785, Accuracy: 0.90625, Computation time: 0.8448631763458252\n",
      "Step: 8594, Loss: 0.6891623139381409, Accuracy: 0.75, Computation time: 0.864997148513794\n",
      "Step: 8595, Loss: 1.103011965751648, Accuracy: 0.6875, Computation time: 0.9993610382080078\n",
      "Step: 8596, Loss: 0.8845281004905701, Accuracy: 0.71875, Computation time: 0.8238339424133301\n",
      "Step: 8597, Loss: 0.6814748048782349, Accuracy: 0.78125, Computation time: 0.98099684715271\n",
      "Step: 8598, Loss: 0.969151496887207, Accuracy: 0.78125, Computation time: 1.0102899074554443\n",
      "Step: 8599, Loss: 0.6924906373023987, Accuracy: 0.84375, Computation time: 1.0121257305145264\n",
      "Step: 8600, Loss: 0.6841386556625366, Accuracy: 0.84375, Computation time: 1.1249263286590576\n",
      "Step: 8601, Loss: 0.5093883275985718, Accuracy: 0.78125, Computation time: 1.0348501205444336\n",
      "Step: 8602, Loss: 0.5543146133422852, Accuracy: 0.90625, Computation time: 0.8559520244598389\n",
      "Step: 8603, Loss: 0.7060774564743042, Accuracy: 0.8125, Computation time: 1.0194649696350098\n",
      "Step: 8604, Loss: 0.6356531977653503, Accuracy: 0.78125, Computation time: 0.8304779529571533\n",
      "Step: 8605, Loss: 0.8966955542564392, Accuracy: 0.6875, Computation time: 0.8914039134979248\n",
      "Step: 8606, Loss: 0.40288910269737244, Accuracy: 0.90625, Computation time: 0.8010637760162354\n",
      "Step: 8607, Loss: 0.535132884979248, Accuracy: 0.84375, Computation time: 0.8783040046691895\n",
      "Step: 8608, Loss: 0.7512564659118652, Accuracy: 0.78125, Computation time: 1.145658254623413\n",
      "Step: 8609, Loss: 0.4926507771015167, Accuracy: 0.875, Computation time: 0.892967939376831\n",
      "Step: 8610, Loss: 0.3455287516117096, Accuracy: 0.84375, Computation time: 1.7835283279418945\n",
      "Step: 8611, Loss: 0.22833307087421417, Accuracy: 0.90625, Computation time: 1.0004348754882812\n",
      "Step: 8612, Loss: 1.0062236785888672, Accuracy: 0.78125, Computation time: 1.1889610290527344\n",
      "Step: 8613, Loss: 0.5956448316574097, Accuracy: 0.78125, Computation time: 0.8553128242492676\n",
      "Step: 8614, Loss: 0.4677518606185913, Accuracy: 0.8125, Computation time: 1.0131351947784424\n",
      "Step: 8615, Loss: 0.5279131531715393, Accuracy: 0.875, Computation time: 0.8168728351593018\n",
      "Step: 8616, Loss: 0.4155729115009308, Accuracy: 0.84375, Computation time: 0.893791913986206\n",
      "Step: 8617, Loss: 0.6691574454307556, Accuracy: 0.84375, Computation time: 1.3338596820831299\n",
      "Step: 8618, Loss: 0.35076385736465454, Accuracy: 0.875, Computation time: 0.9092769622802734\n",
      "Step: 8619, Loss: 0.8539125919342041, Accuracy: 0.78125, Computation time: 0.8211939334869385\n",
      "Step: 8620, Loss: 0.7554110288619995, Accuracy: 0.78125, Computation time: 0.87978196144104\n",
      "Step: 8621, Loss: 1.0164148807525635, Accuracy: 0.71875, Computation time: 0.9682250022888184\n",
      "Step: 8622, Loss: 0.2547583281993866, Accuracy: 0.9375, Computation time: 1.1554088592529297\n",
      "Step: 8623, Loss: 0.4125509560108185, Accuracy: 0.9375, Computation time: 0.9051487445831299\n",
      "Step: 8624, Loss: 0.5076428651809692, Accuracy: 0.875, Computation time: 0.9985370635986328\n",
      "Step: 8625, Loss: 0.4413393437862396, Accuracy: 0.8125, Computation time: 0.7673609256744385\n",
      "Step: 8626, Loss: 0.2112250179052353, Accuracy: 0.90625, Computation time: 0.8892228603363037\n",
      "Step: 8627, Loss: 0.446810781955719, Accuracy: 0.8125, Computation time: 0.8282532691955566\n",
      "Step: 8628, Loss: 0.25072360038757324, Accuracy: 0.90625, Computation time: 0.8345379829406738\n",
      "Step: 8629, Loss: 0.27352815866470337, Accuracy: 0.9375, Computation time: 1.0760679244995117\n",
      "Step: 8630, Loss: 0.37733060121536255, Accuracy: 0.84375, Computation time: 1.0751988887786865\n",
      "Step: 8631, Loss: 0.31654366850852966, Accuracy: 0.875, Computation time: 0.9705901145935059\n",
      "Step: 8632, Loss: 0.7267898321151733, Accuracy: 0.75, Computation time: 1.0921978950500488\n",
      "Step: 8633, Loss: 0.5811469554901123, Accuracy: 0.8125, Computation time: 0.8136909008026123\n",
      "Step: 8634, Loss: 0.34239518642425537, Accuracy: 0.84375, Computation time: 1.0370309352874756\n",
      "Step: 8635, Loss: 0.7701241374015808, Accuracy: 0.84375, Computation time: 0.8700311183929443\n",
      "Step: 8636, Loss: 0.20573563873767853, Accuracy: 0.90625, Computation time: 0.899975061416626\n",
      "Step: 8637, Loss: 0.3376169800758362, Accuracy: 0.84375, Computation time: 0.9607901573181152\n",
      "Step: 8638, Loss: 0.4946347773075104, Accuracy: 0.8125, Computation time: 1.6645848751068115\n",
      "Step: 8639, Loss: 0.3914695978164673, Accuracy: 0.84375, Computation time: 0.8933320045471191\n",
      "Step: 8640, Loss: 0.49995484948158264, Accuracy: 0.875, Computation time: 0.8457989692687988\n",
      "Step: 8641, Loss: 0.46453896164894104, Accuracy: 0.875, Computation time: 0.9146218299865723\n",
      "Step: 8642, Loss: 0.5312850475311279, Accuracy: 0.78125, Computation time: 1.012289047241211\n",
      "Step: 8643, Loss: 0.507898211479187, Accuracy: 0.84375, Computation time: 1.1224281787872314\n",
      "Step: 8644, Loss: 0.5377436876296997, Accuracy: 0.78125, Computation time: 0.8109951019287109\n",
      "Step: 8645, Loss: 0.670943021774292, Accuracy: 0.6875, Computation time: 0.8253049850463867\n",
      "Step: 8646, Loss: 0.4899041950702667, Accuracy: 0.875, Computation time: 0.8737800121307373\n",
      "Step: 8647, Loss: 0.2527512311935425, Accuracy: 0.9375, Computation time: 0.7723538875579834\n",
      "Step: 8648, Loss: 0.17728640139102936, Accuracy: 0.96875, Computation time: 1.3534648418426514\n",
      "Step: 8649, Loss: 0.42234742641448975, Accuracy: 0.8125, Computation time: 1.156278133392334\n",
      "Step: 8650, Loss: 0.6799103021621704, Accuracy: 0.78125, Computation time: 0.9183952808380127\n",
      "Step: 8651, Loss: 0.5671908259391785, Accuracy: 0.78125, Computation time: 0.8105158805847168\n",
      "Step: 8652, Loss: 0.4161350429058075, Accuracy: 0.875, Computation time: 0.9926729202270508\n",
      "Step: 8653, Loss: 0.5712060332298279, Accuracy: 0.84375, Computation time: 0.9920141696929932\n",
      "Step: 8654, Loss: 0.6743705868721008, Accuracy: 0.8125, Computation time: 0.8340868949890137\n",
      "Step: 8655, Loss: 0.5275503396987915, Accuracy: 0.75, Computation time: 0.9030022621154785\n",
      "Step: 8656, Loss: 0.23306803405284882, Accuracy: 0.90625, Computation time: 0.933405876159668\n",
      "Step: 8657, Loss: 0.25273898243904114, Accuracy: 0.96875, Computation time: 0.9377231597900391\n",
      "Step: 8658, Loss: 0.30499884486198425, Accuracy: 0.9375, Computation time: 0.9115309715270996\n",
      "Step: 8659, Loss: 0.27234992384910583, Accuracy: 0.875, Computation time: 0.8933689594268799\n",
      "Step: 8660, Loss: 0.3303794860839844, Accuracy: 0.84375, Computation time: 0.7899951934814453\n",
      "Step: 8661, Loss: 0.28137996792793274, Accuracy: 0.90625, Computation time: 1.1029651165008545\n",
      "Step: 8662, Loss: 0.2691705822944641, Accuracy: 0.90625, Computation time: 0.9309487342834473\n",
      "Step: 8663, Loss: 0.7810324430465698, Accuracy: 0.78125, Computation time: 0.9450907707214355\n",
      "Step: 8664, Loss: 0.3742583096027374, Accuracy: 0.90625, Computation time: 0.8911271095275879\n",
      "Step: 8665, Loss: 0.7263482809066772, Accuracy: 0.75, Computation time: 0.8945000171661377\n",
      "Step: 8666, Loss: 0.4724961817264557, Accuracy: 0.875, Computation time: 1.4263701438903809\n",
      "Step: 8667, Loss: 1.0204799175262451, Accuracy: 0.8125, Computation time: 0.915438175201416\n",
      "Step: 8668, Loss: 0.4757716953754425, Accuracy: 0.875, Computation time: 0.8847978115081787\n",
      "Step: 8669, Loss: 0.4790899157524109, Accuracy: 0.84375, Computation time: 0.928624153137207\n",
      "Step: 8670, Loss: 0.6278505921363831, Accuracy: 0.84375, Computation time: 0.855679988861084\n",
      "Step: 8671, Loss: 0.29419824481010437, Accuracy: 0.90625, Computation time: 0.7687690258026123\n",
      "Step: 8672, Loss: 0.32962706685066223, Accuracy: 0.875, Computation time: 0.8745861053466797\n",
      "Step: 8673, Loss: 0.5366840958595276, Accuracy: 0.71875, Computation time: 1.206007719039917\n",
      "Step: 8674, Loss: 0.4420548975467682, Accuracy: 0.84375, Computation time: 0.9198799133300781\n",
      "Step: 8675, Loss: 0.3938561677932739, Accuracy: 0.84375, Computation time: 1.2312328815460205\n",
      "Step: 8676, Loss: 0.4236313998699188, Accuracy: 0.875, Computation time: 0.9086940288543701\n",
      "Step: 8677, Loss: 0.31236234307289124, Accuracy: 0.875, Computation time: 0.9790098667144775\n",
      "Step: 8678, Loss: 0.33063381910324097, Accuracy: 0.90625, Computation time: 1.0670530796051025\n",
      "Step: 8679, Loss: 0.2623511552810669, Accuracy: 0.875, Computation time: 0.8713359832763672\n",
      "Step: 8680, Loss: 0.430598646402359, Accuracy: 0.84375, Computation time: 1.057164192199707\n",
      "Step: 8681, Loss: 0.3933294117450714, Accuracy: 0.90625, Computation time: 0.9652459621429443\n",
      "Step: 8682, Loss: 0.32469362020492554, Accuracy: 0.875, Computation time: 0.876166820526123\n",
      "Step: 8683, Loss: 0.5396661758422852, Accuracy: 0.8125, Computation time: 0.984196662902832\n",
      "Step: 8684, Loss: 0.4528708755970001, Accuracy: 0.84375, Computation time: 1.0418970584869385\n",
      "Step: 8685, Loss: 0.2880086302757263, Accuracy: 0.875, Computation time: 1.1891472339630127\n",
      "Step: 8686, Loss: 0.24464324116706848, Accuracy: 0.9375, Computation time: 0.869412899017334\n",
      "Step: 8687, Loss: 0.41525760293006897, Accuracy: 0.875, Computation time: 1.041891098022461\n",
      "Step: 8688, Loss: 0.3768124580383301, Accuracy: 0.90625, Computation time: 0.8025228977203369\n",
      "Step: 8689, Loss: 0.19212622940540314, Accuracy: 0.9375, Computation time: 0.898176908493042\n",
      "Step: 8690, Loss: 0.43090713024139404, Accuracy: 0.8125, Computation time: 1.0869319438934326\n",
      "Step: 8691, Loss: 0.6056551337242126, Accuracy: 0.78125, Computation time: 1.0496540069580078\n",
      "Step: 8692, Loss: 0.39774656295776367, Accuracy: 0.875, Computation time: 0.8862311840057373\n",
      "Step: 8693, Loss: 0.4258038103580475, Accuracy: 0.84375, Computation time: 0.9211080074310303\n",
      "Step: 8694, Loss: 0.4930131137371063, Accuracy: 0.875, Computation time: 1.535722017288208\n",
      "Step: 8695, Loss: 0.42243823409080505, Accuracy: 0.84375, Computation time: 0.9618339538574219\n",
      "Step: 8696, Loss: 0.39881229400634766, Accuracy: 0.875, Computation time: 0.8974230289459229\n",
      "Step: 8697, Loss: 0.27128395438194275, Accuracy: 0.875, Computation time: 0.7630677223205566\n",
      "Step: 8698, Loss: 0.24048492312431335, Accuracy: 0.875, Computation time: 1.0244858264923096\n",
      "Step: 8699, Loss: 0.15825793147087097, Accuracy: 0.9375, Computation time: 0.8242747783660889\n",
      "Step: 8700, Loss: 0.6827024221420288, Accuracy: 0.75, Computation time: 1.0464420318603516\n",
      "Step: 8701, Loss: 0.7105460166931152, Accuracy: 0.875, Computation time: 1.040950059890747\n",
      "Step: 8702, Loss: 0.3678329586982727, Accuracy: 0.875, Computation time: 0.8485767841339111\n",
      "Step: 8703, Loss: 0.15177594125270844, Accuracy: 0.96875, Computation time: 0.8688268661499023\n",
      "Step: 8704, Loss: 0.13125744462013245, Accuracy: 0.96875, Computation time: 0.9287288188934326\n",
      "Step: 8705, Loss: 0.5859903693199158, Accuracy: 0.875, Computation time: 0.9869461059570312\n",
      "Step: 8706, Loss: 0.3481115698814392, Accuracy: 0.90625, Computation time: 0.7473840713500977\n",
      "Step: 8707, Loss: 0.24401772022247314, Accuracy: 0.90625, Computation time: 0.9752418994903564\n",
      "Step: 8708, Loss: 0.6569380760192871, Accuracy: 0.8125, Computation time: 0.7743360996246338\n",
      "Step: 8709, Loss: 0.1798733025789261, Accuracy: 0.96875, Computation time: 0.8640727996826172\n",
      "Step: 8710, Loss: 0.7455412149429321, Accuracy: 0.84375, Computation time: 0.9525201320648193\n",
      "Step: 8711, Loss: 0.6123329401016235, Accuracy: 0.84375, Computation time: 0.9052839279174805\n",
      "Step: 8712, Loss: 0.25678113102912903, Accuracy: 0.90625, Computation time: 0.8875939846038818\n",
      "Step: 8713, Loss: 0.2672733962535858, Accuracy: 0.9375, Computation time: 0.8438503742218018\n",
      "Step: 8714, Loss: 0.38112613558769226, Accuracy: 0.875, Computation time: 1.0255959033966064\n",
      "Step: 8715, Loss: 0.42125624418258667, Accuracy: 0.90625, Computation time: 0.9402809143066406\n",
      "Step: 8716, Loss: 0.5398202538490295, Accuracy: 0.875, Computation time: 0.9243040084838867\n",
      "Step: 8717, Loss: 0.4081670641899109, Accuracy: 0.9375, Computation time: 0.9476380348205566\n",
      "Step: 8718, Loss: 0.25371599197387695, Accuracy: 0.90625, Computation time: 0.8090717792510986\n",
      "Step: 8719, Loss: 0.6229931116104126, Accuracy: 0.84375, Computation time: 0.9786300659179688\n",
      "Step: 8720, Loss: 0.20344184339046478, Accuracy: 0.96875, Computation time: 0.8776960372924805\n",
      "Step: 8721, Loss: 0.8730814456939697, Accuracy: 0.78125, Computation time: 0.9862360954284668\n",
      "Step: 8722, Loss: 0.6861456036567688, Accuracy: 0.84375, Computation time: 0.808525800704956\n",
      "Step: 8723, Loss: 0.3647470772266388, Accuracy: 0.9375, Computation time: 0.8751630783081055\n",
      "Step: 8724, Loss: 0.3171981871128082, Accuracy: 0.9375, Computation time: 0.7926211357116699\n",
      "Step: 8725, Loss: 0.5017671585083008, Accuracy: 0.84375, Computation time: 0.9471883773803711\n",
      "Step: 8726, Loss: 0.18885725736618042, Accuracy: 0.90625, Computation time: 0.9139440059661865\n",
      "Step: 8727, Loss: 0.4773733913898468, Accuracy: 0.875, Computation time: 1.02665114402771\n",
      "Step: 8728, Loss: 0.9110351204872131, Accuracy: 0.75, Computation time: 1.1108570098876953\n",
      "Step: 8729, Loss: 0.27866601943969727, Accuracy: 0.90625, Computation time: 1.6837952136993408\n",
      "Step: 8730, Loss: 0.21382364630699158, Accuracy: 0.90625, Computation time: 1.0173981189727783\n",
      "Step: 8731, Loss: 0.5462116003036499, Accuracy: 0.875, Computation time: 0.9387178421020508\n",
      "Step: 8732, Loss: 0.2013477385044098, Accuracy: 1.0, Computation time: 0.9909167289733887\n",
      "Step: 8733, Loss: 1.011527180671692, Accuracy: 0.75, Computation time: 0.9259278774261475\n",
      "Step: 8734, Loss: 0.52984219789505, Accuracy: 0.8125, Computation time: 1.0075879096984863\n",
      "Step: 8735, Loss: 0.07765988260507584, Accuracy: 1.0, Computation time: 0.8165059089660645\n",
      "Step: 8736, Loss: 0.3048878312110901, Accuracy: 0.875, Computation time: 0.7815439701080322\n",
      "Step: 8737, Loss: 0.33218324184417725, Accuracy: 0.90625, Computation time: 0.8473000526428223\n",
      "Step: 8738, Loss: 0.7344608306884766, Accuracy: 0.84375, Computation time: 1.1752021312713623\n",
      "Step: 8739, Loss: 0.1526612639427185, Accuracy: 0.96875, Computation time: 0.8217220306396484\n",
      "Step: 8740, Loss: 0.40090808272361755, Accuracy: 0.875, Computation time: 1.0115010738372803\n",
      "Step: 8741, Loss: 0.45694252848625183, Accuracy: 0.84375, Computation time: 0.7820439338684082\n",
      "Step: 8742, Loss: 0.7048718333244324, Accuracy: 0.875, Computation time: 0.8220541477203369\n",
      "Step: 8743, Loss: 0.44980141520500183, Accuracy: 0.84375, Computation time: 0.9494891166687012\n",
      "Step: 8744, Loss: 0.3240569233894348, Accuracy: 0.875, Computation time: 0.8262960910797119\n",
      "Step: 8745, Loss: 0.7044917345046997, Accuracy: 0.78125, Computation time: 0.9352519512176514\n",
      "Step: 8746, Loss: 0.47704288363456726, Accuracy: 0.8125, Computation time: 0.8756990432739258\n",
      "Step: 8747, Loss: 0.6234464645385742, Accuracy: 0.8125, Computation time: 1.0840671062469482\n",
      "Step: 8748, Loss: 0.4289482831954956, Accuracy: 0.84375, Computation time: 0.8993051052093506\n",
      "Step: 8749, Loss: 0.8617532849311829, Accuracy: 0.84375, Computation time: 0.8906459808349609\n",
      "Step: 8750, Loss: 0.794240415096283, Accuracy: 0.6875, Computation time: 0.893826961517334\n",
      "Step: 8751, Loss: 0.7450780868530273, Accuracy: 0.78125, Computation time: 0.8530609607696533\n",
      "Step: 8752, Loss: 1.3402724266052246, Accuracy: 0.65625, Computation time: 1.669335126876831\n",
      "Step: 8753, Loss: 0.5612283945083618, Accuracy: 0.78125, Computation time: 0.8924970626831055\n",
      "Step: 8754, Loss: 0.4379997253417969, Accuracy: 0.84375, Computation time: 0.7578568458557129\n",
      "Step: 8755, Loss: 0.40683647990226746, Accuracy: 0.90625, Computation time: 0.8715779781341553\n",
      "Step: 8756, Loss: 0.2237369418144226, Accuracy: 0.9375, Computation time: 0.9944851398468018\n",
      "Step: 8757, Loss: 0.41384729743003845, Accuracy: 0.84375, Computation time: 1.0710961818695068\n",
      "Step: 8758, Loss: 0.3794328570365906, Accuracy: 0.875, Computation time: 0.8169229030609131\n",
      "Step: 8759, Loss: 0.5604436993598938, Accuracy: 0.84375, Computation time: 0.9302539825439453\n",
      "Step: 8760, Loss: 0.8927167654037476, Accuracy: 0.8125, Computation time: 0.9421060085296631\n",
      "Step: 8761, Loss: 0.4470111131668091, Accuracy: 0.875, Computation time: 1.0696430206298828\n",
      "Step: 8762, Loss: 0.21754302084445953, Accuracy: 0.90625, Computation time: 0.9330768585205078\n",
      "Step: 8763, Loss: 0.4637787342071533, Accuracy: 0.8125, Computation time: 0.7784919738769531\n",
      "Step: 8764, Loss: 0.47331976890563965, Accuracy: 0.875, Computation time: 1.0334739685058594\n",
      "Step: 8765, Loss: 0.6748669147491455, Accuracy: 0.875, Computation time: 0.9969186782836914\n",
      "Step: 8766, Loss: 0.3541429340839386, Accuracy: 0.875, Computation time: 0.8126800060272217\n",
      "Step: 8767, Loss: 0.28812047839164734, Accuracy: 0.875, Computation time: 0.9336707592010498\n",
      "Step: 8768, Loss: 0.4491880536079407, Accuracy: 0.84375, Computation time: 1.0437841415405273\n",
      "Step: 8769, Loss: 0.2776744067668915, Accuracy: 0.9375, Computation time: 1.0398118495941162\n",
      "Step: 8770, Loss: 0.6163660287857056, Accuracy: 0.8125, Computation time: 1.3499822616577148\n",
      "Step: 8771, Loss: 0.670136570930481, Accuracy: 0.8125, Computation time: 0.9981522560119629\n",
      "Step: 8772, Loss: 0.3596510589122772, Accuracy: 0.84375, Computation time: 1.0987250804901123\n",
      "Step: 8773, Loss: 0.2485085427761078, Accuracy: 0.90625, Computation time: 0.9697389602661133\n",
      "Step: 8774, Loss: 0.45012974739074707, Accuracy: 0.90625, Computation time: 1.0326390266418457\n",
      "Step: 8775, Loss: 0.3747144639492035, Accuracy: 0.875, Computation time: 0.8451581001281738\n",
      "Step: 8776, Loss: 0.4990796446800232, Accuracy: 0.84375, Computation time: 0.9918298721313477\n",
      "Step: 8777, Loss: 0.6651337146759033, Accuracy: 0.875, Computation time: 0.9727370738983154\n",
      "Step: 8778, Loss: 0.6417160630226135, Accuracy: 0.78125, Computation time: 1.0522420406341553\n",
      "Step: 8779, Loss: 0.9785845875740051, Accuracy: 0.8125, Computation time: 0.9385080337524414\n",
      "Step: 8780, Loss: 0.34532490372657776, Accuracy: 0.9375, Computation time: 2.0592429637908936\n",
      "Step: 8781, Loss: 0.9667350053787231, Accuracy: 0.71875, Computation time: 1.0214850902557373\n",
      "Step: 8782, Loss: 0.5072869062423706, Accuracy: 0.78125, Computation time: 0.969947099685669\n",
      "Step: 8783, Loss: 0.3656630218029022, Accuracy: 0.90625, Computation time: 1.0489509105682373\n",
      "Step: 8784, Loss: 0.3368319571018219, Accuracy: 0.90625, Computation time: 0.7256760597229004\n",
      "Step: 8785, Loss: 0.4880521297454834, Accuracy: 0.78125, Computation time: 0.8823120594024658\n",
      "Step: 8786, Loss: 0.6715908050537109, Accuracy: 0.75, Computation time: 0.9230470657348633\n",
      "Step: 8787, Loss: 0.624930202960968, Accuracy: 0.84375, Computation time: 1.189809799194336\n",
      "Step: 8788, Loss: 0.904636025428772, Accuracy: 0.78125, Computation time: 0.9858789443969727\n",
      "Step: 8789, Loss: 0.7356265187263489, Accuracy: 0.84375, Computation time: 1.1545348167419434\n",
      "Step: 8790, Loss: 0.1987084299325943, Accuracy: 0.9375, Computation time: 1.0930957794189453\n",
      "Step: 8791, Loss: 0.40049976110458374, Accuracy: 0.9375, Computation time: 0.834604024887085\n",
      "Step: 8792, Loss: 0.34068796038627625, Accuracy: 0.875, Computation time: 0.9174647331237793\n",
      "Step: 8793, Loss: 0.9283083081245422, Accuracy: 0.71875, Computation time: 0.8249962329864502\n",
      "Step: 8794, Loss: 1.0722044706344604, Accuracy: 0.59375, Computation time: 0.9374709129333496\n",
      "Step: 8795, Loss: 0.2745908200740814, Accuracy: 0.90625, Computation time: 0.8608250617980957\n",
      "Step: 8796, Loss: 0.3709560036659241, Accuracy: 0.875, Computation time: 0.7518856525421143\n",
      "Step: 8797, Loss: 0.3688161373138428, Accuracy: 0.90625, Computation time: 1.1418449878692627\n",
      "Step: 8798, Loss: 0.4643332362174988, Accuracy: 0.90625, Computation time: 1.0414412021636963\n",
      "Step: 8799, Loss: 0.6029903292655945, Accuracy: 0.84375, Computation time: 1.1167759895324707\n",
      "Step: 8800, Loss: 0.7130720615386963, Accuracy: 0.78125, Computation time: 0.8848462104797363\n",
      "Step: 8801, Loss: 0.5885937809944153, Accuracy: 0.8125, Computation time: 0.7758350372314453\n",
      "Step: 8802, Loss: 0.36450880765914917, Accuracy: 0.875, Computation time: 0.8577578067779541\n",
      "Step: 8803, Loss: 0.46226000785827637, Accuracy: 0.84375, Computation time: 0.8245470523834229\n",
      "Step: 8804, Loss: 0.23511816561222076, Accuracy: 0.875, Computation time: 0.8484878540039062\n",
      "Step: 8805, Loss: 0.4973365068435669, Accuracy: 0.84375, Computation time: 0.9668481349945068\n",
      "Step: 8806, Loss: 0.29052573442459106, Accuracy: 0.90625, Computation time: 0.8123009204864502\n",
      "Step: 8807, Loss: 0.3703072965145111, Accuracy: 0.90625, Computation time: 0.9097237586975098\n",
      "Step: 8808, Loss: 0.49195700883865356, Accuracy: 0.8125, Computation time: 1.5096766948699951\n",
      "Step: 8809, Loss: 0.32464322447776794, Accuracy: 0.90625, Computation time: 0.9594480991363525\n",
      "Step: 8810, Loss: 0.672860324382782, Accuracy: 0.75, Computation time: 0.9622347354888916\n",
      "Step: 8811, Loss: 0.4057149887084961, Accuracy: 0.84375, Computation time: 0.9538040161132812\n",
      "Step: 8812, Loss: 0.4854499101638794, Accuracy: 0.90625, Computation time: 0.8666613101959229\n",
      "Step: 8813, Loss: 0.6279628872871399, Accuracy: 0.84375, Computation time: 0.8446810245513916\n",
      "Step: 8814, Loss: 0.37948498129844666, Accuracy: 0.90625, Computation time: 0.9666550159454346\n",
      "Step: 8815, Loss: 0.3197585940361023, Accuracy: 0.9375, Computation time: 0.9669630527496338\n",
      "Step: 8816, Loss: 0.27842381596565247, Accuracy: 0.90625, Computation time: 0.8889539241790771\n",
      "Step: 8817, Loss: 0.1916651874780655, Accuracy: 0.96875, Computation time: 0.7464020252227783\n",
      "Step: 8818, Loss: 0.47855228185653687, Accuracy: 0.875, Computation time: 1.2681689262390137\n",
      "Step: 8819, Loss: 0.6567859649658203, Accuracy: 0.78125, Computation time: 0.8305010795593262\n",
      "Step: 8820, Loss: 0.5316852927207947, Accuracy: 0.875, Computation time: 0.7479510307312012\n",
      "Step: 8821, Loss: 0.3195650577545166, Accuracy: 0.875, Computation time: 1.0856719017028809\n",
      "Step: 8822, Loss: 0.15251348912715912, Accuracy: 0.9375, Computation time: 0.7409820556640625\n",
      "Step: 8823, Loss: 0.23133379220962524, Accuracy: 0.9375, Computation time: 0.8014578819274902\n",
      "Step: 8824, Loss: 0.8760114312171936, Accuracy: 0.75, Computation time: 0.6469507217407227\n",
      "Step: 8825, Loss: 0.5858073830604553, Accuracy: 0.875, Computation time: 0.819087028503418\n",
      "Step: 8826, Loss: 0.3360636532306671, Accuracy: 0.90625, Computation time: 0.8680930137634277\n",
      "Step: 8827, Loss: 0.3642652630805969, Accuracy: 0.875, Computation time: 0.7467761039733887\n",
      "Step: 8828, Loss: 0.7526625990867615, Accuracy: 0.78125, Computation time: 1.0842459201812744\n",
      "Step: 8829, Loss: 0.5925160050392151, Accuracy: 0.84375, Computation time: 0.9288499355316162\n",
      "Step: 8830, Loss: 0.24380755424499512, Accuracy: 0.9375, Computation time: 1.017258882522583\n",
      "Step: 8831, Loss: 0.3402746915817261, Accuracy: 0.9375, Computation time: 0.9907891750335693\n",
      "Step: 8832, Loss: 0.5146322250366211, Accuracy: 0.8125, Computation time: 0.8667359352111816\n",
      "Step: 8833, Loss: 0.7914835810661316, Accuracy: 0.75, Computation time: 0.9258031845092773\n",
      "Step: 8834, Loss: 0.35069504380226135, Accuracy: 0.875, Computation time: 0.8907997608184814\n",
      "Step: 8835, Loss: 0.23694702982902527, Accuracy: 0.90625, Computation time: 0.7593410015106201\n",
      "Step: 8836, Loss: 0.8475220799446106, Accuracy: 0.75, Computation time: 0.9687957763671875\n",
      "Step: 8837, Loss: 0.38353413343429565, Accuracy: 0.9375, Computation time: 0.8251171112060547\n",
      "Step: 8838, Loss: 0.4409151077270508, Accuracy: 0.875, Computation time: 0.9308078289031982\n",
      "Step: 8839, Loss: 0.2735171318054199, Accuracy: 0.90625, Computation time: 0.8657588958740234\n",
      "Step: 8840, Loss: 0.27503177523612976, Accuracy: 0.9375, Computation time: 0.893115758895874\n",
      "Step: 8841, Loss: 0.19304752349853516, Accuracy: 0.9375, Computation time: 0.9387149810791016\n",
      "Step: 8842, Loss: 0.5154414772987366, Accuracy: 0.90625, Computation time: 0.9591729640960693\n",
      "Step: 8843, Loss: 0.23649737238883972, Accuracy: 0.90625, Computation time: 0.8941090106964111\n",
      "Step: 8844, Loss: 0.1323196142911911, Accuracy: 1.0, Computation time: 1.011183261871338\n",
      "Step: 8845, Loss: 0.38044273853302, Accuracy: 0.9375, Computation time: 0.9239890575408936\n",
      "Step: 8846, Loss: 0.41754966974258423, Accuracy: 0.875, Computation time: 0.9216341972351074\n",
      "Step: 8847, Loss: 0.29770633578300476, Accuracy: 0.9375, Computation time: 0.9905860424041748\n",
      "Step: 8848, Loss: 0.27610570192337036, Accuracy: 0.90625, Computation time: 0.8841209411621094\n",
      "Step: 8849, Loss: 0.3157704770565033, Accuracy: 0.875, Computation time: 0.7256879806518555\n",
      "Step: 8850, Loss: 0.3139283359050751, Accuracy: 0.875, Computation time: 0.7318921089172363\n",
      "Step: 8851, Loss: 0.04774484783411026, Accuracy: 1.0, Computation time: 0.7876551151275635\n",
      "Step: 8852, Loss: 0.20902281999588013, Accuracy: 1.0, Computation time: 0.8015758991241455\n",
      "Step: 8853, Loss: 0.4326991140842438, Accuracy: 0.90625, Computation time: 0.8272500038146973\n",
      "Step: 8854, Loss: 0.7847976088523865, Accuracy: 0.75, Computation time: 1.0128178596496582\n",
      "Step: 8855, Loss: 0.4082484245300293, Accuracy: 0.90625, Computation time: 1.0701451301574707\n",
      "Step: 8856, Loss: 0.21374252438545227, Accuracy: 0.9375, Computation time: 0.9661891460418701\n",
      "Step: 8857, Loss: 0.3364681601524353, Accuracy: 0.875, Computation time: 0.8115789890289307\n",
      "Step: 8858, Loss: 0.5087733268737793, Accuracy: 0.8125, Computation time: 1.0752291679382324\n",
      "Step: 8859, Loss: 0.3328116834163666, Accuracy: 0.9375, Computation time: 0.8975851535797119\n",
      "Step: 8860, Loss: 0.3030809760093689, Accuracy: 0.875, Computation time: 1.081070899963379\n",
      "Step: 8861, Loss: 0.2573515772819519, Accuracy: 0.9375, Computation time: 0.8186721801757812\n",
      "Step: 8862, Loss: 0.3723651170730591, Accuracy: 0.84375, Computation time: 1.0092647075653076\n",
      "Step: 8863, Loss: 0.6019154191017151, Accuracy: 0.84375, Computation time: 1.260329008102417\n",
      "Step: 8864, Loss: 0.5877658724784851, Accuracy: 0.8125, Computation time: 1.2913899421691895\n",
      "Step: 8865, Loss: 0.516706109046936, Accuracy: 0.875, Computation time: 0.9712240695953369\n",
      "Step: 8866, Loss: 0.3563162684440613, Accuracy: 0.875, Computation time: 1.8212218284606934\n",
      "Step: 8867, Loss: 0.30884552001953125, Accuracy: 0.9375, Computation time: 1.6685540676116943\n",
      "Step: 8868, Loss: 0.426179975271225, Accuracy: 0.875, Computation time: 0.9358069896697998\n",
      "Step: 8869, Loss: 0.3692276179790497, Accuracy: 0.875, Computation time: 1.1865248680114746\n",
      "Step: 8870, Loss: 0.23413488268852234, Accuracy: 0.9375, Computation time: 1.1055359840393066\n",
      "Step: 8871, Loss: 0.35731029510498047, Accuracy: 0.90625, Computation time: 0.9351370334625244\n",
      "Step: 8872, Loss: 0.13545800745487213, Accuracy: 0.96875, Computation time: 0.9813251495361328\n",
      "Step: 8873, Loss: 0.2899196147918701, Accuracy: 0.90625, Computation time: 0.8637769222259521\n",
      "Step: 8874, Loss: 0.5867943167686462, Accuracy: 0.8125, Computation time: 0.9472579956054688\n",
      "Step: 8875, Loss: 0.21001243591308594, Accuracy: 0.96875, Computation time: 0.8779659271240234\n",
      "Step: 8876, Loss: 0.47473856806755066, Accuracy: 0.875, Computation time: 0.9747977256774902\n",
      "Step: 8877, Loss: 0.43651971220970154, Accuracy: 0.84375, Computation time: 0.9519340991973877\n",
      "Step: 8878, Loss: 0.25063398480415344, Accuracy: 0.875, Computation time: 0.7591590881347656\n",
      "Step: 8879, Loss: 0.13609202206134796, Accuracy: 0.9375, Computation time: 0.8622231483459473\n",
      "Step: 8880, Loss: 0.32331573963165283, Accuracy: 0.84375, Computation time: 0.8712930679321289\n",
      "Step: 8881, Loss: 0.1416858583688736, Accuracy: 0.9375, Computation time: 0.7990448474884033\n",
      "Step: 8882, Loss: 0.21161334216594696, Accuracy: 0.96875, Computation time: 0.8085372447967529\n",
      "Step: 8883, Loss: 0.5008224844932556, Accuracy: 0.84375, Computation time: 0.9392173290252686\n",
      "Step: 8884, Loss: 0.4980783760547638, Accuracy: 0.8125, Computation time: 1.0107150077819824\n",
      "Step: 8885, Loss: 0.5500502586364746, Accuracy: 0.875, Computation time: 0.8737850189208984\n",
      "Step: 8886, Loss: 0.3668909966945648, Accuracy: 0.90625, Computation time: 0.9507021903991699\n",
      "Step: 8887, Loss: 0.13969166576862335, Accuracy: 0.96875, Computation time: 1.0255789756774902\n",
      "Step: 8888, Loss: 0.22928470373153687, Accuracy: 0.9375, Computation time: 1.009887933731079\n",
      "Step: 8889, Loss: 0.29241281747817993, Accuracy: 0.875, Computation time: 0.8823292255401611\n",
      "Step: 8890, Loss: 0.2992016673088074, Accuracy: 0.875, Computation time: 1.371541976928711\n",
      "Step: 8891, Loss: 0.5333861708641052, Accuracy: 0.78125, Computation time: 0.9224448204040527\n",
      "Step: 8892, Loss: 0.6862601637840271, Accuracy: 0.875, Computation time: 1.021737813949585\n",
      "Step: 8893, Loss: 0.6158424615859985, Accuracy: 0.78125, Computation time: 1.2084720134735107\n",
      "Step: 8894, Loss: 0.2771055996417999, Accuracy: 0.875, Computation time: 0.8448481559753418\n",
      "Step: 8895, Loss: 0.2476833611726761, Accuracy: 0.9375, Computation time: 1.2434959411621094\n",
      "Step: 8896, Loss: 0.13471095263957977, Accuracy: 0.9375, Computation time: 0.9939939975738525\n",
      "Step: 8897, Loss: 0.2867608368396759, Accuracy: 0.90625, Computation time: 0.995164155960083\n",
      "Step: 8898, Loss: 0.4109047055244446, Accuracy: 0.90625, Computation time: 1.1390652656555176\n",
      "Step: 8899, Loss: 0.4440747797489166, Accuracy: 0.84375, Computation time: 0.964158296585083\n",
      "Step: 8900, Loss: 0.536972165107727, Accuracy: 0.84375, Computation time: 1.0888452529907227\n",
      "Step: 8901, Loss: 0.2355600893497467, Accuracy: 0.9375, Computation time: 0.8737499713897705\n",
      "Step: 8902, Loss: 0.37462499737739563, Accuracy: 0.90625, Computation time: 0.8523051738739014\n",
      "Step: 8903, Loss: 0.2939489483833313, Accuracy: 0.90625, Computation time: 0.9529881477355957\n",
      "Step: 8904, Loss: 0.9292831420898438, Accuracy: 0.6875, Computation time: 1.009483814239502\n",
      "Step: 8905, Loss: 0.26165637373924255, Accuracy: 0.90625, Computation time: 0.9625468254089355\n",
      "Step: 8906, Loss: 0.7645098567008972, Accuracy: 0.78125, Computation time: 1.0499370098114014\n",
      "Step: 8907, Loss: 0.339138388633728, Accuracy: 0.90625, Computation time: 0.7686889171600342\n",
      "Step: 8908, Loss: 0.34384313225746155, Accuracy: 0.9375, Computation time: 1.009289026260376\n",
      "Step: 8909, Loss: 0.13088180124759674, Accuracy: 0.96875, Computation time: 1.0867578983306885\n",
      "Step: 8910, Loss: 0.49666064977645874, Accuracy: 0.875, Computation time: 0.8406081199645996\n",
      "Step: 8911, Loss: 0.2916947603225708, Accuracy: 0.90625, Computation time: 0.932171106338501\n",
      "Step: 8912, Loss: 0.5402822494506836, Accuracy: 0.84375, Computation time: 0.8743691444396973\n",
      "Step: 8913, Loss: 0.19907571375370026, Accuracy: 0.90625, Computation time: 0.9599568843841553\n",
      "Step: 8914, Loss: 0.3020574450492859, Accuracy: 0.90625, Computation time: 1.0090031623840332\n",
      "Step: 8915, Loss: 0.731115996837616, Accuracy: 0.875, Computation time: 0.7487020492553711\n",
      "Step: 8916, Loss: 0.5418747663497925, Accuracy: 0.875, Computation time: 0.9898831844329834\n",
      "Step: 8917, Loss: 0.3136857748031616, Accuracy: 0.875, Computation time: 0.8927938938140869\n",
      "Step: 8918, Loss: 0.4370048940181732, Accuracy: 0.84375, Computation time: 0.7407741546630859\n",
      "Step: 8919, Loss: 0.1859690099954605, Accuracy: 0.90625, Computation time: 0.8416039943695068\n",
      "Step: 8920, Loss: 0.12209323793649673, Accuracy: 0.96875, Computation time: 0.8081009387969971\n",
      "Step: 8921, Loss: 0.34327685832977295, Accuracy: 0.9375, Computation time: 0.9136688709259033\n",
      "Step: 8922, Loss: 0.5717549324035645, Accuracy: 0.8125, Computation time: 1.4326980113983154\n",
      "Step: 8923, Loss: 0.27622655034065247, Accuracy: 0.9375, Computation time: 0.9269697666168213\n",
      "Step: 8924, Loss: 0.7732628583908081, Accuracy: 0.78125, Computation time: 1.0092239379882812\n",
      "Step: 8925, Loss: 0.28133976459503174, Accuracy: 0.875, Computation time: 0.789146900177002\n",
      "Step: 8926, Loss: 0.3016328513622284, Accuracy: 0.90625, Computation time: 0.9425969123840332\n",
      "Step: 8927, Loss: 0.5839816927909851, Accuracy: 0.875, Computation time: 0.8246500492095947\n",
      "Step: 8928, Loss: 0.57364422082901, Accuracy: 0.90625, Computation time: 0.9492418766021729\n",
      "Step: 8929, Loss: 0.26562318205833435, Accuracy: 0.9375, Computation time: 0.9762089252471924\n",
      "Step: 8930, Loss: 0.493584543466568, Accuracy: 0.84375, Computation time: 1.2858307361602783\n",
      "Step: 8931, Loss: 0.34570831060409546, Accuracy: 0.90625, Computation time: 0.7544741630554199\n",
      "Step: 8932, Loss: 0.33788466453552246, Accuracy: 0.875, Computation time: 0.8814079761505127\n",
      "Step: 8933, Loss: 0.5989779829978943, Accuracy: 0.90625, Computation time: 0.8761930465698242\n",
      "Step: 8934, Loss: 0.1917833834886551, Accuracy: 0.96875, Computation time: 0.9349150657653809\n",
      "Step: 8935, Loss: 0.2600890100002289, Accuracy: 0.9375, Computation time: 1.1194679737091064\n",
      "Step: 8936, Loss: 0.3590579628944397, Accuracy: 0.90625, Computation time: 0.8690340518951416\n",
      "Step: 8937, Loss: 0.42379850149154663, Accuracy: 0.9375, Computation time: 1.2966420650482178\n",
      "Step: 8938, Loss: 0.7072027921676636, Accuracy: 0.71875, Computation time: 1.2338638305664062\n",
      "Step: 8939, Loss: 0.4813857078552246, Accuracy: 0.84375, Computation time: 0.7881410121917725\n",
      "Step: 8940, Loss: 0.32915157079696655, Accuracy: 0.875, Computation time: 0.9188947677612305\n",
      "Step: 8941, Loss: 0.27560338377952576, Accuracy: 0.90625, Computation time: 0.8007481098175049\n",
      "Step: 8942, Loss: 0.46794188022613525, Accuracy: 0.875, Computation time: 1.08461594581604\n",
      "Step: 8943, Loss: 0.1372906118631363, Accuracy: 0.96875, Computation time: 0.9450268745422363\n",
      "Step: 8944, Loss: 0.5504400730133057, Accuracy: 0.90625, Computation time: 0.7912611961364746\n",
      "Step: 8945, Loss: 0.5591748356819153, Accuracy: 0.84375, Computation time: 1.1334190368652344\n",
      "Step: 8946, Loss: 0.30956006050109863, Accuracy: 0.9375, Computation time: 0.8420619964599609\n",
      "Step: 8947, Loss: 0.7540810704231262, Accuracy: 0.78125, Computation time: 0.8038840293884277\n",
      "Step: 8948, Loss: 0.3312304615974426, Accuracy: 0.90625, Computation time: 0.993293046951294\n",
      "Step: 8949, Loss: 0.5120357871055603, Accuracy: 0.875, Computation time: 0.9569032192230225\n",
      "Step: 8950, Loss: 0.4603603184223175, Accuracy: 0.875, Computation time: 1.5944440364837646\n",
      "Step: 8951, Loss: 0.46548956632614136, Accuracy: 0.875, Computation time: 0.7794630527496338\n",
      "Step: 8952, Loss: 0.3477958142757416, Accuracy: 0.875, Computation time: 0.911247968673706\n",
      "Step: 8953, Loss: 0.4466482996940613, Accuracy: 0.875, Computation time: 1.0507221221923828\n",
      "Step: 8954, Loss: 0.5077181458473206, Accuracy: 0.875, Computation time: 0.7955780029296875\n",
      "Step: 8955, Loss: 0.6157519817352295, Accuracy: 0.875, Computation time: 0.8344440460205078\n",
      "Step: 8956, Loss: 0.7584590315818787, Accuracy: 0.84375, Computation time: 0.8099501132965088\n",
      "Step: 8957, Loss: 0.32958197593688965, Accuracy: 0.9375, Computation time: 0.9529953002929688\n",
      "Step: 8958, Loss: 0.47048285603523254, Accuracy: 0.8125, Computation time: 0.936272144317627\n",
      "Step: 8959, Loss: 0.2802541255950928, Accuracy: 0.875, Computation time: 0.9017138481140137\n",
      "Step: 8960, Loss: 0.34686020016670227, Accuracy: 0.875, Computation time: 0.9218568801879883\n",
      "Step: 8961, Loss: 0.4582931399345398, Accuracy: 0.875, Computation time: 0.8790991306304932\n",
      "Step: 8962, Loss: 0.49004095792770386, Accuracy: 0.875, Computation time: 1.5340240001678467\n",
      "Step: 8963, Loss: 1.0909767150878906, Accuracy: 0.65625, Computation time: 0.8145859241485596\n",
      "Step: 8964, Loss: 0.6012058258056641, Accuracy: 0.84375, Computation time: 0.9133450984954834\n",
      "Step: 8965, Loss: 0.6376810073852539, Accuracy: 0.8125, Computation time: 0.912973165512085\n",
      "Step: 8966, Loss: 0.47620949149131775, Accuracy: 0.78125, Computation time: 1.001751184463501\n",
      "Step: 8967, Loss: 0.3266594707965851, Accuracy: 0.875, Computation time: 0.9234988689422607\n",
      "Step: 8968, Loss: 0.14040187001228333, Accuracy: 1.0, Computation time: 0.7935569286346436\n",
      "Step: 8969, Loss: 0.48534902930259705, Accuracy: 0.78125, Computation time: 0.8629770278930664\n",
      "Step: 8970, Loss: 0.31512150168418884, Accuracy: 0.875, Computation time: 0.7986009120941162\n",
      "Step: 8971, Loss: 1.1061276197433472, Accuracy: 0.65625, Computation time: 0.8830127716064453\n",
      "Step: 8972, Loss: 0.5458836555480957, Accuracy: 0.84375, Computation time: 0.9387977123260498\n",
      "Step: 8973, Loss: 0.4291660189628601, Accuracy: 0.875, Computation time: 1.0059690475463867\n",
      "Step: 8974, Loss: 0.4768202304840088, Accuracy: 0.90625, Computation time: 1.1460630893707275\n",
      "Step: 8975, Loss: 0.30940189957618713, Accuracy: 0.9375, Computation time: 0.7748317718505859\n",
      "Step: 8976, Loss: 0.506747305393219, Accuracy: 0.84375, Computation time: 0.8605892658233643\n",
      "Step: 8977, Loss: 0.5583947896957397, Accuracy: 0.8125, Computation time: 0.846545934677124\n",
      "Step: 8978, Loss: 0.5517168045043945, Accuracy: 0.9375, Computation time: 0.8875188827514648\n",
      "Step: 8979, Loss: 0.7077546119689941, Accuracy: 0.8125, Computation time: 1.6921768188476562\n",
      "Step: 8980, Loss: 0.6105579733848572, Accuracy: 0.78125, Computation time: 0.8510539531707764\n",
      "Step: 8981, Loss: 0.5971775650978088, Accuracy: 0.84375, Computation time: 1.0262730121612549\n",
      "Step: 8982, Loss: 0.2767147123813629, Accuracy: 0.875, Computation time: 0.8578338623046875\n",
      "Step: 8983, Loss: 0.5116127133369446, Accuracy: 0.84375, Computation time: 0.7454290390014648\n",
      "Step: 8984, Loss: 0.6616953015327454, Accuracy: 0.78125, Computation time: 0.9514827728271484\n",
      "Step: 8985, Loss: 0.34604114294052124, Accuracy: 0.90625, Computation time: 0.8062889575958252\n",
      "Step: 8986, Loss: 0.7094857692718506, Accuracy: 0.71875, Computation time: 0.8490941524505615\n",
      "Step: 8987, Loss: 0.6216305494308472, Accuracy: 0.84375, Computation time: 1.849142074584961\n",
      "Step: 8988, Loss: 0.40252864360809326, Accuracy: 0.84375, Computation time: 0.9805402755737305\n",
      "Step: 8989, Loss: 0.22200021147727966, Accuracy: 0.9375, Computation time: 0.9475419521331787\n",
      "Step: 8990, Loss: 0.6047728657722473, Accuracy: 0.8125, Computation time: 0.822009801864624\n",
      "Step: 8991, Loss: 0.6225482225418091, Accuracy: 0.8125, Computation time: 0.99947190284729\n",
      "Step: 8992, Loss: 0.45710983872413635, Accuracy: 0.875, Computation time: 0.8215720653533936\n",
      "Step: 8993, Loss: 0.2706144452095032, Accuracy: 0.90625, Computation time: 0.8707849979400635\n",
      "Step: 8994, Loss: 0.3961263597011566, Accuracy: 0.875, Computation time: 0.9541621208190918\n",
      "Step: 8995, Loss: 0.4389328956604004, Accuracy: 0.875, Computation time: 0.8836100101470947\n",
      "Step: 8996, Loss: 0.2961626648902893, Accuracy: 0.90625, Computation time: 0.7861378192901611\n",
      "Step: 8997, Loss: 0.3786207437515259, Accuracy: 0.875, Computation time: 0.7978968620300293\n",
      "Step: 8998, Loss: 0.39700305461883545, Accuracy: 0.90625, Computation time: 0.735497236251831\n",
      "Step: 8999, Loss: 0.14352555572986603, Accuracy: 1.0, Computation time: 0.8563671112060547\n",
      "Step: 9000, Loss: 0.4647354185581207, Accuracy: 0.8125, Computation time: 0.9750430583953857\n",
      "Step: 9001, Loss: 0.4589885473251343, Accuracy: 0.8125, Computation time: 0.9299499988555908\n",
      "Step: 9002, Loss: 0.3716284930706024, Accuracy: 0.9375, Computation time: 0.8871233463287354\n",
      "Step: 9003, Loss: 0.42783012986183167, Accuracy: 0.875, Computation time: 0.7253539562225342\n",
      "Step: 9004, Loss: 0.33100494742393494, Accuracy: 0.875, Computation time: 0.9175443649291992\n",
      "Step: 9005, Loss: 0.34481996297836304, Accuracy: 0.8125, Computation time: 0.9138569831848145\n",
      "Step: 9006, Loss: 0.4947147071361542, Accuracy: 0.8125, Computation time: 1.2126929759979248\n",
      "Step: 9007, Loss: 0.571608304977417, Accuracy: 0.8125, Computation time: 0.7954208850860596\n",
      "Step: 9008, Loss: 0.39209362864494324, Accuracy: 0.90625, Computation time: 1.4885690212249756\n",
      "Step: 9009, Loss: 0.5546795129776001, Accuracy: 0.8125, Computation time: 0.8738441467285156\n",
      "Step: 9010, Loss: 0.39586129784584045, Accuracy: 0.875, Computation time: 0.9977219104766846\n",
      "Step: 9011, Loss: 0.5402839779853821, Accuracy: 0.90625, Computation time: 0.7786381244659424\n",
      "Step: 9012, Loss: 0.41998034715652466, Accuracy: 0.875, Computation time: 0.8764398097991943\n",
      "Step: 9013, Loss: 0.592249870300293, Accuracy: 0.8125, Computation time: 0.9925036430358887\n",
      "Step: 9014, Loss: 0.7567246556282043, Accuracy: 0.78125, Computation time: 0.9369218349456787\n",
      "Step: 9015, Loss: 0.44995301961898804, Accuracy: 0.875, Computation time: 0.9571061134338379\n",
      "Step: 9016, Loss: 0.6433332562446594, Accuracy: 0.84375, Computation time: 0.8776681423187256\n",
      "Step: 9017, Loss: 0.4334844648838043, Accuracy: 0.875, Computation time: 1.0503129959106445\n",
      "Step: 9018, Loss: 0.5245858430862427, Accuracy: 0.84375, Computation time: 1.0770480632781982\n",
      "Step: 9019, Loss: 0.6439184546470642, Accuracy: 0.875, Computation time: 0.8295338153839111\n",
      "Step: 9020, Loss: 0.41409823298454285, Accuracy: 0.90625, Computation time: 0.9512231349945068\n",
      "Step: 9021, Loss: 0.6468464732170105, Accuracy: 0.71875, Computation time: 0.8664209842681885\n",
      "Step: 9022, Loss: 0.5916319489479065, Accuracy: 0.8125, Computation time: 0.8800461292266846\n",
      "Step: 9023, Loss: 0.35968688130378723, Accuracy: 0.875, Computation time: 0.8170208930969238\n",
      "Step: 9024, Loss: 0.6838721036911011, Accuracy: 0.75, Computation time: 0.9935958385467529\n",
      "Step: 9025, Loss: 1.0041673183441162, Accuracy: 0.75, Computation time: 0.9265532493591309\n",
      "Step: 9026, Loss: 0.3159497380256653, Accuracy: 0.90625, Computation time: 1.0207970142364502\n",
      "Step: 9027, Loss: 0.28418654203414917, Accuracy: 0.9375, Computation time: 0.8769838809967041\n",
      "Step: 9028, Loss: 0.7597532272338867, Accuracy: 0.75, Computation time: 0.796795129776001\n",
      "Step: 9029, Loss: 0.1686202436685562, Accuracy: 1.0, Computation time: 0.9483740329742432\n",
      "Step: 9030, Loss: 0.5468893051147461, Accuracy: 0.8125, Computation time: 1.1556730270385742\n",
      "Step: 9031, Loss: 0.4819785952568054, Accuracy: 0.84375, Computation time: 0.8841722011566162\n",
      "Step: 9032, Loss: 0.8417101502418518, Accuracy: 0.71875, Computation time: 0.901608943939209\n",
      "Step: 9033, Loss: 0.7534878253936768, Accuracy: 0.75, Computation time: 1.05460786819458\n",
      "Step: 9034, Loss: 0.1871693730354309, Accuracy: 0.9375, Computation time: 1.1815390586853027\n",
      "Step: 9035, Loss: 0.39287102222442627, Accuracy: 0.875, Computation time: 0.8827121257781982\n",
      "Step: 9036, Loss: 0.44008609652519226, Accuracy: 0.875, Computation time: 0.9238169193267822\n",
      "Step: 9037, Loss: 0.21903158724308014, Accuracy: 0.96875, Computation time: 0.9097747802734375\n",
      "Step: 9038, Loss: 0.5422797203063965, Accuracy: 0.84375, Computation time: 0.8074560165405273\n",
      "Step: 9039, Loss: 0.3310202956199646, Accuracy: 0.90625, Computation time: 1.1840548515319824\n",
      "Step: 9040, Loss: 0.34482723474502563, Accuracy: 0.84375, Computation time: 1.1404929161071777\n",
      "Step: 9041, Loss: 0.3630219101905823, Accuracy: 0.875, Computation time: 0.8554530143737793\n",
      "Step: 9042, Loss: 0.12289785593748093, Accuracy: 0.96875, Computation time: 1.0421760082244873\n",
      "Step: 9043, Loss: 0.25215625762939453, Accuracy: 0.9375, Computation time: 0.8666517734527588\n",
      "Step: 9044, Loss: 0.8884280323982239, Accuracy: 0.75, Computation time: 0.9997708797454834\n",
      "Step: 9045, Loss: 0.28252676129341125, Accuracy: 0.90625, Computation time: 0.9489600658416748\n",
      "Step: 9046, Loss: 0.2226521521806717, Accuracy: 0.9375, Computation time: 0.8868920803070068\n",
      "Step: 9047, Loss: 0.4436655342578888, Accuracy: 0.84375, Computation time: 0.8404059410095215\n",
      "Step: 9048, Loss: 0.4557953476905823, Accuracy: 0.875, Computation time: 0.8882389068603516\n",
      "Step: 9049, Loss: 0.29717394709587097, Accuracy: 0.875, Computation time: 0.8313088417053223\n",
      "Step: 9050, Loss: 0.318426251411438, Accuracy: 0.90625, Computation time: 0.9254288673400879\n",
      "Step: 9051, Loss: 0.2714146673679352, Accuracy: 0.9375, Computation time: 0.8342490196228027\n",
      "Step: 9052, Loss: 0.25140145421028137, Accuracy: 0.9375, Computation time: 0.8620729446411133\n",
      "Step: 9053, Loss: 0.3906731903553009, Accuracy: 0.875, Computation time: 1.0615670680999756\n",
      "Step: 9054, Loss: 0.4731212258338928, Accuracy: 0.9375, Computation time: 0.9219939708709717\n",
      "Step: 9055, Loss: 0.31737932562828064, Accuracy: 0.875, Computation time: 0.789046049118042\n",
      "Step: 9056, Loss: 0.2945989966392517, Accuracy: 0.90625, Computation time: 1.0823900699615479\n",
      "Step: 9057, Loss: 0.7787940502166748, Accuracy: 0.78125, Computation time: 0.8386778831481934\n",
      "Step: 9058, Loss: 0.4519290328025818, Accuracy: 0.8125, Computation time: 1.175487995147705\n",
      "Step: 9059, Loss: 0.586692214012146, Accuracy: 0.8125, Computation time: 0.9221057891845703\n",
      "Step: 9060, Loss: 0.20063325762748718, Accuracy: 0.9375, Computation time: 0.9536750316619873\n",
      "Step: 9061, Loss: 0.34932997822761536, Accuracy: 0.875, Computation time: 1.0240440368652344\n",
      "Step: 9062, Loss: 0.4489902853965759, Accuracy: 0.875, Computation time: 0.9492249488830566\n",
      "Step: 9063, Loss: 0.2899572253227234, Accuracy: 0.875, Computation time: 1.0337986946105957\n",
      "Step: 9064, Loss: 0.21925637125968933, Accuracy: 0.90625, Computation time: 0.8848750591278076\n",
      "Step: 9065, Loss: 0.22311484813690186, Accuracy: 0.90625, Computation time: 1.3668498992919922\n",
      "Step: 9066, Loss: 0.38747715950012207, Accuracy: 0.875, Computation time: 1.0404810905456543\n",
      "Step: 9067, Loss: 0.3377845585346222, Accuracy: 0.90625, Computation time: 0.833233118057251\n",
      "Step: 9068, Loss: 0.2915456295013428, Accuracy: 0.84375, Computation time: 0.8902370929718018\n",
      "Step: 9069, Loss: 0.327958345413208, Accuracy: 0.9375, Computation time: 0.8764097690582275\n",
      "Step: 9070, Loss: 0.47993069887161255, Accuracy: 0.84375, Computation time: 0.9286830425262451\n",
      "Step: 9071, Loss: 0.4498720169067383, Accuracy: 0.8125, Computation time: 0.9117929935455322\n",
      "Step: 9072, Loss: 0.24288009107112885, Accuracy: 0.90625, Computation time: 0.8971009254455566\n",
      "Step: 9073, Loss: 0.5114205479621887, Accuracy: 0.78125, Computation time: 0.8882997035980225\n",
      "Step: 9074, Loss: 0.5197659134864807, Accuracy: 0.84375, Computation time: 0.976409912109375\n",
      "Step: 9075, Loss: 0.6182884573936462, Accuracy: 0.8125, Computation time: 0.9169797897338867\n",
      "Step: 9076, Loss: 0.6365785002708435, Accuracy: 0.84375, Computation time: 1.0642869472503662\n",
      "Step: 9077, Loss: 0.6364477276802063, Accuracy: 0.875, Computation time: 0.905797004699707\n",
      "Step: 9078, Loss: 0.5389023423194885, Accuracy: 0.84375, Computation time: 0.9059398174285889\n",
      "Step: 9079, Loss: 0.5534937977790833, Accuracy: 0.8125, Computation time: 0.9321699142456055\n",
      "Step: 9080, Loss: 0.32993873953819275, Accuracy: 0.90625, Computation time: 1.009796142578125\n",
      "Step: 9081, Loss: 0.44945481419563293, Accuracy: 0.84375, Computation time: 0.8358519077301025\n",
      "Step: 9082, Loss: 0.19002124667167664, Accuracy: 0.96875, Computation time: 0.9611499309539795\n",
      "Step: 9083, Loss: 0.3007115125656128, Accuracy: 0.84375, Computation time: 0.9631819725036621\n",
      "Step: 9084, Loss: 0.4758858382701874, Accuracy: 0.84375, Computation time: 0.8424370288848877\n",
      "Step: 9085, Loss: 0.5010783076286316, Accuracy: 0.875, Computation time: 0.8820400238037109\n",
      "Step: 9086, Loss: 0.1877172440290451, Accuracy: 0.9375, Computation time: 0.8943920135498047\n",
      "Step: 9087, Loss: 0.4271278381347656, Accuracy: 0.875, Computation time: 1.1320991516113281\n",
      "Step: 9088, Loss: 0.36651918292045593, Accuracy: 0.8125, Computation time: 0.8730218410491943\n",
      "Step: 9089, Loss: 0.238906130194664, Accuracy: 0.9375, Computation time: 0.9509479999542236\n",
      "Step: 9090, Loss: 0.5171030163764954, Accuracy: 0.84375, Computation time: 0.9300580024719238\n",
      "Step: 9091, Loss: 0.6652910709381104, Accuracy: 0.84375, Computation time: 0.8238041400909424\n",
      "Step: 9092, Loss: 0.5191236138343811, Accuracy: 0.84375, Computation time: 1.0778849124908447\n",
      "Step: 9093, Loss: 0.30612337589263916, Accuracy: 0.96875, Computation time: 0.9976150989532471\n",
      "Step: 9094, Loss: 0.3923099637031555, Accuracy: 0.875, Computation time: 1.6337699890136719\n",
      "Step: 9095, Loss: 0.19239814579486847, Accuracy: 0.9375, Computation time: 0.86733078956604\n",
      "Step: 9096, Loss: 0.4281991124153137, Accuracy: 0.71875, Computation time: 0.7680490016937256\n",
      "Step: 9097, Loss: 0.39680567383766174, Accuracy: 0.9375, Computation time: 1.0286140441894531\n",
      "Step: 9098, Loss: 0.3922240734100342, Accuracy: 0.90625, Computation time: 1.0076649188995361\n",
      "Step: 9099, Loss: 0.4018614590167999, Accuracy: 0.90625, Computation time: 1.0476408004760742\n",
      "Step: 9100, Loss: 0.44205784797668457, Accuracy: 0.875, Computation time: 1.031383991241455\n",
      "Step: 9101, Loss: 0.3363238275051117, Accuracy: 0.90625, Computation time: 0.8870792388916016\n",
      "Step: 9102, Loss: 0.42205676436424255, Accuracy: 0.84375, Computation time: 0.9080710411071777\n",
      "Step: 9103, Loss: 0.4181644320487976, Accuracy: 0.875, Computation time: 0.8834002017974854\n",
      "Step: 9104, Loss: 0.49471402168273926, Accuracy: 0.875, Computation time: 0.904674768447876\n",
      "Step: 9105, Loss: 0.14880076050758362, Accuracy: 0.9375, Computation time: 1.1807076930999756\n",
      "Step: 9106, Loss: 0.20978891849517822, Accuracy: 0.96875, Computation time: 0.860119104385376\n",
      "Step: 9107, Loss: 0.487194299697876, Accuracy: 0.90625, Computation time: 0.916571855545044\n",
      "Step: 9108, Loss: 0.3379061818122864, Accuracy: 0.875, Computation time: 0.9274821281433105\n",
      "Step: 9109, Loss: 0.21999795734882355, Accuracy: 0.9375, Computation time: 0.9117860794067383\n",
      "Step: 9110, Loss: 0.29362553358078003, Accuracy: 0.90625, Computation time: 0.7892439365386963\n",
      "Step: 9111, Loss: 0.2291000485420227, Accuracy: 0.875, Computation time: 1.0370118618011475\n",
      "Step: 9112, Loss: 0.16391564905643463, Accuracy: 0.9375, Computation time: 0.9896140098571777\n",
      "Step: 9113, Loss: 0.49681583046913147, Accuracy: 0.90625, Computation time: 0.718660831451416\n",
      "Step: 9114, Loss: 0.4955136477947235, Accuracy: 0.875, Computation time: 0.8936831951141357\n",
      "Step: 9115, Loss: 0.2744618058204651, Accuracy: 0.9375, Computation time: 0.8824338912963867\n",
      "Step: 9116, Loss: 0.3698076605796814, Accuracy: 0.90625, Computation time: 0.7604029178619385\n",
      "Step: 9117, Loss: 0.4567849338054657, Accuracy: 0.8125, Computation time: 0.876939058303833\n",
      "Step: 9118, Loss: 0.472370982170105, Accuracy: 0.875, Computation time: 0.8139219284057617\n",
      "Step: 9119, Loss: 0.3664541244506836, Accuracy: 0.9375, Computation time: 0.9780421257019043\n",
      "Step: 9120, Loss: 0.2551170587539673, Accuracy: 0.90625, Computation time: 0.8216919898986816\n",
      "Step: 9121, Loss: 0.15373072028160095, Accuracy: 0.9375, Computation time: 0.7790899276733398\n",
      "Step: 9122, Loss: 0.34029582142829895, Accuracy: 0.90625, Computation time: 0.8093147277832031\n",
      "Step: 9123, Loss: 0.3449110686779022, Accuracy: 0.90625, Computation time: 1.6703121662139893\n",
      "Step: 9124, Loss: 0.5572444200515747, Accuracy: 0.84375, Computation time: 0.893496036529541\n",
      "Step: 9125, Loss: 0.19600991904735565, Accuracy: 0.90625, Computation time: 0.8912858963012695\n",
      "Step: 9126, Loss: 0.4844798147678375, Accuracy: 0.84375, Computation time: 0.9771420955657959\n",
      "Step: 9127, Loss: 0.6367658972740173, Accuracy: 0.75, Computation time: 0.8898799419403076\n",
      "Step: 9128, Loss: 0.6306184530258179, Accuracy: 0.84375, Computation time: 1.0194709300994873\n",
      "Step: 9129, Loss: 0.49524348974227905, Accuracy: 0.84375, Computation time: 0.991492748260498\n",
      "Step: 9130, Loss: 0.16150274872779846, Accuracy: 0.9375, Computation time: 0.852557897567749\n",
      "Step: 9131, Loss: 0.6436753273010254, Accuracy: 0.78125, Computation time: 0.8470261096954346\n",
      "Step: 9132, Loss: 0.35614460706710815, Accuracy: 0.84375, Computation time: 0.9853692054748535\n",
      "Step: 9133, Loss: 0.5998639464378357, Accuracy: 0.875, Computation time: 0.885012149810791\n",
      "Step: 9134, Loss: 0.32203373312950134, Accuracy: 0.8125, Computation time: 0.8121888637542725\n",
      "Step: 9135, Loss: 0.3158186972141266, Accuracy: 0.96875, Computation time: 0.9214053153991699\n",
      "Step: 9136, Loss: 0.260186105966568, Accuracy: 0.96875, Computation time: 0.8640017509460449\n",
      "Step: 9137, Loss: 0.7098045349121094, Accuracy: 0.78125, Computation time: 0.7878620624542236\n",
      "Step: 9138, Loss: 0.2522249221801758, Accuracy: 0.90625, Computation time: 1.2577269077301025\n",
      "Step: 9139, Loss: 0.38089558482170105, Accuracy: 0.875, Computation time: 0.9885351657867432\n",
      "Step: 9140, Loss: 0.24355342984199524, Accuracy: 0.96875, Computation time: 1.0252609252929688\n",
      "Step: 9141, Loss: 0.6345629096031189, Accuracy: 0.71875, Computation time: 0.9780809879302979\n",
      "Step: 9142, Loss: 0.633863627910614, Accuracy: 0.84375, Computation time: 0.7808799743652344\n",
      "Step: 9143, Loss: 0.6309580206871033, Accuracy: 0.84375, Computation time: 1.031855821609497\n",
      "Step: 9144, Loss: 0.23657405376434326, Accuracy: 0.90625, Computation time: 0.9060680866241455\n",
      "Step: 9145, Loss: 0.23507066071033478, Accuracy: 0.90625, Computation time: 0.9414539337158203\n",
      "Step: 9146, Loss: 0.35300692915916443, Accuracy: 0.9375, Computation time: 1.002187967300415\n",
      "Step: 9147, Loss: 0.6143988370895386, Accuracy: 0.90625, Computation time: 1.0068981647491455\n",
      "Step: 9148, Loss: 0.36916738748550415, Accuracy: 0.875, Computation time: 0.8163638114929199\n",
      "Step: 9149, Loss: 0.25632330775260925, Accuracy: 0.875, Computation time: 0.8330838680267334\n",
      "Step: 9150, Loss: 0.6384956240653992, Accuracy: 0.84375, Computation time: 0.7421228885650635\n",
      "Step: 9151, Loss: 0.32996538281440735, Accuracy: 0.875, Computation time: 0.9691898822784424\n",
      "Step: 9152, Loss: 0.25809770822525024, Accuracy: 0.9375, Computation time: 1.6981728076934814\n",
      "Step: 9153, Loss: 0.5092535614967346, Accuracy: 0.8125, Computation time: 1.6626098155975342\n",
      "Step: 9154, Loss: 0.14017672836780548, Accuracy: 1.0, Computation time: 1.0927939414978027\n",
      "Step: 9155, Loss: 0.546669065952301, Accuracy: 0.875, Computation time: 0.9629261493682861\n",
      "Step: 9156, Loss: 0.36783915758132935, Accuracy: 0.875, Computation time: 0.9963257312774658\n",
      "Step: 9157, Loss: 0.47365444898605347, Accuracy: 0.875, Computation time: 1.00266695022583\n",
      "Step: 9158, Loss: 0.37299638986587524, Accuracy: 0.78125, Computation time: 1.0354681015014648\n",
      "Step: 9159, Loss: 0.5322072505950928, Accuracy: 0.84375, Computation time: 0.8377289772033691\n",
      "Step: 9160, Loss: 0.2377023696899414, Accuracy: 0.9375, Computation time: 0.9709370136260986\n",
      "Step: 9161, Loss: 0.5762876868247986, Accuracy: 0.875, Computation time: 0.8345410823822021\n",
      "Step: 9162, Loss: 0.4164246618747711, Accuracy: 0.875, Computation time: 1.075221061706543\n",
      "Step: 9163, Loss: 0.4952079951763153, Accuracy: 0.75, Computation time: 1.0564417839050293\n",
      "Step: 9164, Loss: 0.6545254588127136, Accuracy: 0.84375, Computation time: 0.8411588668823242\n",
      "Step: 9165, Loss: 0.5207929015159607, Accuracy: 0.90625, Computation time: 1.1675069332122803\n",
      "Step: 9166, Loss: 0.18594908714294434, Accuracy: 0.96875, Computation time: 0.8272709846496582\n",
      "Step: 9167, Loss: 0.3398091793060303, Accuracy: 0.84375, Computation time: 1.2218148708343506\n",
      "Step: 9168, Loss: 0.19835463166236877, Accuracy: 0.9375, Computation time: 0.8082549571990967\n",
      "Step: 9169, Loss: 0.36471542716026306, Accuracy: 0.875, Computation time: 0.8678572177886963\n",
      "Step: 9170, Loss: 0.3281913995742798, Accuracy: 0.9375, Computation time: 0.773277759552002\n",
      "Step: 9171, Loss: 0.5963874459266663, Accuracy: 0.8125, Computation time: 0.9146671295166016\n",
      "Step: 9172, Loss: 0.34563949704170227, Accuracy: 0.90625, Computation time: 1.0419132709503174\n",
      "Step: 9173, Loss: 0.7890114188194275, Accuracy: 0.8125, Computation time: 0.9852452278137207\n",
      "Step: 9174, Loss: 0.26184001564979553, Accuracy: 0.90625, Computation time: 1.091944932937622\n",
      "Step: 9175, Loss: 0.20231018960475922, Accuracy: 0.9375, Computation time: 0.93060302734375\n",
      "Step: 9176, Loss: 0.48421546816825867, Accuracy: 0.90625, Computation time: 0.913292646408081\n",
      "Step: 9177, Loss: 0.24085666239261627, Accuracy: 0.90625, Computation time: 1.1057860851287842\n",
      "Step: 9178, Loss: 0.23701299726963043, Accuracy: 0.90625, Computation time: 0.7943329811096191\n",
      "Step: 9179, Loss: 0.881915807723999, Accuracy: 0.875, Computation time: 1.2764811515808105\n",
      "Step: 9180, Loss: 0.537522554397583, Accuracy: 0.8125, Computation time: 0.850405216217041\n",
      "Step: 9181, Loss: 0.5126802921295166, Accuracy: 0.8125, Computation time: 1.041062831878662\n",
      "Step: 9182, Loss: 0.6241086721420288, Accuracy: 0.8125, Computation time: 0.9195981025695801\n",
      "Step: 9183, Loss: 0.41179171204566956, Accuracy: 0.90625, Computation time: 0.9231128692626953\n",
      "Step: 9184, Loss: 0.23672091960906982, Accuracy: 0.90625, Computation time: 1.10368013381958\n",
      "Step: 9185, Loss: 0.43845024704933167, Accuracy: 0.90625, Computation time: 0.8046581745147705\n",
      "Step: 9186, Loss: 0.32317838072776794, Accuracy: 0.96875, Computation time: 0.8056788444519043\n",
      "Step: 9187, Loss: 0.608977198600769, Accuracy: 0.84375, Computation time: 1.0196599960327148\n",
      "Step: 9188, Loss: 0.22123317420482635, Accuracy: 0.9375, Computation time: 1.272120714187622\n",
      "Step: 9189, Loss: 0.5897080302238464, Accuracy: 0.8125, Computation time: 0.9767348766326904\n",
      "Step: 9190, Loss: 0.29709532856941223, Accuracy: 0.90625, Computation time: 0.8250188827514648\n",
      "Step: 9191, Loss: 0.5695745944976807, Accuracy: 0.8125, Computation time: 0.8961660861968994\n",
      "Step: 9192, Loss: 0.3753231465816498, Accuracy: 0.875, Computation time: 0.7972359657287598\n",
      "Step: 9193, Loss: 0.4177929162979126, Accuracy: 0.875, Computation time: 0.8911750316619873\n",
      "Step: 9194, Loss: 0.32334357500076294, Accuracy: 0.9375, Computation time: 0.8396258354187012\n",
      "Step: 9195, Loss: 0.33764946460723877, Accuracy: 0.875, Computation time: 0.9478778839111328\n",
      "Step: 9196, Loss: 0.7930716276168823, Accuracy: 0.78125, Computation time: 1.0601568222045898\n",
      "Step: 9197, Loss: 0.44984695315361023, Accuracy: 0.84375, Computation time: 0.9731278419494629\n",
      "Step: 9198, Loss: 0.2625200152397156, Accuracy: 0.9375, Computation time: 0.9122059345245361\n",
      "Step: 9199, Loss: 0.2440335899591446, Accuracy: 0.9375, Computation time: 1.0114531517028809\n",
      "Step: 9200, Loss: 0.3626522123813629, Accuracy: 0.9375, Computation time: 0.9603238105773926\n",
      "Step: 9201, Loss: 0.32945650815963745, Accuracy: 0.875, Computation time: 0.8970119953155518\n",
      "Step: 9202, Loss: 0.37408891320228577, Accuracy: 0.90625, Computation time: 0.980828046798706\n",
      "Step: 9203, Loss: 0.43309280276298523, Accuracy: 0.8125, Computation time: 0.9254789352416992\n",
      "Step: 9204, Loss: 0.11089296638965607, Accuracy: 1.0, Computation time: 0.8755216598510742\n",
      "Step: 9205, Loss: 0.3646985590457916, Accuracy: 0.8125, Computation time: 0.8609898090362549\n",
      "Step: 9206, Loss: 0.4168522357940674, Accuracy: 0.875, Computation time: 0.9335799217224121\n",
      "Step: 9207, Loss: 0.942287266254425, Accuracy: 0.78125, Computation time: 1.059140682220459\n",
      "Step: 9208, Loss: 0.20908385515213013, Accuracy: 0.9375, Computation time: 1.646956205368042\n",
      "Step: 9209, Loss: 0.43435123562812805, Accuracy: 0.875, Computation time: 0.8593759536743164\n",
      "Step: 9210, Loss: 0.5395017862319946, Accuracy: 0.8125, Computation time: 1.239926815032959\n",
      "Step: 9211, Loss: 0.16356074810028076, Accuracy: 0.9375, Computation time: 1.0342588424682617\n",
      "Step: 9212, Loss: 0.5262525677680969, Accuracy: 0.8125, Computation time: 0.9191141128540039\n",
      "Step: 9213, Loss: 0.19250038266181946, Accuracy: 0.96875, Computation time: 0.9669346809387207\n",
      "Step: 9214, Loss: 0.45738109946250916, Accuracy: 0.8125, Computation time: 0.9751639366149902\n",
      "Step: 9215, Loss: 0.34394770860671997, Accuracy: 0.875, Computation time: 0.8069887161254883\n",
      "Step: 9216, Loss: 0.334339439868927, Accuracy: 0.875, Computation time: 1.0295741558074951\n",
      "Step: 9217, Loss: 0.4230828285217285, Accuracy: 0.84375, Computation time: 0.8027379512786865\n",
      "Step: 9218, Loss: 0.2551790475845337, Accuracy: 0.90625, Computation time: 0.9226822853088379\n",
      "Step: 9219, Loss: 0.5067552328109741, Accuracy: 0.84375, Computation time: 0.9004859924316406\n",
      "Step: 9220, Loss: 0.4849124550819397, Accuracy: 0.84375, Computation time: 1.3066859245300293\n",
      "Step: 9221, Loss: 0.7970743775367737, Accuracy: 0.71875, Computation time: 1.0249710083007812\n",
      "Step: 9222, Loss: 0.29216066002845764, Accuracy: 0.96875, Computation time: 1.0725603103637695\n",
      "Step: 9223, Loss: 0.5113117694854736, Accuracy: 0.84375, Computation time: 0.8810150623321533\n",
      "Step: 9224, Loss: 0.3432766795158386, Accuracy: 0.84375, Computation time: 0.9300520420074463\n",
      "Step: 9225, Loss: 0.26797378063201904, Accuracy: 0.875, Computation time: 1.0470199584960938\n",
      "Step: 9226, Loss: 0.7058322429656982, Accuracy: 0.8125, Computation time: 0.9672439098358154\n",
      "Step: 9227, Loss: 0.34260404109954834, Accuracy: 0.90625, Computation time: 1.0358891487121582\n",
      "Step: 9228, Loss: 0.32504743337631226, Accuracy: 0.875, Computation time: 0.9291040897369385\n",
      "Step: 9229, Loss: 0.36009031534194946, Accuracy: 0.9375, Computation time: 1.0656089782714844\n",
      "Step: 9230, Loss: 0.1333148181438446, Accuracy: 0.96875, Computation time: 0.8718709945678711\n",
      "Step: 9231, Loss: 0.5655277967453003, Accuracy: 0.8125, Computation time: 1.8832340240478516\n",
      "Step: 9232, Loss: 0.2555907368659973, Accuracy: 0.90625, Computation time: 0.8343799114227295\n",
      "Step: 9233, Loss: 0.24300836026668549, Accuracy: 0.9375, Computation time: 0.9168071746826172\n",
      "Step: 9234, Loss: 0.1791713386774063, Accuracy: 0.9375, Computation time: 0.8841941356658936\n",
      "Step: 9235, Loss: 0.8842962980270386, Accuracy: 0.71875, Computation time: 1.4692699909210205\n",
      "Step: 9236, Loss: 0.3778023421764374, Accuracy: 0.875, Computation time: 0.8814411163330078\n",
      "Step: 9237, Loss: 0.2699919641017914, Accuracy: 0.90625, Computation time: 0.9541280269622803\n",
      "Step: 9238, Loss: 0.27235013246536255, Accuracy: 0.90625, Computation time: 0.9494471549987793\n",
      "Step: 9239, Loss: 0.35710543394088745, Accuracy: 0.875, Computation time: 0.9179840087890625\n",
      "Step: 9240, Loss: 0.3897261321544647, Accuracy: 0.875, Computation time: 0.8784117698669434\n",
      "Step: 9241, Loss: 0.33377978205680847, Accuracy: 0.875, Computation time: 0.9009599685668945\n",
      "Step: 9242, Loss: 0.3810202181339264, Accuracy: 0.875, Computation time: 1.0876359939575195\n",
      "Step: 9243, Loss: 0.5236761569976807, Accuracy: 0.84375, Computation time: 0.9277012348175049\n",
      "Step: 9244, Loss: 0.3147869408130646, Accuracy: 0.9375, Computation time: 0.8448750972747803\n",
      "Step: 9245, Loss: 0.4696933627128601, Accuracy: 0.90625, Computation time: 1.028074026107788\n",
      "Step: 9246, Loss: 0.32314833998680115, Accuracy: 0.90625, Computation time: 0.8867859840393066\n",
      "Step: 9247, Loss: 0.25834786891937256, Accuracy: 0.875, Computation time: 0.8509750366210938\n",
      "Step: 9248, Loss: 0.393625944852829, Accuracy: 0.84375, Computation time: 1.0012569427490234\n",
      "Step: 9249, Loss: 0.20181679725646973, Accuracy: 0.96875, Computation time: 1.1540307998657227\n",
      "Step: 9250, Loss: 0.12627550959587097, Accuracy: 1.0, Computation time: 0.8663058280944824\n",
      "Step: 9251, Loss: 0.26351994276046753, Accuracy: 0.84375, Computation time: 1.003720998764038\n",
      "Step: 9252, Loss: 0.6323713660240173, Accuracy: 0.84375, Computation time: 0.7712531089782715\n",
      "Step: 9253, Loss: 0.19406868517398834, Accuracy: 0.96875, Computation time: 0.9039239883422852\n",
      "Step: 9254, Loss: 0.44895562529563904, Accuracy: 0.90625, Computation time: 1.3188719749450684\n",
      "Step: 9255, Loss: 0.4031459093093872, Accuracy: 0.90625, Computation time: 1.4970579147338867\n",
      "Step: 9256, Loss: 0.31483057141304016, Accuracy: 0.90625, Computation time: 0.7086436748504639\n",
      "Step: 9257, Loss: 0.2535172700881958, Accuracy: 0.90625, Computation time: 0.8645970821380615\n",
      "Step: 9258, Loss: 0.5696099400520325, Accuracy: 0.84375, Computation time: 0.8510940074920654\n",
      "Step: 9259, Loss: 0.6185925006866455, Accuracy: 0.84375, Computation time: 0.8734619617462158\n",
      "Step: 9260, Loss: 0.3987618684768677, Accuracy: 0.90625, Computation time: 0.9045412540435791\n",
      "Step: 9261, Loss: 0.4611561596393585, Accuracy: 0.84375, Computation time: 0.9467909336090088\n",
      "Step: 9262, Loss: 0.2458629608154297, Accuracy: 0.96875, Computation time: 0.8559927940368652\n",
      "Step: 9263, Loss: 0.3571963906288147, Accuracy: 0.90625, Computation time: 1.6684608459472656\n",
      "Step: 9264, Loss: 0.2620708644390106, Accuracy: 0.84375, Computation time: 0.8208730220794678\n",
      "Step: 9265, Loss: 0.28787827491760254, Accuracy: 0.90625, Computation time: 1.023169994354248\n",
      "Step: 9266, Loss: 0.33627939224243164, Accuracy: 0.90625, Computation time: 0.8208208084106445\n",
      "Step: 9267, Loss: 0.8356520533561707, Accuracy: 0.8125, Computation time: 1.356407642364502\n",
      "Step: 9268, Loss: 0.11885524541139603, Accuracy: 1.0, Computation time: 1.1297531127929688\n",
      "Step: 9269, Loss: 0.5677215456962585, Accuracy: 0.84375, Computation time: 0.9230449199676514\n",
      "Step: 9270, Loss: 0.3595823347568512, Accuracy: 0.9375, Computation time: 0.976003885269165\n",
      "Step: 9271, Loss: 0.1625506728887558, Accuracy: 0.96875, Computation time: 0.9938399791717529\n",
      "Step: 9272, Loss: 0.2612982988357544, Accuracy: 0.9375, Computation time: 0.8059988021850586\n",
      "Step: 9273, Loss: 0.43713074922561646, Accuracy: 0.84375, Computation time: 0.9467072486877441\n",
      "Step: 9274, Loss: 0.1174154132604599, Accuracy: 0.96875, Computation time: 0.8692800998687744\n",
      "Step: 9275, Loss: 0.5291942954063416, Accuracy: 0.875, Computation time: 1.0224928855895996\n",
      "Step: 9276, Loss: 0.2890106737613678, Accuracy: 0.90625, Computation time: 0.8365688323974609\n",
      "Step: 9277, Loss: 0.6747787594795227, Accuracy: 0.875, Computation time: 0.8662190437316895\n",
      "Step: 9278, Loss: 0.3919690251350403, Accuracy: 0.9375, Computation time: 1.0564830303192139\n",
      "Step: 9279, Loss: 0.33189645409584045, Accuracy: 0.90625, Computation time: 1.020509958267212\n",
      "Step: 9280, Loss: 0.2648591697216034, Accuracy: 0.9375, Computation time: 0.7700581550598145\n",
      "Step: 9281, Loss: 0.3683692514896393, Accuracy: 0.90625, Computation time: 0.7831437587738037\n",
      "Step: 9282, Loss: 0.38953351974487305, Accuracy: 0.90625, Computation time: 0.995812177658081\n",
      "Step: 9283, Loss: 0.14815732836723328, Accuracy: 0.9375, Computation time: 1.0786750316619873\n",
      "Step: 9284, Loss: 0.21370483934879303, Accuracy: 0.9375, Computation time: 0.990792989730835\n",
      "Step: 9285, Loss: 0.4317283630371094, Accuracy: 0.90625, Computation time: 0.796597957611084\n",
      "Step: 9286, Loss: 0.1533554345369339, Accuracy: 0.9375, Computation time: 0.8145170211791992\n",
      "Step: 9287, Loss: 0.3194676339626312, Accuracy: 0.90625, Computation time: 1.1368420124053955\n",
      "Step: 9288, Loss: 0.09985349327325821, Accuracy: 0.96875, Computation time: 0.7386260032653809\n",
      "Step: 9289, Loss: 0.17475658655166626, Accuracy: 0.9375, Computation time: 0.7729668617248535\n",
      "Step: 9290, Loss: 0.4516437351703644, Accuracy: 0.8125, Computation time: 0.9462661743164062\n",
      "Step: 9291, Loss: 0.2106132209300995, Accuracy: 0.96875, Computation time: 0.8645541667938232\n",
      "Step: 9292, Loss: 0.23152539134025574, Accuracy: 0.96875, Computation time: 1.5655980110168457\n",
      "Step: 9293, Loss: 0.2636609971523285, Accuracy: 0.84375, Computation time: 0.8635609149932861\n",
      "Step: 9294, Loss: 0.5128023624420166, Accuracy: 0.8125, Computation time: 0.8230719566345215\n",
      "Step: 9295, Loss: 0.13311567902565002, Accuracy: 0.96875, Computation time: 1.0997161865234375\n",
      "Step: 9296, Loss: 0.3280567228794098, Accuracy: 0.8125, Computation time: 0.8865370750427246\n",
      "Step: 9297, Loss: 0.23442387580871582, Accuracy: 0.9375, Computation time: 0.8895471096038818\n",
      "Step: 9298, Loss: 0.28179603815078735, Accuracy: 0.90625, Computation time: 1.0826430320739746\n",
      "Step: 9299, Loss: 0.22162140905857086, Accuracy: 0.9375, Computation time: 0.8968939781188965\n",
      "Step: 9300, Loss: 0.712174654006958, Accuracy: 0.78125, Computation time: 1.0240111351013184\n",
      "Step: 9301, Loss: 0.35889604687690735, Accuracy: 0.9375, Computation time: 0.8236706256866455\n",
      "Step: 9302, Loss: 0.3230639398097992, Accuracy: 0.875, Computation time: 1.0517356395721436\n",
      "Step: 9303, Loss: 0.3635067939758301, Accuracy: 0.90625, Computation time: 0.9738302230834961\n",
      "Step: 9304, Loss: 0.18018101155757904, Accuracy: 0.9375, Computation time: 0.9664008617401123\n",
      "Step: 9305, Loss: 0.4613398015499115, Accuracy: 0.84375, Computation time: 0.7996249198913574\n",
      "Step: 9306, Loss: 0.6525081992149353, Accuracy: 0.84375, Computation time: 0.8151288032531738\n",
      "Step: 9307, Loss: 0.46586373448371887, Accuracy: 0.8125, Computation time: 0.929520845413208\n",
      "Step: 9308, Loss: 0.2640092074871063, Accuracy: 0.9375, Computation time: 0.9077408313751221\n",
      "Step: 9309, Loss: 0.3608996868133545, Accuracy: 0.9375, Computation time: 0.8543229103088379\n",
      "Step: 9310, Loss: 0.4793166220188141, Accuracy: 0.875, Computation time: 0.9969251155853271\n",
      "Step: 9311, Loss: 0.24316416680812836, Accuracy: 0.9375, Computation time: 0.7792961597442627\n",
      "Step: 9312, Loss: 0.322697252035141, Accuracy: 0.875, Computation time: 0.967292070388794\n",
      "Step: 9313, Loss: 1.1824042797088623, Accuracy: 0.6875, Computation time: 0.8819961547851562\n",
      "Step: 9314, Loss: 0.36273106932640076, Accuracy: 0.90625, Computation time: 0.8775722980499268\n",
      "Step: 9315, Loss: 0.154046431183815, Accuracy: 0.9375, Computation time: 0.8746969699859619\n",
      "Step: 9316, Loss: 0.2558610141277313, Accuracy: 0.875, Computation time: 1.0839869976043701\n",
      "Step: 9317, Loss: 0.2351033091545105, Accuracy: 0.875, Computation time: 0.977736234664917\n",
      "Step: 9318, Loss: 0.24773168563842773, Accuracy: 0.9375, Computation time: 0.8330590724945068\n",
      "Step: 9319, Loss: 0.16048716008663177, Accuracy: 0.9375, Computation time: 1.0277478694915771\n",
      "Step: 9320, Loss: 0.2990855574607849, Accuracy: 0.9375, Computation time: 2.0386269092559814\n",
      "Step: 9321, Loss: 0.29498299956321716, Accuracy: 0.90625, Computation time: 1.0408189296722412\n",
      "Step: 9322, Loss: 0.3222840130329132, Accuracy: 0.90625, Computation time: 0.9075210094451904\n",
      "Step: 9323, Loss: 0.37759295105934143, Accuracy: 0.84375, Computation time: 0.9688320159912109\n",
      "Step: 9324, Loss: 0.2785693109035492, Accuracy: 0.90625, Computation time: 0.8346099853515625\n",
      "Step: 9325, Loss: 0.31352555751800537, Accuracy: 0.875, Computation time: 1.1971158981323242\n",
      "Step: 9326, Loss: 0.23933640122413635, Accuracy: 0.9375, Computation time: 1.240365743637085\n",
      "Step: 9327, Loss: 0.26764267683029175, Accuracy: 0.9375, Computation time: 0.7287161350250244\n",
      "Step: 9328, Loss: 0.3356616199016571, Accuracy: 0.90625, Computation time: 0.9163908958435059\n",
      "Step: 9329, Loss: 0.20751142501831055, Accuracy: 0.9375, Computation time: 0.8091781139373779\n",
      "Step: 9330, Loss: 0.3917713761329651, Accuracy: 0.90625, Computation time: 1.0844721794128418\n",
      "Step: 9331, Loss: 0.3521084487438202, Accuracy: 0.875, Computation time: 0.9897270202636719\n",
      "Step: 9332, Loss: 0.6959977149963379, Accuracy: 0.75, Computation time: 1.086726188659668\n",
      "Step: 9333, Loss: 0.46635007858276367, Accuracy: 0.84375, Computation time: 0.9153850078582764\n",
      "Step: 9334, Loss: 0.7247838377952576, Accuracy: 0.75, Computation time: 0.8097429275512695\n",
      "Step: 9335, Loss: 0.2899992763996124, Accuracy: 0.9375, Computation time: 0.7743229866027832\n",
      "Step: 9336, Loss: 0.4760540723800659, Accuracy: 0.90625, Computation time: 0.8048927783966064\n",
      "Step: 9337, Loss: 0.5588428378105164, Accuracy: 0.84375, Computation time: 0.9749670028686523\n",
      "Step: 9338, Loss: 0.38532885909080505, Accuracy: 0.84375, Computation time: 0.818774938583374\n",
      "Step: 9339, Loss: 0.26282307505607605, Accuracy: 0.9375, Computation time: 0.7345137596130371\n",
      "Step: 9340, Loss: 0.6049646735191345, Accuracy: 0.8125, Computation time: 0.8987071514129639\n",
      "Step: 9341, Loss: 0.12436368316411972, Accuracy: 0.96875, Computation time: 0.7786831855773926\n",
      "Step: 9342, Loss: 0.43220508098602295, Accuracy: 0.84375, Computation time: 1.0904598236083984\n",
      "Step: 9343, Loss: 0.18666742742061615, Accuracy: 0.96875, Computation time: 0.9102551937103271\n",
      "Step: 9344, Loss: 0.2064019739627838, Accuracy: 0.96875, Computation time: 1.1338880062103271\n",
      "Step: 9345, Loss: 0.518001139163971, Accuracy: 0.875, Computation time: 1.0701441764831543\n",
      "Step: 9346, Loss: 0.4280877411365509, Accuracy: 0.8125, Computation time: 0.8290879726409912\n",
      "Step: 9347, Loss: 0.3966415226459503, Accuracy: 0.875, Computation time: 0.9763929843902588\n",
      "Step: 9348, Loss: 0.19443771243095398, Accuracy: 0.9375, Computation time: 0.7698969841003418\n",
      "Step: 9349, Loss: 0.20321770012378693, Accuracy: 0.9375, Computation time: 1.4781298637390137\n",
      "Step: 9350, Loss: 0.5036688446998596, Accuracy: 0.90625, Computation time: 0.9132251739501953\n",
      "Step: 9351, Loss: 0.24785961210727692, Accuracy: 0.9375, Computation time: 0.9478771686553955\n",
      "Step: 9352, Loss: 0.2832251191139221, Accuracy: 0.90625, Computation time: 1.0357141494750977\n",
      "Step: 9353, Loss: 0.46771982312202454, Accuracy: 0.875, Computation time: 0.9252290725708008\n",
      "Step: 9354, Loss: 0.38844993710517883, Accuracy: 0.90625, Computation time: 0.9331908226013184\n",
      "Step: 9355, Loss: 0.10494139045476913, Accuracy: 0.96875, Computation time: 0.8465118408203125\n",
      "Step: 9356, Loss: 0.38610297441482544, Accuracy: 0.875, Computation time: 0.9496917724609375\n",
      "Step: 9357, Loss: 0.14620903134346008, Accuracy: 0.96875, Computation time: 0.9265239238739014\n",
      "Step: 9358, Loss: 0.5904501080513, Accuracy: 0.84375, Computation time: 0.9336369037628174\n",
      "Step: 9359, Loss: 0.49863559007644653, Accuracy: 0.84375, Computation time: 0.9725990295410156\n",
      "Step: 9360, Loss: 0.09881722182035446, Accuracy: 0.96875, Computation time: 0.7241911888122559\n",
      "Step: 9361, Loss: 0.6890978217124939, Accuracy: 0.75, Computation time: 0.7839059829711914\n",
      "Step: 9362, Loss: 0.2894909381866455, Accuracy: 0.9375, Computation time: 0.8941199779510498\n",
      "Step: 9363, Loss: 0.39475637674331665, Accuracy: 0.84375, Computation time: 0.7599020004272461\n",
      "Step: 9364, Loss: 0.4045048654079437, Accuracy: 0.84375, Computation time: 1.0812499523162842\n",
      "Step: 9365, Loss: 0.2991878390312195, Accuracy: 0.90625, Computation time: 0.9417610168457031\n",
      "Step: 9366, Loss: 0.47312071919441223, Accuracy: 0.90625, Computation time: 0.7907669544219971\n",
      "Step: 9367, Loss: 0.7916571497917175, Accuracy: 0.8125, Computation time: 0.9495992660522461\n",
      "Step: 9368, Loss: 0.41098231077194214, Accuracy: 0.875, Computation time: 0.8273611068725586\n",
      "Step: 9369, Loss: 0.35884109139442444, Accuracy: 0.875, Computation time: 0.9296813011169434\n",
      "Step: 9370, Loss: 0.27641940116882324, Accuracy: 0.90625, Computation time: 0.8760912418365479\n",
      "Step: 9371, Loss: 0.5629147887229919, Accuracy: 0.84375, Computation time: 0.8840639591217041\n",
      "Step: 9372, Loss: 0.580808162689209, Accuracy: 0.8125, Computation time: 0.842108964920044\n",
      "Step: 9373, Loss: 0.21210245788097382, Accuracy: 0.9375, Computation time: 0.8765580654144287\n",
      "Step: 9374, Loss: 0.20198354125022888, Accuracy: 0.90625, Computation time: 0.792391300201416\n",
      "Step: 9375, Loss: 0.546829879283905, Accuracy: 0.84375, Computation time: 1.3175537586212158\n",
      "Step: 9376, Loss: 0.3906247019767761, Accuracy: 0.875, Computation time: 0.7864429950714111\n",
      "Step: 9377, Loss: 0.28662294149398804, Accuracy: 0.9375, Computation time: 0.8418822288513184\n",
      "Step: 9378, Loss: 0.534020721912384, Accuracy: 0.84375, Computation time: 0.7194390296936035\n",
      "Step: 9379, Loss: 0.5017481446266174, Accuracy: 0.84375, Computation time: 1.5205249786376953\n",
      "Step: 9380, Loss: 0.20721952617168427, Accuracy: 0.96875, Computation time: 0.8703873157501221\n",
      "Step: 9381, Loss: 0.12943923473358154, Accuracy: 0.96875, Computation time: 0.9845471382141113\n",
      "Step: 9382, Loss: 0.30190375447273254, Accuracy: 0.9375, Computation time: 0.9242591857910156\n",
      "Step: 9383, Loss: 0.452675998210907, Accuracy: 0.875, Computation time: 1.0521726608276367\n",
      "Step: 9384, Loss: 0.4534115791320801, Accuracy: 0.71875, Computation time: 0.9272100925445557\n",
      "Step: 9385, Loss: 0.5528244376182556, Accuracy: 0.84375, Computation time: 0.8665308952331543\n",
      "Step: 9386, Loss: 0.29152923822402954, Accuracy: 0.875, Computation time: 0.7656850814819336\n",
      "Step: 9387, Loss: 0.1636667400598526, Accuracy: 0.90625, Computation time: 0.8512849807739258\n",
      "Step: 9388, Loss: 0.2917577624320984, Accuracy: 0.90625, Computation time: 0.7472038269042969\n",
      "Step: 9389, Loss: 0.30200713872909546, Accuracy: 0.9375, Computation time: 0.9679181575775146\n",
      "Step: 9390, Loss: 0.429090678691864, Accuracy: 0.84375, Computation time: 1.2359538078308105\n",
      "Step: 9391, Loss: 0.3247241973876953, Accuracy: 0.90625, Computation time: 0.917778730392456\n",
      "Step: 9392, Loss: 0.49008265137672424, Accuracy: 0.90625, Computation time: 0.9300730228424072\n",
      "Step: 9393, Loss: 0.14844325184822083, Accuracy: 0.9375, Computation time: 0.9350888729095459\n",
      "Step: 9394, Loss: 0.4053136110305786, Accuracy: 0.84375, Computation time: 0.8290669918060303\n",
      "Step: 9395, Loss: 0.22619274258613586, Accuracy: 0.90625, Computation time: 0.9822158813476562\n",
      "Step: 9396, Loss: 0.09650219976902008, Accuracy: 1.0, Computation time: 1.075023889541626\n",
      "Step: 9397, Loss: 0.3593716025352478, Accuracy: 0.875, Computation time: 0.909034013748169\n",
      "Step: 9398, Loss: 0.7366589903831482, Accuracy: 0.78125, Computation time: 1.452739953994751\n",
      "Step: 9399, Loss: 0.4083300828933716, Accuracy: 0.875, Computation time: 0.8009848594665527\n",
      "Step: 9400, Loss: 0.2865746021270752, Accuracy: 0.9375, Computation time: 0.7653388977050781\n",
      "Step: 9401, Loss: 0.14586305618286133, Accuracy: 0.9375, Computation time: 0.9796249866485596\n",
      "Step: 9402, Loss: 0.05412592738866806, Accuracy: 1.0, Computation time: 1.2219607830047607\n",
      "Step: 9403, Loss: 0.29852256178855896, Accuracy: 0.90625, Computation time: 0.8856797218322754\n",
      "Step: 9404, Loss: 0.3346641957759857, Accuracy: 0.90625, Computation time: 0.927501916885376\n",
      "Step: 9405, Loss: 0.5647954940795898, Accuracy: 0.8125, Computation time: 0.9338059425354004\n",
      "Step: 9406, Loss: 0.2694683372974396, Accuracy: 0.875, Computation time: 0.9388160705566406\n",
      "Step: 9407, Loss: 0.1884637326002121, Accuracy: 0.96875, Computation time: 1.6325578689575195\n",
      "Step: 9408, Loss: 0.1804496943950653, Accuracy: 0.96875, Computation time: 0.8344440460205078\n",
      "Step: 9409, Loss: 0.11473007500171661, Accuracy: 1.0, Computation time: 0.7869048118591309\n",
      "Step: 9410, Loss: 0.30562376976013184, Accuracy: 0.875, Computation time: 1.0660099983215332\n",
      "Step: 9411, Loss: 0.570540189743042, Accuracy: 0.84375, Computation time: 0.8725860118865967\n",
      "Step: 9412, Loss: 0.40206876397132874, Accuracy: 0.90625, Computation time: 0.8201768398284912\n",
      "Step: 9413, Loss: 0.6057743430137634, Accuracy: 0.84375, Computation time: 0.8202080726623535\n",
      "Step: 9414, Loss: 0.6694362163543701, Accuracy: 0.84375, Computation time: 0.9141559600830078\n",
      "Step: 9415, Loss: 0.1121312752366066, Accuracy: 0.96875, Computation time: 0.9650030136108398\n",
      "Step: 9416, Loss: 0.3184964656829834, Accuracy: 0.90625, Computation time: 0.9382078647613525\n",
      "Step: 9417, Loss: 0.3382823169231415, Accuracy: 0.90625, Computation time: 0.830031156539917\n",
      "Step: 9418, Loss: 0.26824527978897095, Accuracy: 0.9375, Computation time: 0.8280670642852783\n",
      "Step: 9419, Loss: 0.25127094984054565, Accuracy: 0.90625, Computation time: 1.062345027923584\n",
      "Step: 9420, Loss: 0.3119305670261383, Accuracy: 0.90625, Computation time: 0.8974409103393555\n",
      "Step: 9421, Loss: 0.29769712686538696, Accuracy: 0.9375, Computation time: 1.393812894821167\n",
      "Step: 9422, Loss: 0.262309730052948, Accuracy: 0.90625, Computation time: 1.0137720108032227\n",
      "Step: 9423, Loss: 0.23075348138809204, Accuracy: 0.875, Computation time: 0.9071710109710693\n",
      "Step: 9424, Loss: 0.2586574852466583, Accuracy: 0.90625, Computation time: 1.0832362174987793\n",
      "Step: 9425, Loss: 0.33059000968933105, Accuracy: 0.90625, Computation time: 1.0168161392211914\n",
      "Step: 9426, Loss: 0.4091286361217499, Accuracy: 0.78125, Computation time: 0.9572727680206299\n",
      "Step: 9427, Loss: 0.2676323354244232, Accuracy: 0.9375, Computation time: 0.9256482124328613\n",
      "Step: 9428, Loss: 1.043412208557129, Accuracy: 0.78125, Computation time: 0.8710298538208008\n",
      "Step: 9429, Loss: 0.3763948380947113, Accuracy: 0.875, Computation time: 0.9352149963378906\n",
      "Step: 9430, Loss: 0.26996588706970215, Accuracy: 0.9375, Computation time: 0.9785950183868408\n",
      "Step: 9431, Loss: 0.2070210576057434, Accuracy: 0.90625, Computation time: 0.8285441398620605\n",
      "Step: 9432, Loss: 0.558506190776825, Accuracy: 0.8125, Computation time: 0.8300619125366211\n",
      "Step: 9433, Loss: 0.4326084852218628, Accuracy: 0.875, Computation time: 0.8694169521331787\n",
      "Step: 9434, Loss: 0.4309493899345398, Accuracy: 0.875, Computation time: 0.898745059967041\n",
      "Step: 9435, Loss: 0.29511603713035583, Accuracy: 0.9375, Computation time: 0.9226288795471191\n",
      "Step: 9436, Loss: 0.3196636736392975, Accuracy: 0.875, Computation time: 1.4606919288635254\n",
      "Step: 9437, Loss: 0.392113596200943, Accuracy: 0.875, Computation time: 0.9182751178741455\n",
      "Step: 9438, Loss: 0.47882983088493347, Accuracy: 0.8125, Computation time: 0.8981418609619141\n",
      "Step: 9439, Loss: 0.22834153473377228, Accuracy: 0.90625, Computation time: 0.9751660823822021\n",
      "Step: 9440, Loss: 0.24290987849235535, Accuracy: 0.90625, Computation time: 0.9000139236450195\n",
      "Step: 9441, Loss: 0.4080274701118469, Accuracy: 0.84375, Computation time: 1.048426866531372\n",
      "Step: 9442, Loss: 0.5032252073287964, Accuracy: 0.78125, Computation time: 0.9240231513977051\n",
      "Step: 9443, Loss: 0.3740184009075165, Accuracy: 0.90625, Computation time: 0.7868759632110596\n",
      "Step: 9444, Loss: 0.4797930121421814, Accuracy: 0.875, Computation time: 0.8113250732421875\n",
      "Step: 9445, Loss: 0.6072563529014587, Accuracy: 0.84375, Computation time: 0.8471150398254395\n",
      "Step: 9446, Loss: 0.27426835894584656, Accuracy: 0.90625, Computation time: 0.8267741203308105\n",
      "Step: 9447, Loss: 0.361281156539917, Accuracy: 0.90625, Computation time: 0.9698870182037354\n",
      "Step: 9448, Loss: 0.2837553024291992, Accuracy: 0.9375, Computation time: 0.7758636474609375\n",
      "Step: 9449, Loss: 0.3814542293548584, Accuracy: 0.84375, Computation time: 0.866779088973999\n",
      "Step: 9450, Loss: 0.2146749198436737, Accuracy: 0.90625, Computation time: 0.8517467975616455\n",
      "Step: 9451, Loss: 0.8676648736000061, Accuracy: 0.8125, Computation time: 0.9280719757080078\n",
      "Step: 9452, Loss: 0.193526953458786, Accuracy: 0.9375, Computation time: 0.9453690052032471\n",
      "Step: 9453, Loss: 0.48396509885787964, Accuracy: 0.8125, Computation time: 0.8920340538024902\n",
      "Step: 9454, Loss: 0.5169104337692261, Accuracy: 0.84375, Computation time: 0.8866381645202637\n",
      "Step: 9455, Loss: 0.29396137595176697, Accuracy: 0.9375, Computation time: 1.1232447624206543\n",
      "Step: 9456, Loss: 0.32889458537101746, Accuracy: 0.9375, Computation time: 0.8489632606506348\n",
      "Step: 9457, Loss: 0.2502366006374359, Accuracy: 0.90625, Computation time: 0.8818328380584717\n",
      "Step: 9458, Loss: 0.20087747275829315, Accuracy: 0.9375, Computation time: 0.8845179080963135\n",
      "Step: 9459, Loss: 0.20118342339992523, Accuracy: 0.9375, Computation time: 0.9855430126190186\n",
      "Step: 9460, Loss: 0.3337121903896332, Accuracy: 0.9375, Computation time: 0.8578369617462158\n",
      "Step: 9461, Loss: 0.19518864154815674, Accuracy: 0.96875, Computation time: 0.859973669052124\n",
      "Step: 9462, Loss: 0.29541635513305664, Accuracy: 0.875, Computation time: 0.8729851245880127\n",
      "Step: 9463, Loss: 0.3417539894580841, Accuracy: 0.9375, Computation time: 0.8738789558410645\n",
      "Step: 9464, Loss: 0.3874812126159668, Accuracy: 0.8125, Computation time: 0.8952703475952148\n",
      "Step: 9465, Loss: 0.4888109862804413, Accuracy: 0.78125, Computation time: 1.7134346961975098\n",
      "Step: 9466, Loss: 0.20495344698429108, Accuracy: 0.9375, Computation time: 0.8598489761352539\n",
      "Step: 9467, Loss: 0.24023309350013733, Accuracy: 0.9375, Computation time: 0.9663450717926025\n",
      "Step: 9468, Loss: 0.4276731610298157, Accuracy: 0.875, Computation time: 0.7860028743743896\n",
      "Step: 9469, Loss: 0.3747943937778473, Accuracy: 0.8125, Computation time: 0.8717031478881836\n",
      "Step: 9470, Loss: 0.3674291670322418, Accuracy: 0.84375, Computation time: 0.8450512886047363\n",
      "Step: 9471, Loss: 0.17776533961296082, Accuracy: 0.9375, Computation time: 0.9408092498779297\n",
      "Step: 9472, Loss: 1.0152636766433716, Accuracy: 0.71875, Computation time: 0.939939022064209\n",
      "Step: 9473, Loss: 0.3221483826637268, Accuracy: 0.875, Computation time: 1.004652976989746\n",
      "Step: 9474, Loss: 0.30366626381874084, Accuracy: 0.875, Computation time: 0.9435219764709473\n",
      "Step: 9475, Loss: 0.5276834964752197, Accuracy: 0.84375, Computation time: 0.8440711498260498\n",
      "Step: 9476, Loss: 0.784790575504303, Accuracy: 0.8125, Computation time: 0.7669508457183838\n",
      "Step: 9477, Loss: 0.4335628151893616, Accuracy: 0.90625, Computation time: 0.9528820514678955\n",
      "Step: 9478, Loss: 0.6266484260559082, Accuracy: 0.84375, Computation time: 1.0717401504516602\n",
      "Step: 9479, Loss: 0.5244236588478088, Accuracy: 0.8125, Computation time: 0.9781191349029541\n",
      "Step: 9480, Loss: 0.299645334482193, Accuracy: 0.9375, Computation time: 0.8085241317749023\n",
      "Step: 9481, Loss: 0.27380722761154175, Accuracy: 0.90625, Computation time: 0.9759140014648438\n",
      "Step: 9482, Loss: 0.42640048265457153, Accuracy: 0.84375, Computation time: 0.9261629581451416\n",
      "Step: 9483, Loss: 0.7133023142814636, Accuracy: 0.75, Computation time: 0.8466980457305908\n",
      "Step: 9484, Loss: 0.37622150778770447, Accuracy: 0.90625, Computation time: 1.0523018836975098\n",
      "Step: 9485, Loss: 0.45586925745010376, Accuracy: 0.84375, Computation time: 0.7842388153076172\n",
      "Step: 9486, Loss: 0.16154098510742188, Accuracy: 0.96875, Computation time: 0.9669029712677002\n",
      "Step: 9487, Loss: 0.4147619307041168, Accuracy: 0.90625, Computation time: 0.8966052532196045\n",
      "Step: 9488, Loss: 0.5635034441947937, Accuracy: 0.84375, Computation time: 0.9238369464874268\n",
      "Step: 9489, Loss: 0.4424627125263214, Accuracy: 0.875, Computation time: 0.9643831253051758\n",
      "Step: 9490, Loss: 0.67704838514328, Accuracy: 0.84375, Computation time: 1.2188892364501953\n",
      "Step: 9491, Loss: 0.5499900579452515, Accuracy: 0.84375, Computation time: 1.1409268379211426\n",
      "Step: 9492, Loss: 0.43879491090774536, Accuracy: 0.84375, Computation time: 0.8497130870819092\n",
      "Step: 9493, Loss: 0.3335230350494385, Accuracy: 0.90625, Computation time: 0.7879648208618164\n",
      "Step: 9494, Loss: 0.4284941554069519, Accuracy: 0.78125, Computation time: 1.5279808044433594\n",
      "Step: 9495, Loss: 0.5667060613632202, Accuracy: 0.84375, Computation time: 0.6694810390472412\n",
      "Step: 9496, Loss: 0.33652806282043457, Accuracy: 0.90625, Computation time: 0.990915060043335\n",
      "Step: 9497, Loss: 0.8498235940933228, Accuracy: 0.78125, Computation time: 0.8336880207061768\n",
      "Step: 9498, Loss: 0.560692310333252, Accuracy: 0.90625, Computation time: 0.8565740585327148\n",
      "Step: 9499, Loss: 0.29942452907562256, Accuracy: 0.84375, Computation time: 0.9029719829559326\n",
      "Step: 9500, Loss: 0.4873352646827698, Accuracy: 0.8125, Computation time: 1.0215389728546143\n",
      "Step: 9501, Loss: 0.35141119360923767, Accuracy: 0.875, Computation time: 1.0043420791625977\n",
      "Step: 9502, Loss: 0.3257904052734375, Accuracy: 0.9375, Computation time: 0.8892903327941895\n",
      "Step: 9503, Loss: 0.11515912413597107, Accuracy: 1.0, Computation time: 0.941091775894165\n",
      "Step: 9504, Loss: 0.10445007681846619, Accuracy: 0.96875, Computation time: 1.025115728378296\n",
      "Step: 9505, Loss: 0.1305580735206604, Accuracy: 0.96875, Computation time: 0.909398078918457\n",
      "Step: 9506, Loss: 0.38509324193000793, Accuracy: 0.9375, Computation time: 0.9746952056884766\n",
      "Step: 9507, Loss: 0.5575106143951416, Accuracy: 0.84375, Computation time: 0.8784730434417725\n",
      "Step: 9508, Loss: 0.2917989492416382, Accuracy: 0.90625, Computation time: 1.0821290016174316\n",
      "Step: 9509, Loss: 0.19456949830055237, Accuracy: 0.96875, Computation time: 0.9509718418121338\n",
      "Step: 9510, Loss: 0.5378388166427612, Accuracy: 0.8125, Computation time: 0.9379022121429443\n",
      "Step: 9511, Loss: 0.4059387743473053, Accuracy: 0.84375, Computation time: 0.976402997970581\n",
      "Step: 9512, Loss: 0.26409775018692017, Accuracy: 0.90625, Computation time: 0.8676197528839111\n",
      "Step: 9513, Loss: 0.40546828508377075, Accuracy: 0.8125, Computation time: 0.7885470390319824\n",
      "Step: 9514, Loss: 0.31308844685554504, Accuracy: 0.875, Computation time: 1.1276969909667969\n",
      "Step: 9515, Loss: 0.5272630453109741, Accuracy: 0.875, Computation time: 0.9389729499816895\n",
      "Step: 9516, Loss: 0.3710132837295532, Accuracy: 0.84375, Computation time: 0.8416550159454346\n",
      "Step: 9517, Loss: 0.48155540227890015, Accuracy: 0.8125, Computation time: 0.806710958480835\n",
      "Step: 9518, Loss: 0.572209358215332, Accuracy: 0.8125, Computation time: 0.984868049621582\n",
      "Step: 9519, Loss: 0.08290483057498932, Accuracy: 1.0, Computation time: 1.011415958404541\n",
      "Step: 9520, Loss: 0.483006089925766, Accuracy: 0.84375, Computation time: 1.1745481491088867\n",
      "Step: 9521, Loss: 0.5617178082466125, Accuracy: 0.78125, Computation time: 0.9872591495513916\n",
      "Step: 9522, Loss: 1.0291169881820679, Accuracy: 0.75, Computation time: 0.9783461093902588\n",
      "Step: 9523, Loss: 0.6559094786643982, Accuracy: 0.78125, Computation time: 1.514266014099121\n",
      "Step: 9524, Loss: 0.09209947288036346, Accuracy: 0.96875, Computation time: 0.8377819061279297\n",
      "Step: 9525, Loss: 0.16489343345165253, Accuracy: 0.9375, Computation time: 0.816950798034668\n",
      "Step: 9526, Loss: 0.27644845843315125, Accuracy: 0.96875, Computation time: 0.7796201705932617\n",
      "Step: 9527, Loss: 0.5254172682762146, Accuracy: 0.84375, Computation time: 0.8559720516204834\n",
      "Step: 9528, Loss: 0.5278199911117554, Accuracy: 0.78125, Computation time: 0.8325340747833252\n",
      "Step: 9529, Loss: 0.4388197660446167, Accuracy: 0.78125, Computation time: 0.9899928569793701\n",
      "Step: 9530, Loss: 0.5738207101821899, Accuracy: 0.8125, Computation time: 0.8072659969329834\n",
      "Step: 9531, Loss: 0.3720571994781494, Accuracy: 0.9375, Computation time: 0.8721849918365479\n",
      "Step: 9532, Loss: 0.17679822444915771, Accuracy: 0.96875, Computation time: 0.8350269794464111\n",
      "Step: 9533, Loss: 0.25537344813346863, Accuracy: 0.90625, Computation time: 0.8678920269012451\n",
      "Step: 9534, Loss: 0.2423219084739685, Accuracy: 0.90625, Computation time: 0.9406890869140625\n",
      "Step: 9535, Loss: 0.32375529408454895, Accuracy: 0.875, Computation time: 1.0220370292663574\n",
      "Step: 9536, Loss: 0.0899643823504448, Accuracy: 1.0, Computation time: 0.978715181350708\n",
      "Step: 9537, Loss: 0.22936010360717773, Accuracy: 0.96875, Computation time: 0.7068221569061279\n",
      "Step: 9538, Loss: 0.6252589225769043, Accuracy: 0.875, Computation time: 0.857367753982544\n",
      "Step: 9539, Loss: 0.576904296875, Accuracy: 0.8125, Computation time: 2.297966957092285\n",
      "Step: 9540, Loss: 0.18460969626903534, Accuracy: 0.96875, Computation time: 0.959418773651123\n",
      "Step: 9541, Loss: 0.1594165712594986, Accuracy: 0.90625, Computation time: 0.8008339405059814\n",
      "Step: 9542, Loss: 0.537331759929657, Accuracy: 0.84375, Computation time: 0.8164339065551758\n",
      "Step: 9543, Loss: 0.3691181242465973, Accuracy: 0.90625, Computation time: 0.8078601360321045\n",
      "Step: 9544, Loss: 0.3166828453540802, Accuracy: 0.90625, Computation time: 0.8790798187255859\n",
      "Step: 9545, Loss: 0.32027509808540344, Accuracy: 0.875, Computation time: 0.9416000843048096\n",
      "Step: 9546, Loss: 0.438376247882843, Accuracy: 0.84375, Computation time: 0.8538980484008789\n",
      "Step: 9547, Loss: 0.43445849418640137, Accuracy: 0.875, Computation time: 0.878591775894165\n",
      "Step: 9548, Loss: 0.45748627185821533, Accuracy: 0.84375, Computation time: 0.8397130966186523\n",
      "Step: 9549, Loss: 0.4339686632156372, Accuracy: 0.875, Computation time: 0.8660218715667725\n",
      "Step: 9550, Loss: 0.5123037099838257, Accuracy: 0.78125, Computation time: 0.8381757736206055\n",
      "Step: 9551, Loss: 0.2804993689060211, Accuracy: 0.9375, Computation time: 0.9220077991485596\n",
      "Step: 9552, Loss: 0.22282999753952026, Accuracy: 0.9375, Computation time: 1.647787094116211\n",
      "Step: 9553, Loss: 0.5430334210395813, Accuracy: 0.8125, Computation time: 1.022885799407959\n",
      "Step: 9554, Loss: 0.21102768182754517, Accuracy: 0.90625, Computation time: 0.892643928527832\n",
      "Step: 9555, Loss: 0.21316595375537872, Accuracy: 0.90625, Computation time: 0.9820640087127686\n",
      "Step: 9556, Loss: 0.3256213068962097, Accuracy: 0.90625, Computation time: 0.8149309158325195\n",
      "Step: 9557, Loss: 0.3092670738697052, Accuracy: 0.9375, Computation time: 0.8515980243682861\n",
      "Step: 9558, Loss: 0.3797941505908966, Accuracy: 0.90625, Computation time: 0.8999612331390381\n",
      "Step: 9559, Loss: 0.6148474812507629, Accuracy: 0.875, Computation time: 1.0337140560150146\n",
      "Step: 9560, Loss: 0.3264138698577881, Accuracy: 0.875, Computation time: 0.9683620929718018\n",
      "Step: 9561, Loss: 0.5306684970855713, Accuracy: 0.875, Computation time: 1.038050889968872\n",
      "Step: 9562, Loss: 0.3549850881099701, Accuracy: 0.90625, Computation time: 1.0123608112335205\n",
      "Step: 9563, Loss: 0.565336287021637, Accuracy: 0.78125, Computation time: 0.8930239677429199\n",
      "Step: 9564, Loss: 0.3281850218772888, Accuracy: 0.90625, Computation time: 0.8850269317626953\n",
      "Step: 9565, Loss: 0.4342685639858246, Accuracy: 0.875, Computation time: 0.8326859474182129\n",
      "Step: 9566, Loss: 0.5255249738693237, Accuracy: 0.875, Computation time: 0.9801619052886963\n",
      "Step: 9567, Loss: 0.26607489585876465, Accuracy: 0.90625, Computation time: 0.8193447589874268\n",
      "Step: 9568, Loss: 0.1534985452890396, Accuracy: 0.9375, Computation time: 0.7941558361053467\n",
      "Step: 9569, Loss: 0.25909551978111267, Accuracy: 0.96875, Computation time: 1.1060612201690674\n",
      "Step: 9570, Loss: 0.44892802834510803, Accuracy: 0.78125, Computation time: 1.141890048980713\n",
      "Step: 9571, Loss: 0.13507695496082306, Accuracy: 0.96875, Computation time: 0.7656519412994385\n",
      "Step: 9572, Loss: 0.17502707242965698, Accuracy: 0.9375, Computation time: 0.9752349853515625\n",
      "Step: 9573, Loss: 0.31055641174316406, Accuracy: 0.875, Computation time: 1.22017502784729\n",
      "Step: 9574, Loss: 0.32902148365974426, Accuracy: 0.875, Computation time: 1.005007028579712\n",
      "Step: 9575, Loss: 0.30879345536231995, Accuracy: 0.9375, Computation time: 0.9138209819793701\n",
      "Step: 9576, Loss: 0.609747052192688, Accuracy: 0.8125, Computation time: 0.9766910076141357\n",
      "Step: 9577, Loss: 0.3319704532623291, Accuracy: 0.875, Computation time: 0.8252050876617432\n",
      "Step: 9578, Loss: 0.34374451637268066, Accuracy: 0.84375, Computation time: 0.9394791126251221\n",
      "Step: 9579, Loss: 0.22795672714710236, Accuracy: 0.90625, Computation time: 1.026987075805664\n",
      "Step: 9580, Loss: 0.45751649141311646, Accuracy: 0.90625, Computation time: 1.5809500217437744\n",
      "Step: 9581, Loss: 0.44719189405441284, Accuracy: 0.84375, Computation time: 0.9537169933319092\n",
      "Step: 9582, Loss: 0.8401318788528442, Accuracy: 0.75, Computation time: 0.9082098007202148\n",
      "Step: 9583, Loss: 0.32492274045944214, Accuracy: 0.84375, Computation time: 0.795964241027832\n",
      "Step: 9584, Loss: 0.23763512074947357, Accuracy: 0.90625, Computation time: 0.85318922996521\n",
      "Step: 9585, Loss: 0.13145402073860168, Accuracy: 0.96875, Computation time: 0.787628173828125\n",
      "Step: 9586, Loss: 0.38886716961860657, Accuracy: 0.78125, Computation time: 1.026102066040039\n",
      "Step: 9587, Loss: 0.3814410865306854, Accuracy: 0.875, Computation time: 1.4631190299987793\n",
      "Step: 9588, Loss: 0.6508906483650208, Accuracy: 0.8125, Computation time: 0.9930880069732666\n",
      "Step: 9589, Loss: 0.348997563123703, Accuracy: 0.84375, Computation time: 0.9779009819030762\n",
      "Step: 9590, Loss: 0.24060967564582825, Accuracy: 0.9375, Computation time: 0.7224540710449219\n",
      "Step: 9591, Loss: 0.4786339998245239, Accuracy: 0.90625, Computation time: 0.8600788116455078\n",
      "Step: 9592, Loss: 0.12453772127628326, Accuracy: 1.0, Computation time: 0.8687469959259033\n",
      "Step: 9593, Loss: 0.27095675468444824, Accuracy: 0.875, Computation time: 0.8685338497161865\n",
      "Step: 9594, Loss: 0.38122475147247314, Accuracy: 0.875, Computation time: 0.88478684425354\n",
      "Step: 9595, Loss: 0.6311906576156616, Accuracy: 0.90625, Computation time: 0.8217389583587646\n",
      "Step: 9596, Loss: 0.22101303935050964, Accuracy: 0.90625, Computation time: 0.8768501281738281\n",
      "Step: 9597, Loss: 0.11733953654766083, Accuracy: 0.96875, Computation time: 0.8692638874053955\n",
      "Step: 9598, Loss: 0.7534705400466919, Accuracy: 0.875, Computation time: 0.8484461307525635\n",
      "Step: 9599, Loss: 0.5726893544197083, Accuracy: 0.84375, Computation time: 0.8542108535766602\n",
      "Step: 9600, Loss: 0.3498074412345886, Accuracy: 0.9375, Computation time: 0.9938969612121582\n",
      "Step: 9601, Loss: 0.32602688670158386, Accuracy: 0.875, Computation time: 0.9123082160949707\n",
      "Step: 9602, Loss: 0.4679364562034607, Accuracy: 0.90625, Computation time: 0.8500909805297852\n",
      "Step: 9603, Loss: 0.2318875789642334, Accuracy: 0.90625, Computation time: 0.7852048873901367\n",
      "Step: 9604, Loss: 0.36173662543296814, Accuracy: 0.84375, Computation time: 0.8704638481140137\n",
      "Step: 9605, Loss: 0.4568091630935669, Accuracy: 0.84375, Computation time: 0.9169149398803711\n",
      "Step: 9606, Loss: 0.29060688614845276, Accuracy: 0.875, Computation time: 0.9076061248779297\n",
      "Step: 9607, Loss: 0.47101452946662903, Accuracy: 0.8125, Computation time: 0.785290002822876\n",
      "Step: 9608, Loss: 0.1343952715396881, Accuracy: 0.9375, Computation time: 0.8293859958648682\n",
      "Step: 9609, Loss: 0.5884652733802795, Accuracy: 0.84375, Computation time: 0.8809809684753418\n",
      "Step: 9610, Loss: 0.2057594209909439, Accuracy: 0.875, Computation time: 1.6555631160736084\n",
      "Step: 9611, Loss: 0.3813442289829254, Accuracy: 0.90625, Computation time: 0.7397100925445557\n",
      "Step: 9612, Loss: 0.28974321484565735, Accuracy: 0.875, Computation time: 0.8080897331237793\n",
      "Step: 9613, Loss: 0.4242057204246521, Accuracy: 0.84375, Computation time: 0.8174548149108887\n",
      "Step: 9614, Loss: 0.3478764593601227, Accuracy: 0.875, Computation time: 0.933506965637207\n",
      "Step: 9615, Loss: 0.4282374978065491, Accuracy: 0.84375, Computation time: 0.9179751873016357\n",
      "Step: 9616, Loss: 0.48962366580963135, Accuracy: 0.84375, Computation time: 0.7837886810302734\n",
      "Step: 9617, Loss: 0.3189908266067505, Accuracy: 0.90625, Computation time: 0.9868311882019043\n",
      "Step: 9618, Loss: 0.27771973609924316, Accuracy: 0.90625, Computation time: 0.8812570571899414\n",
      "Step: 9619, Loss: 0.18466559052467346, Accuracy: 0.96875, Computation time: 0.8148329257965088\n",
      "Step: 9620, Loss: 0.22140513360500336, Accuracy: 0.90625, Computation time: 0.9889092445373535\n",
      "Step: 9621, Loss: 0.667767345905304, Accuracy: 0.75, Computation time: 0.8802146911621094\n",
      "Step: 9622, Loss: 0.555481493473053, Accuracy: 0.8125, Computation time: 0.925666093826294\n",
      "Step: 9623, Loss: 0.4766318202018738, Accuracy: 0.875, Computation time: 0.8256509304046631\n",
      "Step: 9624, Loss: 0.2424928843975067, Accuracy: 0.9375, Computation time: 0.9843337535858154\n",
      "Step: 9625, Loss: 0.2873428463935852, Accuracy: 0.875, Computation time: 0.9241809844970703\n",
      "Step: 9626, Loss: 0.529608964920044, Accuracy: 0.84375, Computation time: 0.7156741619110107\n",
      "Step: 9627, Loss: 0.298957884311676, Accuracy: 0.90625, Computation time: 0.9707839488983154\n",
      "Step: 9628, Loss: 0.19432488083839417, Accuracy: 0.9375, Computation time: 0.9651098251342773\n",
      "Step: 9629, Loss: 0.28724372386932373, Accuracy: 0.9375, Computation time: 0.8937957286834717\n",
      "Step: 9630, Loss: 0.5188359618186951, Accuracy: 0.84375, Computation time: 0.90677809715271\n",
      "Step: 9631, Loss: 0.4061034321784973, Accuracy: 0.90625, Computation time: 0.7696869373321533\n",
      "Step: 9632, Loss: 0.21168705821037292, Accuracy: 0.9375, Computation time: 0.8635168075561523\n",
      "Step: 9633, Loss: 0.37082639336586, Accuracy: 0.875, Computation time: 0.8662641048431396\n",
      "Step: 9634, Loss: 0.5022637844085693, Accuracy: 0.875, Computation time: 0.8170018196105957\n",
      "Step: 9635, Loss: 0.27804651856422424, Accuracy: 0.90625, Computation time: 1.3231959342956543\n",
      "Step: 9636, Loss: 0.6054654121398926, Accuracy: 0.8125, Computation time: 1.0265510082244873\n",
      "Step: 9637, Loss: 0.3075505495071411, Accuracy: 0.90625, Computation time: 0.9095900058746338\n",
      "Step: 9638, Loss: 0.30955907702445984, Accuracy: 0.90625, Computation time: 0.9372677803039551\n",
      "Step: 9639, Loss: 0.44571563601493835, Accuracy: 0.875, Computation time: 1.433218002319336\n",
      "Step: 9640, Loss: 0.4348249137401581, Accuracy: 0.90625, Computation time: 0.8834223747253418\n",
      "Step: 9641, Loss: 0.25004714727401733, Accuracy: 0.9375, Computation time: 0.8037419319152832\n",
      "Step: 9642, Loss: 0.6196801066398621, Accuracy: 0.8125, Computation time: 0.8330099582672119\n",
      "Step: 9643, Loss: 0.5083497166633606, Accuracy: 0.90625, Computation time: 0.8558893203735352\n",
      "Step: 9644, Loss: 0.48413264751434326, Accuracy: 0.84375, Computation time: 0.8007659912109375\n",
      "Step: 9645, Loss: 0.6102328896522522, Accuracy: 0.75, Computation time: 0.9680731296539307\n",
      "Step: 9646, Loss: 0.5650075078010559, Accuracy: 0.8125, Computation time: 1.0400540828704834\n",
      "Step: 9647, Loss: 0.6472810506820679, Accuracy: 0.84375, Computation time: 1.002553939819336\n",
      "Step: 9648, Loss: 0.6269105076789856, Accuracy: 0.8125, Computation time: 0.9172060489654541\n",
      "Step: 9649, Loss: 0.35023725032806396, Accuracy: 0.84375, Computation time: 0.7440187931060791\n",
      "Step: 9650, Loss: 0.29491183161735535, Accuracy: 0.90625, Computation time: 0.9366438388824463\n",
      "Step: 9651, Loss: 0.11262132227420807, Accuracy: 0.96875, Computation time: 1.0157451629638672\n",
      "Step: 9652, Loss: 0.4166276156902313, Accuracy: 0.875, Computation time: 0.8394010066986084\n",
      "Step: 9653, Loss: 0.11377106606960297, Accuracy: 1.0, Computation time: 0.9138278961181641\n",
      "Step: 9654, Loss: 0.9428141117095947, Accuracy: 0.8125, Computation time: 0.9693009853363037\n",
      "Step: 9655, Loss: 0.47374436259269714, Accuracy: 0.84375, Computation time: 0.9082262516021729\n",
      "Step: 9656, Loss: 0.34249281883239746, Accuracy: 0.90625, Computation time: 0.864246129989624\n",
      "Step: 9657, Loss: 0.5349949598312378, Accuracy: 0.84375, Computation time: 0.8590941429138184\n",
      "Step: 9658, Loss: 0.28063857555389404, Accuracy: 0.90625, Computation time: 1.0271432399749756\n",
      "Step: 9659, Loss: 0.508442223072052, Accuracy: 0.78125, Computation time: 0.8662161827087402\n",
      "Step: 9660, Loss: 0.1292692869901657, Accuracy: 0.96875, Computation time: 0.7017698287963867\n",
      "Step: 9661, Loss: 0.35845592617988586, Accuracy: 0.84375, Computation time: 0.9607551097869873\n",
      "Step: 9662, Loss: 0.5467256903648376, Accuracy: 0.8125, Computation time: 0.8091647624969482\n",
      "Step: 9663, Loss: 0.19508525729179382, Accuracy: 0.90625, Computation time: 0.8091399669647217\n",
      "Step: 9664, Loss: 0.29421713948249817, Accuracy: 0.875, Computation time: 0.9542269706726074\n",
      "Step: 9665, Loss: 0.5176447033882141, Accuracy: 0.84375, Computation time: 0.8615560531616211\n",
      "Step: 9666, Loss: 0.4161861538887024, Accuracy: 0.90625, Computation time: 0.8364291191101074\n",
      "Step: 9667, Loss: 0.3448057770729065, Accuracy: 0.84375, Computation time: 0.7240467071533203\n",
      "Step: 9668, Loss: 0.20761272311210632, Accuracy: 0.90625, Computation time: 0.868922233581543\n",
      "Step: 9669, Loss: 0.6418007016181946, Accuracy: 0.8125, Computation time: 0.9139060974121094\n",
      "Step: 9670, Loss: 0.4187679886817932, Accuracy: 0.78125, Computation time: 1.6055078506469727\n",
      "Step: 9671, Loss: 0.5377007126808167, Accuracy: 0.84375, Computation time: 0.9000568389892578\n",
      "Step: 9672, Loss: 0.3829432725906372, Accuracy: 0.84375, Computation time: 0.8854379653930664\n",
      "Step: 9673, Loss: 0.363010048866272, Accuracy: 0.875, Computation time: 0.8985497951507568\n",
      "Step: 9674, Loss: 0.439970463514328, Accuracy: 0.90625, Computation time: 0.8041031360626221\n",
      "Step: 9675, Loss: 0.1800214648246765, Accuracy: 0.9375, Computation time: 0.9011378288269043\n",
      "Step: 9676, Loss: 0.3263533115386963, Accuracy: 0.90625, Computation time: 0.9035370349884033\n",
      "Step: 9677, Loss: 0.3651622235774994, Accuracy: 0.90625, Computation time: 0.8843669891357422\n",
      "Step: 9678, Loss: 0.6214057803153992, Accuracy: 0.78125, Computation time: 0.8515610694885254\n",
      "Step: 9679, Loss: 0.43533003330230713, Accuracy: 0.84375, Computation time: 0.9747660160064697\n",
      "Step: 9680, Loss: 0.28917890787124634, Accuracy: 0.875, Computation time: 0.9325239658355713\n",
      "Step: 9681, Loss: 0.239288330078125, Accuracy: 0.9375, Computation time: 0.9481899738311768\n",
      "Step: 9682, Loss: 0.343572735786438, Accuracy: 0.875, Computation time: 0.8308370113372803\n",
      "Step: 9683, Loss: 0.5812459588050842, Accuracy: 0.78125, Computation time: 1.0298857688903809\n",
      "Step: 9684, Loss: 0.16272586584091187, Accuracy: 0.96875, Computation time: 0.9883809089660645\n",
      "Step: 9685, Loss: 0.3099975883960724, Accuracy: 0.90625, Computation time: 0.8292031288146973\n",
      "Step: 9686, Loss: 0.36017489433288574, Accuracy: 0.90625, Computation time: 0.9256770610809326\n",
      "Step: 9687, Loss: 0.466068297624588, Accuracy: 0.84375, Computation time: 0.9108598232269287\n",
      "Step: 9688, Loss: 0.28255870938301086, Accuracy: 0.9375, Computation time: 0.8687598705291748\n",
      "Step: 9689, Loss: 0.4209652245044708, Accuracy: 0.84375, Computation time: 0.7614672183990479\n",
      "Step: 9690, Loss: 0.3797886371612549, Accuracy: 0.8125, Computation time: 0.8607451915740967\n",
      "Step: 9691, Loss: 0.23423215746879578, Accuracy: 0.875, Computation time: 0.9857759475708008\n",
      "Step: 9692, Loss: 0.37551984190940857, Accuracy: 0.8125, Computation time: 0.9093649387359619\n",
      "Step: 9693, Loss: 0.2144162356853485, Accuracy: 0.9375, Computation time: 0.9824047088623047\n",
      "Step: 9694, Loss: 0.4183904826641083, Accuracy: 0.9375, Computation time: 0.9664590358734131\n",
      "Step: 9695, Loss: 0.3156983256340027, Accuracy: 0.90625, Computation time: 0.981151819229126\n",
      "Step: 9696, Loss: 0.39430662989616394, Accuracy: 0.84375, Computation time: 0.8394067287445068\n",
      "Step: 9697, Loss: 0.40947556495666504, Accuracy: 0.90625, Computation time: 1.0402758121490479\n",
      "Step: 9698, Loss: 0.1146305575966835, Accuracy: 0.96875, Computation time: 0.834650993347168\n",
      "Step: 9699, Loss: 0.3395463824272156, Accuracy: 0.90625, Computation time: 1.6688168048858643\n",
      "Step: 9700, Loss: 0.4122079610824585, Accuracy: 0.9375, Computation time: 0.9642727375030518\n",
      "Step: 9701, Loss: 0.5433556437492371, Accuracy: 0.8125, Computation time: 0.8293700218200684\n",
      "Step: 9702, Loss: 0.4000816345214844, Accuracy: 0.875, Computation time: 0.9314858913421631\n",
      "Step: 9703, Loss: 0.535207986831665, Accuracy: 0.84375, Computation time: 0.9529731273651123\n",
      "Step: 9704, Loss: 0.5261367559432983, Accuracy: 0.84375, Computation time: 0.8609471321105957\n",
      "Step: 9705, Loss: 0.6172104477882385, Accuracy: 0.78125, Computation time: 1.3494610786437988\n",
      "Step: 9706, Loss: 0.6573423743247986, Accuracy: 0.78125, Computation time: 1.0328240394592285\n",
      "Step: 9707, Loss: 0.43883833289146423, Accuracy: 0.78125, Computation time: 0.896460771560669\n",
      "Step: 9708, Loss: 0.3787417709827423, Accuracy: 0.84375, Computation time: 1.1272680759429932\n",
      "Step: 9709, Loss: 0.4776575565338135, Accuracy: 0.84375, Computation time: 0.9043049812316895\n",
      "Step: 9710, Loss: 0.07148135453462601, Accuracy: 1.0, Computation time: 0.8778560161590576\n",
      "Step: 9711, Loss: 0.3475399613380432, Accuracy: 0.84375, Computation time: 0.7173681259155273\n",
      "Step: 9712, Loss: 0.5752831697463989, Accuracy: 0.8125, Computation time: 0.7043120861053467\n",
      "Step: 9713, Loss: 0.2946028709411621, Accuracy: 0.875, Computation time: 1.0929839611053467\n",
      "Step: 9714, Loss: 0.5812793970108032, Accuracy: 0.8125, Computation time: 0.8239600658416748\n",
      "Step: 9715, Loss: 0.3954228162765503, Accuracy: 0.875, Computation time: 0.916954755783081\n",
      "Step: 9716, Loss: 0.3651753067970276, Accuracy: 0.90625, Computation time: 0.9268021583557129\n",
      "Step: 9717, Loss: 0.39583051204681396, Accuracy: 0.875, Computation time: 1.0383119583129883\n",
      "Step: 9718, Loss: 0.5958479642868042, Accuracy: 0.78125, Computation time: 0.861274242401123\n",
      "Step: 9719, Loss: 0.2975076735019684, Accuracy: 0.9375, Computation time: 0.938939094543457\n",
      "Step: 9720, Loss: 0.3139779269695282, Accuracy: 0.84375, Computation time: 1.0667579174041748\n",
      "Step: 9721, Loss: 0.4626813232898712, Accuracy: 0.90625, Computation time: 0.8882107734680176\n",
      "Step: 9722, Loss: 0.24892888963222504, Accuracy: 0.9375, Computation time: 0.9101302623748779\n",
      "Step: 9723, Loss: 0.3702383041381836, Accuracy: 0.875, Computation time: 0.8437201976776123\n",
      "Step: 9724, Loss: 0.31538069248199463, Accuracy: 0.9375, Computation time: 0.8748438358306885\n",
      "Step: 9725, Loss: 0.5711362361907959, Accuracy: 0.84375, Computation time: 0.9223239421844482\n",
      "Step: 9726, Loss: 0.31415224075317383, Accuracy: 0.875, Computation time: 0.7536921501159668\n",
      "Step: 9727, Loss: 0.4060250222682953, Accuracy: 0.8125, Computation time: 1.108030080795288\n",
      "Step: 9728, Loss: 0.24471282958984375, Accuracy: 0.90625, Computation time: 1.409630298614502\n",
      "Step: 9729, Loss: 0.20341803133487701, Accuracy: 0.9375, Computation time: 0.9404857158660889\n",
      "Step: 9730, Loss: 0.36689555644989014, Accuracy: 0.90625, Computation time: 0.9593980312347412\n",
      "Step: 9731, Loss: 0.2923462688922882, Accuracy: 0.90625, Computation time: 0.7672779560089111\n",
      "Step: 9732, Loss: 0.2502235770225525, Accuracy: 0.90625, Computation time: 0.8518133163452148\n",
      "Step: 9733, Loss: 0.36349716782569885, Accuracy: 0.875, Computation time: 0.959399938583374\n",
      "Step: 9734, Loss: 0.5786938071250916, Accuracy: 0.84375, Computation time: 0.8939261436462402\n",
      "Step: 9735, Loss: 0.11568375676870346, Accuracy: 0.96875, Computation time: 0.8740220069885254\n",
      "Step: 9736, Loss: 0.34967464208602905, Accuracy: 0.90625, Computation time: 0.8471736907958984\n",
      "Step: 9737, Loss: 0.7091182470321655, Accuracy: 0.84375, Computation time: 0.895294189453125\n",
      "Step: 9738, Loss: 0.36488181352615356, Accuracy: 0.90625, Computation time: 0.8233580589294434\n",
      "Step: 9739, Loss: 0.25080132484436035, Accuracy: 0.9375, Computation time: 1.0358409881591797\n",
      "Step: 9740, Loss: 0.3654637634754181, Accuracy: 0.875, Computation time: 0.8541009426116943\n",
      "Step: 9741, Loss: 0.6343754529953003, Accuracy: 0.875, Computation time: 1.0231399536132812\n",
      "Step: 9742, Loss: 0.7843029499053955, Accuracy: 0.8125, Computation time: 0.8522310256958008\n",
      "Step: 9743, Loss: 0.5711076855659485, Accuracy: 0.875, Computation time: 0.881101131439209\n",
      "Step: 9744, Loss: 0.3392840027809143, Accuracy: 0.9375, Computation time: 0.8925387859344482\n",
      "Step: 9745, Loss: 0.42923012375831604, Accuracy: 0.90625, Computation time: 0.7700269222259521\n",
      "Step: 9746, Loss: 0.4236118793487549, Accuracy: 0.84375, Computation time: 1.0305631160736084\n",
      "Step: 9747, Loss: 0.28897616267204285, Accuracy: 0.9375, Computation time: 0.868344783782959\n",
      "Step: 9748, Loss: 0.2994917929172516, Accuracy: 0.90625, Computation time: 0.8382041454315186\n",
      "Step: 9749, Loss: 0.2822619676589966, Accuracy: 0.9375, Computation time: 1.0779898166656494\n",
      "Step: 9750, Loss: 0.2460089921951294, Accuracy: 0.90625, Computation time: 0.9577808380126953\n",
      "Step: 9751, Loss: 0.33517396450042725, Accuracy: 0.90625, Computation time: 0.8626031875610352\n",
      "Step: 9752, Loss: 0.37536659836769104, Accuracy: 0.875, Computation time: 0.9810910224914551\n",
      "Step: 9753, Loss: 0.21609264612197876, Accuracy: 0.90625, Computation time: 0.9085719585418701\n",
      "Step: 9754, Loss: 0.21437880396842957, Accuracy: 0.9375, Computation time: 0.7689988613128662\n",
      "Step: 9755, Loss: 0.250283420085907, Accuracy: 0.9375, Computation time: 0.948206901550293\n",
      "Step: 9756, Loss: 0.2418251484632492, Accuracy: 0.9375, Computation time: 0.8373317718505859\n",
      "Step: 9757, Loss: 0.5309289693832397, Accuracy: 0.84375, Computation time: 1.9598028659820557\n",
      "Step: 9758, Loss: 0.23719531297683716, Accuracy: 0.90625, Computation time: 0.7919051647186279\n",
      "Step: 9759, Loss: 0.22705070674419403, Accuracy: 0.9375, Computation time: 1.1685659885406494\n",
      "Step: 9760, Loss: 0.19235271215438843, Accuracy: 0.9375, Computation time: 0.9622950553894043\n",
      "Step: 9761, Loss: 0.14693742990493774, Accuracy: 0.96875, Computation time: 0.983546257019043\n",
      "Step: 9762, Loss: 0.5622546672821045, Accuracy: 0.875, Computation time: 0.8809211254119873\n",
      "Step: 9763, Loss: 0.7981933355331421, Accuracy: 0.78125, Computation time: 2.281604051589966\n",
      "Step: 9764, Loss: 0.4515875279903412, Accuracy: 0.84375, Computation time: 1.0955920219421387\n",
      "Step: 9765, Loss: 0.35531604290008545, Accuracy: 0.90625, Computation time: 1.0944499969482422\n",
      "Step: 9766, Loss: 0.22185194492340088, Accuracy: 0.875, Computation time: 1.155998945236206\n",
      "Step: 9767, Loss: 0.32474446296691895, Accuracy: 0.875, Computation time: 0.962583065032959\n",
      "Step: 9768, Loss: 0.5662581324577332, Accuracy: 0.875, Computation time: 0.9078941345214844\n",
      "Step: 9769, Loss: 0.24222081899642944, Accuracy: 0.90625, Computation time: 0.9615061283111572\n",
      "Step: 9770, Loss: 0.4531042277812958, Accuracy: 0.9375, Computation time: 1.0797760486602783\n",
      "Step: 9771, Loss: 0.13417117297649384, Accuracy: 0.96875, Computation time: 1.1351232528686523\n",
      "Step: 9772, Loss: 0.2410213053226471, Accuracy: 0.90625, Computation time: 0.9666249752044678\n",
      "Step: 9773, Loss: 0.2919815182685852, Accuracy: 0.9375, Computation time: 0.9066739082336426\n",
      "Step: 9774, Loss: 0.5177164673805237, Accuracy: 0.875, Computation time: 1.1122279167175293\n",
      "Step: 9775, Loss: 0.5400229096412659, Accuracy: 0.84375, Computation time: 1.1362550258636475\n",
      "Step: 9776, Loss: 0.6068593859672546, Accuracy: 0.8125, Computation time: 0.891638994216919\n",
      "Step: 9777, Loss: 1.6748584508895874, Accuracy: 0.8125, Computation time: 0.7940170764923096\n",
      "Step: 9778, Loss: 0.3181125223636627, Accuracy: 0.875, Computation time: 1.0166988372802734\n",
      "Step: 9779, Loss: 0.6671639680862427, Accuracy: 0.8125, Computation time: 0.9741458892822266\n",
      "Step: 9780, Loss: 0.6128432750701904, Accuracy: 0.84375, Computation time: 0.9467320442199707\n",
      "Step: 9781, Loss: 0.38780447840690613, Accuracy: 0.90625, Computation time: 0.7968282699584961\n",
      "Step: 9782, Loss: 0.2490953654050827, Accuracy: 0.90625, Computation time: 0.9224271774291992\n",
      "Step: 9783, Loss: 0.5089350342750549, Accuracy: 0.84375, Computation time: 1.770050048828125\n",
      "Step: 9784, Loss: 0.5871568322181702, Accuracy: 0.875, Computation time: 0.8023989200592041\n",
      "Step: 9785, Loss: 0.3392626643180847, Accuracy: 0.9375, Computation time: 1.29079008102417\n",
      "Step: 9786, Loss: 0.3523131310939789, Accuracy: 0.90625, Computation time: 0.8453061580657959\n",
      "Step: 9787, Loss: 0.3183770775794983, Accuracy: 0.90625, Computation time: 0.8073740005493164\n",
      "Step: 9788, Loss: 0.41159939765930176, Accuracy: 0.875, Computation time: 0.8308119773864746\n",
      "Step: 9789, Loss: 0.29571396112442017, Accuracy: 0.9375, Computation time: 0.8719139099121094\n",
      "Step: 9790, Loss: 0.8899298310279846, Accuracy: 0.875, Computation time: 0.9934430122375488\n",
      "Step: 9791, Loss: 0.4574880599975586, Accuracy: 0.875, Computation time: 0.9779000282287598\n",
      "Step: 9792, Loss: 0.16788728535175323, Accuracy: 0.9375, Computation time: 0.8117103576660156\n",
      "Step: 9793, Loss: 0.31070026755332947, Accuracy: 0.9375, Computation time: 0.9479389190673828\n",
      "Step: 9794, Loss: 0.2724631726741791, Accuracy: 0.9375, Computation time: 0.8792738914489746\n",
      "Step: 9795, Loss: 0.30244457721710205, Accuracy: 0.875, Computation time: 0.9240531921386719\n",
      "Step: 9796, Loss: 0.7394887208938599, Accuracy: 0.8125, Computation time: 0.892122745513916\n",
      "Step: 9797, Loss: 0.34631896018981934, Accuracy: 0.9375, Computation time: 1.1367170810699463\n",
      "Step: 9798, Loss: 0.3430481553077698, Accuracy: 0.875, Computation time: 0.9779160022735596\n",
      "Step: 9799, Loss: 0.29491499066352844, Accuracy: 0.9375, Computation time: 0.8378570079803467\n",
      "Step: 9800, Loss: 0.47858089208602905, Accuracy: 0.875, Computation time: 1.408637285232544\n",
      "Step: 9801, Loss: 0.11735239624977112, Accuracy: 0.96875, Computation time: 0.886110782623291\n",
      "Step: 9802, Loss: 0.15107104182243347, Accuracy: 0.96875, Computation time: 0.8596820831298828\n",
      "Step: 9803, Loss: 0.20281890034675598, Accuracy: 0.96875, Computation time: 0.8299930095672607\n",
      "Step: 9804, Loss: 0.23996073007583618, Accuracy: 0.9375, Computation time: 0.7505679130554199\n",
      "Step: 9805, Loss: 0.24466878175735474, Accuracy: 0.90625, Computation time: 0.8674359321594238\n",
      "Step: 9806, Loss: 0.1280004233121872, Accuracy: 0.96875, Computation time: 0.9285910129547119\n",
      "Step: 9807, Loss: 0.6867664456367493, Accuracy: 0.78125, Computation time: 0.9050240516662598\n",
      "Step: 9808, Loss: 0.4396655857563019, Accuracy: 0.84375, Computation time: 0.8600859642028809\n",
      "Step: 9809, Loss: 0.15385738015174866, Accuracy: 0.96875, Computation time: 0.9284071922302246\n",
      "Step: 9810, Loss: 0.3045988976955414, Accuracy: 0.9375, Computation time: 0.8341329097747803\n",
      "Step: 9811, Loss: 0.9311763644218445, Accuracy: 0.75, Computation time: 0.9044299125671387\n",
      "Step: 9812, Loss: 0.41610831022262573, Accuracy: 0.84375, Computation time: 1.6778740882873535\n",
      "Step: 9813, Loss: 0.3945671319961548, Accuracy: 0.90625, Computation time: 0.8184938430786133\n",
      "Step: 9814, Loss: 0.4625318646430969, Accuracy: 0.78125, Computation time: 0.9148271083831787\n",
      "Step: 9815, Loss: 0.5510257482528687, Accuracy: 0.84375, Computation time: 0.8634476661682129\n",
      "Step: 9816, Loss: 0.6082499027252197, Accuracy: 0.84375, Computation time: 0.7559700012207031\n",
      "Step: 9817, Loss: 0.11795869469642639, Accuracy: 1.0, Computation time: 0.8794269561767578\n",
      "Step: 9818, Loss: 0.5363280773162842, Accuracy: 0.84375, Computation time: 1.0681500434875488\n",
      "Step: 9819, Loss: 0.2978547513484955, Accuracy: 0.90625, Computation time: 0.8502631187438965\n",
      "Step: 9820, Loss: 0.6942487359046936, Accuracy: 0.8125, Computation time: 0.8108217716217041\n",
      "Step: 9821, Loss: 0.4254051744937897, Accuracy: 0.875, Computation time: 0.8620059490203857\n",
      "Step: 9822, Loss: 0.4381420612335205, Accuracy: 0.875, Computation time: 1.5516681671142578\n",
      "Step: 9823, Loss: 0.49315792322158813, Accuracy: 0.8125, Computation time: 0.8154270648956299\n",
      "Step: 9824, Loss: 0.3728662431240082, Accuracy: 0.78125, Computation time: 1.0726747512817383\n",
      "Step: 9825, Loss: 0.5490245223045349, Accuracy: 0.8125, Computation time: 0.90578293800354\n",
      "Step: 9826, Loss: 0.30556774139404297, Accuracy: 0.90625, Computation time: 0.7985060214996338\n",
      "Step: 9827, Loss: 1.049617886543274, Accuracy: 0.65625, Computation time: 0.9176511764526367\n",
      "Step: 9828, Loss: 0.24929848313331604, Accuracy: 0.90625, Computation time: 0.9659030437469482\n",
      "Step: 9829, Loss: 0.2661665976047516, Accuracy: 0.9375, Computation time: 0.8200609683990479\n",
      "Step: 9830, Loss: 0.637414813041687, Accuracy: 0.90625, Computation time: 0.9567439556121826\n",
      "Step: 9831, Loss: 0.4934017062187195, Accuracy: 0.8125, Computation time: 0.9575450420379639\n",
      "Step: 9832, Loss: 0.16857916116714478, Accuracy: 0.9375, Computation time: 0.8987209796905518\n",
      "Step: 9833, Loss: 0.5046918988227844, Accuracy: 0.84375, Computation time: 0.8852419853210449\n",
      "Step: 9834, Loss: 0.13151642680168152, Accuracy: 0.96875, Computation time: 0.861536979675293\n",
      "Step: 9835, Loss: 0.24590516090393066, Accuracy: 0.96875, Computation time: 0.7244079113006592\n",
      "Step: 9836, Loss: 0.27226170897483826, Accuracy: 0.9375, Computation time: 0.7906970977783203\n",
      "Step: 9837, Loss: 0.8192269206047058, Accuracy: 0.78125, Computation time: 0.9790668487548828\n",
      "Step: 9838, Loss: 0.2317081093788147, Accuracy: 0.90625, Computation time: 0.9021658897399902\n",
      "Step: 9839, Loss: 0.3288860619068146, Accuracy: 0.9375, Computation time: 0.8295242786407471\n",
      "Step: 9840, Loss: 0.20362870395183563, Accuracy: 0.96875, Computation time: 0.9021360874176025\n",
      "Step: 9841, Loss: 0.6832093000411987, Accuracy: 0.875, Computation time: 1.7602245807647705\n",
      "Step: 9842, Loss: 0.5041074752807617, Accuracy: 0.84375, Computation time: 0.9038548469543457\n",
      "Step: 9843, Loss: 0.29746702313423157, Accuracy: 0.90625, Computation time: 0.960230827331543\n",
      "Step: 9844, Loss: 0.6526417136192322, Accuracy: 0.8125, Computation time: 0.9028048515319824\n",
      "Step: 9845, Loss: 0.3227863609790802, Accuracy: 0.90625, Computation time: 0.9096970558166504\n",
      "Step: 9846, Loss: 0.4356629252433777, Accuracy: 0.90625, Computation time: 0.9289441108703613\n",
      "Step: 9847, Loss: 0.7703177332878113, Accuracy: 0.8125, Computation time: 0.918687105178833\n",
      "Step: 9848, Loss: 0.2883395254611969, Accuracy: 0.90625, Computation time: 1.0501267910003662\n",
      "Step: 9849, Loss: 0.14776158332824707, Accuracy: 0.96875, Computation time: 0.9810340404510498\n",
      "Step: 9850, Loss: 0.6024360656738281, Accuracy: 0.8125, Computation time: 0.9364111423492432\n",
      "Step: 9851, Loss: 0.15146014094352722, Accuracy: 0.96875, Computation time: 0.8425197601318359\n",
      "Step: 9852, Loss: 0.38534387946128845, Accuracy: 0.84375, Computation time: 0.904994010925293\n",
      "Step: 9853, Loss: 0.5568239092826843, Accuracy: 0.84375, Computation time: 0.9665579795837402\n",
      "Step: 9854, Loss: 0.5314170122146606, Accuracy: 0.8125, Computation time: 1.1121160984039307\n",
      "Step: 9855, Loss: 0.2773008346557617, Accuracy: 0.90625, Computation time: 0.9449069499969482\n",
      "Step: 9856, Loss: 0.1511557549238205, Accuracy: 0.9375, Computation time: 0.8042440414428711\n",
      "Step: 9857, Loss: 0.26603198051452637, Accuracy: 0.90625, Computation time: 0.9745919704437256\n",
      "Step: 9858, Loss: 0.35759320855140686, Accuracy: 0.90625, Computation time: 0.9644789695739746\n",
      "Step: 9859, Loss: 0.8250707387924194, Accuracy: 0.78125, Computation time: 0.9800379276275635\n",
      "Step: 9860, Loss: 0.3840053677558899, Accuracy: 0.90625, Computation time: 0.8253588676452637\n",
      "Step: 9861, Loss: 0.6240290403366089, Accuracy: 0.78125, Computation time: 1.5768001079559326\n",
      "Step: 9862, Loss: 0.34912461042404175, Accuracy: 0.90625, Computation time: 1.379746913909912\n",
      "Step: 9863, Loss: 0.435220330953598, Accuracy: 0.90625, Computation time: 0.9144549369812012\n",
      "Step: 9864, Loss: 0.5739283561706543, Accuracy: 0.75, Computation time: 0.843235969543457\n",
      "Step: 9865, Loss: 0.4817337989807129, Accuracy: 0.84375, Computation time: 1.1169579029083252\n",
      "Step: 9866, Loss: 0.3704618513584137, Accuracy: 0.8125, Computation time: 0.9089808464050293\n",
      "Step: 9867, Loss: 0.26093167066574097, Accuracy: 0.90625, Computation time: 0.7754578590393066\n",
      "Step: 9868, Loss: 0.20524506270885468, Accuracy: 0.90625, Computation time: 0.9968738555908203\n",
      "Step: 9869, Loss: 0.592561662197113, Accuracy: 0.84375, Computation time: 1.2819201946258545\n",
      "Step: 9870, Loss: 0.47558578848838806, Accuracy: 0.84375, Computation time: 1.0890040397644043\n",
      "Step: 9871, Loss: 0.4683922529220581, Accuracy: 0.90625, Computation time: 0.8608989715576172\n",
      "Step: 9872, Loss: 0.15492236614227295, Accuracy: 0.96875, Computation time: 0.8147921562194824\n",
      "Step: 9873, Loss: 0.2337474822998047, Accuracy: 0.90625, Computation time: 0.9844076633453369\n",
      "Step: 9874, Loss: 0.6762222051620483, Accuracy: 0.75, Computation time: 0.8309900760650635\n",
      "Step: 9875, Loss: 0.7676776647567749, Accuracy: 0.875, Computation time: 0.8770349025726318\n",
      "Step: 9876, Loss: 0.5313851833343506, Accuracy: 0.90625, Computation time: 0.8045370578765869\n",
      "Step: 9877, Loss: 0.3768557012081146, Accuracy: 0.875, Computation time: 0.9302029609680176\n",
      "Step: 9878, Loss: 0.8126800656318665, Accuracy: 0.71875, Computation time: 0.9777729511260986\n",
      "Step: 9879, Loss: 0.4687189757823944, Accuracy: 0.8125, Computation time: 0.9573488235473633\n",
      "Step: 9880, Loss: 0.623706579208374, Accuracy: 0.8125, Computation time: 0.9771740436553955\n",
      "Step: 9881, Loss: 0.35105377435684204, Accuracy: 0.90625, Computation time: 1.2336211204528809\n",
      "Step: 9882, Loss: 0.5133013129234314, Accuracy: 0.84375, Computation time: 0.9940507411956787\n",
      "Step: 9883, Loss: 0.9777928590774536, Accuracy: 0.65625, Computation time: 0.994251012802124\n",
      "Step: 9884, Loss: 0.3707970678806305, Accuracy: 0.875, Computation time: 0.9536840915679932\n",
      "Step: 9885, Loss: 0.5992352366447449, Accuracy: 0.875, Computation time: 0.8439738750457764\n",
      "Step: 9886, Loss: 0.9170713424682617, Accuracy: 0.71875, Computation time: 1.022247076034546\n",
      "Step: 9887, Loss: 0.7645524144172668, Accuracy: 0.875, Computation time: 0.8323819637298584\n",
      "Step: 9888, Loss: 1.0671063661575317, Accuracy: 0.84375, Computation time: 0.8613440990447998\n",
      "Step: 9889, Loss: 0.3401942551136017, Accuracy: 0.90625, Computation time: 0.8368868827819824\n",
      "Step: 9890, Loss: 0.3257892429828644, Accuracy: 0.90625, Computation time: 0.9425361156463623\n",
      "Step: 9891, Loss: 0.6128746867179871, Accuracy: 0.8125, Computation time: 0.8352789878845215\n",
      "Step: 9892, Loss: 0.4250733256340027, Accuracy: 0.84375, Computation time: 0.846750020980835\n",
      "Step: 9893, Loss: 0.7772572636604309, Accuracy: 0.75, Computation time: 0.9201581478118896\n",
      "Step: 9894, Loss: 0.4994804859161377, Accuracy: 0.84375, Computation time: 0.8278779983520508\n",
      "Step: 9895, Loss: 0.3032147288322449, Accuracy: 0.9375, Computation time: 0.9224638938903809\n",
      "Step: 9896, Loss: 0.4484313428401947, Accuracy: 0.8125, Computation time: 1.0875592231750488\n",
      "Step: 9897, Loss: 0.38916030526161194, Accuracy: 0.90625, Computation time: 1.388166904449463\n",
      "Step: 9898, Loss: 0.48537200689315796, Accuracy: 0.84375, Computation time: 1.1256308555603027\n",
      "Step: 9899, Loss: 0.9124675989151001, Accuracy: 0.78125, Computation time: 0.876835823059082\n",
      "Step: 9900, Loss: 0.8411552906036377, Accuracy: 0.78125, Computation time: 1.1102190017700195\n",
      "Step: 9901, Loss: 0.381497323513031, Accuracy: 0.875, Computation time: 0.8439910411834717\n",
      "Step: 9902, Loss: 0.10185020416975021, Accuracy: 1.0, Computation time: 0.7929110527038574\n",
      "Step: 9903, Loss: 0.41138869524002075, Accuracy: 0.84375, Computation time: 0.9852948188781738\n",
      "Step: 9904, Loss: 0.4419217109680176, Accuracy: 0.84375, Computation time: 0.9989440441131592\n",
      "Step: 9905, Loss: 0.6370455622673035, Accuracy: 0.78125, Computation time: 0.7839879989624023\n",
      "Step: 9906, Loss: 0.2836241126060486, Accuracy: 0.96875, Computation time: 0.7842178344726562\n",
      "Step: 9907, Loss: 0.41845589876174927, Accuracy: 0.90625, Computation time: 0.8345637321472168\n",
      "Step: 9908, Loss: 0.3929760456085205, Accuracy: 0.90625, Computation time: 0.8624708652496338\n",
      "Step: 9909, Loss: 0.44491615891456604, Accuracy: 0.875, Computation time: 0.8242549896240234\n",
      "Step: 9910, Loss: 0.6652176380157471, Accuracy: 0.84375, Computation time: 0.8282663822174072\n",
      "Step: 9911, Loss: 0.4985560476779938, Accuracy: 0.84375, Computation time: 0.851128101348877\n",
      "Step: 9912, Loss: 0.7696940898895264, Accuracy: 0.78125, Computation time: 0.8407459259033203\n",
      "Step: 9913, Loss: 0.37489980459213257, Accuracy: 0.90625, Computation time: 0.906627893447876\n",
      "Step: 9914, Loss: 0.6129164695739746, Accuracy: 0.78125, Computation time: 0.8191418647766113\n",
      "Step: 9915, Loss: 0.4169318675994873, Accuracy: 0.90625, Computation time: 1.065765142440796\n",
      "Step: 9916, Loss: 0.17482849955558777, Accuracy: 0.9375, Computation time: 0.8045458793640137\n",
      "Step: 9917, Loss: 0.13680985569953918, Accuracy: 0.96875, Computation time: 0.755424976348877\n",
      "Step: 9918, Loss: 0.34530386328697205, Accuracy: 0.9375, Computation time: 0.6842191219329834\n",
      "Step: 9919, Loss: 0.19092512130737305, Accuracy: 0.9375, Computation time: 0.8273649215698242\n",
      "Step: 9920, Loss: 0.3957933187484741, Accuracy: 0.875, Computation time: 0.8854830265045166\n",
      "Step: 9921, Loss: 0.33599337935447693, Accuracy: 0.875, Computation time: 0.8412959575653076\n",
      "Step: 9922, Loss: 0.3484397232532501, Accuracy: 0.90625, Computation time: 0.9214580059051514\n",
      "Step: 9923, Loss: 0.4785766303539276, Accuracy: 0.875, Computation time: 0.9362599849700928\n",
      "Step: 9924, Loss: 0.4507201015949249, Accuracy: 0.8125, Computation time: 1.0701508522033691\n",
      "Step: 9925, Loss: 0.2382972091436386, Accuracy: 0.96875, Computation time: 0.8455963134765625\n",
      "Step: 9926, Loss: 0.37788155674934387, Accuracy: 0.875, Computation time: 0.8254549503326416\n",
      "Step: 9927, Loss: 0.32421034574508667, Accuracy: 0.84375, Computation time: 1.0096321105957031\n",
      "Step: 9928, Loss: 0.4173436462879181, Accuracy: 0.84375, Computation time: 1.063270092010498\n",
      "Step: 9929, Loss: 0.7195457816123962, Accuracy: 0.8125, Computation time: 0.8656647205352783\n",
      "Step: 9930, Loss: 0.7217817306518555, Accuracy: 0.78125, Computation time: 0.9014389514923096\n",
      "Step: 9931, Loss: 0.4545953571796417, Accuracy: 0.84375, Computation time: 0.9821209907531738\n",
      "Step: 9932, Loss: 0.37313586473464966, Accuracy: 0.875, Computation time: 0.8686151504516602\n",
      "Step: 9933, Loss: 0.14253059029579163, Accuracy: 0.9375, Computation time: 0.8360209465026855\n",
      "Step: 9934, Loss: 0.6665722727775574, Accuracy: 0.78125, Computation time: 0.9525339603424072\n",
      "Step: 9935, Loss: 0.16898173093795776, Accuracy: 0.9375, Computation time: 0.9788119792938232\n",
      "Step: 9936, Loss: 0.1872723251581192, Accuracy: 0.96875, Computation time: 1.020219087600708\n",
      "Step: 9937, Loss: 0.3760538101196289, Accuracy: 0.90625, Computation time: 0.99452805519104\n",
      "Step: 9938, Loss: 0.30115368962287903, Accuracy: 0.9375, Computation time: 0.8735649585723877\n",
      "Step: 9939, Loss: 0.3553140163421631, Accuracy: 0.90625, Computation time: 0.7830369472503662\n",
      "Step: 9940, Loss: 0.2141944169998169, Accuracy: 0.9375, Computation time: 1.102705955505371\n",
      "Step: 9941, Loss: 0.7325359582901001, Accuracy: 0.78125, Computation time: 0.8325071334838867\n",
      "Step: 9942, Loss: 0.5761680603027344, Accuracy: 0.84375, Computation time: 1.1419739723205566\n",
      "Step: 9943, Loss: 0.28515392541885376, Accuracy: 0.90625, Computation time: 0.8987200260162354\n",
      "Step: 9944, Loss: 0.580660343170166, Accuracy: 0.84375, Computation time: 0.8684689998626709\n",
      "Step: 9945, Loss: 0.42044180631637573, Accuracy: 0.8125, Computation time: 0.8414437770843506\n",
      "Step: 9946, Loss: 0.5222863554954529, Accuracy: 0.875, Computation time: 0.9639301300048828\n",
      "Step: 9947, Loss: 0.38752228021621704, Accuracy: 0.9375, Computation time: 1.002492904663086\n",
      "Step: 9948, Loss: 0.41430824995040894, Accuracy: 0.9375, Computation time: 0.8658289909362793\n",
      "Step: 9949, Loss: 0.3440838158130646, Accuracy: 0.875, Computation time: 0.8953499794006348\n",
      "Step: 9950, Loss: 0.3718079924583435, Accuracy: 0.875, Computation time: 0.8787381649017334\n",
      "Step: 9951, Loss: 0.5726385712623596, Accuracy: 0.8125, Computation time: 0.9481301307678223\n",
      "Step: 9952, Loss: 0.4700618386268616, Accuracy: 0.84375, Computation time: 0.8553998470306396\n",
      "Step: 9953, Loss: 0.7097697257995605, Accuracy: 0.75, Computation time: 0.8644647598266602\n",
      "Step: 9954, Loss: 0.5976185202598572, Accuracy: 0.78125, Computation time: 0.8490087985992432\n",
      "Step: 9955, Loss: 0.39141640067100525, Accuracy: 0.84375, Computation time: 1.0498292446136475\n",
      "Step: 9956, Loss: 0.3560391664505005, Accuracy: 0.90625, Computation time: 1.5156927108764648\n",
      "Step: 9957, Loss: 0.6309254765510559, Accuracy: 0.84375, Computation time: 0.9845681190490723\n",
      "Step: 9958, Loss: 0.2917994260787964, Accuracy: 0.90625, Computation time: 0.8851191997528076\n",
      "Step: 9959, Loss: 0.33529165387153625, Accuracy: 0.84375, Computation time: 0.9602010250091553\n",
      "Step: 9960, Loss: 0.4487435817718506, Accuracy: 0.8125, Computation time: 0.8694882392883301\n",
      "Step: 9961, Loss: 0.43003425002098083, Accuracy: 0.875, Computation time: 1.1038682460784912\n",
      "Step: 9962, Loss: 0.19129709899425507, Accuracy: 0.90625, Computation time: 0.9841248989105225\n",
      "Step: 9963, Loss: 0.5472581386566162, Accuracy: 0.875, Computation time: 0.9477901458740234\n",
      "Step: 9964, Loss: 0.21567057073116302, Accuracy: 0.96875, Computation time: 0.8925430774688721\n",
      "Step: 9965, Loss: 0.21266262233257294, Accuracy: 0.96875, Computation time: 0.8741707801818848\n",
      "Step: 9966, Loss: 0.4540224075317383, Accuracy: 0.90625, Computation time: 0.9126901626586914\n",
      "Step: 9967, Loss: 0.24015459418296814, Accuracy: 0.96875, Computation time: 1.0625250339508057\n",
      "Step: 9968, Loss: 0.4621850848197937, Accuracy: 0.90625, Computation time: 0.8917078971862793\n",
      "Step: 9969, Loss: 0.43951666355133057, Accuracy: 0.875, Computation time: 0.7417080402374268\n",
      "Step: 9970, Loss: 0.48970478773117065, Accuracy: 0.8125, Computation time: 0.8167109489440918\n",
      "Step: 9971, Loss: 0.4944545030593872, Accuracy: 0.84375, Computation time: 1.0953681468963623\n",
      "Step: 9972, Loss: 0.6276231408119202, Accuracy: 0.78125, Computation time: 1.4051177501678467\n",
      "Step: 9973, Loss: 0.6421483159065247, Accuracy: 0.78125, Computation time: 1.0580189228057861\n",
      "Step: 9974, Loss: 0.5275713205337524, Accuracy: 0.84375, Computation time: 0.7911801338195801\n",
      "Step: 9975, Loss: 0.3802608847618103, Accuracy: 0.90625, Computation time: 1.0216031074523926\n",
      "Step: 9976, Loss: 0.6730159521102905, Accuracy: 0.8125, Computation time: 1.098433017730713\n",
      "Step: 9977, Loss: 0.2963770627975464, Accuracy: 0.875, Computation time: 0.749251127243042\n",
      "Step: 9978, Loss: 0.18451452255249023, Accuracy: 0.9375, Computation time: 0.9669287204742432\n",
      "Step: 9979, Loss: 0.44671952724456787, Accuracy: 0.90625, Computation time: 0.9571018218994141\n",
      "Step: 9980, Loss: 0.4164547026157379, Accuracy: 0.90625, Computation time: 0.9108717441558838\n",
      "Step: 9981, Loss: 0.5393156409263611, Accuracy: 0.875, Computation time: 0.94638991355896\n",
      "Step: 9982, Loss: 0.2812112271785736, Accuracy: 0.90625, Computation time: 0.8237671852111816\n",
      "Step: 9983, Loss: 0.6754565238952637, Accuracy: 0.78125, Computation time: 1.498023271560669\n",
      "Step: 9984, Loss: 0.30941516160964966, Accuracy: 0.90625, Computation time: 1.7436919212341309\n",
      "Step: 9985, Loss: 0.3159734904766083, Accuracy: 0.90625, Computation time: 1.0385730266571045\n",
      "Step: 9986, Loss: 0.5618324279785156, Accuracy: 0.84375, Computation time: 0.8222768306732178\n",
      "Step: 9987, Loss: 0.5703780055046082, Accuracy: 0.84375, Computation time: 1.0080201625823975\n",
      "Step: 9988, Loss: 0.1437307596206665, Accuracy: 0.9375, Computation time: 0.7553369998931885\n",
      "Step: 9989, Loss: 0.0846463069319725, Accuracy: 1.0, Computation time: 0.9341287612915039\n",
      "Step: 9990, Loss: 0.4775490164756775, Accuracy: 0.875, Computation time: 0.8654699325561523\n",
      "Step: 9991, Loss: 0.30466586351394653, Accuracy: 0.96875, Computation time: 0.9791920185089111\n",
      "Step: 9992, Loss: 0.4616325795650482, Accuracy: 0.8125, Computation time: 0.8156530857086182\n",
      "Step: 9993, Loss: 0.7977052330970764, Accuracy: 0.78125, Computation time: 0.7857542037963867\n",
      "Step: 9994, Loss: 0.3806478977203369, Accuracy: 0.90625, Computation time: 1.0285711288452148\n",
      "Step: 9995, Loss: 0.18324314057826996, Accuracy: 0.9375, Computation time: 0.90212082862854\n",
      "Step: 9996, Loss: 0.372478723526001, Accuracy: 0.875, Computation time: 0.9943652153015137\n",
      "Step: 9997, Loss: 0.9151981472969055, Accuracy: 0.84375, Computation time: 1.0458250045776367\n",
      "Step: 9998, Loss: 0.37753206491470337, Accuracy: 0.90625, Computation time: 0.9298722743988037\n",
      "Step: 9999, Loss: 0.18556080758571625, Accuracy: 0.90625, Computation time: 0.9090089797973633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 10000/10000 [05:59<00:00, 27.85it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af351f5730434c7b995a68cbf8b87601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5493088960647583, Test Accuracy: 0.8355000019073486, Computation time: 0.008337065577507019\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61d1adc-1024-4119-ad69-05e8d4446a89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
